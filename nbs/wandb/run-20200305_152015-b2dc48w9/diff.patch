diff --git a/.gitignore b/.gitignore
deleted file mode 100644
index 9ca0988..0000000
--- a/.gitignore
+++ /dev/null
@@ -1,141 +0,0 @@
-*.bak
-.gitattributes
-.last_checked
-.gitconfig
-*.bak
-*.log
-*~
-~*
-_tmp*
-tmp*
-tags
-
-# Byte-compiled / optimized / DLL files
-__pycache__/
-*.py[cod]
-*$py.class
-
-# C extensions
-*.so
-
-# Distribution / packaging
-.Python
-env/
-build/
-develop-eggs/
-dist/
-downloads/
-eggs/
-.eggs/
-lib/
-lib64/
-parts/
-sdist/
-var/
-wheels/
-*.egg-info/
-.installed.cfg
-*.egg
-
-# PyInstaller
-#  Usually these files are written by a python script from a template
-#  before PyInstaller builds the exe, so as to inject date/other infos into it.
-*.manifest
-*.spec
-
-# Installer logs
-pip-log.txt
-pip-delete-this-directory.txt
-
-# Unit test / coverage reports
-htmlcov/
-.tox/
-.coverage
-.coverage.*
-.cache
-nosetests.xml
-coverage.xml
-*.cover
-.hypothesis/
-
-# Translations
-*.mo
-*.pot
-
-# Django stuff:
-*.log
-local_settings.py
-
-# Flask stuff:
-instance/
-.webassets-cache
-
-# Scrapy stuff:
-.scrapy
-
-# Sphinx documentation
-docs/_build/
-
-# PyBuilder
-target/
-
-# Jupyter Notebook
-.ipynb_checkpoints
-
-# pyenv
-.python-version
-
-# celery beat schedule file
-celerybeat-schedule
-
-# SageMath parsed files
-*.sage.py
-
-# dotenv
-.env
-
-# virtualenv
-.venv
-venv/
-ENV/
-
-# Spyder project settings
-.spyderproject
-.spyproject
-
-# Rope project settings
-.ropeproject
-
-# mkdocs documentation
-/site
-
-# mypy
-.mypy_cache/
-
-.vscode
-*.swp
-
-# osx generated files
-.DS_Store
-.DS_Store?
-.Trashes
-ehthumbs.db
-Thumbs.db
-.idea
-
-# pytest
-.pytest_cache
-
-# tools/trust-doc-nbs
-docs_src/.last_checked
-
-# symlinks to fastai
-docs_src/fastai
-tools/fastai
-
-# link checker
-checklink/cookies.txt
-
-# .gitconfig is now autogenerated
-.gitconfig
-
diff --git a/.ipynb_checkpoints/Dockerfile-checkpoint b/.ipynb_checkpoints/Dockerfile-checkpoint
new file mode 100644
index 0000000..79bd0fd
--- /dev/null
+++ b/.ipynb_checkpoints/Dockerfile-checkpoint
@@ -0,0 +1,54 @@
+FROM jupyter/datascience-notebook
+
+# NECCESARY FOR RUNNING R CODE
+#RUN apt-get -qq update
+#RUN apt-get install -y software-properties-common
+#RUN apt-get install -y libxml2-dev
+#RUN apt-get install -y r-base
+
+# PYTHON PACKAGES
+RUN pip install nbdev
+RUN pip install umap-learn
+RUN pip install fastcore
+RUN pip install jupyter_contrib_nbextensions
+RUN pip install tqdm
+RUN pip install keras
+RUN pip install tensorflow
+RUN pip install voila
+RUN pip install bqplot
+RUN pip install ipyvuetify
+RUN pip install ipympl
+RUN pip install voila-vuetify
+RUN pip install papermill
+RUN pip install --upgrade wandb
+
+# R PACKAGES
+RUN Rscript -e "install.packages(c('xts'), repo = 'http://cran.rstudio.com/')"
+
+# user id for jupyter
+ARG user_id=1000
+
+USER root
+
+# CHANGE THE USER AND GROUP OF JOVYAN
+RUN usermod -u $user_id jovyan
+#RUN groupmod -g $user_id jovyan
+
+USER jovyan
+
+WORKDIR /home/jovyan
+
+# MAKE DEFAULT CONFIG
+# RUN jupyter notebook --generate-config
+RUN mkdir data
+
+# Install Jupyter extensions
+RUN jupyter contrib nbextension install --user
+RUN jupyter nbextensions_configurator enable --user
+RUN jupyter nbextension enable collapsible_headings/main --user
+
+# Enable juyterlab extensions
+RUN pip install --upgrade jupyterlab-git
+RUN jupyter lab build
+RUN jupyter labextension install @jupyter-voila/jupyterlab-preview
+
diff --git a/00_core.ipynb b/00_core.ipynb
deleted file mode 100644
index 6c17de9..0000000
--- a/00_core.ipynb
+++ /dev/null
@@ -1,48 +0,0 @@
-{
- "cells": [
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "# default_exp core"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "# module name here\n",
-    "\n",
-    "> API details."
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "#hide\n",
-    "from nbdev.showdoc import *"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "metadata": {},
-   "outputs": [],
-   "source": []
-  }
- ],
- "metadata": {
-  "kernelspec": {
-   "display_name": "Python 3",
-   "language": "python",
-   "name": "python3"
-  }
- },
- "nbformat": 4,
- "nbformat_minor": 2
-}
diff --git a/Dockerfile b/Dockerfile
new file mode 100644
index 0000000..79bd0fd
--- /dev/null
+++ b/Dockerfile
@@ -0,0 +1,54 @@
+FROM jupyter/datascience-notebook
+
+# NECCESARY FOR RUNNING R CODE
+#RUN apt-get -qq update
+#RUN apt-get install -y software-properties-common
+#RUN apt-get install -y libxml2-dev
+#RUN apt-get install -y r-base
+
+# PYTHON PACKAGES
+RUN pip install nbdev
+RUN pip install umap-learn
+RUN pip install fastcore
+RUN pip install jupyter_contrib_nbextensions
+RUN pip install tqdm
+RUN pip install keras
+RUN pip install tensorflow
+RUN pip install voila
+RUN pip install bqplot
+RUN pip install ipyvuetify
+RUN pip install ipympl
+RUN pip install voila-vuetify
+RUN pip install papermill
+RUN pip install --upgrade wandb
+
+# R PACKAGES
+RUN Rscript -e "install.packages(c('xts'), repo = 'http://cran.rstudio.com/')"
+
+# user id for jupyter
+ARG user_id=1000
+
+USER root
+
+# CHANGE THE USER AND GROUP OF JOVYAN
+RUN usermod -u $user_id jovyan
+#RUN groupmod -g $user_id jovyan
+
+USER jovyan
+
+WORKDIR /home/jovyan
+
+# MAKE DEFAULT CONFIG
+# RUN jupyter notebook --generate-config
+RUN mkdir data
+
+# Install Jupyter extensions
+RUN jupyter contrib nbextension install --user
+RUN jupyter nbextensions_configurator enable --user
+RUN jupyter nbextension enable collapsible_headings/main --user
+
+# Enable juyterlab extensions
+RUN pip install --upgrade jupyterlab-git
+RUN jupyter lab build
+RUN jupyter labextension install @jupyter-voila/jupyterlab-preview
+
diff --git a/Makefile b/Makefile
new file mode 100644
index 0000000..d39bb6d
--- /dev/null
+++ b/Makefile
@@ -0,0 +1,29 @@
+SRC = $(wildcard ./*.ipynb)
+
+all: pacmel_mining_use_case docs
+
+pacmel_mining_use_case: $(SRC)
+	nbdev_build_lib
+	touch pacmel_mining_use_case
+
+docs_serve: docs
+	cd docs && bundle exec jekyll serve
+
+docs: $(SRC)
+	nbdev_build_docs
+	touch docs
+
+test:
+	nbdev_test_nbs
+
+release: pypi
+	nbdev_bump_version
+
+pypi: dist
+	twine upload --repository pypi dist/*
+
+dist: clean
+	python setup.py sdist bdist_wheel
+
+clean:
+	rm -rf dist
\ No newline at end of file
diff --git a/docker-compose.yml b/docker-compose.yml
new file mode 100644
index 0000000..39d2a94
--- /dev/null
+++ b/docker-compose.yml
@@ -0,0 +1,24 @@
+version: "3"
+services:
+  notebook:
+    build:
+      context: ./
+      dockerfile: Dockerfile
+      args:
+        user_id: 1005
+    entrypoint: /bin/bash /home/jovyan/work/start-notebook.sh
+    environment:
+      - JUPYTER_ENABLE_LAB=yes
+    volumes:
+      - ./:/home/jovyan/work
+      - ~/.gitconfig:/etc/gitconfig
+    ports:
+      - "7878:8888" # Jupyter
+      - "8866:8866" # Voila
+    expose:
+      - "8888"
+      - "8866"
+    deploy:
+      replicas: 1
+      restart_policy:
+        condition: on-failure
diff --git a/docs/_config.yml b/docs/_config.yml
new file mode 100644
index 0000000..174b000
--- /dev/null
+++ b/docs/_config.yml
@@ -0,0 +1,64 @@
+repository: vrodriguezf/pacmel_mining_use_case
+output: web
+topnav_title: pacmel_mining_use_case
+site_title: pacmel_mining_use_case
+company_name: AGH University of Science and Technology
+description: Experiments related to the mining use case within the PACMEL project
+# Set to false to disable KaTeX math
+use_math: true
+# Add Google analytics id if you have one and want to use it here
+google_analytics:
+# See http://nbdev.fast.ai/search for help with adding Search
+google_search:
+
+host: 127.0.0.1
+# the preview server used. Leave as is.
+port: 4000
+# the port where the preview is rendered.
+
+exclude:
+  - .idea/
+  - .gitignore
+  - vendor
+ 
+exclude: [vendor]
+
+highlighter: rouge
+markdown: kramdown
+kramdown:
+ input: GFM
+ auto_ids: true
+ hard_wrap: false
+ syntax_highlighter: rouge
+
+collections:
+  tooltips:
+    output: false
+
+defaults:
+  -
+    scope:
+      path: ""
+      type: "pages"
+    values:
+      layout: "page"
+      comments: true
+      search: true
+      sidebar: home_sidebar
+      topnav: topnav
+  -
+    scope:
+      path: ""
+      type: "tooltips"
+    values:
+      layout: "page"
+      comments: true
+      search: true
+      tooltip: true
+
+sidebars:
+- home_sidebar
+permalink: pretty
+
+theme: jekyll-theme-cayman
+baseurl: /pacmel_mining_use_case/
\ No newline at end of file
diff --git a/docs/_data/topnav.yml b/docs/_data/topnav.yml
new file mode 100644
index 0000000..fbbff08
--- /dev/null
+++ b/docs/_data/topnav.yml
@@ -0,0 +1,10 @@
+topnav:
+- title: Topnav
+  items:
+    - title: GitHub
+      external_url: https://github.com/vrodriguezf/pacmel_mining_use_case
+
+#Topnav dropdowns
+topnav_dropdowns:
+- title: Topnav dropdowns
+  folders:
\ No newline at end of file
diff --git a/pacmel_mining_use_case/.ipynb_checkpoints/__init__.py b/pacmel_mining_use_case/.ipynb_checkpoints/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/pacmel_mining_use_case/.ipynb_checkpoints/core-checkpoint.py b/pacmel_mining_use_case/.ipynb_checkpoints/core-checkpoint.py
new file mode 100644
index 0000000..3d542c9
--- /dev/null
+++ b/pacmel_mining_use_case/.ipynb_checkpoints/core-checkpoint.py
@@ -0,0 +1,3 @@
+# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_core.ipynb (unless otherwise specified).
+
+__all__ = []
\ No newline at end of file
diff --git a/pacmel_mining_use_case/.ipynb_checkpoints/timecluster-checkpoint.py b/pacmel_mining_use_case/.ipynb_checkpoints/timecluster-checkpoint.py
new file mode 100644
index 0000000..ecf476e
--- /dev/null
+++ b/pacmel_mining_use_case/.ipynb_checkpoints/timecluster-checkpoint.py
@@ -0,0 +1,55 @@
+# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/Timecluster_high_dimensional_data.ipynb (unless otherwise specified).
+
+__all__ = ['fslicer', 'createDCAE', 'slices2array']
+
+# Cell
+import pandas as pd
+import seaborn as sns
+import numpy as np
+from fastcore import test
+from keras.models import Sequential, Model
+from keras.layers import Dense, Flatten, Conv1D, MaxPool1D, Reshape, UpSampling1D
+import tensorflow as tf
+from tqdm import tqdm
+import umap
+import matplotlib.pyplot as plt
+import seaborn as sns
+
+# Cell
+def fslicer(df, w, s=1, padding=0):
+    "Transform a numeric dataframe `df` into slices (sub-dataframes) of `w` rows and the same number of columns than the \
+    original dataframe. The distance between each slice is given by the stride `s`. The last slices which have \
+    less than `w` points are filled with the value marked in the argument `padding`"
+    aux = [df.iloc[x:x+w] for x in range(0,len(df), s)]
+    with_padding = [x.append(pd.DataFrame(np.full((w - len(x), len(df.columns)), padding), columns=df.columns.values)) if len(x) < w else x for x in aux]
+    return with_padding
+
+# Cell
+def createDCAE(w, d, delta):
+    "Create a Deep Convolutional Autoencoder for multivariate time series of `d` dimensions, \
+    sliced with a window size of `w`. The parameter `delta` sets the number of latent features that will be \
+    contained in the Dense layer of the network."
+    model = Sequential()
+    model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=(w,d), padding='same'))
+    model.add(MaxPool1D(pool_size=2))
+    model.add(Conv1D(filters=32, kernel_size=5, activation='relu', padding='same'))
+    model.add(MaxPool1D(pool_size=2))
+    model.add(Conv1D(filters=12, kernel_size=5, activation='relu', padding='same'))
+    model.add(MaxPool1D(pool_size=3))
+    aux_shape = model.output_shape[1:]
+    model.add(Flatten())
+    model.add(Dense(units=delta, activation='linear', name='latent_features'))
+    model.add(Reshape(target_shape=aux_shape))
+    model.add(Conv1D(filters=12, kernel_size=5, activation='relu', padding='same'))
+    model.add(UpSampling1D(size=3))
+    model.add(Conv1D(filters=32, kernel_size=5, activation='relu', padding='same'))
+    model.add(UpSampling1D(size=2))
+    model.add(Conv1D(filters=64, kernel_size=10, activation='relu', padding='same'))
+    model.add(UpSampling1D(size=2))
+    model.add(Conv1D(filters=d, kernel_size=10, activation='linear', padding='same'))
+    return model
+
+# Cell
+def slices2array(slices):
+    "`slices` is a list of dataframes, each of them containing an slice of a multivariate time series."
+    return np.rollaxis(np.dstack([x.values for x in slices]), -1)
\ No newline at end of file
diff --git a/pacmel_mining_use_case/__init__.py b/pacmel_mining_use_case/__init__.py
new file mode 100644
index 0000000..f102a9c
--- /dev/null
+++ b/pacmel_mining_use_case/__init__.py
@@ -0,0 +1 @@
+__version__ = "0.0.1"
diff --git a/pacmel_mining_use_case/__pycache__/_nbdev.cpython-37.pyc b/pacmel_mining_use_case/__pycache__/_nbdev.cpython-37.pyc
new file mode 100644
index 0000000..7c4d45c
Binary files /dev/null and b/pacmel_mining_use_case/__pycache__/_nbdev.cpython-37.pyc differ
diff --git a/pacmel_mining_use_case/_nbdev.py b/pacmel_mining_use_case/_nbdev.py
new file mode 100644
index 0000000..49614db
--- /dev/null
+++ b/pacmel_mining_use_case/_nbdev.py
@@ -0,0 +1,17 @@
+# AUTOGENERATED BY NBDEV! DO NOT EDIT!
+
+__all__ = ["index", "modules", "custom_doc_links", "git_url"]
+
+index = {"load_numeric_vars": "00_load.ipynb",
+         "fslicer": "01_Timecluster_replication.ipynb",
+         "createDCAE": "01_Timecluster_replication.ipynb",
+         "slices2array": "01_Timecluster_replication.ipynb"}
+
+modules = ["load.py",
+           "timecluster.py"]
+
+doc_url = "https://vrodriguezf.github.io/pacmel_mining_use_case/"
+
+git_url = "https://github.com/vrodriguezf/pacmel_mining_use_case/tree/master/"
+
+def custom_doc_links(name): return None
diff --git a/pacmel_mining_use_case/core.py b/pacmel_mining_use_case/core.py
new file mode 100644
index 0000000..3d542c9
--- /dev/null
+++ b/pacmel_mining_use_case/core.py
@@ -0,0 +1,3 @@
+# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_core.ipynb (unless otherwise specified).
+
+__all__ = []
\ No newline at end of file
diff --git a/pacmel_mining_use_case/timecluster.py b/pacmel_mining_use_case/timecluster.py
new file mode 100644
index 0000000..16362c4
--- /dev/null
+++ b/pacmel_mining_use_case/timecluster.py
@@ -0,0 +1,51 @@
+# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_Timecluster_replication.ipynb (unless otherwise specified).
+
+__all__ = ['fslicer', 'createDCAE', 'slices2array']
+
+# Cell
+import pandas as pd
+import seaborn as sns
+import numpy as np
+from keras.models import Sequential, Model
+from keras.layers import Dense, Flatten, Conv1D, MaxPool1D, Reshape, UpSampling1D
+import tensorflow as tf
+import umap
+
+# Cell
+def fslicer(df, w, s=1, padding=0):
+    "Transform a numeric dataframe `df` into slices (sub-dataframes) of `w` rows and the same number of columns than the \
+    original dataframe. The distance between each slice is given by the stride `s`. The last slices which have \
+    less than `w` points are filled with the value marked in the argument `padding`"
+    aux = [df.iloc[x:x+w] for x in range(0,len(df), s)]
+    with_padding = [x.append(pd.DataFrame(np.full((w - len(x), len(df.columns)), padding), columns=df.columns.values)) if len(x) < w else x for x in aux]
+    return with_padding
+
+# Cell
+def createDCAE(w, d, delta):
+    "Create a Deep Convolutional Autoencoder for multivariate time series of `d` dimensions, \
+    sliced with a window size of `w`. The parameter `delta` sets the number of latent features that will be \
+    contained in the Dense layer of the network."
+    model = Sequential()
+    model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=(w,d), padding='same'))
+    model.add(MaxPool1D(pool_size=2))
+    model.add(Conv1D(filters=32, kernel_size=5, activation='relu', padding='same'))
+    model.add(MaxPool1D(pool_size=2))
+    model.add(Conv1D(filters=12, kernel_size=5, activation='relu', padding='same'))
+    model.add(MaxPool1D(pool_size=3))
+    aux_shape = model.output_shape[1:]
+    model.add(Flatten())
+    model.add(Dense(units=delta, activation='linear', name='latent_features'))
+    model.add(Reshape(target_shape=aux_shape))
+    model.add(Conv1D(filters=12, kernel_size=5, activation='relu', padding='same'))
+    model.add(UpSampling1D(size=3))
+    model.add(Conv1D(filters=32, kernel_size=5, activation='relu', padding='same'))
+    model.add(UpSampling1D(size=2))
+    model.add(Conv1D(filters=64, kernel_size=10, activation='relu', padding='same'))
+    model.add(UpSampling1D(size=2))
+    model.add(Conv1D(filters=d, kernel_size=10, activation='linear', padding='same'))
+    return model
+
+# Cell
+def slices2array(slices):
+    "`slices` is a list of dataframes, each of them containing an slice of a multivariate time series."
+    return np.rollaxis(np.dstack([x.values for x in slices]), -1)
\ No newline at end of file
diff --git a/settings.ini b/settings.ini
index f2dddad..524c17b 100644
--- a/settings.ini
+++ b/settings.ini
@@ -1,12 +1,12 @@
 [DEFAULT]
 # All sections below are required unless otherwise specified
-lib_name = nbdev_template
-user = fastai
-# description = A description of your project
-# keywords = some keywords
-# author = Your Name
-# author_email = email@example.com
-# copyright = Your Name or Company Name
+lib_name = pacmel_mining_use_case
+user = vrodriguezf
+description = Experiments related to the mining use case within the PACMEL project
+keywords = pacmel time-series machine-learning
+author = Victor Rodriguez-Fernandez
+author_email = victor.rodriguezf@uam.es
+copyright = AGH University of Science and Technology
 branch = master
 version = 0.0.1
 min_python = 3.6
@@ -20,7 +20,7 @@ license = apache2
 status = 2
 
 # Optional. Same format as setuptools requirements
-# requirements = 
+requirements = umap-learn fastcore tqdm keras tensorflow voila bqplot ipyvuetify ipympl
 # Optional. Same format as setuptools console_scripts
 # console_scripts = 
 
@@ -30,7 +30,7 @@ status = 2
 ###
 
 # Change to, e.g. "nbs", to put your notebooks in nbs dir instead of repo root
-nbs_path = .
+nbs_path = nbs
 doc_path = docs
 
 # Anything shown as '%(...)s' is substituted with that setting automatically
diff --git a/start-notebook.sh b/start-notebook.sh
new file mode 100644
index 0000000..926ea76
--- /dev/null
+++ b/start-notebook.sh
@@ -0,0 +1 @@
+jupyter notebook --ip=0.0.0.0 --no-browser --allow-root
