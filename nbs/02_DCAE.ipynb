{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dcae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCAE: Deep Convolutional Autoencoder\n",
    "\n",
    "> This notebook tries to apply the ideas of the paper [TimeCluster](https://link.springer.com/article/10.1007/s00371-019-01673-y),\n",
    "with regard to the application of DCAEs for compressing multivariate time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastcore import test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPool1D, Reshape, UpSampling1D, InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from pacmel_mining_use_case.load import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from yaml import load, FullLoader\n",
    "from fastcore.utils import Path\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the experiment tracking and hyperparameter we will use the tool **Weights & Biases**. The actual version of the library that we are using can be installed via `\n",
    "pip install https://github.com/wandb/client/archive/artifacts/next.zip`. It contains features that are not part of the public release version, such as the management of artifacts for things like dataset versioning.\n",
    "\n",
    "Before running this notebook, make sure you run in a terminal `wandb login [API_KEY]`. You can see your API_KEY in the settings of your wandb account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/vrodriguezf/timecluster-extension\" target=\"_blank\">https://app.wandb.ai/vrodriguezf/timecluster-extension</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/vrodriguezf/timecluster-extension/runs/36ax1g3b\" target=\"_blank\">https://app.wandb.ai/vrodriguezf/timecluster-extension/runs/36ax1g3b</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "run_dcae = wandb.init(project=\"timecluster-extension\",\n",
    "                      job_type='train_DCAE',\n",
    "                      allow_val_change=True,\n",
    "                      resume=False)\n",
    "config = wandb.config  # Object for storing hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "To load the dataset we will download a specific dataset artifact from the collection of artifacts\n",
    "stored in the weights and biases (wandb) project associated to this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_name_and_version = 'JNK:interpolated-normalized-10000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_artifact = run_dcae.use_artifact(artifact=artifact_name_and_version, type='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dataset',\n",
       " 'JNK:interpolated-normalized-10000',\n",
       " '078808c2a8537f9b69064a6a68d199b6')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters (uncomment to override the yaml file)\n",
    "config.update(allow_val_change=True,\n",
    "              params={\n",
    "                  'ds_artifact_type': ds_artifact.type,\n",
    "                  'ds_artifact_name': ds_artifact.name,\n",
    "                  'ds_artifact_digest': ds_artifact.digest\n",
    "              })\n",
    "ds_artifact.type, ds_artifact.name, ds_artifact.digest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The artifact must have been logged from a `TSArtifact` object. IF that's true, the metadata of the downloaded artifact will contain all the necessary information to recover the dataframe containing the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TS': {'ed': '2019-06-01 02:46:39',\n",
       "  'sd': '2019-06-01 00:00:00',\n",
       "  'vars': ['RCD_AverageThree-phaseCurrent',\n",
       "   'LCD_AverageThree-phaseCurrent',\n",
       "   'LP_AverageThree-phaseCurrent',\n",
       "   'LHD_LeftHaulageDrive(tractor)Temperature(gearbox)',\n",
       "   'RHD_RightHaulageDrive(tractor)Temperature(gearbox)',\n",
       "   'LA_LeftArmTemperature',\n",
       "   'RA_RightArmTemperature',\n",
       "   'SM_DailyRouteOfTheShearer',\n",
       "   'SM_TotalRoute',\n",
       "   'LHD_EngineCurrent',\n",
       "   'RHD_EngineCurrent',\n",
       "   'RCD_BearingTemperature',\n",
       "   'SM_ShearerSpeed',\n",
       "   'SM_ShearerLocation',\n",
       "   'SM_ShearerMoveInLeft',\n",
       "   'SM_ShearerMoveInRight'],\n",
       "  'n_vars': 16,\n",
       "  'created': 'from-df',\n",
       "  'n_samples': 10000,\n",
       "  'has_missing_values': 'True'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_artifact.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds_artifact.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that will be used in the rest of the notebook will be stored in the dataframe `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RCD_AverageThree-phaseCurrent</th>\n",
       "      <th>LCD_AverageThree-phaseCurrent</th>\n",
       "      <th>LP_AverageThree-phaseCurrent</th>\n",
       "      <th>LHD_LeftHaulageDrive(tractor)Temperature(gearbox)</th>\n",
       "      <th>RHD_RightHaulageDrive(tractor)Temperature(gearbox)</th>\n",
       "      <th>LA_LeftArmTemperature</th>\n",
       "      <th>RA_RightArmTemperature</th>\n",
       "      <th>SM_DailyRouteOfTheShearer</th>\n",
       "      <th>SM_TotalRoute</th>\n",
       "      <th>LHD_EngineCurrent</th>\n",
       "      <th>RHD_EngineCurrent</th>\n",
       "      <th>RCD_BearingTemperature</th>\n",
       "      <th>SM_ShearerSpeed</th>\n",
       "      <th>SM_ShearerLocation</th>\n",
       "      <th>SM_ShearerMoveInLeft</th>\n",
       "      <th>SM_ShearerMoveInRight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <td>-0.978277</td>\n",
       "      <td>-1.050135</td>\n",
       "      <td>-0.768410</td>\n",
       "      <td>-8.159552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.988304</td>\n",
       "      <td>-9.858337</td>\n",
       "      <td>-0.867778</td>\n",
       "      <td>-10.551536</td>\n",
       "      <td>-0.692452</td>\n",
       "      <td>-0.702871</td>\n",
       "      <td>-4.346935</td>\n",
       "      <td>-0.279013</td>\n",
       "      <td>0.492080</td>\n",
       "      <td>-0.171269</td>\n",
       "      <td>-0.26495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01 00:00:01</th>\n",
       "      <td>-0.978277</td>\n",
       "      <td>-1.050135</td>\n",
       "      <td>-0.768410</td>\n",
       "      <td>-8.159552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.988304</td>\n",
       "      <td>-9.858337</td>\n",
       "      <td>-0.867778</td>\n",
       "      <td>-10.551536</td>\n",
       "      <td>-0.692452</td>\n",
       "      <td>-0.702871</td>\n",
       "      <td>-4.346935</td>\n",
       "      <td>-0.279013</td>\n",
       "      <td>0.492080</td>\n",
       "      <td>-0.171269</td>\n",
       "      <td>-0.26495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01 00:00:02</th>\n",
       "      <td>-0.978277</td>\n",
       "      <td>-1.050135</td>\n",
       "      <td>-0.768410</td>\n",
       "      <td>-8.159552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.988304</td>\n",
       "      <td>-9.858337</td>\n",
       "      <td>-0.867778</td>\n",
       "      <td>-10.551536</td>\n",
       "      <td>-0.692452</td>\n",
       "      <td>-0.702871</td>\n",
       "      <td>-4.346935</td>\n",
       "      <td>-0.279013</td>\n",
       "      <td>0.492080</td>\n",
       "      <td>-0.171269</td>\n",
       "      <td>-0.26495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01 00:00:03</th>\n",
       "      <td>-0.978277</td>\n",
       "      <td>-1.050135</td>\n",
       "      <td>-0.768410</td>\n",
       "      <td>-8.159552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.988304</td>\n",
       "      <td>-9.858337</td>\n",
       "      <td>-0.867778</td>\n",
       "      <td>-10.551536</td>\n",
       "      <td>-0.692452</td>\n",
       "      <td>-0.702871</td>\n",
       "      <td>-4.346935</td>\n",
       "      <td>-0.279013</td>\n",
       "      <td>0.492080</td>\n",
       "      <td>-0.171269</td>\n",
       "      <td>-0.26495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01 00:00:04</th>\n",
       "      <td>-0.978277</td>\n",
       "      <td>-1.050135</td>\n",
       "      <td>-0.768410</td>\n",
       "      <td>-8.159552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.988304</td>\n",
       "      <td>-9.858337</td>\n",
       "      <td>-0.867778</td>\n",
       "      <td>-10.551536</td>\n",
       "      <td>-0.692452</td>\n",
       "      <td>-0.702871</td>\n",
       "      <td>-4.346935</td>\n",
       "      <td>-0.279013</td>\n",
       "      <td>0.492080</td>\n",
       "      <td>-0.171269</td>\n",
       "      <td>-0.26495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01 02:46:35</th>\n",
       "      <td>1.511583</td>\n",
       "      <td>0.986317</td>\n",
       "      <td>0.111348</td>\n",
       "      <td>1.098870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762655</td>\n",
       "      <td>-0.334500</td>\n",
       "      <td>-0.519322</td>\n",
       "      <td>0.123080</td>\n",
       "      <td>0.757984</td>\n",
       "      <td>1.747462</td>\n",
       "      <td>1.150451</td>\n",
       "      <td>-0.279013</td>\n",
       "      <td>-1.139261</td>\n",
       "      <td>-0.171269</td>\n",
       "      <td>-0.26495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01 02:46:36</th>\n",
       "      <td>1.511583</td>\n",
       "      <td>0.986317</td>\n",
       "      <td>0.111348</td>\n",
       "      <td>1.098870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762655</td>\n",
       "      <td>-0.334500</td>\n",
       "      <td>-0.519322</td>\n",
       "      <td>0.123080</td>\n",
       "      <td>0.757984</td>\n",
       "      <td>1.747462</td>\n",
       "      <td>1.150451</td>\n",
       "      <td>-0.279013</td>\n",
       "      <td>-1.139261</td>\n",
       "      <td>-0.171269</td>\n",
       "      <td>-0.26495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01 02:46:37</th>\n",
       "      <td>1.640369</td>\n",
       "      <td>0.986317</td>\n",
       "      <td>2.164117</td>\n",
       "      <td>1.098870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762655</td>\n",
       "      <td>-0.334500</td>\n",
       "      <td>-0.519322</td>\n",
       "      <td>0.123080</td>\n",
       "      <td>0.664407</td>\n",
       "      <td>2.708377</td>\n",
       "      <td>1.150451</td>\n",
       "      <td>-0.279013</td>\n",
       "      <td>-1.122443</td>\n",
       "      <td>-0.171269</td>\n",
       "      <td>-0.26495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01 02:46:38</th>\n",
       "      <td>2.048191</td>\n",
       "      <td>1.059047</td>\n",
       "      <td>0.111348</td>\n",
       "      <td>1.098870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762655</td>\n",
       "      <td>-0.334500</td>\n",
       "      <td>-0.518407</td>\n",
       "      <td>0.123080</td>\n",
       "      <td>0.991925</td>\n",
       "      <td>2.372057</td>\n",
       "      <td>1.150451</td>\n",
       "      <td>-0.279013</td>\n",
       "      <td>-1.122443</td>\n",
       "      <td>-0.171269</td>\n",
       "      <td>-0.26495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01 02:46:39</th>\n",
       "      <td>1.296940</td>\n",
       "      <td>0.865099</td>\n",
       "      <td>0.111348</td>\n",
       "      <td>1.098870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.762655</td>\n",
       "      <td>-0.334500</td>\n",
       "      <td>-0.518407</td>\n",
       "      <td>0.123080</td>\n",
       "      <td>1.600173</td>\n",
       "      <td>1.555279</td>\n",
       "      <td>1.150451</td>\n",
       "      <td>-0.279013</td>\n",
       "      <td>-1.122443</td>\n",
       "      <td>-0.171269</td>\n",
       "      <td>-0.26495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RCD_AverageThree-phaseCurrent  \\\n",
       "TIMESTAMP                                            \n",
       "2019-06-01 00:00:00                      -0.978277   \n",
       "2019-06-01 00:00:01                      -0.978277   \n",
       "2019-06-01 00:00:02                      -0.978277   \n",
       "2019-06-01 00:00:03                      -0.978277   \n",
       "2019-06-01 00:00:04                      -0.978277   \n",
       "...                                            ...   \n",
       "2019-06-01 02:46:35                       1.511583   \n",
       "2019-06-01 02:46:36                       1.511583   \n",
       "2019-06-01 02:46:37                       1.640369   \n",
       "2019-06-01 02:46:38                       2.048191   \n",
       "2019-06-01 02:46:39                       1.296940   \n",
       "\n",
       "                     LCD_AverageThree-phaseCurrent  \\\n",
       "TIMESTAMP                                            \n",
       "2019-06-01 00:00:00                      -1.050135   \n",
       "2019-06-01 00:00:01                      -1.050135   \n",
       "2019-06-01 00:00:02                      -1.050135   \n",
       "2019-06-01 00:00:03                      -1.050135   \n",
       "2019-06-01 00:00:04                      -1.050135   \n",
       "...                                            ...   \n",
       "2019-06-01 02:46:35                       0.986317   \n",
       "2019-06-01 02:46:36                       0.986317   \n",
       "2019-06-01 02:46:37                       0.986317   \n",
       "2019-06-01 02:46:38                       1.059047   \n",
       "2019-06-01 02:46:39                       0.865099   \n",
       "\n",
       "                     LP_AverageThree-phaseCurrent  \\\n",
       "TIMESTAMP                                           \n",
       "2019-06-01 00:00:00                     -0.768410   \n",
       "2019-06-01 00:00:01                     -0.768410   \n",
       "2019-06-01 00:00:02                     -0.768410   \n",
       "2019-06-01 00:00:03                     -0.768410   \n",
       "2019-06-01 00:00:04                     -0.768410   \n",
       "...                                           ...   \n",
       "2019-06-01 02:46:35                      0.111348   \n",
       "2019-06-01 02:46:36                      0.111348   \n",
       "2019-06-01 02:46:37                      2.164117   \n",
       "2019-06-01 02:46:38                      0.111348   \n",
       "2019-06-01 02:46:39                      0.111348   \n",
       "\n",
       "                     LHD_LeftHaulageDrive(tractor)Temperature(gearbox)  \\\n",
       "TIMESTAMP                                                                \n",
       "2019-06-01 00:00:00                                          -8.159552   \n",
       "2019-06-01 00:00:01                                          -8.159552   \n",
       "2019-06-01 00:00:02                                          -8.159552   \n",
       "2019-06-01 00:00:03                                          -8.159552   \n",
       "2019-06-01 00:00:04                                          -8.159552   \n",
       "...                                                                ...   \n",
       "2019-06-01 02:46:35                                           1.098870   \n",
       "2019-06-01 02:46:36                                           1.098870   \n",
       "2019-06-01 02:46:37                                           1.098870   \n",
       "2019-06-01 02:46:38                                           1.098870   \n",
       "2019-06-01 02:46:39                                           1.098870   \n",
       "\n",
       "                     RHD_RightHaulageDrive(tractor)Temperature(gearbox)  \\\n",
       "TIMESTAMP                                                                 \n",
       "2019-06-01 00:00:00                                                NaN    \n",
       "2019-06-01 00:00:01                                                NaN    \n",
       "2019-06-01 00:00:02                                                NaN    \n",
       "2019-06-01 00:00:03                                                NaN    \n",
       "2019-06-01 00:00:04                                                NaN    \n",
       "...                                                                ...    \n",
       "2019-06-01 02:46:35                                                NaN    \n",
       "2019-06-01 02:46:36                                                NaN    \n",
       "2019-06-01 02:46:37                                                NaN    \n",
       "2019-06-01 02:46:38                                                NaN    \n",
       "2019-06-01 02:46:39                                                NaN    \n",
       "\n",
       "                     LA_LeftArmTemperature  RA_RightArmTemperature  \\\n",
       "TIMESTAMP                                                            \n",
       "2019-06-01 00:00:00              -9.988304               -9.858337   \n",
       "2019-06-01 00:00:01              -9.988304               -9.858337   \n",
       "2019-06-01 00:00:02              -9.988304               -9.858337   \n",
       "2019-06-01 00:00:03              -9.988304               -9.858337   \n",
       "2019-06-01 00:00:04              -9.988304               -9.858337   \n",
       "...                                    ...                     ...   \n",
       "2019-06-01 02:46:35               0.762655               -0.334500   \n",
       "2019-06-01 02:46:36               0.762655               -0.334500   \n",
       "2019-06-01 02:46:37               0.762655               -0.334500   \n",
       "2019-06-01 02:46:38               0.762655               -0.334500   \n",
       "2019-06-01 02:46:39               0.762655               -0.334500   \n",
       "\n",
       "                     SM_DailyRouteOfTheShearer  SM_TotalRoute  \\\n",
       "TIMESTAMP                                                       \n",
       "2019-06-01 00:00:00                  -0.867778     -10.551536   \n",
       "2019-06-01 00:00:01                  -0.867778     -10.551536   \n",
       "2019-06-01 00:00:02                  -0.867778     -10.551536   \n",
       "2019-06-01 00:00:03                  -0.867778     -10.551536   \n",
       "2019-06-01 00:00:04                  -0.867778     -10.551536   \n",
       "...                                        ...            ...   \n",
       "2019-06-01 02:46:35                  -0.519322       0.123080   \n",
       "2019-06-01 02:46:36                  -0.519322       0.123080   \n",
       "2019-06-01 02:46:37                  -0.519322       0.123080   \n",
       "2019-06-01 02:46:38                  -0.518407       0.123080   \n",
       "2019-06-01 02:46:39                  -0.518407       0.123080   \n",
       "\n",
       "                     LHD_EngineCurrent  RHD_EngineCurrent  \\\n",
       "TIMESTAMP                                                   \n",
       "2019-06-01 00:00:00          -0.692452          -0.702871   \n",
       "2019-06-01 00:00:01          -0.692452          -0.702871   \n",
       "2019-06-01 00:00:02          -0.692452          -0.702871   \n",
       "2019-06-01 00:00:03          -0.692452          -0.702871   \n",
       "2019-06-01 00:00:04          -0.692452          -0.702871   \n",
       "...                                ...                ...   \n",
       "2019-06-01 02:46:35           0.757984           1.747462   \n",
       "2019-06-01 02:46:36           0.757984           1.747462   \n",
       "2019-06-01 02:46:37           0.664407           2.708377   \n",
       "2019-06-01 02:46:38           0.991925           2.372057   \n",
       "2019-06-01 02:46:39           1.600173           1.555279   \n",
       "\n",
       "                     RCD_BearingTemperature  SM_ShearerSpeed  \\\n",
       "TIMESTAMP                                                      \n",
       "2019-06-01 00:00:00               -4.346935        -0.279013   \n",
       "2019-06-01 00:00:01               -4.346935        -0.279013   \n",
       "2019-06-01 00:00:02               -4.346935        -0.279013   \n",
       "2019-06-01 00:00:03               -4.346935        -0.279013   \n",
       "2019-06-01 00:00:04               -4.346935        -0.279013   \n",
       "...                                     ...              ...   \n",
       "2019-06-01 02:46:35                1.150451        -0.279013   \n",
       "2019-06-01 02:46:36                1.150451        -0.279013   \n",
       "2019-06-01 02:46:37                1.150451        -0.279013   \n",
       "2019-06-01 02:46:38                1.150451        -0.279013   \n",
       "2019-06-01 02:46:39                1.150451        -0.279013   \n",
       "\n",
       "                     SM_ShearerLocation  SM_ShearerMoveInLeft  \\\n",
       "TIMESTAMP                                                       \n",
       "2019-06-01 00:00:00            0.492080             -0.171269   \n",
       "2019-06-01 00:00:01            0.492080             -0.171269   \n",
       "2019-06-01 00:00:02            0.492080             -0.171269   \n",
       "2019-06-01 00:00:03            0.492080             -0.171269   \n",
       "2019-06-01 00:00:04            0.492080             -0.171269   \n",
       "...                                 ...                   ...   \n",
       "2019-06-01 02:46:35           -1.139261             -0.171269   \n",
       "2019-06-01 02:46:36           -1.139261             -0.171269   \n",
       "2019-06-01 02:46:37           -1.122443             -0.171269   \n",
       "2019-06-01 02:46:38           -1.122443             -0.171269   \n",
       "2019-06-01 02:46:39           -1.122443             -0.171269   \n",
       "\n",
       "                     SM_ShearerMoveInRight  \n",
       "TIMESTAMP                                   \n",
       "2019-06-01 00:00:00               -0.26495  \n",
       "2019-06-01 00:00:01               -0.26495  \n",
       "2019-06-01 00:00:02               -0.26495  \n",
       "2019-06-01 00:00:03               -0.26495  \n",
       "2019-06-01 00:00:04               -0.26495  \n",
       "...                                    ...  \n",
       "2019-06-01 02:46:35               -0.26495  \n",
       "2019-06-01 02:46:36               -0.26495  \n",
       "2019-06-01 02:46:37               -0.26495  \n",
       "2019-06-01 02:46:38               -0.26495  \n",
       "2019-06-01 02:46:39               -0.26495  \n",
       "\n",
       "[10000 rows x 16 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding window features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a continuous multivariate time-series data $D$ of dimension $d$ with $n$ time-steps, $D = X_1,X_2,\\dots,X_n$ , where each $X_i = \\{x_i^1,\\dots,x_i^d\\}$ . Let $w$ be the window width, $s$ the stride, and $t$ the start time of a sliding window in the data.\n",
    "\n",
    "Define a new matrix $Z_k$ where each row is a vector of size $w$ of data extracted from the $k^{th}$ dimension.\n",
    "\n",
    "\\begin{aligned}&Z_k(w,s,t)\\\\&\\quad =\\begin{bmatrix} x_{t}^k&\\quad x_{t+1}^k&\\quad \\dots&\\quad x_{t+w-1}^k \\\\ x_{t+s}^k&\\quad x_{t+s+1}^k&\\quad \\dots&\\quad x_{t+s+w-1}^k \\\\ \\vdots&\\quad \\vdots&\\quad \\ddots&\\quad \\vdots \\\\ x_{t+(r-1)s}^k&\\quad x_{t+(r-1)s+1}^k&\\quad \\dots&\\quad x_{t+(r-1)s+w-1}^k \\end{bmatrix} \\end{aligned}\n",
    "\n",
    "where $r$ is the number of desired rows, and $t+(r-1)s+w-1 \\le n$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z$ is a $w \\times s \\times t$ matrix. The first step consists in slicing the original multivariate time series into slices of shape ($w \\times d$), as shown in this figure from the paper.\n",
    "<img src=\"https://i.imgur.com/R9Fx8uO.png\" style=\"width:800px;height:400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters (uncomment to override the yaml file)\n",
    "config.update(allow_val_change=True,\n",
    "              params={\n",
    "                  'w': 48,\n",
    "                  'stride': 1,\n",
    "                  't': 0  # Not supported yet\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.equals(config.w % 12, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sliced data must be converted to a numpy array with shape $(n \\times w \\times d)$, where $n$ is the length of the time series, $w$ is the window size and $d$ is the number of dimensions in the time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export utils\n",
    "def df_slicer(df, w, s=1, padding=False, padding_value=0, return_as='ndarray'):\n",
    "    \"Transform a numeric dataframe `df` into slices (np arrays) of `w` \\\n",
    "    rows and the same number of columns than the original dataframe. The \\\n",
    "    distance between each slice is given by the stride `s`. If `padding` is \\\n",
    "    equals to True, the last slices which have less than `w` points are filled \\\n",
    "    with the value marked in the argument `padding_value`. Otherwise, those \\\n",
    "    slices are removed from the result.\"\n",
    "    aux = [df.iloc[x:x+w] for x in range(0, len(df), s)]\n",
    "    if padding:\n",
    "        with_padding = [x.append(pd.DataFrame(\n",
    "            np.full((w - len(x), len(df.columns)), padding_value),\n",
    "            columns=df.columns.values)) if len(x) < w else x for x in aux]\n",
    "    else:\n",
    "        with_padding = [x for x in aux if len(x) == w]\n",
    "    return np.rollaxis(np.dstack([x.values for x in with_padding]), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9953"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_slices = df_slicer(df, w=config.w, s=config.stride)\n",
    "len(df_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.9782767 ,  -1.05013538,  -0.76841012,  -8.15955247,\n",
       "                nan,  -9.988304  ,  -9.85833737,  -0.86777833,\n",
       "       -10.55153638,  -0.69245226,  -0.70287086,  -4.34693533,\n",
       "        -0.27901305,   0.49207951,  -0.17126922,  -0.26494992])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_slices[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the number of slices and the size of each slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_nwindows = (int)((len(df) - config.w)/config.stride + 1)\n",
    "expected = [(config.w, len(df.columns))]*expected_nwindows\n",
    "actual = [x.shape for x in df_slices]\n",
    "test.all_equal(expected, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export load\n",
    "def slices2array(slices):\n",
    "    \"`slices` is a list of dataframes, each of them containing an slice of a multivariate time series.\"\n",
    "    return np.rollaxis(np.dstack([x.values for x in slices]), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = slices2array([x for x in df_slices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.equals(input_data.shape, (len(df_slices), len(df_slices[0]), len(df_slices[0].columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it is very handy to provide a function to preprocess a dataframe as a sliced tensor suitable for model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export load\n",
    "def fmultiTSloader(df, w, stride, **kwargs):\n",
    "    \"Preprocess a dataframe with multivariate time series from a df `df` or from set of paths `paths`, \\\n",
    "    preprocess it calling `fpreprocess_numeric_vars` \\\n",
    "    slice it into time windows of length `w` and stride `stride` calling `fslicer`, and \\\n",
    "    conert the result into a numpy array, suitable for ML libraries. Optional arguments for \\\n",
    "    the intermediate functions can be passed through `**kwargs`\"\n",
    "    df_slices = fslicer(df, w, stride)\n",
    "    array_slices = slices2array([x for x in df_slices])\n",
    "    return (df, df_slices, array_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df, f_df_slices, f_array_slices = fmultiTSloader(df, config.w, config.stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.equals(df, f_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.equals(df_slices, f_df_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.equals(input_data, f_array_slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract important features from the multivariate time series data through Deep Convolutional Autoencoders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Convolutional Auto Encoders (DCAE) is a powerful method for learning high-level and mid-level abstractions from low-level raw data. It has the ability to extract features from complex and large time-series in an unsupervised manner. This is useful to overcome the complexity of multivariate time-series.\n",
    "\n",
    "Compared to the conventional auto-encoder, DCAE has fewer parameters than the conventional auto-encoder which means less training time. Also, DCAE uses local information to reconstruct the signal while conventional auto-encoders utilize fully connected layers to globally do the reconstruction. DCAE is an unsupervised model for representation learning which maps inputs into a new representation space. It has two main parts which are the encoding part that is used to project the data into a set of feature spaces and the decoding part that reconstructs the original data. The latent space representation is the space where the data lie in the bottleneck layers.\n",
    "\n",
    "The loss function of the DCAE is defined as the error between the input and the output. DCAE aims to find a code for each input by minimizing the mean squared error (MSE) between its input (original data) and output (reconstructed data). The MSE is used which assists to minimize the loss; thus, the network is forced to learn a low-dimensional representation of the input.\n",
    "\n",
    "We will implement the DCAE of the paper [TimeCluster](https://link.springer.com/article/10.1007/s00371-019-01673-y), whose architecture is shown in the table below:\n",
    "\n",
    "![](https://i.imgur.com/3EjuAfQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, in the paper, the input shape is $60 \\times 3$, due to multivariate time series has 3 variables and the window size is 60. Generally, the size of the input/output of the autoencoder will depend on the shape of each slice obtained in the previos step. The number of latent features to be discovered is $60$ in the table above, but we can consider this as a free hyperparameter $\\delta$. Also, according to the paper: \"*The number of feature maps, size of filter and depth of the model are set based on the reconstruction error on validation set.*\". Thus, we must provide flexibility in the creation of the DCAE in terms of these hyperparameters.º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you are not using a config file, you can also uncomment the following cell and define the hyperparameters in the fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "config.update(allow_val_change=True,\n",
    "    params = {\n",
    "        'lr': 0.0009044187712482472,\n",
    "        'n_filters': [32, 16, 12],\n",
    "        'filter_sizes': [20, 10, 10],\n",
    "        'output_filter_size': 20,\n",
    "        'pool_sizes': [2, 2, 3],\n",
    "        'delta': config.w,\n",
    "        'batch_size': 92,\n",
    "        'epochs': 10,\n",
    "        'val_pct': 0.2\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "test.all_equal([len(x) for x in [config.n_filters, config.filter_sizes, config.pool_sizes]], np.repeat(len(config.n_filters), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "\n",
    "The implementation of the DCAE is done using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def createDCAE(w, d, delta, n_filters=[64,32,12], filter_sizes=[10,5,5], pool_sizes=[2,2,3], output_filter_size=10):\n",
    "    \"Create a Deep Convolutional Autoencoder for multivariate time series of `d` dimensions, \\\n",
    "    sliced with a window size of `w`. The parameter `delta` sets the number of latent features that will be \\\n",
    "    contained in the Dense layer of the network. The the number of features \\\n",
    "    maps (filters), the filter size and the pool size can also be adjusted.\"\n",
    "    # Test that the parameterization of the model is correct\n",
    "    # 1. n_filters, filter_sizes and pool_sizes have the same length\n",
    "    assert test.all_equal([len(x) for x in [n_filters, filter_sizes, pool_sizes]], np.repeat(len(n_filters), 3))\n",
    "    # 2. Test that the number of filters in the last convLayer is equal to the product of the pool sizes\n",
    "    assert np.prod(pool_sizes) == n_filters[-1]\n",
    "    # 3. Test that the product of pool sizes is a divisor of the window size\n",
    "    assert w % np.prod(pool_sizes).all() == 0\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(w,d)))\n",
    "    for (i, x) in enumerate(n_filters):\n",
    "        model.add(Conv1D(filters=n_filters[i], kernel_size=filter_sizes[i], activation='relu', padding='same'))\n",
    "        model.add(MaxPool1D(pool_size=pool_sizes[i]))\n",
    "    aux_shape = model.output_shape[1:]\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=np.prod(aux_shape), activation='linear', name='latent_features'))\n",
    "    model.add(Reshape(target_shape=aux_shape))\n",
    "    for i, x in reversed(list(enumerate(n_filters))):\n",
    "        model.add(Conv1D(filters=n_filters[i], kernel_size=filter_sizes[i], activation='relu', padding='same'))\n",
    "        model.add(UpSampling1D(size=pool_sizes[i]))\n",
    "    model.add(Conv1D(filters=d, kernel_size=output_filter_size, activation='linear', padding='same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 48, 32)            10272     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 24, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 24, 16)            5136      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 12, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 12, 12)            1932      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 4, 12)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "latent_features (Dense)      (None, 48)                2352      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 12)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 4, 12)             1452      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1 (None, 12, 12)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 12, 16)            1936      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_4 (UpSampling1 (None, 24, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 24, 32)            10272     \n",
      "_________________________________________________________________\n",
      "up_sampling1d_5 (UpSampling1 (None, 48, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 48, 16)            10256     \n",
      "=================================================================\n",
      "Total params: 43,608\n",
      "Trainable params: 43,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = createDCAE(config.w, input_data.shape[-1], config.delta, n_filters=config.n_filters, \n",
    "              filter_sizes=config.filter_sizes, pool_sizes=config.pool_sizes,\n",
    "              output_filter_size=config.output_filter_size)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(loss='mean_squared_error', optimizer=opt, metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = m.fit(x=input_data, y=input_data, batch_size=config.batch_size, \n",
    "      validation_split=config.val_pct, epochs=config.epochs, verbose=0, \n",
    "      callbacks=[WandbCallback(log_weights=True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "To track the performance of this model fit, go to the project dashboard in Weights & Biases. The link is provided at the beginning of this notebook, after the execution of the function `wandb.init()'' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
