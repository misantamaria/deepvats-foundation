{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa093821-a793-49fd-a8c2-32cacdbdc964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f6adb50-be0c-4f0b-9beb-38d4e78c5e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a4a02-5015-4a3e-9a64-6089de4e9532",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "> Architectures and functions for creating encoders that create the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b014a18f-8538-4ed7-98ee-ddb165692553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "from tsai.imports import *\n",
    "from tsai.models.InceptionTimePlus import InceptionTimePlus\n",
    "from tsai.models.explainability import get_acts_and_grads\n",
    "from tsai.models.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class DCAE_torch(Module):\n",
    "    def __init__(self, c_in, seq_len, delta, nfs=[64, 32, 12], kss=[10, 5, 5], \n",
    "                 pool_szs=[2,2,3], output_fsz=10):\n",
    "        \"\"\"\n",
    "        Create a Deep Convolutional Autoencoder for multivariate time series of `d` dimensions,\n",
    "        sliced with a window size of `w`. The parameter `delta` sets the number of latent features that will be\n",
    "        contained in the Dense layer of the network. The the number of features\n",
    "        maps (filters), the filter size and the pool size can also be adjusted.\"\n",
    "        \"\"\"\n",
    "        assert all_equal([len(x) for x in [nfs, kss, pool_szs]], np.repeat(len(nfs), 3)), \\\n",
    "            'nfs, kss, and pool_szs must have the same length'\n",
    "        assert np.prod(pool_szs) == nfs[-1], \\\n",
    "            'The number of filters in the last conv layer must be equal to the product of pool sizes'\n",
    "        assert seq_len % np.prod(pool_szs) == 0, \\\n",
    "            'The product of pool sizes must be a divisor of the window size'\n",
    "        layers = []\n",
    "        for i in range_of(kss):\n",
    "            layers += [Conv1d(ni=nfs[i-1] if i>0 else c_in, nf=nfs[i], ks=kss[i]),\n",
    "                       nn.MaxPool1d(kernel_size=pool_szs[i])]\n",
    "        self.downsample = nn.Sequential(*layers)\n",
    "        self.bottleneck = nn.Sequential(OrderedDict([\n",
    "            ('flatten', nn.Flatten()),\n",
    "            ('latent_in', nn.Linear(seq_len, delta)), \n",
    "            ('latent_out', nn.Linear(delta, seq_len)),\n",
    "            ('reshape', Reshape(nfs[-1], seq_len // np.prod(pool_szs)))\n",
    "        ]))\n",
    "        layers = []\n",
    "        for i in reversed(range_of(kss)):\n",
    "            layers += [Conv1d(ni=nfs[i+1] if i != (len(nfs)-1) else nfs[-1], \n",
    "                              nf=nfs[i], ks=kss[i]),\n",
    "                       nn.Upsample(scale_factor=pool_szs[i])]\n",
    "        layers += [Conv1d(ni=nfs[0], nf=c_in, kernel_size=output_fsz)]\n",
    "        self.upsample = nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.downsample(x)\n",
    "        x = self.bottleneck(x)\n",
    "        x = self.upsample(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 48])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = torch.rand(3, 1, 48)\n",
    "m = DCAE_torch(c_in=foo.shape[1], seq_len=foo.shape[2], delta=12)\n",
    "m(foo).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1a4a1d-389c-481a-a54d-3f86cd2115f5",
   "metadata": {},
   "source": [
    "### Dictionary to get the default backbone modules to get the embeddings from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3eb9f1b6-ae45-4b6e-b535-c7f121208721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "ENCODER_EMBS_MODULE_NAME = {\n",
    "    InceptionTimePlus: 'backbone', # for mvp based models\n",
    "    DCAE_torch: 'bottleneck.latent_in'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268a268f-8b4e-4432-b203-79263a247c4c",
   "metadata": {},
   "source": [
    "### Getting the embeddings (activations) from the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65c66ae6-3178-49dc-bd16-64c082012e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_enc_embs(X, enc_learn, module=None, cpu=False, average_seq_dim=True, to_numpy=True):\n",
    "    \"\"\"\n",
    "        Get the embeddings of X from an encoder, passed in `enc_learn as a fastai \n",
    "        learner. By default, the embeddings are obtained from the last layer \n",
    "        before the model head, although any layer can be passed to `model`. \n",
    "        Input\n",
    "        - `cpu`: Whether to do the model inference in cpu of gpu (GPU recommended)\n",
    "        - `average_seq_dim`: Whether to aggregate the embeddings in the sequence dimensions\n",
    "        - `to_numpy`: Whether to return the result as a numpy array (if false returns a tensor)\n",
    "    \"\"\"\n",
    "    if cpu:\n",
    "        enc_learn.dls.cpu()\n",
    "        enc_learn.cpu()\n",
    "    else:\n",
    "        enc_learn.dls.cuda()\n",
    "        enc_learn.cuda()\n",
    "    aux_dl = enc_learn.dls.valid.new_dl(X=X)\n",
    "    aux_dl.bs = enc_learn.dls.bs if enc_learn.dls.bs>0 else 64\n",
    "    module = nested_attr(enc_learn.model, \n",
    "                         ENCODER_EMBS_MODULE_NAME[type(enc_learn.model)]) \\\n",
    "                if module is None else module\n",
    "    embs = [get_acts_and_grads(model=enc_learn.model, \n",
    "                               modules=module, \n",
    "                               x=xb[0], cpu=cpu)[0] for xb in aux_dl]\n",
    "    embs = to_concat(embs)\n",
    "    if embs.ndim == 3 and average_seq_dim: embs = embs.mean(axis=2)\n",
    "    if to_numpy: embs = embs.numpy() if cpu else embs.cpu().numpy()\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93dc6c6c-df80-44de-a49e-f27e86b8964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tchub.utils import *\n",
    "wandb_api = wandb.Api()\n",
    "enc_artifact = wandb_api.artifact('tchub/learner-mvp:run-tchub-3tipekxw')\n",
    "enc_learner = enc_artifact.to_obj()\n",
    "X = torch.rand(9, 1, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bf504f6-a765-4a8e-b7e3-7ea521bdd96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "%%time\n",
    "embs = get_enc_embs(X, enc_learner, cpu=True)\n",
    "test_eq(embs.shape[0], X.shape[0])\n",
    "embs.shape, embs.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e4ddae2-e646-442f-86c2-2a8c8ad8606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.22 s, sys: 34.4 ms, total: 1.25 s\n",
      "Wall time: 102 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/env/lib/python3.8/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([9, 128]), torch.Tensor, device(type='cuda', index=0))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "embs = get_enc_embs(X, enc_learner, cpu=False, to_numpy=False)\n",
    "test_eq(embs.shape[0], X.shape[0])\n",
    "embs.shape, embs.__class__, embs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed7336d9-7e63-4635-8552-4a5d86492ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 ms, sys: 61 Âµs, total: 16.3 ms\n",
      "Wall time: 15.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9, 128), numpy.ndarray)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "embs = get_enc_embs(X, enc_learner, cpu=False, to_numpy=True)\n",
    "test_eq(embs.shape[0], X.shape[0])\n",
    "embs.shape, embs.__class__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824e92c8-3932-470f-8f6a-1b7810032c18",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11c6132f-be0d-4e4e-abab-754cbe9a365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 02a_encoder_DCAE-torch.ipynb.\n",
      "Converted dr.ipynb.\n",
      "Converted encoder.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted load.ipynb.\n",
      "Converted utils.ipynb.\n",
      "Converted visualization.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "beep(1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d45d555be0220b07bf61be557bfa0ebbf7a95015976aec9a23277863e1bd4593"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
