{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "> This notebook gets the latent features from a multivariate time series \n",
    "given by an autoencoder and uses them as input for a dimensionality reduction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import umap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "from timecluster_extension.load import *\n",
    "from timecluster_extension.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from yaml import load, FullLoader\n",
    "from tensorflow.keras.models import load_model\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put here everything that could be needed if this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AttrDict(\n",
    "    use_wandb = True, # Whether to use or not wandb for experiment tracking\n",
    "    wandb_group = None, # Whether to group this run in a wandb group\n",
    "    dr_artifact_name = 'JNK:v18', # * Set to None for using the default one (DCAE)\n",
    "    dcae_run_path= 'pacmel/timecluster-extension/48afdwny', #'pacmel/timecluster-extension/red8g4bp' # *\n",
    "    n_neighbors = 15, #UMAP\n",
    "    min_dist = 0.1, #UMAP\n",
    "    metric = 'euclidean', #UMAP\n",
    "    verbose = True # UMAP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model needs to restore the model fitted in the notebook `02_DCAE`, as well as the data and configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the best run from a sweep. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:7p7mfj9h) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2415<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6df5f872a241a081115dbd53ff778d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/victor/work/nbs/wandb/run-20210520_113008-7p7mfj9h/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/victor/work/nbs/wandb/run-20210520_113008-7p7mfj9h/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">flowing-terrain-502</strong>: <a href=\"https://wandb.ai/pacmel/timecluster-extension/runs/7p7mfj9h\" target=\"_blank\">https://wandb.ai/pacmel/timecluster-extension/runs/7p7mfj9h</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:7p7mfj9h). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.21<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fanciful-field-503</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/pacmel/timecluster-extension\" target=\"_blank\">https://wandb.ai/pacmel/timecluster-extension</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/pacmel/timecluster-extension/runs/2222s20w\" target=\"_blank\">https://wandb.ai/pacmel/timecluster-extension/runs/2222s20w</a><br/>\n",
       "                Run data is saved locally in <code>/home/victor/work/nbs/wandb/run-20210521_143717-2222s20w</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_dr = wandb.init(entity=\"pacmel\",\n",
    "                    project=\"timecluster-extension\", \n",
    "                    group=config.wandb_group,\n",
    "                    allow_val_change=True, \n",
    "                    job_type='dimensionality_reduction', \n",
    "                    mode='online' if config.use_wandb else 'offline',\n",
    "                    config=config)\n",
    "config_dr = wandb.config # Object for storing hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore a DCAE model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcae_model = load_model(wandb.restore('model-best.h5', replace=True, run_path=config_dr.dcae_run_path).name)\n",
    "with open(wandb.restore('config.yaml', replace=True, run_path=config_dr.dcae_run_path).name) as file:\n",
    "    dcae_config = load(file, FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the dataset artifact used for creating the DCAE. Even if we do not compute the dimensionality reduction over this dataset,\n",
    "we need to know the metadata of the dataset of the DCAE, to check that it matches with the dataset that we want to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dataset', 'JNK:v17', 'bc2c682a76fd28127848efd52c6a9d87')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcae_artifact_type = dcae_config.get('ds_train_artifact_type').get('value')\n",
    "dcae_artifact_name = dcae_config.get('ds_train_artifact_name').get('value')\n",
    "dcae_artifact_digest = dcae_config.get('ds_train_artifact_digest').get('value')\n",
    "dcae_artifact_type, dcae_artifact_name, dcae_artifact_digest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TS': {'ed': '2019-06-23 23:59:55',\n",
       "  'sd': '2019-06-01 00:00:00',\n",
       "  'freq': '<5 * Seconds>',\n",
       "  'hash': '2649617295588873929',\n",
       "  'vars': ['RCD_AverageThree-phaseCurrent',\n",
       "   'LCD_AverageThree-phaseCurrent',\n",
       "   'LP_AverageThree-phaseCurrent',\n",
       "   'LHD_LeftHaulageDrive(tractor)Temperature(gearbox)',\n",
       "   'RHD_RightHaulageDrive(tractor)Temperature(gearbox)',\n",
       "   'LA_LeftArmTemperature',\n",
       "   'RA_RightArmTemperature',\n",
       "   'SM_DailyRouteOfTheShearer',\n",
       "   'SM_TotalRoute',\n",
       "   'LHD_EngineCurrent',\n",
       "   'RHD_EngineCurrent',\n",
       "   'RCD_BearingTemperature',\n",
       "   'SM_ShearerSpeed',\n",
       "   'SM_ShearerLocation',\n",
       "   'SM_ShearerMoveInLeft',\n",
       "   'SM_ShearerMoveInRight'],\n",
       "  'n_vars': 16,\n",
       "  'created': 'from-df',\n",
       "  'n_samples': 397440,\n",
       "  'normalization': {'stds': {'SM_TotalRoute': 21.992641402532836,\n",
       "    'SM_ShearerSpeed': 2.724568932534116,\n",
       "    'LHD_EngineCurrent': 21.62938860961895,\n",
       "    'RHD_EngineCurrent': 21.0185248258138,\n",
       "    'SM_ShearerLocation': 79.54958101088538,\n",
       "    'SM_ShearerMoveInLeft': 0.23984552514921795,\n",
       "    'LA_LeftArmTemperature': 11.703453684488062,\n",
       "    'SM_ShearerMoveInRight': 0.2740396394970838,\n",
       "    'RA_RightArmTemperature': 14.241837114195002,\n",
       "    'RCD_BearingTemperature': 16.38976490874,\n",
       "    'SM_DailyRouteOfTheShearer': 1041.6509027057057,\n",
       "    'LP_AverageThree-phaseCurrent': 2.602739399288098,\n",
       "    'LCD_AverageThree-phaseCurrent': 37.53576607948344,\n",
       "    'RCD_AverageThree-phaseCurrent': 37.94242587020688,\n",
       "    'LHD_LeftHaulageDrive(tractor)Temperature(gearbox)': 23.849734730214823,\n",
       "    'RHD_RightHaulageDrive(tractor)Temperature(gearbox)': 13.529230119837738},\n",
       "   'means': {'SM_TotalRoute': 147.6549115589775,\n",
       "    'SM_ShearerSpeed': 0.959477657004831,\n",
       "    'LHD_EngineCurrent': 12.01001207729469,\n",
       "    'RHD_EngineCurrent': 11.658245018115943,\n",
       "    'SM_ShearerLocation': 107.85175322061193,\n",
       "    'SM_ShearerMoveInLeft': 0.06354418276972625,\n",
       "    'LA_LeftArmTemperature': 39.38937726449275,\n",
       "    'SM_ShearerMoveInRight': 0.08480525362318843,\n",
       "    'RA_RightArmTemperature': 43.229178995571665,\n",
       "    'RCD_BearingTemperature': 52.631301328502424,\n",
       "    'SM_DailyRouteOfTheShearer': 1025.0101570048312,\n",
       "    'LP_AverageThree-phaseCurrent': 1.782810990338164,\n",
       "    'LCD_AverageThree-phaseCurrent': 34.773016304347834,\n",
       "    'RCD_AverageThree-phaseCurrent': 35.77255963164252,\n",
       "    'LHD_LeftHaulageDrive(tractor)Temperature(gearbox)': 54.08012253421901,\n",
       "    'RHD_RightHaulageDrive(tractor)Temperature(gearbox)': 3.4972851247987125}},\n",
       "  'has_missing_values': 'False'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcae_artifact = run_dr.use_artifact(dcae_artifact_name)\n",
    "dcae_artifact.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify the dataset artifact that we want to use for the reduction. If no artifact is defined, the artifact to reduce will be the one used for training the DCAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config_dr.dr_artifact_name is not None:\n",
    "    dr_artifact = run_dr.use_artifact(config_dr.dr_artifact_name, type='dataset')\n",
    "else:\n",
    "    dr_artifact = dcae_artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to check whether the artifact that is going to be used fort the dimensionality reduction matches the artifact used to train the DCAE. Matching means having the same number of variables, the same window size and stride, and the same frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def check_compatibility(dr_ar:TSArtifact, dcae_ar:TSArtifact):\n",
    "    \"Function to check that the artifact used by the DCAE and the artifact that is \\\n",
    "    going to be passed through the DR are compatible\"\n",
    "    try:\n",
    "        # Check that both artifacts have the same variables\n",
    "        chk_vars = dr_ar.metadata['TS']['vars'] == dcae_ar.metadata['TS']['vars']\n",
    "        # Check that both artifacts have the same freq\n",
    "        chk_freq = dr_ar.metadata['TS']['freq'] == dcae_ar.metadata['TS']['freq']\n",
    "        # Check that the dr artifact is not normalized (not normalized data has not the key normalization)\n",
    "        chk_norm = dr_ar.metadata['TS'].get('normalization') is None\n",
    "        # Check that the dr artifact has not missing values\n",
    "        chk_miss = dr_ar.metadata['TS']['has_missing_values'] == \"False\"\n",
    "        # Check all logical vars.\n",
    "        if chk_vars and chk_freq and chk_norm and chk_miss:\n",
    "            print(\"Artifacts are compatible.\")\n",
    "        else:\n",
    "            raise Exception\n",
    "    except Exception as e:\n",
    "        print(\"Artifacts are not complatible.\")\n",
    "        raise e\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def normalize_artifact(artifact:TSArtifact, artifact_norm:TSArtifact):\n",
    "    \"Function to normalize an artifact with the normalization parameters of another \\\n",
    "    one\"\n",
    "    # Check that artifacts are compatible\n",
    "    check_compatibility(artifact,artifact_norm)\n",
    "    # Get the normalization parameters of artifact_norm\n",
    "    ar_norm_stds = artifact_norm.metadata['TS']['normalization']['stds']\n",
    "    ar_norm_means = artifact_norm.metadata['TS']['normalization']['means']\n",
    "    # Transform artifact to pandas and iterate over columns\n",
    "    artifact_df = artifact.to_df()\n",
    "    # Iterate over df columns to normalize them with means and stds of artifact_norm\n",
    "    for column_name in artifact_df:\n",
    "        artifact_df[column_name] = (artifact_df[column_name] - ar_norm_means[column_name])/ar_norm_stds[column_name]\n",
    "    \n",
    "    return artifact_df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts are compatible.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RCD_AverageThree-phaseCurrent</th>\n",
       "      <th>LCD_AverageThree-phaseCurrent</th>\n",
       "      <th>LP_AverageThree-phaseCurrent</th>\n",
       "      <th>LHD_LeftHaulageDrive(tractor)Temperature(gearbox)</th>\n",
       "      <th>RHD_RightHaulageDrive(tractor)Temperature(gearbox)</th>\n",
       "      <th>LA_LeftArmTemperature</th>\n",
       "      <th>RA_RightArmTemperature</th>\n",
       "      <th>SM_DailyRouteOfTheShearer</th>\n",
       "      <th>SM_TotalRoute</th>\n",
       "      <th>LHD_EngineCurrent</th>\n",
       "      <th>RHD_EngineCurrent</th>\n",
       "      <th>RCD_BearingTemperature</th>\n",
       "      <th>SM_ShearerSpeed</th>\n",
       "      <th>SM_ShearerLocation</th>\n",
       "      <th>SM_ShearerMoveInLeft</th>\n",
       "      <th>SM_ShearerMoveInRight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-24 00:00:00</th>\n",
       "      <td>-0.626543</td>\n",
       "      <td>-0.638671</td>\n",
       "      <td>-0.684975</td>\n",
       "      <td>-1.261235</td>\n",
       "      <td>-0.258498</td>\n",
       "      <td>-1.400388</td>\n",
       "      <td>-1.420405</td>\n",
       "      <td>-0.981145</td>\n",
       "      <td>1.211546</td>\n",
       "      <td>-0.555264</td>\n",
       "      <td>-0.554665</td>\n",
       "      <td>-1.563860</td>\n",
       "      <td>-0.352158</td>\n",
       "      <td>-0.563821</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.309463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-24 00:00:05</th>\n",
       "      <td>-0.626543</td>\n",
       "      <td>-0.633343</td>\n",
       "      <td>-0.684975</td>\n",
       "      <td>-1.261235</td>\n",
       "      <td>-0.258498</td>\n",
       "      <td>-1.400388</td>\n",
       "      <td>-1.420405</td>\n",
       "      <td>-0.984025</td>\n",
       "      <td>1.211546</td>\n",
       "      <td>-0.555264</td>\n",
       "      <td>-0.554665</td>\n",
       "      <td>-1.563860</td>\n",
       "      <td>-0.352158</td>\n",
       "      <td>-0.563821</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.309463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-24 00:00:10</th>\n",
       "      <td>-0.626543</td>\n",
       "      <td>-0.638671</td>\n",
       "      <td>-0.684975</td>\n",
       "      <td>-1.261235</td>\n",
       "      <td>-0.258498</td>\n",
       "      <td>-1.400388</td>\n",
       "      <td>-1.420405</td>\n",
       "      <td>-0.984025</td>\n",
       "      <td>1.211546</td>\n",
       "      <td>-0.555264</td>\n",
       "      <td>-0.554665</td>\n",
       "      <td>-1.563860</td>\n",
       "      <td>-0.352158</td>\n",
       "      <td>-0.563821</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.309463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-24 00:00:15</th>\n",
       "      <td>-0.626543</td>\n",
       "      <td>-0.633343</td>\n",
       "      <td>-0.684975</td>\n",
       "      <td>-1.261235</td>\n",
       "      <td>-0.258498</td>\n",
       "      <td>-1.400388</td>\n",
       "      <td>-1.420405</td>\n",
       "      <td>-0.984025</td>\n",
       "      <td>1.211546</td>\n",
       "      <td>-0.555264</td>\n",
       "      <td>-0.554665</td>\n",
       "      <td>-1.563860</td>\n",
       "      <td>-0.352158</td>\n",
       "      <td>-0.563821</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.309463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-24 00:00:20</th>\n",
       "      <td>-0.626543</td>\n",
       "      <td>-0.644000</td>\n",
       "      <td>-0.684975</td>\n",
       "      <td>-1.261235</td>\n",
       "      <td>-0.258498</td>\n",
       "      <td>-1.400388</td>\n",
       "      <td>-1.420405</td>\n",
       "      <td>-0.984025</td>\n",
       "      <td>1.211546</td>\n",
       "      <td>-0.555264</td>\n",
       "      <td>-0.554665</td>\n",
       "      <td>-1.563860</td>\n",
       "      <td>-0.352158</td>\n",
       "      <td>-0.563821</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.309463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-28 23:59:40</th>\n",
       "      <td>-0.600187</td>\n",
       "      <td>-0.633343</td>\n",
       "      <td>-0.684975</td>\n",
       "      <td>0.667508</td>\n",
       "      <td>-0.258498</td>\n",
       "      <td>0.479399</td>\n",
       "      <td>0.334986</td>\n",
       "      <td>1.597454</td>\n",
       "      <td>1.984531</td>\n",
       "      <td>-0.555264</td>\n",
       "      <td>-0.554665</td>\n",
       "      <td>-0.099532</td>\n",
       "      <td>-0.352158</td>\n",
       "      <td>0.466982</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.309463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-28 23:59:45</th>\n",
       "      <td>-0.600187</td>\n",
       "      <td>-0.633343</td>\n",
       "      <td>-0.684975</td>\n",
       "      <td>0.667508</td>\n",
       "      <td>-0.258498</td>\n",
       "      <td>0.479399</td>\n",
       "      <td>0.334986</td>\n",
       "      <td>1.597454</td>\n",
       "      <td>1.984531</td>\n",
       "      <td>-0.555264</td>\n",
       "      <td>-0.554665</td>\n",
       "      <td>-0.099532</td>\n",
       "      <td>-0.352158</td>\n",
       "      <td>0.466982</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.309463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-28 23:59:50</th>\n",
       "      <td>-0.600187</td>\n",
       "      <td>-0.633343</td>\n",
       "      <td>-0.684975</td>\n",
       "      <td>0.667508</td>\n",
       "      <td>-0.258498</td>\n",
       "      <td>0.479399</td>\n",
       "      <td>0.334986</td>\n",
       "      <td>1.597454</td>\n",
       "      <td>1.984531</td>\n",
       "      <td>-0.555264</td>\n",
       "      <td>-0.554665</td>\n",
       "      <td>-0.099532</td>\n",
       "      <td>-0.352158</td>\n",
       "      <td>0.466982</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.309463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-28 23:59:55</th>\n",
       "      <td>-0.600187</td>\n",
       "      <td>-0.633343</td>\n",
       "      <td>-0.684975</td>\n",
       "      <td>0.667508</td>\n",
       "      <td>-0.258498</td>\n",
       "      <td>0.479399</td>\n",
       "      <td>0.334986</td>\n",
       "      <td>1.597454</td>\n",
       "      <td>1.984531</td>\n",
       "      <td>-0.555264</td>\n",
       "      <td>-0.554665</td>\n",
       "      <td>-0.099532</td>\n",
       "      <td>-0.352158</td>\n",
       "      <td>0.466982</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.309463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-29 00:00:00</th>\n",
       "      <td>-0.600187</td>\n",
       "      <td>-0.633343</td>\n",
       "      <td>-0.684975</td>\n",
       "      <td>0.667508</td>\n",
       "      <td>-0.258498</td>\n",
       "      <td>0.479399</td>\n",
       "      <td>0.334986</td>\n",
       "      <td>-0.984025</td>\n",
       "      <td>1.984531</td>\n",
       "      <td>-0.555264</td>\n",
       "      <td>-0.554665</td>\n",
       "      <td>-0.099532</td>\n",
       "      <td>-0.352158</td>\n",
       "      <td>0.466982</td>\n",
       "      <td>-0.264938</td>\n",
       "      <td>-0.309463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86401 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RCD_AverageThree-phaseCurrent  \\\n",
       "TIMESTAMP                                            \n",
       "2019-06-24 00:00:00                      -0.626543   \n",
       "2019-06-24 00:00:05                      -0.626543   \n",
       "2019-06-24 00:00:10                      -0.626543   \n",
       "2019-06-24 00:00:15                      -0.626543   \n",
       "2019-06-24 00:00:20                      -0.626543   \n",
       "...                                            ...   \n",
       "2019-06-28 23:59:40                      -0.600187   \n",
       "2019-06-28 23:59:45                      -0.600187   \n",
       "2019-06-28 23:59:50                      -0.600187   \n",
       "2019-06-28 23:59:55                      -0.600187   \n",
       "2019-06-29 00:00:00                      -0.600187   \n",
       "\n",
       "                     LCD_AverageThree-phaseCurrent  \\\n",
       "TIMESTAMP                                            \n",
       "2019-06-24 00:00:00                      -0.638671   \n",
       "2019-06-24 00:00:05                      -0.633343   \n",
       "2019-06-24 00:00:10                      -0.638671   \n",
       "2019-06-24 00:00:15                      -0.633343   \n",
       "2019-06-24 00:00:20                      -0.644000   \n",
       "...                                            ...   \n",
       "2019-06-28 23:59:40                      -0.633343   \n",
       "2019-06-28 23:59:45                      -0.633343   \n",
       "2019-06-28 23:59:50                      -0.633343   \n",
       "2019-06-28 23:59:55                      -0.633343   \n",
       "2019-06-29 00:00:00                      -0.633343   \n",
       "\n",
       "                     LP_AverageThree-phaseCurrent  \\\n",
       "TIMESTAMP                                           \n",
       "2019-06-24 00:00:00                     -0.684975   \n",
       "2019-06-24 00:00:05                     -0.684975   \n",
       "2019-06-24 00:00:10                     -0.684975   \n",
       "2019-06-24 00:00:15                     -0.684975   \n",
       "2019-06-24 00:00:20                     -0.684975   \n",
       "...                                           ...   \n",
       "2019-06-28 23:59:40                     -0.684975   \n",
       "2019-06-28 23:59:45                     -0.684975   \n",
       "2019-06-28 23:59:50                     -0.684975   \n",
       "2019-06-28 23:59:55                     -0.684975   \n",
       "2019-06-29 00:00:00                     -0.684975   \n",
       "\n",
       "                     LHD_LeftHaulageDrive(tractor)Temperature(gearbox)  \\\n",
       "TIMESTAMP                                                                \n",
       "2019-06-24 00:00:00                                          -1.261235   \n",
       "2019-06-24 00:00:05                                          -1.261235   \n",
       "2019-06-24 00:00:10                                          -1.261235   \n",
       "2019-06-24 00:00:15                                          -1.261235   \n",
       "2019-06-24 00:00:20                                          -1.261235   \n",
       "...                                                                ...   \n",
       "2019-06-28 23:59:40                                           0.667508   \n",
       "2019-06-28 23:59:45                                           0.667508   \n",
       "2019-06-28 23:59:50                                           0.667508   \n",
       "2019-06-28 23:59:55                                           0.667508   \n",
       "2019-06-29 00:00:00                                           0.667508   \n",
       "\n",
       "                     RHD_RightHaulageDrive(tractor)Temperature(gearbox)  \\\n",
       "TIMESTAMP                                                                 \n",
       "2019-06-24 00:00:00                                          -0.258498    \n",
       "2019-06-24 00:00:05                                          -0.258498    \n",
       "2019-06-24 00:00:10                                          -0.258498    \n",
       "2019-06-24 00:00:15                                          -0.258498    \n",
       "2019-06-24 00:00:20                                          -0.258498    \n",
       "...                                                                ...    \n",
       "2019-06-28 23:59:40                                          -0.258498    \n",
       "2019-06-28 23:59:45                                          -0.258498    \n",
       "2019-06-28 23:59:50                                          -0.258498    \n",
       "2019-06-28 23:59:55                                          -0.258498    \n",
       "2019-06-29 00:00:00                                          -0.258498    \n",
       "\n",
       "                     LA_LeftArmTemperature  RA_RightArmTemperature  \\\n",
       "TIMESTAMP                                                            \n",
       "2019-06-24 00:00:00              -1.400388               -1.420405   \n",
       "2019-06-24 00:00:05              -1.400388               -1.420405   \n",
       "2019-06-24 00:00:10              -1.400388               -1.420405   \n",
       "2019-06-24 00:00:15              -1.400388               -1.420405   \n",
       "2019-06-24 00:00:20              -1.400388               -1.420405   \n",
       "...                                    ...                     ...   \n",
       "2019-06-28 23:59:40               0.479399                0.334986   \n",
       "2019-06-28 23:59:45               0.479399                0.334986   \n",
       "2019-06-28 23:59:50               0.479399                0.334986   \n",
       "2019-06-28 23:59:55               0.479399                0.334986   \n",
       "2019-06-29 00:00:00               0.479399                0.334986   \n",
       "\n",
       "                     SM_DailyRouteOfTheShearer  SM_TotalRoute  \\\n",
       "TIMESTAMP                                                       \n",
       "2019-06-24 00:00:00                  -0.981145       1.211546   \n",
       "2019-06-24 00:00:05                  -0.984025       1.211546   \n",
       "2019-06-24 00:00:10                  -0.984025       1.211546   \n",
       "2019-06-24 00:00:15                  -0.984025       1.211546   \n",
       "2019-06-24 00:00:20                  -0.984025       1.211546   \n",
       "...                                        ...            ...   \n",
       "2019-06-28 23:59:40                   1.597454       1.984531   \n",
       "2019-06-28 23:59:45                   1.597454       1.984531   \n",
       "2019-06-28 23:59:50                   1.597454       1.984531   \n",
       "2019-06-28 23:59:55                   1.597454       1.984531   \n",
       "2019-06-29 00:00:00                  -0.984025       1.984531   \n",
       "\n",
       "                     LHD_EngineCurrent  RHD_EngineCurrent  \\\n",
       "TIMESTAMP                                                   \n",
       "2019-06-24 00:00:00          -0.555264          -0.554665   \n",
       "2019-06-24 00:00:05          -0.555264          -0.554665   \n",
       "2019-06-24 00:00:10          -0.555264          -0.554665   \n",
       "2019-06-24 00:00:15          -0.555264          -0.554665   \n",
       "2019-06-24 00:00:20          -0.555264          -0.554665   \n",
       "...                                ...                ...   \n",
       "2019-06-28 23:59:40          -0.555264          -0.554665   \n",
       "2019-06-28 23:59:45          -0.555264          -0.554665   \n",
       "2019-06-28 23:59:50          -0.555264          -0.554665   \n",
       "2019-06-28 23:59:55          -0.555264          -0.554665   \n",
       "2019-06-29 00:00:00          -0.555264          -0.554665   \n",
       "\n",
       "                     RCD_BearingTemperature  SM_ShearerSpeed  \\\n",
       "TIMESTAMP                                                      \n",
       "2019-06-24 00:00:00               -1.563860        -0.352158   \n",
       "2019-06-24 00:00:05               -1.563860        -0.352158   \n",
       "2019-06-24 00:00:10               -1.563860        -0.352158   \n",
       "2019-06-24 00:00:15               -1.563860        -0.352158   \n",
       "2019-06-24 00:00:20               -1.563860        -0.352158   \n",
       "...                                     ...              ...   \n",
       "2019-06-28 23:59:40               -0.099532        -0.352158   \n",
       "2019-06-28 23:59:45               -0.099532        -0.352158   \n",
       "2019-06-28 23:59:50               -0.099532        -0.352158   \n",
       "2019-06-28 23:59:55               -0.099532        -0.352158   \n",
       "2019-06-29 00:00:00               -0.099532        -0.352158   \n",
       "\n",
       "                     SM_ShearerLocation  SM_ShearerMoveInLeft  \\\n",
       "TIMESTAMP                                                       \n",
       "2019-06-24 00:00:00           -0.563821             -0.264938   \n",
       "2019-06-24 00:00:05           -0.563821             -0.264938   \n",
       "2019-06-24 00:00:10           -0.563821             -0.264938   \n",
       "2019-06-24 00:00:15           -0.563821             -0.264938   \n",
       "2019-06-24 00:00:20           -0.563821             -0.264938   \n",
       "...                                 ...                   ...   \n",
       "2019-06-28 23:59:40            0.466982             -0.264938   \n",
       "2019-06-28 23:59:45            0.466982             -0.264938   \n",
       "2019-06-28 23:59:50            0.466982             -0.264938   \n",
       "2019-06-28 23:59:55            0.466982             -0.264938   \n",
       "2019-06-29 00:00:00            0.466982             -0.264938   \n",
       "\n",
       "                     SM_ShearerMoveInRight  \n",
       "TIMESTAMP                                   \n",
       "2019-06-24 00:00:00              -0.309463  \n",
       "2019-06-24 00:00:05              -0.309463  \n",
       "2019-06-24 00:00:10              -0.309463  \n",
       "2019-06-24 00:00:15              -0.309463  \n",
       "2019-06-24 00:00:20              -0.309463  \n",
       "...                                    ...  \n",
       "2019-06-28 23:59:40              -0.309463  \n",
       "2019-06-28 23:59:45              -0.309463  \n",
       "2019-06-28 23:59:50              -0.309463  \n",
       "2019-06-28 23:59:55              -0.309463  \n",
       "2019-06-29 00:00:00              -0.309463  \n",
       "\n",
       "[86401 rows x 16 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalize_artifact(dr_artifact, dcae_artifact)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86401, 16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12330, 96, 16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcae_input = df_slicer(df=df,\n",
    "                       w=dcae_config.get('w').get('value'),\n",
    "                       s=dcae_config.get('stride').get('value'))\n",
    "dcae_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the latent variables from the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the DCAE model is trained, we are interested in the information contained in the **Dense** layer (also called *bottleneck*)for each slice of data. To do that, we have to call the `predict` function on an intermediate model that gets the output of the intermediate layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export dcae\n",
    "from tensorflow.keras.models import Model\n",
    "def get_latent_features(dcae, input_data, bottleneck_ln='latent_features'):\n",
    "    \"Get the activations of the bottleneck layer within the fitted autoencoder `dcae` (a Keras model) \\\n",
    "    for the input data `input_data` (a tensor). The name of the bottleneck layer is given in `bottleneck_ln\"\n",
    "    layer_latent_output = dcae.get_layer(bottleneck_ln).output\n",
    "    intermediate_model = Model(inputs=dcae.input, outputs=layer_latent_output)\n",
    "    intermediate_prediction = intermediate_model.predict(input_data)\n",
    "    return intermediate_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12330, 96)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_prediction = get_latent_features(dcae_model, dcae_input, 'latent_features')\n",
    "intermediate_prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction using UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use DR techniques to provide an alternative view for users to visually analyze and explore the time-series data. The algorithm UMAP shows its high competitiveness compared to t-SNE. t-SNE suffers from some limitations such as loss of large-scale information (the inter-cluster relationships). UMAP has a faster runtime and provides better scaling which helps to gain a meaningful organization of clusters, outliers and the preservation of continuums compared to t-SNE\n",
    "\n",
    "For this part of the implementation, the package [umap-learn](https://github.com/lmcinnes/umap) is used. The input of the algoritm is the $n \\times \\delta$ that contains, for each slice of the time series, the corresponding $\\delta$ latent features given by the DCAE.\n",
    "\n",
    "The hyperparameters of UMAP are given values by default here. If the value has been already set previously, that means this notebook is being called from a wandb sweep, and we must use the value that the sweep is bringing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_params = {\n",
    "    'n_neighbors' : config_dr.n_neighbors,\n",
    "    'min_dist' : config_dr.min_dist,\n",
    "    'metric' : config_dr.metric,\n",
    "    'verbose': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_dr.update(umap_params, allow_val_change=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finall, we gather all this functionality into a function for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import warnings\n",
    "from numba.core.errors import NumbaPerformanceWarning\n",
    "@delegates(umap.umap_.UMAP)\n",
    "def fget_UMAP_embeddings(input_data, **kwargs):\n",
    "    \"Compute the embeddings of `input_data` using UMAP, with a configuration contained in `**kwargs`. \\\n",
    "    Returns also information of the reducer.\"\n",
    "    warnings.filterwarnings(\"ignore\", category=NumbaPerformanceWarning) # silence NumbaPerformanceWarning\n",
    "    reducer = umap.UMAP(**kwargs)\n",
    "    reducer.fit(input_data)\n",
    "    embeddings = reducer.transform(input_data)\n",
    "    return (embeddings, reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(dens_frac=0.0, dens_lambda=0.0, verbose=True)\n",
      "Construct fuzzy simplicial set\n",
      "Fri May 21 14:40:05 2021 Finding Nearest Neighbors\n",
      "Fri May 21 14:40:05 2021 Building RP forest with 11 trees\n",
      "Fri May 21 14:40:09 2021 NN descent for 14 iterations\n",
      "\t 1  /  14\n",
      "\t 2  /  14\n",
      "\t 3  /  14\n",
      "\t 4  /  14\n",
      "\tStopping threshold met -- exiting after 4 iterations\n",
      "Fri May 21 14:40:25 2021 Finished Nearest Neighbor Search\n",
      "Fri May 21 14:40:27 2021 Construct embedding\n",
      "\tcompleted  0  /  200 epochs\n",
      "\tcompleted  20  /  200 epochs\n",
      "\tcompleted  40  /  200 epochs\n",
      "\tcompleted  60  /  200 epochs\n",
      "\tcompleted  80  /  200 epochs\n",
      "\tcompleted  100  /  200 epochs\n",
      "\tcompleted  120  /  200 epochs\n",
      "\tcompleted  140  /  200 epochs\n",
      "\tcompleted  160  /  200 epochs\n",
      "\tcompleted  180  /  200 epochs\n",
      "Fri May 21 14:40:37 2021 Finished embedding\n",
      "CPU times: user 4min 52s, sys: 48.7 s, total: 5min 41s\n",
      "Wall time: 32.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12330, 2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "embeddings, reducer = fget_UMAP_embeddings(intermediate_prediction, **umap_params)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(embeddings.shape, (intermediate_prediction.shape[0], reducer.n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the reducer contains the items of the configuration object\n",
    "test_eq(all(item in reducer.get_params().items() for item in dict(umap_params).items()), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the embeddings as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timecluster_extension.utils import ReferenceArtifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ref': {'hash': '-7137006075972365459', 'type': \"<class 'numpy.ndarray'>\"}},\n",
       " dict_values([<ManifestEntry ref: file:///home/victor/data/PACMEL-2019/wandb_artifacts/-7137006075972365459/-7137006075972365459>]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_ar = ReferenceArtifact(obj=embeddings, name='embeddings')\n",
    "embeddings_ar.metadata, embeddings_ar.manifest.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<timecluster_extension.utils.ReferenceArtifact at 0x7f2d4847e640>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_dr.log_artifact(embeddings_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must call wait() before accessing logged artifact properties",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-a511b58fb399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings_ar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_artifacts.py\u001b[0m in \u001b[0;36mdigest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_artifact\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_artifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_artifacts.py\u001b[0m in \u001b[0;36mdigest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_artifact\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logged_artifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2392\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2393\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2394\u001b[0m                 \u001b[0;34m\"Must call wait() before accessing logged artifact properties\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2395\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Must call wait() before accessing logged artifact properties"
     ]
    }
   ],
   "source": [
    "embeddings_ar.digest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dr.update(\n",
    "    {\n",
    "          'emb_artifact_type': embeddings_ar.type,\n",
    "          'emb_artifact_name': embeddings_ar.name,\n",
    "          'emb_artifact_digest': embeddings_ar.digest\n",
    "    }, \n",
    "    allow_val_change=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Precompudet Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to integrate precomputed clusters into the embedding space, it's necessary to log artifacts that include the labels of the newly created clusters. \n",
    "\n",
    "The cluster creation process is presented below. This creation procedure can be modified according to specific needs. However, the structure of the new artifact must be preserved (it must be a numpy.ndarray and the number of elements must be equal to the number of points in the embedding space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'HDBSCAN supported metrics: {list(hdbscan.dist_metrics.METRIC_MAPPING.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HDBSCAN parameters\n",
    "hdbscan_kwargs = {\n",
    "    'min_cluster_size' : 100,\n",
    "    'min_samples' : 15,\n",
    "    'cluster_selection_epsilon' : 0.08,\n",
    "}\n",
    "metric_kwargs = {\n",
    "    'metric' : 'jaccard'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clusters using HDBSCAN\n",
    "clusters = hdbscan.HDBSCAN(**hdbscan_kwargs, **metric_kwargs).fit(embeddings)\n",
    "clusters_labels = clusters.labels_\n",
    "clusters_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing artifact structure \n",
    "test_eq_type(type(clusters_labels), np.ndarray)\n",
    "test_eq(clusters_labels.size, embeddings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and log 'clusters_labels' artifact\n",
    "clusters_ar = ReferenceArtifact(obj=clusters_labels, name='clusters_labels')\n",
    "clusters_ar.metadata, clusters_ar.manifest.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dr.log_artifact(clusters_ar, aliases=['hdbscan_jaccard'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the connected scatter plot is a simple visualization technique, it has very specific functions in our approach. Every sliding window is represented as a dot in the plot after the projection process (Fig. 4C, D of the paper). Before labeling, all points have the same color and transparency, and when they are concentrated in one area, the densities are accumulated. Lines are used to connect consecutive points preserving the temporal ordering of the data and allowing the user to see temporal connections (Fig. 4B of the paper). Thus, the point is linked to the previous point (inner) and to the posterior point (outer) as an indication of the flow of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plot_embeddings(embeddings, umap_params, fig_size = (25,25)):\n",
    "    \"Plot 2D embeddings thorugh a connected scatter plot\"\n",
    "    df_embeddings = pd.DataFrame(embeddings, columns = ['x1', 'x2'])\n",
    "    fig = plt.figure(figsize=(fig_size[0],fig_size[1]))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(df_embeddings['x1'], df_embeddings['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)\n",
    "    ax.plot(df_embeddings['x1'], df_embeddings['x2'], alpha=0.5, picker=1)\n",
    "    plt.title('DR params -  n_neighbors:{:d} min_dist:{:f} metric:{:s}'.format(umap_params['n_neighbors'],umap_params['min_dist'],umap_params['metric']))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_plot = plot_embeddings(embeddings, umap_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log this plot as part of the current wandb run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "# Get the figure of the embedding plot, and save it on thea wandb run.\n",
    "run_dr.log({\"img\": [wandb.Image(embeddings_plot.get_figure(), caption=\"dr_embedding_plot\")]})\n",
    "\n",
    "#run_dr.log({'embeddings_plot': embeddings_plot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "run_dr.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability with SHAP (future work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# ax.scatter(df_embeddings['x1'], df_embeddings['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)\n",
    "# ax.plot(df_embeddings['x1'], df_embeddings['x2'], alpha=0.5, picker=1)\n",
    "# ax.set_title('Select the point you want to visualize as a time window in the original space')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the plot interactive to allow selection of subsets of the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_indices = None\n",
    "# selected_points = None\n",
    "\n",
    "# def onpick(event):\n",
    "#     global selected_points\n",
    "#     thisline = event.artist\n",
    "#     xdata = thisline.get_xdata()\n",
    "#     ydata = thisline.get_ydata()\n",
    "#     global selected_indices\n",
    "#     selected_indices = event.ind\n",
    "#     selected_points = tuple(zip(xdata[selected_indices], ydata[selected_indices]))\n",
    "#     print('onpick points (first):', selected_points[0])\n",
    "\n",
    "# fig.canvas.mpl_connect('pick_event', onpick)\n",
    "\n",
    "# plt.show()\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(f'../img/w={w}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for the dimensionality reduction\n",
    "\n",
    "There are a number of parameters that can be set for the UMAP algorithm. The major \n",
    "ones are `n_neighbors` and `min_dist`. Thus, we will carry out a hyperparameter \n",
    "sweep in Weights and Biases for these two parameters. Note that there is no objective\n",
    "way of deciding that some embeddings are better than others. Thus, we must rely on our\n",
    "intuition by visualizing the 2D plots of each of the runs in the sweep.\n",
    "\n",
    "The first thing we need is gather all the pipeline of the previous section into a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Linking back points of the 2D projection to the original time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `selected_points` and `ind` contain an array of the points and indices selected in the previous 2D projection. We will take the first of them (there can be many selected points with just one click), and use its index to get the corresponding time window of the original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_window = input_data[df_embeddings.sample(n=1).index][0] if selected_indices is None else input_data[selected_indices[0]]\n",
    "# selected_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing all the variables in the time window (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# g = sns.FacetGrid(df_output_tidy, col=\"variable\", col_wrap=3, aspect=2)\n",
    "# g = g.map(plt.plot, \"timestamp\", \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution: Visualize only the most relevant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In high dimensional time series, not only is interesting to see the window associated to a point in the 2D space, but also it is extremely important to spot which variables are mainly causing that the window is positioned in that point of the 2D space.\n",
    "\n",
    "Since UMAP does not provide capabilities to understand feature importance, there are [different ways](https://stats.stackexchange.com/questions/438025/understand-important-features-in-umap) to tackle this problem:\n",
    "\n",
    "1. Use another dimensionality reduction technique that provides importance, such as [sparse PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html)\n",
    "\n",
    "2. Create a surrogate model on top of the inputs/output of UMAP and explain it using XAI techniques. We will try here this option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to have a surrogate model that takes the multivariate time series as input and produces the associated points in the 2D space as ouput. Since we already have a Deep Convolutional Autoencoder (DCAE) that takes a multivariate time series as input, and it contains the latent features that represent that input, we can use it for the surrogate. We will use the intermediate model that goes from the input to the layer containing the latent space, and then add a `Dense` layer with 2 units and linear activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# def train_surrogate_model(dcae, embeddings, lat_ln='latent_features'):\n",
    "#     \"Train a surrogate model that learns the `embeddings` from the latent features contained in the layer \\\n",
    "#     `lat_ln` of a previously trained Deep Convolutional AutoEncoder `dcae`\"\n",
    "#     x = dcae.get_layer(lat_ln).output\n",
    "#     x = Dense(units=embeddings.shape[1], activation='linear')(x)\n",
    "#     surrogate_model = Model(dcae.input, x)\n",
    "#     l_nms = [layer.name for layer in surrogate_model.layers]\n",
    "#     layer_idx = l_nms.index(lat_ln)\n",
    "#     # The layers that are already trained from the autoencoder must be `frozen`\n",
    "#     for layer in surrogate_model.layers[:layer_idx]:\n",
    "#         layer.trainable = False\n",
    "#     return surrogate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = train_surrogate_model(m, embeddings, lat_ln='latent_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.equals(sm.input.shape, m.input.shape)\n",
    "# test.equals(sm.output.shape[1], embeddings.shape[1])\n",
    "# l_nms = [layer.name for layer in sm.layers]\n",
    "# layer_idx = l_nms.index('latent_features')\n",
    "# test.all_equal([layer.trainable for layer in sm.layers], \\\n",
    "#                np.repeat([False, True], [layer_idx + 1, len(sm.layers) -1 -layer_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = 'mean_squared_error'\n",
    "# opt = 'adam'\n",
    "# bs = 100\n",
    "# epochs = 10\n",
    "# val = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.fit(x=input_data, y=embeddings, batch_size=bs, validation_split=val, epochs=epochs, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import innvestigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer = innvestigate.create_analyzer(\"gradient\", intermediate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asd= innvestigate.create_analyzer(\"gradient\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data[np.random.choice(input_data.shape[0], 100, replace=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background = input_data[np.random.choice(input_data.shape[0], 100, replace=False)]\n",
    "# e = shap.DeepExplainer(intermediate_model, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values = e.shap_values(input_data[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
