{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells will be exported to pacmel_mining_use_case.dr,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "%nbdev_default_export dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put here everything that could be needed if this notebook was called from outside, using papermill. Parameters that are part of a sweep do not need to be defined here, even if they are called through papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dr_artifact_name = 'JNK:v3' # * Set to None for using the default one (DCAE)\n",
    "dcae_run_path = 'pacmel/timecluster-extension/24kd7cn2' # *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "> This notebook gets the latent features from a multivariate time series \n",
    "given by an autoencoder and uses them as input for a dimensionality reduction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "import umap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "from timecluster_extension.load import *\n",
    "from timecluster_extension.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_hide\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from yaml import load, FullLoader\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model needs to restore the model fitted in the notebook `01_DCAE`, as well as the data and configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the best run from a sweep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/pacmel/timecluster-extension\" target=\"_blank\">https://app.wandb.ai/pacmel/timecluster-extension</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/pacmel/timecluster-extension/runs/2y8gbwmf\" target=\"_blank\">https://app.wandb.ai/pacmel/timecluster-extension/runs/2y8gbwmf</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "run_dr = wandb.init(entity=\"pacmel\",\n",
    "                    project=\"timecluster-extension\", \n",
    "                    allow_val_change=True, \n",
    "                    job_type='dimensionality_reduction')\n",
    "config_dr = wandb.config # Object for storing hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore a DCAE model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcae_model = load_model(wandb.restore('model-best.h5', replace=True, run_path=dcae_run_path).name)\n",
    "with open(wandb.restore('config.yaml', replace=True, run_path=dcae_run_path).name) as file:\n",
    "    dcae_config = load(file, FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb_version: 1\n",
      "\n",
      "_wandb:\n",
      "  desc: null\n",
      "  value:\n",
      "    cli_version: 0.9.7\n",
      "    framework: tensorflow\n",
      "    is_jupyter_run: true\n",
      "    is_kaggle_kernel: false\n",
      "    python_version: 3.6.9\n",
      "dcae_run_path:\n",
      "  desc: null\n",
      "  value: pacmel/timecluster-extension/24kd7cn2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_dr.update({\n",
    "    'dcae_run_path' : dcae_run_path\n",
    "    }, \n",
    "    allow_val_change=True\n",
    ")\n",
    "print(config_dr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the dataset artifact used for creating the DCAE. Even if we do not compute the dimensionality reduction over this dataset,\n",
    "we need to know the metadata of the dataset of the DCAE, to check that it matches with the dataset that we want to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dataset', 'JNK:v2', '7eb36be001b3789dd2f8d1619a2720a5')"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcae_artifact_type = dcae_config.get('ds_artifact_type').get('value')\n",
    "dcae_artifact_name = dcae_config.get('ds_artifact_name').get('value')\n",
    "dcae_artifact_digest = dcae_config.get('ds_artifact_digest').get('value')\n",
    "dcae_artifact_type, dcae_artifact_name, dcae_artifact_digest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TS': {'ed': '2019-06-10 23:59:55',\n",
       "  'sd': '2019-06-01 00:00:00',\n",
       "  'freq': '<5 * Seconds>',\n",
       "  'hash': '1919020611002141401',\n",
       "  'vars': ['RCD_AverageThree-phaseCurrent',\n",
       "   'LCD_AverageThree-phaseCurrent',\n",
       "   'LP_AverageThree-phaseCurrent',\n",
       "   'LHD_LeftHaulageDrive(tractor)Temperature(gearbox)',\n",
       "   'RHD_RightHaulageDrive(tractor)Temperature(gearbox)',\n",
       "   'LA_LeftArmTemperature',\n",
       "   'RA_RightArmTemperature',\n",
       "   'SM_DailyRouteOfTheShearer',\n",
       "   'SM_TotalRoute',\n",
       "   'LHD_EngineCurrent',\n",
       "   'RHD_EngineCurrent',\n",
       "   'RCD_BearingTemperature',\n",
       "   'SM_ShearerSpeed',\n",
       "   'SM_ShearerLocation',\n",
       "   'SM_ShearerMoveInLeft',\n",
       "   'SM_ShearerMoveInRight'],\n",
       "  'n_vars': 16,\n",
       "  'created': 'from-df',\n",
       "  'n_samples': 172800,\n",
       "  'normalization': {'stds': {'SM_TotalRoute': 11.225787346697574,\n",
       "    'SM_ShearerSpeed': 2.9077431001835867,\n",
       "    'LHD_EngineCurrent': 22.343715753020746,\n",
       "    'RHD_EngineCurrent': 21.791498792904196,\n",
       "    'SM_ShearerLocation': 89.69297001102812,\n",
       "    'SM_ShearerMoveInLeft': 0.2438426450950956,\n",
       "    'LA_LeftArmTemperature': 12.625185345268926,\n",
       "    'SM_ShearerMoveInRight': 0.29917885746919287,\n",
       "    'RA_RightArmTemperature': 16.54166491720409,\n",
       "    'RCD_BearingTemperature': 15.94356411274981,\n",
       "    'SM_DailyRouteOfTheShearer': 1069.2643430117464,\n",
       "    'LP_AverageThree-phaseCurrent': 2.4762511407604766,\n",
       "    'LCD_AverageThree-phaseCurrent': 34.32679724514462,\n",
       "    'RCD_AverageThree-phaseCurrent': 37.83062195455937,\n",
       "    'LHD_LeftHaulageDrive(tractor)Temperature(gearbox)': 25.85561071304018,\n",
       "    'RHD_RightHaulageDrive(tractor)Temperature(gearbox)': 18.96694374934663},\n",
       "   'means': {'SM_TotalRoute': 129.42983975694443,\n",
       "    'SM_ShearerSpeed': 1.1204710648148148,\n",
       "    'LHD_EngineCurrent': 12.796800347222224,\n",
       "    'RHD_EngineCurrent': 12.471776041666669,\n",
       "    'SM_ShearerLocation': 120.40853993055558,\n",
       "    'SM_ShearerMoveInLeft': 0.06525289351851851,\n",
       "    'LA_LeftArmTemperature': 38.294305555555546,\n",
       "    'SM_ShearerMoveInRight': 0.10231539351851852,\n",
       "    'RA_RightArmTemperature': 45.11199421296297,\n",
       "    'RCD_BearingTemperature': 55.20641030092592,\n",
       "    'SM_DailyRouteOfTheShearer': 1050.316368634259,\n",
       "    'LP_AverageThree-phaseCurrent': 1.6554114583333333,\n",
       "    'LCD_AverageThree-phaseCurrent': 35.23550983796297,\n",
       "    'RCD_AverageThree-phaseCurrent': 37.00287326388889,\n",
       "    'LHD_LeftHaulageDrive(tractor)Temperature(gearbox)': 55.24939930555555,\n",
       "    'RHD_RightHaulageDrive(tractor)Temperature(gearbox)': 7.749042824074075}},\n",
       "  'has_missing_values': 'False'}}"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcae_artifact = run_dr.use_artifact(dcae_artifact_name)\n",
    "dcae_artifact.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify the dataset artifact that we want to use for the reduction. If no artifact is defined, the artifact to reduce will be the one used for training the DCAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "if dr_artifact_name is not None:\n",
    "    dr_artifact = run_dr.use_artifact(dr_artifact_name, type='dataset')\n",
    "else:\n",
    "    dr_artifact = dcae_artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to check whether the artifact that is going to be used fort the dimensionality reduction matches the artifact used to train the DCAE. Matching means having the same number of variables, the same window size and stride, and the same frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def check_compatibility(dr_ar:TSArtifact, dcae_ar:TSArtifact):\n",
    "    \"Function to check that the artifact used by the DCAE and the artifact that is \\\n",
    "    going to be passed through the DR are compatible\"\n",
    "    try:\n",
    "        # Check that both artifacts have the same variables\n",
    "        chk_vars = dr_ar.metadata['TS']['vars'] == dcae_ar.metadata['TS']['vars']\n",
    "        # Check that both artifacts have the same freq\n",
    "        chk_freq = dr_ar.metadata['TS']['freq'] == dcae_ar.metadata['TS']['freq']\n",
    "        # Check that the dr artifact is not normalized (not normalized data has not the key normalization)\n",
    "        chk_norm = dr_ar.metadata['TS'].get('normalization') is None\n",
    "        # Check that the dr artifact has not missing values\n",
    "        chk_miss = dr_ar.metadata['TS']['has_missing_values'] == \"False\"\n",
    "        # Check all logical vars.\n",
    "        if chk_vars and chk_freq and chk_norm and chk_miss:\n",
    "            print(\"Artifacts are compatible.\")\n",
    "        else:\n",
    "            raise Exception\n",
    "    except Exception as e:\n",
    "        print(\"Artifacts are not complatible.\")\n",
    "        raise e\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def normalize_dr_artifact(dr_ar:TSArtifact, dcae_ar:TSArtifact):\n",
    "    \"Function to normalize the dr artifact with the normalization parameters of the \\\n",
    "    dcae artifact\"\n",
    "    # Check that artifacts are compatible\n",
    "    check_compatibility(dr_ar,dcae_ar)\n",
    "    # Get the normalization parameters of dcae_ar\n",
    "    dcae_stds = dcae_ar.metadata['TS']['normalization']['stds']\n",
    "    dcae_means = dcae_ar.metadata['TS']['normalization']['means']\n",
    "    # Transform dr_ar to pandas and iterate over columns\n",
    "    dr_ar_df = dr_ar.to_df()\n",
    "    # Iterate over df columns to normalize them with means and stds of dcae_ar\n",
    "    for column_name in dr_ar_df:\n",
    "        dr_ar_df[column_name] = (dr_ar_df[column_name] - dcae_means[column_name])/dcae_stds[column_name]\n",
    "    \n",
    "    return dr_ar_df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts are compatible.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RCD_AverageThree-phaseCurrent</th>\n",
       "      <th>LCD_AverageThree-phaseCurrent</th>\n",
       "      <th>LP_AverageThree-phaseCurrent</th>\n",
       "      <th>LHD_LeftHaulageDrive(tractor)Temperature(gearbox)</th>\n",
       "      <th>RHD_RightHaulageDrive(tractor)Temperature(gearbox)</th>\n",
       "      <th>LA_LeftArmTemperature</th>\n",
       "      <th>RA_RightArmTemperature</th>\n",
       "      <th>SM_DailyRouteOfTheShearer</th>\n",
       "      <th>SM_TotalRoute</th>\n",
       "      <th>LHD_EngineCurrent</th>\n",
       "      <th>RHD_EngineCurrent</th>\n",
       "      <th>RCD_BearingTemperature</th>\n",
       "      <th>SM_ShearerSpeed</th>\n",
       "      <th>SM_ShearerLocation</th>\n",
       "      <th>SM_ShearerMoveInLeft</th>\n",
       "      <th>SM_ShearerMoveInRight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-06-11 00:00:00</th>\n",
       "      <td>0.745352</td>\n",
       "      <td>0.896224</td>\n",
       "      <td>0.785295</td>\n",
       "      <td>0.261088</td>\n",
       "      <td>-0.408555</td>\n",
       "      <td>1.243997</td>\n",
       "      <td>0.658217</td>\n",
       "      <td>-0.459864</td>\n",
       "      <td>1.342459</td>\n",
       "      <td>1.056369</td>\n",
       "      <td>1.143943</td>\n",
       "      <td>1.492363</td>\n",
       "      <td>-0.316559</td>\n",
       "      <td>1.054614</td>\n",
       "      <td>-0.267602</td>\n",
       "      <td>0.326509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-11 00:00:05</th>\n",
       "      <td>0.808793</td>\n",
       "      <td>0.896224</td>\n",
       "      <td>0.542994</td>\n",
       "      <td>0.261088</td>\n",
       "      <td>-0.408555</td>\n",
       "      <td>1.243997</td>\n",
       "      <td>0.658217</td>\n",
       "      <td>-0.982279</td>\n",
       "      <td>1.342459</td>\n",
       "      <td>1.217488</td>\n",
       "      <td>1.336678</td>\n",
       "      <td>1.492363</td>\n",
       "      <td>-0.041431</td>\n",
       "      <td>1.054614</td>\n",
       "      <td>-0.267602</td>\n",
       "      <td>3.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-11 00:00:10</th>\n",
       "      <td>1.078415</td>\n",
       "      <td>0.913703</td>\n",
       "      <td>0.542994</td>\n",
       "      <td>0.261088</td>\n",
       "      <td>-0.408555</td>\n",
       "      <td>1.243997</td>\n",
       "      <td>0.658217</td>\n",
       "      <td>-0.982279</td>\n",
       "      <td>1.342459</td>\n",
       "      <td>1.405460</td>\n",
       "      <td>1.373390</td>\n",
       "      <td>1.492363</td>\n",
       "      <td>0.302478</td>\n",
       "      <td>1.054614</td>\n",
       "      <td>-0.267602</td>\n",
       "      <td>3.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-11 00:00:15</th>\n",
       "      <td>1.020261</td>\n",
       "      <td>0.954487</td>\n",
       "      <td>0.623761</td>\n",
       "      <td>0.261088</td>\n",
       "      <td>-0.408555</td>\n",
       "      <td>1.243997</td>\n",
       "      <td>0.658217</td>\n",
       "      <td>-0.982279</td>\n",
       "      <td>1.342459</td>\n",
       "      <td>1.468117</td>\n",
       "      <td>1.098053</td>\n",
       "      <td>1.492363</td>\n",
       "      <td>0.646388</td>\n",
       "      <td>1.054614</td>\n",
       "      <td>-0.267602</td>\n",
       "      <td>3.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-11 00:00:20</th>\n",
       "      <td>1.173576</td>\n",
       "      <td>0.971966</td>\n",
       "      <td>1.027597</td>\n",
       "      <td>0.261088</td>\n",
       "      <td>-0.408555</td>\n",
       "      <td>1.243997</td>\n",
       "      <td>0.658217</td>\n",
       "      <td>-0.982279</td>\n",
       "      <td>1.342459</td>\n",
       "      <td>1.342803</td>\n",
       "      <td>1.171476</td>\n",
       "      <td>1.492363</td>\n",
       "      <td>0.646388</td>\n",
       "      <td>1.056844</td>\n",
       "      <td>-0.267602</td>\n",
       "      <td>3.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-12 23:59:35</th>\n",
       "      <td>0.930387</td>\n",
       "      <td>1.135104</td>\n",
       "      <td>1.350666</td>\n",
       "      <td>0.299765</td>\n",
       "      <td>-0.408555</td>\n",
       "      <td>0.847963</td>\n",
       "      <td>-0.006770</td>\n",
       "      <td>2.376104</td>\n",
       "      <td>2.099644</td>\n",
       "      <td>-0.572725</td>\n",
       "      <td>-0.572323</td>\n",
       "      <td>0.614266</td>\n",
       "      <td>-0.385340</td>\n",
       "      <td>-0.439372</td>\n",
       "      <td>-0.267602</td>\n",
       "      <td>-0.341987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-12 23:59:40</th>\n",
       "      <td>0.940961</td>\n",
       "      <td>1.140931</td>\n",
       "      <td>1.350666</td>\n",
       "      <td>0.299765</td>\n",
       "      <td>-0.408555</td>\n",
       "      <td>0.847963</td>\n",
       "      <td>-0.006770</td>\n",
       "      <td>2.376104</td>\n",
       "      <td>2.099644</td>\n",
       "      <td>-0.572725</td>\n",
       "      <td>-0.572323</td>\n",
       "      <td>0.614266</td>\n",
       "      <td>-0.385340</td>\n",
       "      <td>-0.439372</td>\n",
       "      <td>-0.267602</td>\n",
       "      <td>-0.341987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-12 23:59:45</th>\n",
       "      <td>0.946247</td>\n",
       "      <td>1.146757</td>\n",
       "      <td>1.350666</td>\n",
       "      <td>0.299765</td>\n",
       "      <td>-0.408555</td>\n",
       "      <td>0.847963</td>\n",
       "      <td>-0.006770</td>\n",
       "      <td>2.376104</td>\n",
       "      <td>2.099644</td>\n",
       "      <td>-0.572725</td>\n",
       "      <td>-0.572323</td>\n",
       "      <td>0.614266</td>\n",
       "      <td>-0.385340</td>\n",
       "      <td>-0.439372</td>\n",
       "      <td>-0.267602</td>\n",
       "      <td>-0.341987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-12 23:59:50</th>\n",
       "      <td>0.940961</td>\n",
       "      <td>1.158410</td>\n",
       "      <td>1.350666</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>-0.408555</td>\n",
       "      <td>0.847963</td>\n",
       "      <td>-0.006770</td>\n",
       "      <td>2.376104</td>\n",
       "      <td>2.099644</td>\n",
       "      <td>0.940005</td>\n",
       "      <td>1.070519</td>\n",
       "      <td>0.614266</td>\n",
       "      <td>-0.316559</td>\n",
       "      <td>-0.439372</td>\n",
       "      <td>0.552599</td>\n",
       "      <td>-0.341987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-12 23:59:55</th>\n",
       "      <td>0.972681</td>\n",
       "      <td>1.129278</td>\n",
       "      <td>1.350666</td>\n",
       "      <td>0.338441</td>\n",
       "      <td>-0.408555</td>\n",
       "      <td>0.847963</td>\n",
       "      <td>-0.006770</td>\n",
       "      <td>2.376104</td>\n",
       "      <td>2.099644</td>\n",
       "      <td>0.940005</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.614266</td>\n",
       "      <td>0.302478</td>\n",
       "      <td>-0.441601</td>\n",
       "      <td>3.833403</td>\n",
       "      <td>-0.341987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34560 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RCD_AverageThree-phaseCurrent  \\\n",
       "TIMESTAMP                                            \n",
       "2019-06-11 00:00:00                       0.745352   \n",
       "2019-06-11 00:00:05                       0.808793   \n",
       "2019-06-11 00:00:10                       1.078415   \n",
       "2019-06-11 00:00:15                       1.020261   \n",
       "2019-06-11 00:00:20                       1.173576   \n",
       "...                                            ...   \n",
       "2019-06-12 23:59:35                       0.930387   \n",
       "2019-06-12 23:59:40                       0.940961   \n",
       "2019-06-12 23:59:45                       0.946247   \n",
       "2019-06-12 23:59:50                       0.940961   \n",
       "2019-06-12 23:59:55                       0.972681   \n",
       "\n",
       "                     LCD_AverageThree-phaseCurrent  \\\n",
       "TIMESTAMP                                            \n",
       "2019-06-11 00:00:00                       0.896224   \n",
       "2019-06-11 00:00:05                       0.896224   \n",
       "2019-06-11 00:00:10                       0.913703   \n",
       "2019-06-11 00:00:15                       0.954487   \n",
       "2019-06-11 00:00:20                       0.971966   \n",
       "...                                            ...   \n",
       "2019-06-12 23:59:35                       1.135104   \n",
       "2019-06-12 23:59:40                       1.140931   \n",
       "2019-06-12 23:59:45                       1.146757   \n",
       "2019-06-12 23:59:50                       1.158410   \n",
       "2019-06-12 23:59:55                       1.129278   \n",
       "\n",
       "                     LP_AverageThree-phaseCurrent  \\\n",
       "TIMESTAMP                                           \n",
       "2019-06-11 00:00:00                      0.785295   \n",
       "2019-06-11 00:00:05                      0.542994   \n",
       "2019-06-11 00:00:10                      0.542994   \n",
       "2019-06-11 00:00:15                      0.623761   \n",
       "2019-06-11 00:00:20                      1.027597   \n",
       "...                                           ...   \n",
       "2019-06-12 23:59:35                      1.350666   \n",
       "2019-06-12 23:59:40                      1.350666   \n",
       "2019-06-12 23:59:45                      1.350666   \n",
       "2019-06-12 23:59:50                      1.350666   \n",
       "2019-06-12 23:59:55                      1.350666   \n",
       "\n",
       "                     LHD_LeftHaulageDrive(tractor)Temperature(gearbox)  \\\n",
       "TIMESTAMP                                                                \n",
       "2019-06-11 00:00:00                                           0.261088   \n",
       "2019-06-11 00:00:05                                           0.261088   \n",
       "2019-06-11 00:00:10                                           0.261088   \n",
       "2019-06-11 00:00:15                                           0.261088   \n",
       "2019-06-11 00:00:20                                           0.261088   \n",
       "...                                                                ...   \n",
       "2019-06-12 23:59:35                                           0.299765   \n",
       "2019-06-12 23:59:40                                           0.299765   \n",
       "2019-06-12 23:59:45                                           0.299765   \n",
       "2019-06-12 23:59:50                                           0.307500   \n",
       "2019-06-12 23:59:55                                           0.338441   \n",
       "\n",
       "                     RHD_RightHaulageDrive(tractor)Temperature(gearbox)  \\\n",
       "TIMESTAMP                                                                 \n",
       "2019-06-11 00:00:00                                          -0.408555    \n",
       "2019-06-11 00:00:05                                          -0.408555    \n",
       "2019-06-11 00:00:10                                          -0.408555    \n",
       "2019-06-11 00:00:15                                          -0.408555    \n",
       "2019-06-11 00:00:20                                          -0.408555    \n",
       "...                                                                ...    \n",
       "2019-06-12 23:59:35                                          -0.408555    \n",
       "2019-06-12 23:59:40                                          -0.408555    \n",
       "2019-06-12 23:59:45                                          -0.408555    \n",
       "2019-06-12 23:59:50                                          -0.408555    \n",
       "2019-06-12 23:59:55                                          -0.408555    \n",
       "\n",
       "                     LA_LeftArmTemperature  RA_RightArmTemperature  \\\n",
       "TIMESTAMP                                                            \n",
       "2019-06-11 00:00:00               1.243997                0.658217   \n",
       "2019-06-11 00:00:05               1.243997                0.658217   \n",
       "2019-06-11 00:00:10               1.243997                0.658217   \n",
       "2019-06-11 00:00:15               1.243997                0.658217   \n",
       "2019-06-11 00:00:20               1.243997                0.658217   \n",
       "...                                    ...                     ...   \n",
       "2019-06-12 23:59:35               0.847963               -0.006770   \n",
       "2019-06-12 23:59:40               0.847963               -0.006770   \n",
       "2019-06-12 23:59:45               0.847963               -0.006770   \n",
       "2019-06-12 23:59:50               0.847963               -0.006770   \n",
       "2019-06-12 23:59:55               0.847963               -0.006770   \n",
       "\n",
       "                     SM_DailyRouteOfTheShearer  SM_TotalRoute  \\\n",
       "TIMESTAMP                                                       \n",
       "2019-06-11 00:00:00                  -0.459864       1.342459   \n",
       "2019-06-11 00:00:05                  -0.982279       1.342459   \n",
       "2019-06-11 00:00:10                  -0.982279       1.342459   \n",
       "2019-06-11 00:00:15                  -0.982279       1.342459   \n",
       "2019-06-11 00:00:20                  -0.982279       1.342459   \n",
       "...                                        ...            ...   \n",
       "2019-06-12 23:59:35                   2.376104       2.099644   \n",
       "2019-06-12 23:59:40                   2.376104       2.099644   \n",
       "2019-06-12 23:59:45                   2.376104       2.099644   \n",
       "2019-06-12 23:59:50                   2.376104       2.099644   \n",
       "2019-06-12 23:59:55                   2.376104       2.099644   \n",
       "\n",
       "                     LHD_EngineCurrent  RHD_EngineCurrent  \\\n",
       "TIMESTAMP                                                   \n",
       "2019-06-11 00:00:00           1.056369           1.143943   \n",
       "2019-06-11 00:00:05           1.217488           1.336678   \n",
       "2019-06-11 00:00:10           1.405460           1.373390   \n",
       "2019-06-11 00:00:15           1.468117           1.098053   \n",
       "2019-06-11 00:00:20           1.342803           1.171476   \n",
       "...                                ...                ...   \n",
       "2019-06-12 23:59:35          -0.572725          -0.572323   \n",
       "2019-06-12 23:59:40          -0.572725          -0.572323   \n",
       "2019-06-12 23:59:45          -0.572725          -0.572323   \n",
       "2019-06-12 23:59:50           0.940005           1.070519   \n",
       "2019-06-12 23:59:55           0.940005           0.942029   \n",
       "\n",
       "                     RCD_BearingTemperature  SM_ShearerSpeed  \\\n",
       "TIMESTAMP                                                      \n",
       "2019-06-11 00:00:00                1.492363        -0.316559   \n",
       "2019-06-11 00:00:05                1.492363        -0.041431   \n",
       "2019-06-11 00:00:10                1.492363         0.302478   \n",
       "2019-06-11 00:00:15                1.492363         0.646388   \n",
       "2019-06-11 00:00:20                1.492363         0.646388   \n",
       "...                                     ...              ...   \n",
       "2019-06-12 23:59:35                0.614266        -0.385340   \n",
       "2019-06-12 23:59:40                0.614266        -0.385340   \n",
       "2019-06-12 23:59:45                0.614266        -0.385340   \n",
       "2019-06-12 23:59:50                0.614266        -0.316559   \n",
       "2019-06-12 23:59:55                0.614266         0.302478   \n",
       "\n",
       "                     SM_ShearerLocation  SM_ShearerMoveInLeft  \\\n",
       "TIMESTAMP                                                       \n",
       "2019-06-11 00:00:00            1.054614             -0.267602   \n",
       "2019-06-11 00:00:05            1.054614             -0.267602   \n",
       "2019-06-11 00:00:10            1.054614             -0.267602   \n",
       "2019-06-11 00:00:15            1.054614             -0.267602   \n",
       "2019-06-11 00:00:20            1.056844             -0.267602   \n",
       "...                                 ...                   ...   \n",
       "2019-06-12 23:59:35           -0.439372             -0.267602   \n",
       "2019-06-12 23:59:40           -0.439372             -0.267602   \n",
       "2019-06-12 23:59:45           -0.439372             -0.267602   \n",
       "2019-06-12 23:59:50           -0.439372              0.552599   \n",
       "2019-06-12 23:59:55           -0.441601              3.833403   \n",
       "\n",
       "                     SM_ShearerMoveInRight  \n",
       "TIMESTAMP                                   \n",
       "2019-06-11 00:00:00               0.326509  \n",
       "2019-06-11 00:00:05               3.000495  \n",
       "2019-06-11 00:00:10               3.000495  \n",
       "2019-06-11 00:00:15               3.000495  \n",
       "2019-06-11 00:00:20               3.000495  \n",
       "...                                    ...  \n",
       "2019-06-12 23:59:35              -0.341987  \n",
       "2019-06-12 23:59:40              -0.341987  \n",
       "2019-06-12 23:59:45              -0.341987  \n",
       "2019-06-12 23:59:50              -0.341987  \n",
       "2019-06-12 23:59:55              -0.341987  \n",
       "\n",
       "[34560 rows x 16 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalize_dr_artifact(dr_artifact, dcae_artifact)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2953, 48, 16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcae_input = df_slicer(df = df[:3000], # TODO: This is just for testing, the subset must be something implicit in the artifact\n",
    "                       w=dcae_config.get('w').get('value'),\n",
    "                       s=dcae_config.get('stride').get('value'))\n",
    "dcae_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the latent variables from the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the DCAE model is trained, we are interested in the information contained in the **Dense** layer (also called *bottleneck*)for each slice of data. To do that, we have to call the `predict` function on an intermediate model that gets the output of the intermediate layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export dcae\n",
    "from tensorflow.keras.models import Model\n",
    "def get_latent_features(dcae, input_data, bottleneck_ln='latent_features'):\n",
    "    \"Get the activations of the bottleneck layer within the fitted autoencoder `dcae` (a Keras model) \\\n",
    "    for the input data `input_data` (a tensor). The name of the bottleneck layer is given in `bottleneck_ln\"\n",
    "    layer_latent_output = dcae.get_layer(bottleneck_ln).output\n",
    "    intermediate_model = Model(inputs=dcae.input, outputs=layer_latent_output)\n",
    "    intermediate_prediction = intermediate_model.predict(input_data)\n",
    "    return intermediate_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2953, 48)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_prediction = get_latent_features(dcae_model, dcae_input, 'latent_features')\n",
    "intermediate_prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction using UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use DR techniques to provide an alternative view for users to visually analyze and explore the time-series data. The algorithm UMAP shows its high competitiveness compared to t-SNE. t-SNE suffers from some limitations such as loss of large-scale information (the inter-cluster relationships). UMAP has a faster runtime and provides better scaling which helps to gain a meaningful organization of clusters, outliers and the preservation of continuums compared to t-SNE\n",
    "\n",
    "For this part of the implementation, the package [umap-learn](https://github.com/lmcinnes/umap) is used. The input of the algoritm is the $n \\times \\delta$ that contains, for each slice of the time series, the corresponding $\\delta$ latent features given by the DCAE.\n",
    "\n",
    "The hyperparameters of UMAP are given values by default here. If the value has been already set previously, that means this notebook is being called from a wandb sweep, and we must use the value that the sweep is bringing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config_dr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9578219272e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'config_dr' is not defined"
     ]
    }
   ],
   "source": [
    "config_dr.n_neighbors = ifnone(config_dr.get('n_neighbors'), 15)\n",
    "config_dr.min_dist = ifnone(config_dr.get('min_dist'), 0.1)\n",
    "config_dr.metric = ifnone(config_dr.get('metric'), 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_params = {\n",
    "    'n_neighbors' : config_dr.n_neighbors,\n",
    "    'min_dist' : config_dr.min_dist,\n",
    "    'metric' : config_dr.metric,\n",
    "    'verbose': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "# config_dr.update(umap_params, allow_val_change=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finall, we gather all this functionality into a function for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "import warnings\n",
    "from numba.core.errors import NumbaPerformanceWarning\n",
    "@delegates(umap.umap_.UMAP)\n",
    "def fget_UMAP_embeddings(input_data, **kwargs):\n",
    "    \"Compute the embeddings of `input_data` using UMAP, with a configuration contained in `**kwargs`. \\\n",
    "    Returns also information of the reducer.\"\n",
    "    warnings.filterwarnings(\"ignore\", category=NumbaPerformanceWarning) # silence NumbaPerformanceWarning\n",
    "    reducer = umap.UMAP(**kwargs)\n",
    "    reducer.fit(input_data)\n",
    "    embeddings = reducer.transform(input_data)\n",
    "    return (embeddings, reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(min_dist=0.2, n_neighbors=5, verbose=True)\n",
      "Construct fuzzy simplicial set\n",
      "Mon Oct 19 09:39:15 2020 Finding Nearest Neighbors\n",
      "Mon Oct 19 09:39:15 2020 Finished Nearest Neighbor Search\n",
      "Mon Oct 19 09:39:15 2020 Construct embedding\n",
      "\tcompleted  0  /  500 epochs\n",
      "\tcompleted  50  /  500 epochs\n",
      "\tcompleted  100  /  500 epochs\n",
      "\tcompleted  150  /  500 epochs\n",
      "\tcompleted  200  /  500 epochs\n",
      "\tcompleted  250  /  500 epochs\n",
      "\tcompleted  300  /  500 epochs\n",
      "\tcompleted  350  /  500 epochs\n",
      "\tcompleted  400  /  500 epochs\n",
      "\tcompleted  450  /  500 epochs\n",
      "Mon Oct 19 09:39:53 2020 Finished embedding\n",
      "CPU times: user 4min 35s, sys: 11min 53s, total: 16min 29s\n",
      "Wall time: 42.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2953, 2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "embeddings, reducer = fget_UMAP_embeddings(intermediate_prediction, **umap_params)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(embeddings.shape, (intermediate_prediction.shape[0], reducer.n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the reducer contains the items of the configuration object\n",
    "test_eq(all(item in reducer.get_params().items() for item in dict(umap_params).items()), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the embeddings as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timecluster_extension.utils import ReferenceArtifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ref': {'hash': '-8004226821615815487', 'type': \"<class 'numpy.ndarray'>\"}},\n",
       " dict_values([<ManifestEntry ref: file:///home/user/data/PACMEL-2019/wandb_artifacts/-8004226821615815487/-8004226821615815487>]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_ar = ReferenceArtifact(obj=embeddings, name='embeddings')\n",
    "embeddings_ar.metadata, embeddings_ar.manifest.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ruta_wandb_artifacts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-3970a631f5db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mruta_wandb_artifacts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ruta_wandb_artifacts' is not defined"
     ]
    }
   ],
   "source": [
    "Path.home()/ruta_wandb_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dr.log_artifact(embeddings_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_ar.digest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dr.update(\n",
    "    {\n",
    "          'emb_artifact_type': embeddings_ar.type,\n",
    "          'emb_artifact_name': embeddings_ar.name,\n",
    "          'emb_artifact_digest': embeddings_ar.digest\n",
    "    }, \n",
    "    allow_val_change=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the connected scatter plot is a simple visualization technique, it has very specific functions in our approach. Every sliding window is represented as a dot in the plot after the projection process (Fig. 4C, D of the paper). Before labeling, all points have the same color and transparency, and when they are concentrated in one area, the densities are accumulated. Lines are used to connect consecutive points preserving the temporal ordering of the data and allowing the user to see temporal connections (Fig. 4B of the paper). Thus, the point is linked to the previous point (inner) and to the posterior point (outer) as an indication of the flow of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def plot_embeddings(embeddings):\n",
    "    \"Plot 2D embeddings thorugh a connected scatter plot\"\n",
    "    df_embeddings = pd.DataFrame(embeddings, columns = ['x1', 'x2'])\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(df_embeddings['x1'], df_embeddings['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)\n",
    "    ax.plot(df_embeddings['x1'], df_embeddings['x2'], alpha=0.5, picker=1)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_plot = plot_embeddings(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log this plot as part of the current wandb run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_hide\n",
    "run_dr.log({'embeddings_plot': embeddings_plot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dr.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability with SHAP (future work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# ax.scatter(df_embeddings['x1'], df_embeddings['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)\n",
    "# ax.plot(df_embeddings['x1'], df_embeddings['x2'], alpha=0.5, picker=1)\n",
    "# ax.set_title('Select the point you want to visualize as a time window in the original space')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the plot interactive to allow selection of subsets of the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_indices = None\n",
    "# selected_points = None\n",
    "\n",
    "# def onpick(event):\n",
    "#     global selected_points\n",
    "#     thisline = event.artist\n",
    "#     xdata = thisline.get_xdata()\n",
    "#     ydata = thisline.get_ydata()\n",
    "#     global selected_indices\n",
    "#     selected_indices = event.ind\n",
    "#     selected_points = tuple(zip(xdata[selected_indices], ydata[selected_indices]))\n",
    "#     print('onpick points (first):', selected_points[0])\n",
    "\n",
    "# fig.canvas.mpl_connect('pick_event', onpick)\n",
    "\n",
    "# plt.show()\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(f'../img/w={w}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for the dimensionality reduction\n",
    "\n",
    "There are a number of parameters that can be set for the UMAP algorithm. The major \n",
    "ones are `n_neighbors` and `min_dist`. Thus, we will carry out a hyperparameter \n",
    "sweep in Weights and Biases for these two parameters. Note that there is no objective\n",
    "way of deciding that some embeddings are better than others. Thus, we must rely on our\n",
    "intuition by visualizing the 2D plots of each of the runs in the sweep.\n",
    "\n",
    "The first thing we need is gather all the pipeline of the previous section into a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Linking back points of the 2D projection to the original time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `selected_points` and `ind` contain an array of the points and indices selected in the previous 2D projection. We will take the first of them (there can be many selected points with just one click), and use its index to get the corresponding time window of the original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_window = input_data[df_embeddings.sample(n=1).index][0] if selected_indices is None else input_data[selected_indices[0]]\n",
    "# selected_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing all the variables in the time window (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# g = sns.FacetGrid(df_output_tidy, col=\"variable\", col_wrap=3, aspect=2)\n",
    "# g = g.map(plt.plot, \"timestamp\", \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution: Visualize only the most relevant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In high dimensional time series, not only is interesting to see the window associated to a point in the 2D space, but also it is extremely important to spot which variables are mainly causing that the window is positioned in that point of the 2D space.\n",
    "\n",
    "Since UMAP does not provide capabilities to understand feature importance, there are [different ways](https://stats.stackexchange.com/questions/438025/understand-important-features-in-umap) to tackle this problem:\n",
    "\n",
    "1. Use another dimensionality reduction technique that provides importance, such as [sparse PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html)\n",
    "\n",
    "2. Create a surrogate model on top of the inputs/output of UMAP and explain it using XAI techniques. We will try here this option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to have a surrogate model that takes the multivariate time series as input and produces the associated points in the 2D space as ouput. Since we already have a Deep Convolutional Autoencoder (DCAE) that takes a multivariate time series as input, and it contains the latent features that represent that input, we can use it for the surrogate. We will use the intermediate model that goes from the input to the layer containing the latent space, and then add a `Dense` layer with 2 units and linear activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "# def train_surrogate_model(dcae, embeddings, lat_ln='latent_features'):\n",
    "#     \"Train a surrogate model that learns the `embeddings` from the latent features contained in the layer \\\n",
    "#     `lat_ln` of a previously trained Deep Convolutional AutoEncoder `dcae`\"\n",
    "#     x = dcae.get_layer(lat_ln).output\n",
    "#     x = Dense(units=embeddings.shape[1], activation='linear')(x)\n",
    "#     surrogate_model = Model(dcae.input, x)\n",
    "#     l_nms = [layer.name for layer in surrogate_model.layers]\n",
    "#     layer_idx = l_nms.index(lat_ln)\n",
    "#     # The layers that are already trained from the autoencoder must be `frozen`\n",
    "#     for layer in surrogate_model.layers[:layer_idx]:\n",
    "#         layer.trainable = False\n",
    "#     return surrogate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = train_surrogate_model(m, embeddings, lat_ln='latent_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.equals(sm.input.shape, m.input.shape)\n",
    "# test.equals(sm.output.shape[1], embeddings.shape[1])\n",
    "# l_nms = [layer.name for layer in sm.layers]\n",
    "# layer_idx = l_nms.index('latent_features')\n",
    "# test.all_equal([layer.trainable for layer in sm.layers], \\\n",
    "#                np.repeat([False, True], [layer_idx + 1, len(sm.layers) -1 -layer_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = 'mean_squared_error'\n",
    "# opt = 'adam'\n",
    "# bs = 100\n",
    "# epochs = 10\n",
    "# val = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.fit(x=input_data, y=embeddings, batch_size=bs, validation_split=val, epochs=epochs, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import innvestigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer = innvestigate.create_analyzer(\"gradient\", intermediate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asd= innvestigate.create_analyzer(\"gradient\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data[np.random.choice(input_data.shape[0], 100, replace=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background = input_data[np.random.choice(input_data.shape[0], 100, replace=False)]\n",
    "# e = shap.DeepExplainer(intermediate_model, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values = e.shap_values(input_data[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
