# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/03_dimensionality_reduction.ipynb (unless otherwise specified).

__all__ = ['check_compatibility', 'normalize_dr_artifact', 'fget_UMAP_embeddings', 'plot_embeddings']

# Cell
import umap
import pandas as pd
import numpy as np
from fastcore.all import *
from .load import *
from .utils import *

# Cell
def check_compatibility(dr_ar:TSArtifact, dcae_ar:TSArtifact):
    "Function to check that the artifact used by the DCAE and the artifact that is \
    going to be passed through the DR are compatible"
    try:
        # Check that both artifacts have the same variables
        chk_vars = dr_ar.metadata['TS']['vars'] == dcae_ar.metadata['TS']['vars']
        # Check that both artifacts have the same freq
        chk_freq = dr_ar.metadata['TS']['freq'] == dcae_ar.metadata['TS']['freq']
        # Check that the dr artifact is not normalized (not normalized data has not the key normalization)
        chk_norm = dr_ar.metadata['TS'].get('normalization') is None
        # Check that the dr artifact has not missing values
        chk_miss = dr_ar.metadata['TS']['has_missing_values'] == "False"
        # Check all logical vars.
        if chk_vars and chk_freq and chk_norm and chk_miss:
            print("Artifacts are compatible.")
        else:
            raise Exception
    except Exception as e:
        print("Artifacts are not complatible.")
        raise e
    return None


# Cell
def normalize_dr_artifact(dr_ar:TSArtifact, dcae_ar:TSArtifact):
    "Function to normalize the dr artifact with the normalization parameters of the \
    dcae artifact"
    # Check that artifacts are compatible
    check_compatibility(dr_ar,dcae_ar)
    # Get the normalization parameters of dcae_ar
    dcae_stds = dcae_ar.metadata['TS']['normalization']['stds']
    dcae_means = dcae_ar.metadata['TS']['normalization']['means']
    # Transform dr_ar to pandas and iterate over columns
    dr_ar_df = dr_ar.to_df()
    # Iterate over df columns to normalize them with means and stds of dcae_ar
    for column_name in dr_ar_df:
        dr_ar_df[column_name] = (dr_ar_df[column_name] - dcae_means[column_name])/dcae_stds[column_name]

    return dr_ar_df


# Cell
import warnings
from numba.core.errors import NumbaPerformanceWarning
@delegates(umap.umap_.UMAP)
def fget_UMAP_embeddings(input_data, **kwargs):
    "Compute the embeddings of `input_data` using UMAP, with a configuration contained in `**kwargs`. \
    Returns also information of the reducer."
    warnings.filterwarnings("ignore", category=NumbaPerformanceWarning) # silence NumbaPerformanceWarning
    reducer = umap.UMAP(**kwargs)
    reducer.fit(input_data)
    embeddings = reducer.transform(input_data)
    return (embeddings, reducer)

# Cell
def plot_embeddings(embeddings, umap_params):
    "Plot 2D embeddings thorugh a connected scatter plot"
    df_embeddings = pd.DataFrame(embeddings, columns = ['x1', 'x2'])
    fig = plt.figure(figsize=(10,10))
    ax = fig.add_subplot(111)
    ax.scatter(df_embeddings['x1'], df_embeddings['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)
    ax.plot(df_embeddings['x1'], df_embeddings['x2'], alpha=0.5, picker=1)
    plt.title('DR params -  n_neighbors:{:d} min_dist:{:f} metric:{:s}'.format(umap_params['n_neighbors'],umap_params['min_dist'],umap_params['metric']))
    return ax

# Cell
# def train_surrogate_model(dcae, embeddings, lat_ln='latent_features'):
#     "Train a surrogate model that learns the `embeddings` from the latent features contained in the layer \
#     `lat_ln` of a previously trained Deep Convolutional AutoEncoder `dcae`"
#     x = dcae.get_layer(lat_ln).output
#     x = Dense(units=embeddings.shape[1], activation='linear')(x)
#     surrogate_model = Model(dcae.input, x)
#     l_nms = [layer.name for layer in surrogate_model.layers]
#     layer_idx = l_nms.index(lat_ln)
#     # The layers that are already trained from the autoencoder must be `frozen`
#     for layer in surrogate_model.layers[:layer_idx]:
#         layer.trainable = False
#     return surrogate_model