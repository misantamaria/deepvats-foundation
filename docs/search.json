[
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Utils",
    "section": "",
    "text": "#default_exp utils\n#hide\n#export\nfrom dvats.imports import *\nfrom fastcore.all import *\nimport wandb\nimport pickle\nimport pandas as pd\nimport numpy as np\n#import tensorflow as tf\nimport torch.nn as nn\nfrom fastai.basics import *"
  },
  {
    "objectID": "utils.html#pandas-dataframe-utilities",
    "href": "utils.html#pandas-dataframe-utilities",
    "title": "Utils",
    "section": "pandas Dataframe utilities",
    "text": "pandas Dataframe utilities\n\nNormalize columns\n\n#export\ndef normalize_columns(df:pd.DataFrame):\n    \"Normalize columns from `df` to have 0 mean and 1 standard deviation\"\n    mean = df.mean()\n    std = df.std() + 1e-7\n    return (df-mean)/std\n\n\nfoo = generate_TS_df(3, 3)\nfoo.describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\ncount\n3.000000\n3.000000\n3.000000\n\n\nmean\n-0.356446\n-0.217669\n-0.451268\n\n\nstd\n1.567722\n0.268632\n0.309269\n\n\nmin\n-1.327362\n-0.480470\n-0.693929\n\n\n25%\n-1.260753\n-0.354722\n-0.625384\n\n\n50%\n-1.194144\n-0.228973\n-0.556840\n\n\n75%\n0.129012\n-0.086268\n-0.329938\n\n\nmax\n1.452169\n0.056437\n-0.103037\n\n\n\n\n\n\n\n\nbar = normalize_columns(foo)\nbar.describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\ncount\n3.000000e+00\n3.000000e+00\n3.000000e+00\n\n\nmean\n-3.700743e-17\n-3.700743e-17\n-9.251859e-17\n\n\nstd\n9.999999e-01\n9.999996e-01\n9.999997e-01\n\n\nmin\n-6.193166e-01\n-9.782957e-01\n-7.846253e-01\n\n\n25%\n-5.768289e-01\n-5.101875e-01\n-5.629913e-01\n\n\n50%\n-5.343411e-01\n-4.207935e-02\n-3.413573e-01\n\n\n75%\n3.096583e-01\n4.891479e-01\n3.923127e-01\n\n\nmax\n1.153658e+00\n1.020375e+00\n1.125983e+00\n\n\n\n\n\n\n\n\ntest_close(bar.describe().loc['mean'].values, np.repeat(0.0, len(bar.columns)))\n\n\ntest_close(bar.describe().loc['std'].values, np.repeat(1.0, len(bar.columns)))\n\n\n\nRemove constant columns\n\n#export\ndef remove_constant_columns(df:pd.DataFrame):\n    return df.loc[:, (df != df.iloc[0]).any()]\n\n\nfoo = generate_TS_df(3, 3)\nfoo['constant'] = [0.0]*len(foo)\nfoo\n\n\n\n\n\n\n\n\n0\n1\n2\nconstant\n\n\n\n\n2022-04-23 10:32:47.134188\n-0.658749\n1.680371\n1.426223\n0.0\n\n\n2022-04-23 10:32:48.134188\n1.961724\n1.247468\n-1.358013\n0.0\n\n\n2022-04-23 10:32:49.134188\n-0.195324\n0.413195\n0.504546\n0.0\n\n\n\n\n\n\n\n\nbar = remove_constant_columns(foo)\nbar\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n2022-04-23 10:32:47.134188\n-0.658749\n1.680371\n1.426223\n\n\n2022-04-23 10:32:48.134188\n1.961724\n1.247468\n-1.358013\n\n\n2022-04-23 10:32:49.134188\n-0.195324\n0.413195\n0.504546\n\n\n\n\n\n\n\n\ncolumn_diff = set(foo.columns) - set(bar.columns)\ntest_eq_type(column_diff, set(['constant']))"
  },
  {
    "objectID": "utils.html#create-wandb-artifact-containing-just-the-reference-to-an-object-pass-as-argument",
    "href": "utils.html#create-wandb-artifact-containing-just-the-reference-to-an-object-pass-as-argument",
    "title": "Utils",
    "section": "Create wandb artifact containing just the reference to an object pass as argument",
    "text": "Create wandb artifact containing just the reference to an object pass as argument\n\n#export\nclass ReferenceArtifact(wandb.Artifact):\n    default_storage_path = Path('data/wandb_artifacts/') # * this path is relative to Path.home()\n    \"This class is meant to create an artifact with a single reference to an object \\\n    passed as argument in the contructor. The object will be pickled, hashed and stored \\\n    in a specified folder.\"\n    @delegates(wandb.Artifact.__init__)\n    def __init__(self, obj, name, type='object', folder=None, **kwargs):\n        super().__init__(type=type, name=name, **kwargs)\n        # pickle dumps the object and then hash it\n        hash_code = str(hash(pickle.dumps(obj)))\n        folder = Path(ifnone(folder, Path.home()/self.default_storage_path))\n        with open(f'{folder}/{hash_code}', 'wb') as f:\n            pickle.dump(obj, f)\n        self.add_reference(f'file://{folder}/{hash_code}')\n        if self.metadata is None:\n            self.metadata = dict()\n        self.metadata['ref'] = dict()\n        self.metadata['ref']['hash'] = hash_code\n        self.metadata['ref']['type'] = str(obj.__class__)\n\n\nfoo = np.arange(10)\nbar = ReferenceArtifact(obj=foo, name='foo', folder='.')\nbar_path = Path(f'./{bar.metadata[\"ref\"][\"hash\"]}')\ntest_eq(bar_path.exists(), True)\ntest_eq(bar.metadata['ref']['type'], \"&lt;class 'numpy.ndarray'&gt;\")\n\nWhen a reference artifact is used by one wandb run, we should have a method to get the original object from it\n\n#export\n@patch\ndef to_obj(self:wandb.apis.public.Artifact):\n    \"\"\"Download the files of a saved ReferenceArtifact and get the referenced object. The artifact must \\\n    come from a call to `run.use_artifact` with a proper wandb run.\"\"\"\n    if self.metadata.get('ref') is None:\n        print(f'ERROR:{self} does not come from a saved ReferenceArtifact')\n        return None\n    original_path = ReferenceArtifact.default_storage_path/self.metadata['ref']['hash']\n    path = original_path if original_path.exists() else Path(self.download()).ls()[0]\n    with open(path, 'rb') as f:\n        obj = pickle.load(f)\n    return obj\n\nTest with Reference artifact from a df\n\nfoo = generate_TS_df(3, 3)\nbar = ReferenceArtifact(obj=foo, name='test_reference_artifact')\nbar.manifest.entries.values()\n\ndict_values([&lt;ManifestEntry ref: file:///home/dmontalvo/data/wandb_artifacts/776758047213944476/776758047213944476&gt;])\n\n\n\ntest_eq(bar.name, 'test_reference_artifact')\n\n\ntest_eq(bar.metadata['ref']['type'], str(type(foo)))\n\nTODO: Test method to_obj\nReferenceArtifact with a numpy array\n\nfoo = np.random.randn(5)\nbar = ReferenceArtifact(obj=foo, name='test_reference_artifact')\nbar.manifest.entries.values()\n\ndict_values([&lt;ManifestEntry ref: file:///home/dmontalvo/data/wandb_artifacts/-8161467246553937997/-8161467246553937997&gt;])\n\n\n\ntest_eq(bar.metadata['ref']['type'], str(type(foo)))\n\n\n#export\nimport torch.nn as nn\nclass PrintLayer(nn.Module):\n    def __init__(self):\n        super(PrintLayer, self).__init__()\n\n    def forward(self, x):\n        # Do your print / debug stuff here\n        print(x.shape)\n        return x\n\n\n#export\n@patch\ndef export_and_get(self:Learner, keep_exported_file=False):\n    \"\"\"\n        Export the learner into an auxiliary file, load it and return it back.\n    \"\"\"\n    aux_path = Path('aux.pkl')\n    self.export(fname='aux.pkl')\n    aux_learn = load_learner('aux.pkl')\n    if not keep_exported_file: aux_path.unlink()\n    return aux_learn\n\n\nget_wandb_artifacts\n\n#export\ndef get_wandb_artifacts(project_path, type=None, name=None, last_version=True):\n    \"\"\"\n        Get the artifacts logged in a wandb project.\n        Input:\n        - `project_path` (str): entity/project_name\n        - `type` (str): whether to return only one type of artifacts\n        - `name` (str): Leave none to have all artifact names\n        - `last_version`: whether to return only the last version of each artifact or not\n\n        Output: List of artifacts\n    \"\"\"\n    public_api = wandb.Api()\n    if type is not None:\n        types = [public_api.artifact_type(type, project_path)]\n    else:\n        types = public_api.artifact_types(project_path)\n\n    res = L()\n    for kind in types:\n        for collection in kind.collections():\n            if name is None or name == collection.name:\n                versions = public_api.artifact_versions(\n                    kind.type,\n                    \"/\".join([kind.entity, kind.project, collection.name]),\n                    per_page=1,\n                )\n                if last_version: res += next(versions)\n                else: res += L(versions)\n    return list(res)\n\n\nfoo = get_wandb_artifacts('wandb/artifacts-example', type='model')\ntest_eq(len(foo), 2)\nfoo = get_wandb_artifacts('wandb/artifacts-example', type='model', name='convnet')\ntest_eq(len(foo), 1)\nfoo = get_wandb_artifacts('wandb/artifacts-example', type='model', name='convnet', last_version=False)\ntest_eq(len(foo), 2)\n\n\n\nget_pickle_artifact\n\n#export\ndef get_pickle_artifact(filename):\n\n    with open(filename, \"rb\") as f:\n        df = pickle.load(f)\n    \n    return df\n\n\n#hide\n#from nbdev.export import notebook2script\n#notebook2script()\nbeep(1)\n\nConverted dr.ipynb.\nConverted encoder.ipynb.\nConverted index.ipynb.\nConverted load.ipynb.\nConverted utils.ipynb.\nConverted visualization.ipynb.\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "dr.html",
    "href": "dr.html",
    "title": "Get projections (UMAP, T-SNET, PCA)",
    "section": "",
    "text": "#default_exp dr\n\n\n\n#hide\n\n\n# Dimensionality reduction\n\n\n#export\nimport umap\nimport cudf\nimport cuml\nimport pandas as pd\nimport numpy as np\nfrom fastcore.all import *\nfrom dvats.imports import *\nfrom dvats.load import TSArtifact\n\n\n#export\ndef check_compatibility(dr_ar:TSArtifact, enc_ar:TSArtifact):\n    \"Function to check that the artifact used by the encoder model and the artifact that is \\\n    going to be passed through the DR are compatible\"\n    try:\n        # Check that both artifacts have the same variables\n        chk_vars = dr_ar.metadata['TS']['vars'] == enc_ar.metadata['TS']['vars']\n        # Check that both artifacts have the same freq\n        chk_freq = dr_ar.metadata['TS']['freq'] == enc_ar.metadata['TS']['freq']\n        # Check that the dr artifact is not normalized (not normalized data has not the key normalization)\n        chk_norm = dr_ar.metadata['TS'].get('normalization') is None\n        # Check that the dr artifact has not missing values\n        chk_miss = dr_ar.metadata['TS']['has_missing_values'] == \"False\"\n        # Check all logical vars.\n        if chk_vars and chk_freq and chk_norm and chk_miss:\n            print(\"Artifacts are compatible.\")\n        else:\n            raise Exception\n    except Exception as e:\n        print(\"Artifacts are not compatible.\")\n        raise e\n    return None\n\n\n#export\nimport warnings\nfrom numba.core.errors import NumbaPerformanceWarning\n@delegates(cuml.UMAP)\ndef get_UMAP_prjs(input_data, cpu=True, **kwargs):\n    \"Compute the projections of `input_data` using UMAP, with a configuration contained in `**kwargs`.\"\n    warnings.filterwarnings(\"ignore\", category=NumbaPerformanceWarning) # silence NumbaPerformanceWarning\n    reducer = umap.UMAP(**kwargs) if cpu else cuml.UMAP(**kwargs)\n    projections = reducer.fit_transform(input_data)\n    return projections\n\n\n#slow\nfoo = np.random.rand(5, 10)\nbar = get_UMAP_prjs(foo, cpu=True, n_neighbors=3, min_dist=0.1)\ntest_eq(bar.shape, (foo.shape[0], 2))\n\nIf you want to have consistent results across executions, use random_state\n\nbar = get_UMAP_prjs(foo, cpu=True, n_neighbors=3, random_state=1234)\nbaz = get_UMAP_prjs(foo, cpu=True, n_neighbors=3, random_state=1234)\ntest_eq(bar, baz)\n\n\n#export\n@delegates(cuml.PCA)\ndef get_PCA_prjs(X, cpu=False, **kwargs):\n    r\"\"\"\n    Computes PCA projections of X\n    \"\"\"\n    if cpu:\n        raise NotImplementedError\n    else:\n        reducer = cuml.PCA(**kwargs)\n    projections = reducer.fit_transform(X)\n    return projections\n\n\n# Test the function get_PCA_prjs\nfoo = np.random.rand(5, 10)\nbar = get_PCA_prjs(foo, cpu=False, n_components=2)\n\n\n#export\n@delegates(cuml.TSNE)\ndef get_TSNE_prjs(X, cpu=False, **kwargs):\n    r\"\"\"\n    Computes TSNE projections of X\n    \"\"\"\n    if cpu:\n        raise NotImplementedError\n    else:\n        reducer = cuml.TSNE(**kwargs)\n    projections = reducer.fit_transform(X)\n    return projections\n\n\n# Test the function get_TSNE_prjs\nfoo = np.random.rand(90, 10)\nbar = get_TSNE_prjs(foo, cpu=False)\n\n\n#hide\n#from nbdev.export import notebook2script\n#notebook2script()\nbeep(1)\n\nConverted dr.ipynb.\nConverted encoder.ipynb.\nConverted index.ipynb.\nConverted load.ipynb.\nConverted utils.ipynb.\nConverted visualization.ipynb.\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "encoder.html",
    "href": "encoder.html",
    "title": "Encoder",
    "section": "",
    "text": "#default_exp encoder\n\n\n#hide\n\n\n#export\nimport pandas as pd\nimport numpy as np\nfrom fastcore.all import *\nfrom tsai.callback.MVP import *\nfrom tsai.imports import *\nfrom tsai.models.InceptionTimePlus import InceptionTimePlus\nfrom tsai.models.explainability import get_acts_and_grads\nfrom tsai.models.layers import *\nfrom tsai.data.validation import combine_split_data\n\n\n#hide\nfrom tsai.all import *\n\n\nArchitectures\n\n#export \nclass DCAE_torch(Module):\n    def __init__(self, c_in, seq_len, delta, nfs=[64, 32, 12], kss=[10, 5, 5],\n                 pool_szs=[2,2,3], output_fsz=10):\n        \"\"\"\n        Create a Deep Convolutional Autoencoder for multivariate time series of `d` dimensions,\n        sliced with a window size of `w`. The parameter `delta` sets the number of latent features that will be\n        contained in the Dense layer of the network. The the number of features\n        maps (filters), the filter size and the pool size can also be adjusted.\"\n        \"\"\"\n        assert all_equal([len(x) for x in [nfs, kss, pool_szs]], np.repeat(len(nfs), 3)), \\\n            'nfs, kss, and pool_szs must have the same length'\n        assert np.prod(pool_szs) == nfs[-1], \\\n            'The number of filters in the last conv layer must be equal to the product of pool sizes'\n        assert seq_len % np.prod(pool_szs) == 0, \\\n            'The product of pool sizes must be a divisor of the window size'\n        layers = []\n        for i in range_of(kss):\n            layers += [Conv1d(ni=nfs[i-1] if i&gt;0 else c_in, nf=nfs[i], ks=kss[i]),\n                       nn.MaxPool1d(kernel_size=pool_szs[i])]\n        self.downsample = nn.Sequential(*layers)\n        self.bottleneck = nn.Sequential(OrderedDict([\n            ('flatten', nn.Flatten()),\n            ('latent_in', nn.Linear(seq_len, delta)),\n            ('latent_out', nn.Linear(delta, seq_len)),\n            ('reshape', Reshape(nfs[-1], seq_len // np.prod(pool_szs)))\n        ]))\n        layers = []\n        for i in reversed(range_of(kss)):\n            layers += [Conv1d(ni=nfs[i+1] if i != (len(nfs)-1) else nfs[-1],\n                              nf=nfs[i], ks=kss[i]),\n                       nn.Upsample(scale_factor=pool_szs[i])]\n        layers += [Conv1d(ni=nfs[0], nf=c_in, kernel_size=output_fsz)]\n        self.upsample = nn.Sequential(*layers)\n\n\n    def forward(self, x):\n        x = self.downsample(x)\n        x = self.bottleneck(x)\n        x = self.upsample(x)\n        return x\n\n\nfoo = torch.rand(3, 1, 48)\nm = DCAE_torch(c_in=foo.shape[1], seq_len=foo.shape[2], delta=12)\nm(foo).shape\n\ntorch.Size([3, 1, 48])\n\n\n\n\nDictionary to get the default backbone modules to get the embeddings from\n\n#export\nENCODER_EMBS_MODULE_NAME = {\n    InceptionTimePlus: 'backbone', # for mvp based models\n    DCAE_torch: 'bottleneck.latent_in'\n}\n\n\n\nGetting the embeddings (activations) from the encoder\n\n#export\ndef get_enc_embs(X, enc_learn, module=None, cpu=False, average_seq_dim=True, to_numpy=True):\n    \"\"\"\n        Get the embeddings of X from an encoder, passed in `enc_learn as a fastai\n        learner. By default, the embeddings are obtained from the last layer\n        before the model head, although any layer can be passed to `model`.\n        Input\n        - `cpu`: Whether to do the model inference in cpu of gpu (GPU recommended)\n        - `average_seq_dim`: Whether to aggregate the embeddings in the sequence dimensions\n        - `to_numpy`: Whether to return the result as a numpy array (if false returns a tensor)\n    \"\"\"\n    if cpu:\n        print(\"--&gt; Get enc embs CPU\")\n        enc_learn.dls.cpu()\n        enc_learn.cpu()\n    else:\n        print(\"--&gt; Use CUDA |Get enc embs GPU\")\n        enc_learn.dls.cuda()\n        enc_learn.cuda()\n        print(\"devices: \", enc_learn.dls.device, enc_learn.device)\n        print(\"Use CUDA --&gt;\")\n    if enc_learn.dls.bs == 0: enc_learn.dls.bs = 64\n    print(\"--&gt; Get enc embs bs: \", enc_learn.dls.bs)\n    aux_dl = enc_learn.dls.valid.new_dl(X=X)\n    aux_dl.bs = enc_learn.dls.bs if enc_learn.dls.bs&gt;0 else 64\n    module = nested_attr(enc_learn.model,\n                         ENCODER_EMBS_MODULE_NAME[type(enc_learn.model)]) \\\n                if module is None else module\n    embs = [get_acts_and_grads(model=enc_learn.model,\n                               modules=module,\n                               x=xb[0], cpu=cpu)[0] for xb in aux_dl]\n    embs = to_concat(embs)\n    if embs.ndim == 3 and average_seq_dim: embs = embs.mean(axis=2)\n    if to_numpy: embs = embs.numpy() if cpu else embs.cpu().numpy()\n    return embs\n\n\nimport wandb\nfrom dvats.utils import *\nwandb_api = wandb.Api()\nenc_artifact = wandb_api.artifact('deepvats/mvp:latest')\nenc_learner = enc_artifact.to_obj()\nX = torch.rand(9, 1, 48)\n\nwandb:   1 of 1 files downloaded.  \n\n\n\n#slow\n#%%time\nembs = get_enc_embs(X, enc_learner, cpu=True)\ntest_eq(embs.shape[0], X.shape[0])\nembs.shape, embs.__class__\n\n--&gt; Get enc embs CPU\n--&gt; Get enc embs bs:  1\n\n\nRuntimeError: Given groups=1, weight of size [32, 2, 1], expected input[1, 1, 48] to have 2 channels, but got 1 channels instead\n\n\n\nembs = get_enc_embs(X, enc_learner, cpu=False, to_numpy=False)\ntest_eq(embs.shape[0], X.shape[0])\nembs.shape, embs.__class__, embs.device\n\n--&gt; Get enc embs GPU\n\n\nAttributeError: 'InceptionTimePlus' object has no attribute 'device'\n\n\n\nembs = get_enc_embs(X, enc_learner, cpu=False, to_numpy=True)\ntest_eq(embs.shape[0], X.shape[0])\nembs.shape, embs.__class__\n\n\n#hide\n\n#from nbdev.export import notebook2script\n\n#notebook2script()\n\n#from tsai import nb2py\n#nb2py\n#beep(1)\n\nImportError: cannot import name 'nb2py' from 'tsai' (/home/macu/env/lib/python3.10/site-packages/tsai/__init__.py)"
  },
  {
    "objectID": "visualization.html",
    "href": "visualization.html",
    "title": "Visualization",
    "section": "",
    "text": "#default_exp visualization\n#hide\n#export\nfrom fastcore.all import *\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\n#hide\nfrom dvats.imports import *\nfrom dvats.utils import *"
  },
  {
    "objectID": "visualization.html#plot-mask",
    "href": "visualization.html#plot-mask",
    "title": "Visualization",
    "section": "Plot mask",
    "text": "Plot mask\n\n#export\ndef plot_mask(mask, i=0, fig_size=(10,10), title_str=\"Mask\", return_fig=False):\n    \"\"\"\n    Plot the mask passed as argument. The mask is a 3D boolean tensor. The first \n    dimension is the window number (or item index), the second is the variable, and the third is the time step.\n    Input:\n        mask: 3D boolean tensor\n        i: index of the window to plot\n        fig_size: size of the figure\n        title_str: title of the plot\n        return_fig: if True, returns the figure\n    Output:\n        if return_fig is True, returns the figure, otherwise, it does not return anything\n    \"\"\"\n    plt.figure(figsize=fig_size)\n    plt.pcolormesh(mask[i], cmap='cool')\n    plt.title(f'{title_str} {i}, mean: {mask[0].float().mean().item():.3f}')\n    if return_fig:\n        return plt.gcf()\n    else:\n        plt.show()\n        return None\n\n\n# Creates a mask (3d boolean tensor) with random values masked and call the previous function to plot it\nmask = torch.rand(3,10,5) &gt; 0.9\ntest_eq(mask.dtype, torch.bool)\nplot_mask(mask, 0, fig_size=(10,5), return_fig=False)\n\n\n\n\n\n# Test the parameter return_fig\nm = plot_mask(mask, 0, fig_size=(10,5), return_fig=True)\nm\n\n\n\n\n\n\n\n\n#hide\n#from nbdev.export import notebook2script\n#notebook2script()\nbeep(1)\n\nConverted dr.ipynb.\nConverted encoder.ipynb.\nConverted index.ipynb.\nConverted load.ipynb.\nConverted utils.ipynb.\nConverted visualization.ipynb.\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "load.html",
    "href": "load.html",
    "title": "Load",
    "section": "",
    "text": "#default_exp load\n#export\nimport pandas as pd\nimport numpy as np\nfrom fastcore.all import *\nimport wandb\nfrom datetime import datetime, timedelta\nfrom dvats.imports import *\nfrom dvats.utils import *\nimport pickle\n#hide\nfrom tsai.imports import beep\nbase_path = Path.home()\nbase_path\n\nPath('/home/dmontalvo')"
  },
  {
    "objectID": "load.html#time-series-artifacts-to-be-used-with-weights-and-biases",
    "href": "load.html#time-series-artifacts-to-be-used-with-weights-and-biases",
    "title": "Load",
    "section": "Time series artifacts (to be used with weights and biases)",
    "text": "Time series artifacts (to be used with weights and biases)\nThis class is meant to extend wandb.Artifact for logging/using files with time series data.\n\n#export\nclass TSArtifact(wandb.Artifact):\n\n    default_storage_path = Path(Path.home()/'data/wandb_artifacts/')\n    date_format = '%Y-%m-%d %H:%M:%S' # TODO add milliseconds\n    handle_missing_values_techniques = {\n        'linear_interpolation': lambda df : df.interpolate(method='linear', limit_direction='both'),\n        'overall_mean': lambda df : df.fillna(df.mean()),\n        'overall_median': lambda df : df.fillna(df.median()),\n        'backward_fill' : lambda df : df.fillna(method='bfill'),\n        'forward_fill' : lambda df : df.fillna(method='ffill')\n    }\n\n    \"Class that represents a wandb artifact containing time series data. sd stands for start_date \\\n    and ed for end_date. Both should be pd.Timestamps\"\n\n    @delegates(wandb.Artifact.__init__)\n    def __init__(self, name, sd:pd.Timestamp, ed:pd.Timestamp, **kwargs):\n        super().__init__(type='dataset', name=name, **kwargs)\n        self.sd = sd\n        self.ed = ed\n        if self.metadata is None:\n            self.metadata = dict()\n        self.metadata['TS'] = dict(sd = self.sd.strftime(self.date_format),\n                                   ed = self.ed.strftime(self.date_format))\n\n\n    @classmethod\n    def from_daily_csv_files(cls, root_path, fread=pd.read_csv, start_date=None, end_date=None, metadata=None, **kwargs):\n\n        \"Create a wandb artifact of type `dataset`, containing the CSV files from `start_date` \\\n        to `end_date`. Dates must be pased as `datetime.datetime` objects. If a `wandb_run` is \\\n        defined, the created artifact will be logged to that run, using the longwall name as \\\n        artifact name, and the date range as version.\"\n\n        return None\n\n\n    @classmethod\n    @delegates(__init__)\n    def from_df(cls, df:pd.DataFrame, name:str, path:str=None, sd:pd.Timestamp=None, ed:pd.Timestamp=None,\n                normalize:bool=False, missing_values_technique:str=None, resampling_freq:str=None, **kwargs):\n\n        \"\"\"\n        Create a TSArtifact of type `dataset`, using the DataFrame `df` samples from \\\n        `sd` (start date) to `ed` (end date). Dates must be passed as `datetime.datetime` \\\n        objects. The transformed DataFrame is stored as a pickle file in the path `path` \\\n        and its reference is added to the artifact entries. Additionally, the dataset can \\\n        be normalized (see `normalize` argument) or transformed using missing values \\\n        handling techniques (see `missing_values_technique` argument) or resampling (see \\\n        `resampling_freq` argument).\n\n        Arguments:\n            df: (DataFrame) The dataframe you want to convert into an artifact.\n            name: (str) The artifact name.\n            path: (str, optional) The path where the file, containing the new transformed \\\n                dataframe, is saved. Default None.\n            sd: (sd, optional) Start date. By default, the first index of `df` is taken.\n            ed: (ed, optional) End date. By default, the last index of `df` is taken.\n            normalize: (bool, optional) If the dataset values should be normalized. Default\\\n                False.\n            missing_values_technique: (str, optional) The technique used to handle missing \\\n                values. Options: \"linear_iterpolation\", \"overall_mean\", \"overall_median\" or \\\n                None. Default None.\n            resampling_freq: (str, optional) The offset string or object representing \\\n                frequency conversion for time series resampling. Default None.\n\n        Returns:\n            TSArtifact object.\n        \"\"\"\n        sd = df.index[0] if sd is None else sd\n        ed = df.index[-1] if ed is None else ed\n        obj = cls(name, sd=sd, ed=ed, **kwargs)\n        df = df.query('@obj.sd &lt;= index &lt;= @obj.ed')\n        obj.metadata['TS']['created'] = 'from-df'\n        obj.metadata['TS']['n_vars'] = df.columns.__len__()\n\n        # Handle Missing Values\n        df = obj.handle_missing_values_techniques[missing_values_technique](df) if missing_values_technique is not None else df\n        obj.metadata['TS']['handle_missing_values_technique'] = missing_values_technique.__str__()\n        obj.metadata['TS']['has_missing_values'] = np.any(df.isna().values).__str__()\n\n        # Indexing and Resampling\n        if resampling_freq: df = df.resample(resampling_freq).mean()\n        obj.metadata['TS']['n_samples'] = len(df)\n        obj.metadata['TS']['freq'] = str(df.index.freq)\n\n        # Time Series Variables\n        obj.metadata['TS']['vars'] = list(df.columns)\n\n        # Normalization - Save the previous means and stds\n        if normalize:\n            obj.metadata['TS']['normalization'] = dict(means = df.describe().loc['mean'].to_dict(),\n                                                       stds = df.describe().loc['std'].to_dict())\n            df = normalize_columns(df)\n\n        # Hash and save\n        hash_code = str(pd.util.hash_pandas_object(df).sum()) # str(hash(df.values.tobytes()))\n        path = obj.default_storage_path/f'{hash_code}' if path is None else Path(path)/f'{hash_code}'\n        df.to_pickle(path)\n        obj.metadata['TS']['hash'] = hash_code\n        obj.add_file(str(path))\n\n        return obj\n\n\n# TSArtifact class TEST\n\n# resampling frequency\nresampling_freq = '5s'\n# handle missing values technique\nmissing_values_technique='overall_median'\n\n# testing dataframe\ndf_test = pd.util.testing.makeMissingDataframe()\ndf_test.index = pd.date_range(start='2021-01-01', periods=len(df_test), freq='s')\n\nartifact = TSArtifact.from_df(df_test, \n                              name='JNK', \n                              missing_values_technique=missing_values_technique,\n                              resampling_freq=resampling_freq, \n                              normalize=True)\nartifact.metadata\n\n{'TS': {'sd': '2021-01-01 00:00:00',\n  'ed': '2021-01-01 00:00:29',\n  'created': 'from-df',\n  'n_vars': 4,\n  'handle_missing_values_technique': 'overall_median',\n  'has_missing_values': 'False',\n  'n_samples': 6,\n  'freq': '&lt;5 * Seconds&gt;',\n  'vars': ['A', 'B', 'C', 'D'],\n  'normalization': {'means': {'A': 0.1002685079534481,\n    'B': -0.16042842008767608,\n    'C': -0.10298237550830798,\n    'D': 0.19358963401507653},\n   'stds': {'A': 0.5626162534877364,\n    'B': 0.2772564183824689,\n    'C': 0.3820528754231953,\n    'D': 0.4135742342545782}},\n  'hash': '5105739722437803594'}}\n\n\nAt the end, we are interested in working with time series as a dataframe. So we need a function to download the files contained in a wandb.apis.public.Artifact object and process them into a TS dataframe. The process of passing from files to dataframe must be different depending on what type of creation method was used to generate the original TSArtifact.\n\n#export\n@patch\ndef to_df(self:wandb.apis.public.Artifact):\n    \"Download the files of a saved wandb artifact and process them as a single dataframe. The artifact must \\\n    come from a call to `run.use_artifact` with a proper wandb run.\"\n    # The way we have to ensure that the argument comes from a TS arfitact is the metadata\n    if self.metadata.get('TS') is None:\n        print(f'ERROR:{self} does not come from a logged TSArtifact')\n        return None\n    dir = Path(self.download())\n    if self.metadata['TS']['created'] == 'from-df':\n        # Call read_pickle with the single file from dir\n        return pd.read_pickle(dir.ls()[0])\n    else:\n        print(\"ERROR: Only from_df method is allowed yet\")\n\nFor convenience, we can write a method to cast a downloaded wandb artifact (instance from wandb.apis.public,Artifact) to a TSArtifact\n\n#export\n@patch\ndef to_tsartifact(self:wandb.apis.public.Artifact):\n    \"Cast an artifact as a TS artifact. The artifact must have been created from one of the \\\n    class creation methods of the class `TSArtifact`. This is useful to go back to a TSArtifact \\\n    after downloading an artifact through the wand API\"\n    return TSArtifact(name=self.digest, #TODO change this\n                      sd=pd.to_datetime(self.metadata['TS']['sd'], format=TSArtifact.date_format),\n                      ed=pd.to_datetime(self.metadata['TS']['sd'], format=TSArtifact.date_format),\n                      description=self.description,\n                      metadata=self.metadata)"
  },
  {
    "objectID": "load.html#inject-or-infer-frequencies-in-a-dataframe",
    "href": "load.html#inject-or-infer-frequencies-in-a-dataframe",
    "title": "Load",
    "section": "Inject or infer frequencies in a dataframe",
    "text": "Inject or infer frequencies in a dataframe\n\n#export\n@delegates(pd.to_datetime)\ndef infer_or_inject_freq(df, injected_freq='1s', start_date=None, **kwargs):\n    \"\"\"\n        Infer index frequency. If there's not a proper time index, create fake timestamps,\n        keeping the desired `injected_freq`. If that is None, set a default one of 1 second.\n        start_date: the first date of the index (int or string).\n    \"\"\"\n    inferred_freq = pd.infer_freq(df.index)\n    if inferred_freq == 'N':\n        timedelta = pd.to_timedelta(injected_freq)\n        df.index = pd.to_datetime(ifnone(start_date, 0), **kwargs) + timedelta*df.index\n        df.index.freq = pd.infer_freq(df.index)\n    else:\n        df.index.freq = inferred_freq\n    return df\n\n\nfoo = pd.DataFrame([1, 2, 3])\nbar = pd.DataFrame([1, 2, 3])\nfoo = infer_or_inject_freq(foo)\nbar = infer_or_inject_freq(bar, injected_freq='2s')\ntest_eq(foo.index.freq, '1s')\ntest_eq(bar.index.freq, '2s')\nfoo, bar\n\n(                     0\n 1970-01-01 00:00:00  1\n 1970-01-01 00:00:01  2\n 1970-01-01 00:00:02  3,\n                      0\n 1970-01-01 00:00:00  1\n 1970-01-01 00:00:02  2\n 1970-01-01 00:00:04  3)\n\n\n\nfoo = pd.DataFrame([1, 2, 3])\nbar = infer_or_inject_freq(foo, injected_freq='1W', start_date='01/01/2020')\nbaz = infer_or_inject_freq(foo, injected_freq='1W', start_date='2020-01-01', format = '%Y-%m-%d')\ntest_eq(bar, baz)\n\n\n#hide\n#from nbdev.export import *\n#notebook2script()\nbeep(1)\n\nConverted dr.ipynb.\nConverted encoder.ipynb.\nConverted index.ipynb.\nConverted load.ipynb.\nConverted utils.ipynb.\nConverted visualization.ipynb.\n\n\n\n                \n                    \n                    Your browser does not support the audio element."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Timecluster hub",
    "section": "",
    "text": "The main intention of this repo is twofold: 1. Replicate the ideas of the Timecluster paper, and apply them to the data from PACMEL. 2. Extend the ideas of the paper for high-dimensional time series. The idea is to find the most important variables that make that a time window from the original space (high-dimensional time series) is mapped to a specific point of the final 2D space, and focus only on them, to make it easier for the domain expert to analyse and cluster the behaviour of the process.\nThe visual part of this repo can also be used as a testbed to validate different approaches to unsupervised learning for time series data. This includes clustering, anomaly detection, segmentation, annotation…"
  },
  {
    "objectID": "index.html#deploy",
    "href": "index.html#deploy",
    "title": "Timecluster hub",
    "section": "Deploy",
    "text": "Deploy\nTo run the notebooks and the app, install docker and docker-compose in your system. Then, create a new .env file in the root of the project following the structure:\n# The name of the docker-compose project\nCOMPOSE_PROJECT_NAME=your_project_name\n# The user ID you are using to run docker-compose\nUSER_ID=your_numeric_id\n# The group ID you are using to run docker-compose (you can get it with id -g in a terminal)\nGROUP_ID=your_numeric_id\n# The user name assigned to the user id\nUSER_NAME=your_user_name\n# The port from which you want to access Jupyter lab\nJUPYTER_PORT=XXXX\n# The port from which you want to access RStudio server\nRSTUDIO_PORT=XXXX\n# The password you want to access RStudio server (user is given by USER_NAME)\nRSTUDIO_PASSWD=XXXX\n# The path to your data files to train/test the models\nLOCAL_DATA_PATH=/path/to/your/data\n# The W&B personal API key (see https://wandb.ai/authorize)\nWANDB_API_KEY=your_wandb_api_key\nYou’ll also need to have a .gitconfig file in your home folder. It can be an empty file that you create manually, or it can contain your git global configuration. For the latter case, run: - git config --global user.name \"YOUR NAME IN THIS GITLAB INSTANCE\" - git config --global user.email \"YOUR EMAIL IN THIS GITLAB INSTANCE\"\nThis will automatically create the ~/.gitconfig file in your home folder.\nFinally, in a terminal located in the root of this repository, run:\ndocker-compose up -d --build\nthen go to localhost:{{JUPYTER_PORT}} to run the notebooks or go to localhost:{{RSTUDIO_PORT}} to run the app. In case you are working in a remote server, replace localhost with the IP of your remote server."
  },
  {
    "objectID": "index.html#contribute",
    "href": "index.html#contribute",
    "title": "Timecluster hub",
    "section": "Contribute",
    "text": "Contribute\nThis project has been created using nbdev, a library that allows to create Python projects directly from Jupyter Notebooks. Please refer to this library when adding new functionalities to the project, in order to keep the structure of it.\nWe recommend using the following procedure to contribute and resolve issues in the repository:\n\nBecause the project uses nbdev, we need to run nbdev_install_git_hooks the first time after the repo is cloned and deployed; this ensures that our notebooks are automatically cleaned and trusted whenever we push to Github/Gitlab. The command has to be run from within the container. Also, it can be run from outside if you pip install nbdev in your local machine.\nCreate a local branch in your development environment to solve the issue XX (or add a new functionality), with the name you want to give your merge request (use something that will be easy for you to remember in the future if you need to update your request): git checkout -b issueXX\nMake whatever changes you want to make in the code and notebooks, and remember to run nbdev_build_lib when you’re done to ensure that the libraries are built from your notebook changes (unless you only changed markdown, in which case that’s not needed). It’s also a good idea to check the output of git diff to ensure that you haven’t accidentally made more changes than you planned.\nMake a commit of the changes made git commit -am \"Fix issue #XX\"\nTest that there are not merging problems in the Jupyter Notebooks with the function nbdev_fix_merge\nPush your local branch to a branch in the gitlab repository with an identiffying name: git push -u origin HEAD\nWhen the push is made, a link will appear in the terminal to create a merge request. Click on it. remote:     remote: To create a merge request for test_branch, visit:     remote:   https://gitlab.geist.re/pml/x_timecluster_extension/-/merge_requests/new?merge_request%5Bsource_branch%5D=issueXX_solved     remote:\nIn the gitlab website:\n\nWrite in the description what is the problem to solve with your branch using a hyperlink to the issue (just use the hashtag symbol “#” followed by the issue number)\nClick on the option “Delete source branch when merge request is accepted” and assign the merge to your profile.\nClick on the button “Create merge request” \n\nWait to the merge to be accepted. In case you’re solving an issue, we recommend to move the issue to the field “In review” (in the Issue Board). To keep your branch up to date with the changes to the main repo, run:\n\ngit pull upstream master\n\nIf there are no problems, the merge request will be accepted and the issue will be closed. Once your PR has been merged or rejected, you can delete your branch if you don’t need it any more:\n\ngit branch -d issueXX"
  }
]