# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/utils.ipynb (unless otherwise specified).

__all__ = ['baseline_model_predictor', 'get_windows_mse', 'generate_TS_df', 'normalize_columns',
           'remove_constant_columns', 'ReferenceArtifact']

# Comes from 04_baseline_models.ipynb, cell
def baseline_model_predictor(input_array, operation = "mean"):
    " Perform an arithmetic operation (median or average) on a three-dimensional numpy array from df_slicer"
    # Calculate mean/median for each window in the dataset
    if operation == "mean":
        prediction = np.mean(input_array,axis=1)
    elif operation == "median":
        prediction = np.median(input_array,axis=1)
    # Generate an output numpy array with the same size that input_array with
    # baseline predictions
    # Create a 3-d numpy array with ones
    output_array = np.ones(input_array.shape)
    # Multiply it by the prediction array, with a new dimension in axis 1
    output_array = output_array * np.expand_dims(prediction, axis=1)
    return output_array

# Comes from 04_baseline_models.ipynb, cell
import tensorflow as tf
def get_windows_mse(predictions, original_data):
    " Function that calculates the mse for each of the windows in which an auto-encoder model has made a prediction."
    # Test that dimensions are correct.
    assert predictions.shape == original_data.shape
    # Create a mse object
    mse = tf.keras.losses.MeanSquaredError(
        reduction=tf.keras.losses.Reduction.NONE)
    # We need to adapt the axes to calculate the mse in the manner we want.
    prediction_swaped = np.swapaxes(predictions,1,2)
    original_data_swaped = np.swapaxes(original_data,1,2)
    # Calculate mses
    windows_mse = mse(original_data_swaped, prediction_swaped).numpy()

    return windows_mse

# Cell
from .imports import *
from fastcore.all import *
import wandb
import pickle
import pandas as pd
import numpy as np
import tensorflow as tf

# Cell
def generate_TS_df(rows, cols):
    "Generates a dataframe containing a multivariate time series, where each column \
    represents a variable and each row a time point (sample). The timestamp is in the \
    index of the dataframe, and it is created with a even space of 1 second between samples"
    index = np.arange(pd.Timestamp.now(),
                      pd.Timestamp.now() + pd.Timedelta(rows-1, 'seconds'),
                      pd.Timedelta(1, 'seconds'))
    data = np.random.randn(len(index), cols)
    return pd.DataFrame(data, index=index)

# Cell
def normalize_columns(df:pd.DataFrame):
    "Normalize columns from `df` to have 0 mean and 1 standard deviation"
    mean = df.mean()
    std = df.std() + 1e-7
    return (df-mean)/std

# Cell
def remove_constant_columns(df:pd.DataFrame):
    return df.loc[:, (df != df.iloc[0]).any()]

# Cell
class ReferenceArtifact(wandb.Artifact):
    default_storage_path = Path('data/wandb_artifacts/') # * this path is relative to Path.home()
    "This class is meant to create an artifact with a single reference to an object \
    passed as argument in the contructor. The object will be pickled, hashed and stored \
    in a specified folder."
    @delegates(wandb.Artifact.__init__)
    def __init__(self, obj, name, folder=None, **kwargs):
        super().__init__(type='object', name=name, **kwargs)
        # pickle dumps the object and then hash it
        hash_code = str(hash(pickle.dumps(obj)))
        folder = Path(ifnone(folder, Path.home()/self.default_storage_path))
        with open(f'{folder}/{hash_code}', 'wb') as f:
            pickle.dump(obj, f)
        self.add_reference(f'file://{folder}/{hash_code}')
        if self.metadata is None:
            self.metadata = dict()
        self.metadata['ref'] = dict()
        self.metadata['ref']['hash'] = hash_code
        self.metadata['ref']['type'] = str(type(obj))

# Cell
@patch
def to_obj(self:wandb.apis.public.Artifact):
    "Download the files of a saved ReferenceArtifact and get the referenced object. The artifact must \
    come from a call to `run.use_artifact` with a proper wandb run."
    if self.metadata.get('ref') is None:
        print(f'ERROR:{self} does not come from a saved ReferenceArtifact')
        return None
    path = Path(self.download()).ls()[0]
    with open(path, 'rb') as f:
        obj = pickle.load(f)
    return obj

# Cell
from .visualization import *

# Cell
@patch
def plot_top_losses(self:tf.keras.Sequential, validation_data, k, largest=True, return_fig=True, title_pos=0.99, **kwargs):
    "Take the validation data of model self, compute the model losses for every item there, sort, and plot the results.\
    If `largest` is True, the validation losses will be sorted from larger to lower. Once they are sorted, take the\
    k first items based on this order and plot the predictions.\
    If 'return_fig' is true, a Figure-set of plots is returned. If not, just showed on screen"
    # Get a prediction with the validation_data
    pred_validation_data = self.predict(validation_data)
    # Calculate the MSE with respect to original_data
    mse_values = np.mean(np.square(validation_data - pred_validation_data), axis=(1,2))

    # Order the numpy array and take the top k.
    if largest:
        id_loss_values = mse_values.argsort()[-k:]
        txt_var = "Largest MSE of the model for validation dataset"
    else:
        id_loss_values = mse_values.argsort()[:k]
        txt_var = "Smallest MSE of the model for validation dataset"

    # Plot figures
    list_figs = [None] * k
    for i in range(k):
        title = txt_var + " windoes_num: " + str(id_loss_values[i])
        list_figs[i] = plot_validation_ts_ae(validation_data,
                                             pred_validation_data,
                                             title_str = title,
                                             title_pos = title_pos,
                                             window_num = id_loss_values[i],
                                             return_fig = True,
                                             **kwargs)

    # Returns
    if return_fig:
        return list_figs
    else:
        list_figs
        return None