# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_Timecluster_replication.ipynb (unless otherwise specified).

__all__ = ['fslicer', 'createDCAE', 'slices2array', 'train_surrogate_model']

# Cell
import pandas as pd
import seaborn as sns
import numpy as np
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Flatten, Conv1D, MaxPool1D, Reshape, UpSampling1D
import umap

# Cell
def fslicer(df, w, s=1, padding=False, padding_value=0):
    "Transform a numeric dataframe `df` into slices (sub-dataframes) of `w` rows and the same number of columns than the \
    original dataframe. The distance between each slice is given by the stride `s`. If `padding` is equals to True, \
    the last slices which have less than `w` points are filled with the value marked in the argument \
    `padding_value`. Otherwise, those slices are removed from the result."
    aux = [df.iloc[x:x+w] for x in range(0,len(df), s)]
    if padding:
        with_padding = [x.append(pd.DataFrame(np.full((w - len(x), len(df.columns)), padding_value), columns=df.columns.values)) if len(x) < w else x for x in aux]
    else:
        with_padding = [x for x in aux if len(x)==w]
    return with_padding

# Cell
def createDCAE(w, d, delta):
    "Create a Deep Convolutional Autoencoder for multivariate time series of `d` dimensions, \
    sliced with a window size of `w`. The parameter `delta` sets the number of latent features that will be \
    contained in the Dense layer of the network."
    model = Sequential()
    model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=(w,d), padding='same'))
    model.add(MaxPool1D(pool_size=2))
    model.add(Conv1D(filters=32, kernel_size=5, activation='relu', padding='same'))
    model.add(MaxPool1D(pool_size=2))
    model.add(Conv1D(filters=12, kernel_size=5, activation='relu', padding='same'))
    model.add(MaxPool1D(pool_size=3))
    aux_shape = model.output_shape[1:]
    model.add(Flatten())
    model.add(Dense(units=np.prod(aux_shape), activation='linear', name='latent_features'))
    model.add(Reshape(target_shape=aux_shape))
    model.add(Conv1D(filters=12, kernel_size=5, activation='relu', padding='same'))
    model.add(UpSampling1D(size=3))
    model.add(Conv1D(filters=32, kernel_size=5, activation='relu', padding='same'))
    model.add(UpSampling1D(size=2))
    model.add(Conv1D(filters=64, kernel_size=10, activation='relu', padding='same'))
    model.add(UpSampling1D(size=2))
    model.add(Conv1D(filters=d, kernel_size=10, activation='linear', padding='same'))
    return model

# Cell
def slices2array(slices):
    "`slices` is a list of dataframes, each of them containing an slice of a multivariate time series."
    return np.rollaxis(np.dstack([x.values for x in slices]), -1)

# Cell
def train_surrogate_model(dcae, embeddings, lat_ln='latent_features'):
    "Train a surrogate model that learns the `embeddings` from the latent features contained in the layer \
    `lat_ln` of a previously trained Deep Convolutional AutoEncoder `dcae`"
    x = dcae.get_layer(lat_ln).output
    x = Dense(units=embeddings.shape[1], activation='linear')(x)
    surrogate_model = Model(dcae.input, x)
    l_nms = [layer.name for layer in surrogate_model.layers]
    layer_idx = l_nms.index(lat_ln)
    # The layers that are already trained from the autoencoder must be `frozen`
    for layer in surrogate_model.layers[:layer_idx]:
        layer.trainable = False
    return surrogate_model