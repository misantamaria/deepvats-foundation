{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de2cd87-7d93-45ec-bd92-d97a85cf73b3",
   "metadata": {},
   "source": [
    "# Getting the embeddings\n",
    "\n",
    "> This notebook gets the embeddings (or latent space) from a multivariate time series \n",
    "given by a encoder (e.g., autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db2cd5f-dd8d-42a3-bdc1-afc12ff80afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tchub.all import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from yaml import load, FullLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280e30d-8195-4f39-898a-495d9253778b",
   "metadata": {},
   "source": [
    "## Config parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c114f4-ba8e-48ae-9a6d-b5dda96b717b",
   "metadata": {},
   "source": [
    "Put here everything that could be needed if this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "312f776f-e284-4ab8-b888-8caa723d7a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AttrDict(\n",
    "    use_wandb = False, # Whether to use or not wandb for experiment tracking\n",
    "    wandb_group = 'embeddings', # Whether to group this run in a wandb group\n",
    "    wandb_entity = 'pacmel',\n",
    "    wandb_project = 'tchub',\n",
    "    enc_artifact = 'pacmel/tchub/mvp:v5', # Name:version of the encoder artifact\n",
    "    input_ar = None,\n",
    "    cpu = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe624f-f4ff-4310-9d3c-23099381ed91",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa46f602-bbf9-4d2d-ae68-771adae56199",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=config.wandb_entity,\n",
    "                    project=config.wandb_project if config.use_wandb else 'work-nbs', \n",
    "                    group=config.wandb_group,\n",
    "                    job_type='embeddings', \n",
    "                    mode='online' if config.use_wandb else 'disabled',\n",
    "                    anonymous = 'never' if config.use_wandb else 'must',\n",
    "                    config=config,\n",
    "                    #id = 'embeddingsProvider',\n",
    "                    resume='allow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26dac90a-ed13-4f50-b95e-fc78c635e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Botch to use artifacts offline\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08922829-19f7-4cdc-97b1-86f5a3b4f3d2",
   "metadata": {},
   "source": [
    "Restore the encoder model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e978658-78de-4dff-9679-d2ed1453dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_artifact = artifacts_gettr(config.enc_artifact, type='learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7fbe313-d3b6-4793-aaf3-34d4b858065c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f2dbbe9ffd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: This only works when you run it two timeS! WTF?\n",
    "try:\n",
    "    enc_learner = enc_artifact.to_obj()\n",
    "except:\n",
    "    enc_learner = enc_artifact.to_obj()\n",
    "enc_learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1dfa6-52b9-4114-a4f8-16a94b83b21c",
   "metadata": {},
   "source": [
    "Restore the dataset artifact used for training the encoder. Even if we do not compute the dimensionality reduction over this dataset, we need to know the metadata of the encoder training set, to check that \n",
    "it matches with the dataset that we want to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4335e626-5faa-4d27-845c-015f23ab9375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('steamflow:v0', 'steamflow:v0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run = enc_artifact.logged_by()\n",
    "enc_artifact_train = artifacts_gettr(enc_run.config['train_artifact'], type='dataset')\n",
    "enc_artifact_valid = artifacts_gettr(enc_run.config['valid_artifact'], type='dataset')\n",
    "enc_artifact_train.name, enc_artifact_valid.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918829a-dd1f-4ddb-915c-cebf41665160",
   "metadata": {},
   "source": [
    "Now we specify the dataset artifact that we want to get the embeddings from. If no \n",
    "artifact is defined, the artifact to reduce will be the one used for validate the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59ff4ef9-cabd-41cb-84c8-ec86cadf5848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'steamflow:v0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ar_name = ifnone(config.input_ar, \n",
    "                       f'{enc_artifact_valid.entity}/{enc_artifact_valid.project}/{enc_artifact_valid.name}')\n",
    "wandb.config.update({'input_ar': input_ar_name}, allow_val_change=True)\n",
    "input_ar = artifacts_gettr(input_ar_name)\n",
    "input_ar.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a84cf086-f6ee-4f04-a234-581a738fc338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steam flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>9.302970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>9.662621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:06</th>\n",
       "      <td>10.990955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:09</th>\n",
       "      <td>12.430107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:12</th>\n",
       "      <td>13.681666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 07:59:45</th>\n",
       "      <td>7.898815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 07:59:48</th>\n",
       "      <td>7.729076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 07:59:51</th>\n",
       "      <td>7.856854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 07:59:54</th>\n",
       "      <td>7.799764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 07:59:57</th>\n",
       "      <td>7.767867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9600 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     steam flow\n",
       "1970-01-01 00:00:00    9.302970\n",
       "1970-01-01 00:00:03    9.662621\n",
       "1970-01-01 00:00:06   10.990955\n",
       "1970-01-01 00:00:09   12.430107\n",
       "1970-01-01 00:00:12   13.681666\n",
       "...                         ...\n",
       "1970-01-01 07:59:45    7.898815\n",
       "1970-01-01 07:59:48    7.729076\n",
       "1970-01-01 07:59:51    7.856854\n",
       "1970-01-01 07:59:54    7.799764\n",
       "1970-01-01 07:59:57    7.767867\n",
       "\n",
       "[9600 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = input_ar.to_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46c6bb02-9a43-4917-93a9-0832ee98b5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49908f03-6875-4e27-8050-09af41dc62bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8961, 1, 640)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input, _ = SlidingWindow(window_len=enc_run.config['w'], \n",
    "                             stride=enc_run.config['stride'], \n",
    "                             get_y=[])(df)\n",
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08bfd363-3c5d-4f4d-a7e7-cb65c8bd9f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/env/lib/python3.8/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.71 s, sys: 127 ms, total: 4.84 s\n",
      "Wall time: 4.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embs = get_enc_embs(enc_input, enc_learner, cpu=config.cpu, to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3393cc12-f6c2-4bdc-adba-662689a9c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.use_wandb: \n",
    "    run.log_artifact(ReferenceArtifact(embs, 'embeddings', metadata=dict(run.config)), \n",
    "                     aliases=f'run-{run.project}-{run.id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2de38c4f-a266-45b5-a99f-0964f5a55113",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d45d555be0220b07bf61be557bfa0ebbf7a95015976aec9a23277863e1bd4593"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
