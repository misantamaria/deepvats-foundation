{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de2cd87-7d93-45ec-bd92-d97a85cf73b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Getting the embeddings\n",
    "\n",
    "> This notebook gets the embeddings (or latent space) from a multivariate time series \n",
    "given by a encoder (e.g., autoencoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816ae963-a2d2-467a-90ee-2be0f383c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_patch_size = 8\n",
    "verbose          = 0\n",
    "reset_kernel     = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db2cd5f-dd8d-42a3-bdc1-afc12ff80afb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7f4b2cd8a140>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "from dvats.all import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from yaml import load, FullLoader\n",
    "import dvats.utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6774bdd-fc22-4e8e-96c4-c29417380137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280e30d-8195-4f39-898a-495d9253778b",
   "metadata": {},
   "source": [
    "## Config parameters\n",
    "> Configuration parameters are obtained from 'config\\03-embeddings.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fd16b-1ca7-4bed-9173-642cabdbe9bb",
   "metadata": {},
   "source": [
    "### Get configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47519e96-4dd2-4096-8189-d735f88155ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, job_type = get_artifact_config_embeddings(verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515769be-e06d-4ae2-b3ab-1636642a158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/zeroshot-moment-small-embedding:latest\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372ce1e-f3c8-4df4-a802-1250bc9a80cb",
   "metadata": {},
   "source": [
    "### Show configuration artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08922829-19f7-4cdc-97b1-86f5a3b4f3d2",
   "metadata": {},
   "source": [
    "### Get the model from W&B\n",
    "> Restore the encoder model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c15b94a4-19cb-47c0-a000-b0890d303ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'mi-santamaria'\n",
    "project = 'deepvats'\n",
    "folder = entity+'/'+project+'/'\n",
    "model_family = 'zeroshot-moment'\n",
    "task = 'embedding'\n",
    "dataset = 'gtrends_kohls'\n",
    "dataset_version = 'v2'\n",
    "enc_artifact_dataset = folder + dataset + ':' + dataset_version\n",
    "enc_artifact_small = folder + model_family + '-small-' + task + ':v0'\n",
    "enc_artifact_base  =  folder + model_family + '-base-' + task + ':v0'\n",
    "enc_artifact_large = folder + model_family + '-large-' + task + ':v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e978658-78de-4dff-9679-d2ed1453dec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataset artifact:  mi-santamaria/deepvats/gtrends_kohls:v2\n",
      "Getting small artifact:  mi-santamaria/deepvats/zeroshot-moment-small-embedding:v0\n",
      "Getting base artifact:  mi-santamaria/deepvats/zeroshot-moment-base-embedding:v0\n",
      "Getting large artifact:  mi-santamaria/deepvats/zeroshot-moment-large-embedding:v0\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting dataset artifact: \", enc_artifact_dataset)\n",
    "df_artifact = wandb_api.artifact(enc_artifact_dataset, type = 'dataset')\n",
    "print(\"Getting small artifact: \", enc_artifact_small)\n",
    "enc_artifact_small = wandb_api.artifact(enc_artifact_small, type='learner')\n",
    "print(\"Getting base artifact: \", enc_artifact_base)\n",
    "enc_artifact_base  = wandb_api.artifact(enc_artifact_base, type='learner')\n",
    "print(\"Getting large artifact: \", enc_artifact_large)\n",
    "enc_artifact_large = wandb_api.artifact(enc_artifact_large, type='learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dfcdf28-2518-49af-8c64-c2305ba71a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtrends_kohls:v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of               volume\n",
       "2004-01-01  0.010417\n",
       "2004-01-08  0.010417\n",
       "2004-01-15  0.010417\n",
       "2004-01-22  0.000000\n",
       "2004-01-29  0.000000\n",
       "...              ...\n",
       "2012-05-03  0.322917\n",
       "2012-05-10  0.312500\n",
       "2012-05-17  0.281250\n",
       "2012-05-24  0.291667\n",
       "2012-05-31  0.322917\n",
       "\n",
       "[440 rows x 1 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440, 1)\n"
     ]
    }
   ],
   "source": [
    "print(df_artifact.name)\n",
    "df = df_artifact.to_df()\n",
    "display(df.head)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e24131d-d4f7-4931-88ca-df2680838050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Artifact QXJ0aWZhY3Q6MTM1Mzc4Nzc3MQ==>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact zeroshot-moment-small-embedding:v0, 144.63MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.5\n"
     ]
    }
   ],
   "source": [
    "print(enc_artifact_small.name)\n",
    "enc_learner_small = enc_artifact_small.to_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3b60372-ee00-443e-a0e8-f95f10422c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeroshot-moment-base-embedding:v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact zeroshot-moment-base-embedding:v0, 432.97MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.3\n"
     ]
    }
   ],
   "source": [
    "print(enc_artifact_base.name)\n",
    "enc_learner_base  = enc_artifact_base.to_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7fbe313-d3b6-4793-aaf3-34d4b858065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeroshot-moment-large-embedding:v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact zeroshot-moment-large-embedding:v0, 1321.42MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:4.1\n"
     ]
    }
   ],
   "source": [
    "print(enc_artifact_large.name)\n",
    "enc_learner_large = enc_artifact_large.to_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c96a07c9-7211-4d2a-ab1b-50838d630b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35341512\n",
      "109641608\n",
      "341248520\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    #return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "print(count_parameters(enc_learner_small))\n",
    "print(count_parameters(enc_learner_base))\n",
    "print(count_parameters(enc_learner_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff3d78e0-5847-4606-9cab-b9c9e02c0a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341248520"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "count_parameters(enc_learner_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a05c5be8-47c7-45f9-8ba9-43201e704a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.losses import MSELossFlat\n",
    "from dvats.encoder import MAELossFlat, EvalMSE, EvalRMSE, EvalMAE, EvalSMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "983727b7-d41a-4ed1-be07-fe381be1b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame(\n",
    "    columns = [\n",
    "        'model size',\n",
    "        'n_epochs',\n",
    "        'dataset_percent',\n",
    "        'maskared_percent',\n",
    "        'losses',\n",
    "        'eval_results_pre',\n",
    "        'eval_results_post',\n",
    "        'time'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49908f03-6875-4e27-8050-09af41dc62bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 1, 17)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input, _ = SlidingWindow(window_len=17, stride=2, get_y=[])(df)\n",
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1600f495-f021-4b4e-88a7-5ad6a949fe83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 21, 42]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = [5, 10, 20, 40, 80, 100]\n",
    "epochs = vals[:2]\n",
    "dataset_percents = [ val / 100 for val in vals ][:2]\n",
    "maskared_percents = [ val / 100 for val in vals[:-1]] [:2]\n",
    "sizes_percents = [5,10,20]\n",
    "n_sizes = [int(np.floor(val*enc_input.shape[0]/100)) for val in sizes_percents]\n",
    "n_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f66dd47-58ad-4067-81ea-3282eff61a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import dvats.config as cfg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d77cb4e-da4b-4f01-a30c-c145b97d1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, project, version, data, config, job_type = cfg_.get_artifact_config_MVP(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04301513-8b67-47a5-8140-96f4381e64e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "0.4\n",
      "online\n"
     ]
    }
   ],
   "source": [
    "print(config['batch_size'])\n",
    "print(config['r'])\n",
    "print(config['analysis_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fafa294-2aca-4448-a6c9-c5b67a2668f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args = {\n",
    "    \"X\": df,\n",
    "    \"stride\": 1,\n",
    "    \"batch_size\": config['batch_size'],\n",
    "    \"cpu\": False,\n",
    "    \"to_numpy\": False,\n",
    "    \"time_flag\": True,\n",
    "    \"n_windows\": None,\n",
    "    \"n_windows_percent\": 0.8, # Comprobando si el None es el problema\n",
    "    \"shot\": True,\n",
    "    \"eval_pre\": True,\n",
    "    \"eval_post\": True,\n",
    "    \"lr\": config['r'], #use enc_run lr,\n",
    "    \"lr_scheduler_flag\": False,\n",
    "    \"lr_scheduler_name\": \"cosine_with_restarts\",\n",
    "    \"lr_scheduler_num_warmup_steps\": None,\n",
    "    \"window_sizes\": None,\n",
    "    \"full_dataset\": True,\n",
    "    \"window_sizes_offset\": 0.05,\n",
    "    \"windows_min_distance\": 5, #2.5*enc_input.shape[0]/100,\n",
    "    \"print_to_path\": False,\n",
    "    \"print_path\": \"~/data/logs.txt\",\n",
    "    \"print_mode\": \"w\",\n",
    "    \"use_moment_masks\": False,\n",
    "    \"mask_stateful\": config['mask_stateful'],\n",
    "    \"mask_future\": config['mask_future'],\n",
    "    \"mask_sync\": config['mask_sync'],\n",
    "    \"analysis_mode\": config['analysis_mode'],\n",
    "    \"use_wandb\": config['use_wandb'],\n",
    "    \"norm_by_sample\": config['norm_by_sample'],\n",
    "    \"norm_use_single_batch\": config['norm_use_single_batch'],\n",
    "    \"show_plot\": True,\n",
    "    \"metrics\": [EvalMSE, EvalRMSE, EvalMAE, EvalSMAPE],\n",
    "    \"metrics_args\": [{'squared': False}, {'squared': True}, {}, {}],\n",
    "    \"metrics_names\":[\"mse\", \"rmse\", \"mae\", \"smape\"],\n",
    "    \"metrics_dict\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c505452b-ab49-464f-856c-46288048c233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> epoch 5, dataset_percent 0.3, mask 0.4\n",
      " sizes 3\n",
      "[5] [ --> _get_encoder ]\n",
      "[5]  [ _get_encoder ] About to exec _get_enc_input\n",
      "[5] [ --> _get_enc_input ]\n",
      "[5]  [ _get_enc_input ] is none enc_input? True\n",
      "[5]  [ _get_enc_input ] About to get the windows\n",
      "[5] [ --> windowed_dataset ]\n",
      "[5]  [ _get_enc_input ] X is a DataFrame, X~(440, 1) | window_sizes 0, n_window_sizes 3\n",
      "[5]  [ _get_enc_input ] X is a DataFrame | Selecting Fourier's dominant frequences\n",
      "[5] [ --> Find_dominant_window_sizes_list ]\n",
      "[5]  [ Find_dominant_window_sizes_list ] X ~ (440, 1)\n",
      "[5]  [ Find_dominant_window_sizes_list ] Get sizes for var 0\n",
      "[5] [ --> find_dominant_window_sizes_list_single ]\n",
      "[5]  [ Find_dominant_window_sizes_list ] X ~ (440,)\n",
      "[5]  [ Find_dominant_window_sizes_list ] Looking for - at most - the best 3 window sizes\n",
      "[5]  [ Find_dominant_window_sizes_list ] Offset 0.05 max size: 22.0\n",
      "[5]  [ Find_dominant_window_sizes_list ] --> Freqs\n",
      "[5]  [ Find_dominant_window_sizes_list ] Find_dominant_window_sizes_list | Freqs [ 0.          0.00227273  0.00454545  0.00681818  0.00909091  0.01136364\n",
      "  0.01363636  0.01590909  0.01818182  0.02045455  0.02272727  0.025\n",
      "  0.02727273  0.02954545  0.03181818  0.03409091  0.03636364  0.03863636\n",
      "  0.04090909  0.04318182  0.04545455  0.04772727  0.05        0.05227273\n",
      "  0.05454545  0.05681818  0.05909091  0.06136364  0.06363636  0.06590909\n",
      "  0.06818182  0.07045455  0.07272727  0.075       0.07727273  0.07954545\n",
      "  0.08181818  0.08409091  0.08636364  0.08863636  0.09090909  0.09318182\n",
      "  0.09545455  0.09772727  0.1         0.10227273  0.10454545  0.10681818\n",
      "  0.10909091  0.11136364  0.11363636  0.11590909  0.11818182  0.12045455\n",
      "  0.12272727  0.125       0.12727273  0.12954545  0.13181818  0.13409091\n",
      "  0.13636364  0.13863636  0.14090909  0.14318182  0.14545455  0.14772727\n",
      "  0.15        0.15227273  0.15454545  0.15681818  0.15909091  0.16136364\n",
      "  0.16363636  0.16590909  0.16818182  0.17045455  0.17272727  0.175\n",
      "  0.17727273  0.17954545  0.18181818  0.18409091  0.18636364  0.18863636\n",
      "  0.19090909  0.19318182  0.19545455  0.19772727  0.2         0.20227273\n",
      "  0.20454545  0.20681818  0.20909091  0.21136364  0.21363636  0.21590909\n",
      "  0.21818182  0.22045455  0.22272727  0.225       0.22727273  0.22954545\n",
      "  0.23181818  0.23409091  0.23636364  0.23863636  0.24090909  0.24318182\n",
      "  0.24545455  0.24772727  0.25        0.25227273  0.25454545  0.25681818\n",
      "  0.25909091  0.26136364  0.26363636  0.26590909  0.26818182  0.27045455\n",
      "  0.27272727  0.275       0.27727273  0.27954545  0.28181818  0.28409091\n",
      "  0.28636364  0.28863636  0.29090909  0.29318182  0.29545455  0.29772727\n",
      "  0.3         0.30227273  0.30454545  0.30681818  0.30909091  0.31136364\n",
      "  0.31363636  0.31590909  0.31818182  0.32045455  0.32272727  0.325\n",
      "  0.32727273  0.32954545  0.33181818  0.33409091  0.33636364  0.33863636\n",
      "  0.34090909  0.34318182  0.34545455  0.34772727  0.35        0.35227273\n",
      "  0.35454545  0.35681818  0.35909091  0.36136364  0.36363636  0.36590909\n",
      "  0.36818182  0.37045455  0.37272727  0.375       0.37727273  0.37954545\n",
      "  0.38181818  0.38409091  0.38636364  0.38863636  0.39090909  0.39318182\n",
      "  0.39545455  0.39772727  0.4         0.40227273  0.40454545  0.40681818\n",
      "  0.40909091  0.41136364  0.41363636  0.41590909  0.41818182  0.42045455\n",
      "  0.42272727  0.425       0.42727273  0.42954545  0.43181818  0.43409091\n",
      "  0.43636364  0.43863636  0.44090909  0.44318182  0.44545455  0.44772727\n",
      "  0.45        0.45227273  0.45454545  0.45681818  0.45909091  0.46136364\n",
      "  0.46363636  0.46590909  0.46818182  0.47045455  0.47272727  0.475\n",
      "  0.47727273  0.47954545  0.48181818  0.48409091  0.48636364  0.48863636\n",
      "  0.49090909  0.49318182  0.49545455  0.49772727 -0.5        -0.49772727\n",
      " -0.49545455 -0.49318182 -0.49090909 -0.48863636 -0.48636364 -0.48409091\n",
      " -0.48181818 -0.47954545 -0.47727273 -0.475      -0.47272727 -0.47045455\n",
      " -0.46818182 -0.46590909 -0.46363636 -0.46136364 -0.45909091 -0.45681818\n",
      " -0.45454545 -0.45227273 -0.45       -0.44772727 -0.44545455 -0.44318182\n",
      " -0.44090909 -0.43863636 -0.43636364 -0.43409091 -0.43181818 -0.42954545\n",
      " -0.42727273 -0.425      -0.42272727 -0.42045455 -0.41818182 -0.41590909\n",
      " -0.41363636 -0.41136364 -0.40909091 -0.40681818 -0.40454545 -0.40227273\n",
      " -0.4        -0.39772727 -0.39545455 -0.39318182 -0.39090909 -0.38863636\n",
      " -0.38636364 -0.38409091 -0.38181818 -0.37954545 -0.37727273 -0.375\n",
      " -0.37272727 -0.37045455 -0.36818182 -0.36590909 -0.36363636 -0.36136364\n",
      " -0.35909091 -0.35681818 -0.35454545 -0.35227273 -0.35       -0.34772727\n",
      " -0.34545455 -0.34318182 -0.34090909 -0.33863636 -0.33636364 -0.33409091\n",
      " -0.33181818 -0.32954545 -0.32727273 -0.325      -0.32272727 -0.32045455\n",
      " -0.31818182 -0.31590909 -0.31363636 -0.31136364 -0.30909091 -0.30681818\n",
      " -0.30454545 -0.30227273 -0.3        -0.29772727 -0.29545455 -0.29318182\n",
      " -0.29090909 -0.28863636 -0.28636364 -0.28409091 -0.28181818 -0.27954545\n",
      " -0.27727273 -0.275      -0.27272727 -0.27045455 -0.26818182 -0.26590909\n",
      " -0.26363636 -0.26136364 -0.25909091 -0.25681818 -0.25454545 -0.25227273\n",
      " -0.25       -0.24772727 -0.24545455 -0.24318182 -0.24090909 -0.23863636\n",
      " -0.23636364 -0.23409091 -0.23181818 -0.22954545 -0.22727273 -0.225\n",
      " -0.22272727 -0.22045455 -0.21818182 -0.21590909 -0.21363636 -0.21136364\n",
      " -0.20909091 -0.20681818 -0.20454545 -0.20227273 -0.2        -0.19772727\n",
      " -0.19545455 -0.19318182 -0.19090909 -0.18863636 -0.18636364 -0.18409091\n",
      " -0.18181818 -0.17954545 -0.17727273 -0.175      -0.17272727 -0.17045455\n",
      " -0.16818182 -0.16590909 -0.16363636 -0.16136364 -0.15909091 -0.15681818\n",
      " -0.15454545 -0.15227273 -0.15       -0.14772727 -0.14545455 -0.14318182\n",
      " -0.14090909 -0.13863636 -0.13636364 -0.13409091 -0.13181818 -0.12954545\n",
      " -0.12727273 -0.125      -0.12272727 -0.12045455 -0.11818182 -0.11590909\n",
      " -0.11363636 -0.11136364 -0.10909091 -0.10681818 -0.10454545 -0.10227273\n",
      " -0.1        -0.09772727 -0.09545455 -0.09318182 -0.09090909 -0.08863636\n",
      " -0.08636364 -0.08409091 -0.08181818 -0.07954545 -0.07727273 -0.075\n",
      " -0.07272727 -0.07045455 -0.06818182 -0.06590909 -0.06363636 -0.06136364\n",
      " -0.05909091 -0.05681818 -0.05454545 -0.05227273 -0.05       -0.04772727\n",
      " -0.04545455 -0.04318182 -0.04090909 -0.03863636 -0.03636364 -0.03409091\n",
      " -0.03181818 -0.02954545 -0.02727273 -0.025      -0.02272727 -0.02045455\n",
      " -0.01818182 -0.01590909 -0.01363636 -0.01136364 -0.00909091 -0.00681818\n",
      " -0.00454545 -0.00227273] -->\n",
      "[5]  [ Find_dominant_window_sizes_list ] Find_dominant_window_sizes_list | coefs [7.05208450e+01 2.17522066e+01 1.51117073e+01 1.08917429e+01\n",
      " 7.98043598e+00 4.85509881e+00 5.08770649e+00 4.61865603e+00\n",
      " 1.05418881e+01 4.14979431e+00 4.76953214e-01 5.86317778e-01\n",
      " 7.18337760e-01 1.07780909e+00 2.35498782e-01 7.20215333e-01\n",
      " 1.96347247e+00 9.38784226e+00 2.99297830e+00 2.08189696e+00\n",
      " 2.49385046e+00 1.71487275e+00 1.94407839e+00 1.96098531e+00\n",
      " 1.89724827e+00 8.15590795e+00 3.52111673e+00 8.99907928e-01\n",
      " 1.06066847e+00 8.28651027e-01 7.64079256e-01 9.36246469e-01\n",
      " 5.81945408e-01 2.59914187e+00 5.88234408e+00 1.81839487e+00\n",
      " 1.61762788e+00 1.39577649e+00 1.43216216e+00 1.49479629e+00\n",
      " 1.19792146e+00 1.31164524e+00 3.67380021e+00 1.11452862e+00\n",
      " 4.83337162e-01 1.82045706e-01 2.51375542e-01 8.59942592e-02\n",
      " 5.14102525e-01 3.07583414e-01 7.76624319e-01 2.75514067e+00\n",
      " 1.37824354e+00 1.46632219e-01 8.67086600e-01 5.33131622e-01\n",
      " 5.37527585e-01 3.35078734e-01 3.15423069e-01 5.14284786e-01\n",
      " 9.10117190e-01 7.90460275e-01 4.32711634e-01 3.93838231e-01\n",
      " 4.18690901e-01 4.23629859e-01 7.50179324e-01 1.13851179e+00\n",
      " 6.40861403e-01 1.26757880e-01 3.62668541e-01 1.03689586e-01\n",
      " 4.53112006e-01 3.77366888e-01 8.20368247e-02 4.02314524e-01\n",
      " 1.43060549e+00 5.70117079e-01 5.80550972e-01 2.43891425e-01\n",
      " 5.09424523e-01 3.41242063e-01 5.75738081e-01 5.46758534e-01\n",
      " 1.61731453e+00 1.83306734e-01 4.29781084e-01 1.72372519e-01\n",
      " 9.96824171e-02 6.16629699e-02 3.83731539e-01 1.94739951e-01\n",
      " 1.05264356e+00 2.19393275e+00 9.63156393e-01 6.26881821e-01\n",
      " 5.32550231e-01 6.29025335e-01 6.22641311e-01 5.86583104e-01\n",
      " 4.87077570e-01 1.32796671e+00 3.82040960e-01 4.77883625e-01\n",
      " 1.24875209e-01 2.62341193e-01 1.43642833e-01 3.16621068e-01\n",
      " 2.30396944e-01 1.27399937e+00 1.96126638e+00 1.19371022e+00\n",
      " 8.59447880e-01 7.97778595e-01 5.27269828e-01 3.98809808e-01\n",
      " 4.32951835e-01 7.52366345e-01 1.93323776e+00 7.28311360e-01\n",
      " 4.15258679e-01 1.40513014e-01 3.91111899e-01 1.09665817e-01\n",
      " 5.06474122e-01 2.67548244e-01 7.78454603e-01 1.28718009e+00\n",
      " 9.37300430e-01 1.74514937e-01 4.80464220e-01 1.46025905e-01\n",
      " 3.35117279e-01 1.05098177e-01 6.42178473e-01 4.91593538e-01\n",
      " 1.83137275e-01 5.87990897e-01 9.85901654e-02 3.78025387e-01\n",
      " 1.71697441e-01 5.45500234e-01 4.62014884e-01 8.06124751e-01\n",
      " 6.32469073e-01 3.20604343e-01 3.13630825e-01 7.09827408e-01\n",
      " 2.42198416e-01 4.83588209e-01 1.78252899e-01 4.82234424e-01\n",
      " 2.84326895e-01 3.58662760e-01 5.60258251e-01 1.49563774e-01\n",
      " 3.85001188e-01 1.86587731e-01 6.02123474e-01 1.71488932e-01\n",
      " 9.20529001e-01 5.86678171e-01 4.16942363e-01 1.20759219e-01\n",
      " 2.03270008e-01 2.56957857e-01 4.97482399e-01 2.21753783e-01\n",
      " 7.77688688e-01 9.70753417e-01 9.64500032e-01 5.24903110e-01\n",
      " 2.37929172e-01 2.68556750e-01 2.81549865e-01 4.23825895e-01\n",
      " 7.07139444e-01 1.40628665e+00 7.23895052e-01 2.87939965e-01\n",
      " 1.70589963e-01 1.86167939e-01 1.24306854e-01 4.02796030e-01\n",
      " 3.43824952e-01 7.82722618e-01 9.60348143e-01 9.03734349e-01\n",
      " 2.05860795e-01 5.30708958e-01 3.87088594e-01 3.65813128e-01\n",
      " 3.92789116e-01 7.51960126e-01 9.55793288e-01 6.46895798e-01\n",
      " 6.06062984e-01 1.06755334e-01 3.46925168e-01 1.18433818e-01\n",
      " 4.65098476e-01 4.01014572e-01 3.82187726e-01 3.89927607e-01\n",
      " 6.39409585e-01 1.16398430e-01 5.37536982e-01 2.60664188e-01\n",
      " 5.94530536e-01 3.42324045e-01 5.92096914e-01 6.69123580e-01\n",
      " 3.82960792e-01 3.88082937e-01 3.15541249e-01 5.47114371e-01\n",
      " 1.58975566e-01 3.59959298e-01 3.04271830e-01 4.07639725e-01\n",
      " 3.33335000e-01 4.07639725e-01 3.04271830e-01 3.59959298e-01\n",
      " 1.58975566e-01 5.47114371e-01 3.15541249e-01 3.88082937e-01\n",
      " 3.82960792e-01 6.69123580e-01 5.92096914e-01 3.42324045e-01\n",
      " 5.94530536e-01 2.60664188e-01 5.37536982e-01 1.16398430e-01\n",
      " 6.39409585e-01 3.89927607e-01 3.82187726e-01 4.01014572e-01\n",
      " 4.65098476e-01 1.18433818e-01 3.46925168e-01 1.06755334e-01\n",
      " 6.06062984e-01 6.46895798e-01 9.55793288e-01 7.51960126e-01\n",
      " 3.92789116e-01 3.65813128e-01 3.87088594e-01 5.30708958e-01\n",
      " 2.05860795e-01 9.03734349e-01 9.60348143e-01 7.82722618e-01\n",
      " 3.43824952e-01 4.02796030e-01 1.24306854e-01 1.86167939e-01\n",
      " 1.70589963e-01 2.87939965e-01 7.23895052e-01 1.40628665e+00\n",
      " 7.07139444e-01 4.23825895e-01 2.81549865e-01 2.68556750e-01\n",
      " 2.37929172e-01 5.24903110e-01 9.64500032e-01 9.70753417e-01\n",
      " 7.77688688e-01 2.21753783e-01 4.97482399e-01 2.56957857e-01\n",
      " 2.03270008e-01 1.20759219e-01 4.16942363e-01 5.86678171e-01\n",
      " 9.20529001e-01 1.71488932e-01 6.02123474e-01 1.86587731e-01\n",
      " 3.85001188e-01 1.49563774e-01 5.60258251e-01 3.58662760e-01\n",
      " 2.84326895e-01 4.82234424e-01 1.78252899e-01 4.83588209e-01\n",
      " 2.42198416e-01 7.09827408e-01 3.13630825e-01 3.20604343e-01\n",
      " 6.32469073e-01 8.06124751e-01 4.62014884e-01 5.45500234e-01\n",
      " 1.71697441e-01 3.78025387e-01 9.85901654e-02 5.87990897e-01\n",
      " 1.83137275e-01 4.91593538e-01 6.42178473e-01 1.05098177e-01\n",
      " 3.35117279e-01 1.46025905e-01 4.80464220e-01 1.74514937e-01\n",
      " 9.37300430e-01 1.28718009e+00 7.78454603e-01 2.67548244e-01\n",
      " 5.06474122e-01 1.09665817e-01 3.91111899e-01 1.40513014e-01\n",
      " 4.15258679e-01 7.28311360e-01 1.93323776e+00 7.52366345e-01\n",
      " 4.32951835e-01 3.98809808e-01 5.27269828e-01 7.97778595e-01\n",
      " 8.59447880e-01 1.19371022e+00 1.96126638e+00 1.27399937e+00\n",
      " 2.30396944e-01 3.16621068e-01 1.43642833e-01 2.62341193e-01\n",
      " 1.24875209e-01 4.77883625e-01 3.82040960e-01 1.32796671e+00\n",
      " 4.87077570e-01 5.86583104e-01 6.22641311e-01 6.29025335e-01\n",
      " 5.32550231e-01 6.26881821e-01 9.63156393e-01 2.19393275e+00\n",
      " 1.05264356e+00 1.94739951e-01 3.83731539e-01 6.16629699e-02\n",
      " 9.96824171e-02 1.72372519e-01 4.29781084e-01 1.83306734e-01\n",
      " 1.61731453e+00 5.46758534e-01 5.75738081e-01 3.41242063e-01\n",
      " 5.09424523e-01 2.43891425e-01 5.80550972e-01 5.70117079e-01\n",
      " 1.43060549e+00 4.02314524e-01 8.20368247e-02 3.77366888e-01\n",
      " 4.53112006e-01 1.03689586e-01 3.62668541e-01 1.26757880e-01\n",
      " 6.40861403e-01 1.13851179e+00 7.50179324e-01 4.23629859e-01\n",
      " 4.18690901e-01 3.93838231e-01 4.32711634e-01 7.90460275e-01\n",
      " 9.10117190e-01 5.14284786e-01 3.15423069e-01 3.35078734e-01\n",
      " 5.37527585e-01 5.33131622e-01 8.67086600e-01 1.46632219e-01\n",
      " 1.37824354e+00 2.75514067e+00 7.76624319e-01 3.07583414e-01\n",
      " 5.14102525e-01 8.59942592e-02 2.51375542e-01 1.82045706e-01\n",
      " 4.83337162e-01 1.11452862e+00 3.67380021e+00 1.31164524e+00\n",
      " 1.19792146e+00 1.49479629e+00 1.43216216e+00 1.39577649e+00\n",
      " 1.61762788e+00 1.81839487e+00 5.88234408e+00 2.59914187e+00\n",
      " 5.81945408e-01 9.36246469e-01 7.64079256e-01 8.28651027e-01\n",
      " 1.06066847e+00 8.99907928e-01 3.52111673e+00 8.15590795e+00\n",
      " 1.89724827e+00 1.96098531e+00 1.94407839e+00 1.71487275e+00\n",
      " 2.49385046e+00 2.08189696e+00 2.99297830e+00 9.38784226e+00\n",
      " 1.96347247e+00 7.20215333e-01 2.35498782e-01 1.07780909e+00\n",
      " 7.18337760e-01 5.86317778e-01 4.76953214e-01 4.14979431e+00\n",
      " 1.05418881e+01 4.61865603e+00 5.08770649e+00 4.85509881e+00\n",
      " 7.98043598e+00 1.08917429e+01 1.51117073e+01 2.17522066e+01] -->\n",
      "[5]  [ Find_dominant_window_sizes_list ] Find_dominant_window_sizes_list | Freqs -->\n",
      "[5]  [ Find_dominant_window_sizes_list ] Find_dominant_window_sizes_list | Coefs and window_sizes -->\n",
      "[5]  [ Find_dominant_window_sizes_list ] Find_dominant_window_sizes_list | --> Find and return valid window_sizes\n",
      "[5]  [ Find_dominant_window_sizes_list ] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 0 ... [  0   1   2   7  16  24   3  33   5   4   6   8  41  25  17  50  32  19\n",
      "  92  18  15 109  22  21 117  23  34  20  35  83  38  37  75 176  36  51\n",
      " 100  40 126 108  39 110  66  42  12  27  91 168 169  93 185 193 127  30\n",
      " 159  59 186  26  53 111  28 142 112  60 184 125 167  49  29 116 192  65\n",
      " 118 177  14  11 146 175 210 194 133  67 203 143  96  94  97 195 157 207\n",
      " 209 136 160  98  10  31  77  81  76 153 214  82 140 205  55  54  95 188\n",
      " 113 170  58  47  79 123 165 134  99 148  43 150 129 102   9 199 141  71\n",
      " 115  61  85 174  64  63 161 119 218 182  74 200 114  62 191 121 202 212\n",
      " 189 155  89 211 201 101 138  72 190  69 216 152 197 183 208  80 131  56\n",
      " 144 106 213  57 145  48 217 178 151 173 172 124 104 206 164  45  78 147\n",
      " 171  13 107 166 187 163  90 156 180  84 135  44 149 128  86 139 158 179\n",
      " 215 154  52 130 105 120  68 103 181 162 198 204 122 196 132  70  87 137\n",
      "  46  73  88]\n",
      "[5]  [ Find_dominant_window_sizes_list ] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 1 ... [  0   1   2   7  16  24   3  33   5   4   6   8  41  25  17  50  32  19\n",
      "  92  18  15 109  22  21 117  23  34  20  35  83  38  37  75 176  36  51\n",
      " 100  40 126 108  39 110  66  42  12  27  91 168 169  93 185 193 127  30\n",
      " 159  59 186  26  53 111  28 142 112  60 184 125 167  49  29 116 192  65\n",
      " 118 177  14  11 146 175 210 194 133  67 203 143  96  94  97 195 157 207\n",
      " 209 136 160  98  10  31  77  81  76 153 214  82 140 205  55  54  95 188\n",
      " 113 170  58  47  79 123 165 134  99 148  43 150 129 102   9 199 141  71\n",
      " 115  61  85 174  64  63 161 119 218 182  74 200 114  62 191 121 202 212\n",
      " 189 155  89 211 201 101 138  72 190  69 216 152 197 183 208  80 131  56\n",
      " 144 106 213  57 145  48 217 178 151 173 172 124 104 206 164  45  78 147\n",
      " 171  13 107 166 187 163  90 156 180  84 135  44 149 128  86 139 158 179\n",
      " 215 154  52 130 105 120  68 103 181 162 198 204 122 196 132  70  87 137\n",
      "  46  73  88]\n",
      "[5]  [ Find_dominant_window_sizes_list ] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 2 ... [  0   1   2   7  16  24   3  33   5   4   6   8  41  25  17  50  32  19\n",
      "  92  18  15 109  22  21 117  23  34  20  35  83  38  37  75 176  36  51\n",
      " 100  40 126 108  39 110  66  42  12  27  91 168 169  93 185 193 127  30\n",
      " 159  59 186  26  53 111  28 142 112  60 184 125 167  49  29 116 192  65\n",
      " 118 177  14  11 146 175 210 194 133  67 203 143  96  94  97 195 157 207\n",
      " 209 136 160  98  10  31  77  81  76 153 214  82 140 205  55  54  95 188\n",
      " 113 170  58  47  79 123 165 134  99 148  43 150 129 102   9 199 141  71\n",
      " 115  61  85 174  64  63 161 119 218 182  74 200 114  62 191 121 202 212\n",
      " 189 155  89 211 201 101 138  72 190  69 216 152 197 183 208  80 131  56\n",
      " 144 106 213  57 145  48 217 178 151 173 172 124 104 206 164  45  78 147\n",
      " 171  13 107 166 187 163  90 156 180  84 135  44 149 128  86 139 158 179\n",
      " 215 154  52 130 105 120  68 103 181 162 198 204 122 196 132  70  87 137\n",
      "  46  73  88]\n",
      "[5]  [ Find_dominant_window_sizes_list ] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 2b ... 3\n",
      "[5]  [ Find_dominant_window_sizes_list ] Find_dominant_window_sizes_list | Find and return valid window_sizes -->\n",
      "[5]  [ Find_dominant_window_sizes_list ] Find_dominant_window_sizes_list | Sizes: [17, 12, 4]\n",
      "[5]  [ Find_dominant_window_sizes_list ] Find dominant_window_sizes_list --->\n",
      "[5]  [ Find_dominant_window_sizes_list ] Get sizes for var 0 | [17, 12, 4]\n",
      "[5]  [ Find_dominant_window_sizes_list ] Grouping sizes\n",
      "[5]  [ Find_dominant_window_sizes_list ] Final selected window sizes: [17, 12, 4]\n",
      "[5] [Find_dominant_window_sizes_list --> ]\n",
      "[5]  [ windowed_dataset ] X is a DataFrame | Window sizes: 3\n",
      "[5]  [ windowed_dataset ] Building the windows\n",
      "[5]  [ windowed_dataset ] w = 17\n",
      "[5]  [ windowed_dataset ] w 17 | enc_input~(424, 1, 17) | dss~1\n",
      "[5]  [ windowed_dataset ] w = 12\n",
      "[5]  [ windowed_dataset ] w 12 | enc_input~(429, 1, 12) | dss~2\n",
      "[5]  [ windowed_dataset ] w = 4\n",
      "[5]  [ windowed_dataset ] w 4 | enc_input~(437, 1, 4) | dss~3\n",
      "[5]  [ windowed_dataset ] Number of windows: 3\n",
      "[5] [windowed_dataset --> ]\n",
      "[5]  [ _get_enc_input ] About to get the encoder input | windows~3\n",
      "[5]  [ _get_enc_input ] Enc input obtained | enc_input~(424, 1, 17)\n",
      "[5] [_get_enc_input --> ]\n",
      "[5]  [ _get_enc_input ] enc_input~(424, 1, 17)\n",
      "[5]  [ _get_enc_input ] About to exec _get_optimizer\n",
      "[5] [ --> _get_optimizer ]\n",
      "[5] [_get_enc_input --> ]\n",
      "[5] [_get_enc_input --> ]\n",
      "[5] [ --> set_fine_tune_ ]\n",
      "[5]  [ set_fine_tune_ ] Model class: momentfm.models.moment.MOMENTPipeline\n",
      "[5]  [ set_fine_tune_ ] Moment\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [_get_encoder --> ]\n",
      "[5] [ --> fine_tune ]\n",
      "[5]  [ fine_tune ] Original enc_learn MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")  | Final model MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")\n",
      "[5] [ --> set_fine_tune_ ]\n",
      "[5]  [ set_fine_tune_ ] Model class: momentfm.models.moment.MOMENTPipeline\n",
      "[5]  [ set_fine_tune_ ] Moment\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5]  [ set_fine_tune_ ] Use fine_tune_moment parameters\n",
      "[5] [ --> fine_tune_moment_ ]\n",
      "[5]  [ set_fine_tune_ ] Processing 3 datasets : (424, 1, 17)\n",
      "[5]  [ set_fine_tune_ ] Setting up optimizer as AdamW\n",
      "[5]  [ set_fine_tune_ ] Processing wlen 17\n",
      "[5] [ --> fine_tune_moment_single ]\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Prepare the dataset | X ~ (424, 1, 17)\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting ds train | 102 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting validation train | 102 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | Random windows\n",
      "[4] [ --> fine_tune_moment_single | prepare_train_and_eval_dataloaders | random_windows ]\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] N windows: None\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] n_windows: 82\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] windows~torch.Size([82, 1, 17])\n",
      "[4] [fine_tune_moment_single | prepare_train_and_eval_dataloaders --> ]\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | DataLoader\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Validation DataLoader\n",
      "[5]  [ fine_tune_moment_single ] Eval Pre | wlen 17\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14% 1/7 [00:01<00:06,  1.06s/it]\u001b[A\n",
      " 29% 2/7 [00:01<00:02,  1.96it/s]\u001b[A\n",
      " 43% 3/7 [00:01<00:01,  2.94it/s]\u001b[A\n",
      "100% 7/7 [00:01<00:00,  4.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737477460.542753 | End: 1737477462.0687225 | Duration: 1.53 seconds\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n",
      "[5]  [ fine_tune_moment_single ] Train | wlen 17\n",
      "[4] fine_tune_moment_train_ | Training loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | Fine tune loop | print_to_path False | batch_masks~tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0% 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | num_epochs 5 | n_batches 6\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 0 | train 0 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0012490900699049234\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 0 | train 0 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 0 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0013447467936202884\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 0 | train 1 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7% 2/30 [00:00<00:01, 17.93it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 0 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0010177548974752426\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 0 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 0 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0012080804444849491\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 0 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13% 4/30 [00:00<00:01, 17.44it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 0 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0008844381663948298\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 0 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 0 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 5.952037463430315e-05\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 0 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20% 6/30 [00:00<00:01, 17.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 1 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.001616135472431779\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 1 | train 1 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 1 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0007603394915349782\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 1 | train 2 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27% 8/30 [00:00<00:01, 18.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 1 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0010583256371319294\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 1 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 1 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0006449793581850827\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 1 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33% 10/30 [00:00<00:01, 18.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 1 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.001356923603452742\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 1 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 1 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0027155911084264517\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 1 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40% 12/30 [00:00<00:01, 15.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 2 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0007224339060485363\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 2 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 2 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0012819108087569475\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 2 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47% 14/30 [00:00<00:01, 15.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 2 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0013008282985538244\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 2 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 2 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0011922259582206607\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 2 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53% 16/30 [00:00<00:00, 15.82it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 2 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0015004752203822136\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 2 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 2 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.00011437552166171372\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 2 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60% 18/30 [00:01<00:00, 16.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 3 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0013681347481906414\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 3 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 3 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0009007542976178229\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 3 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67% 20/30 [00:01<00:00, 16.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 3 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0014137147227302194\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 3 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 3 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0015357270603999496\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 3 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73% 22/30 [00:01<00:00, 17.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 3 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0006817501853220165\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 3 | train 7 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 3 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 6.400480924639851e-05\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 3 | train 8 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80% 24/30 [00:01<00:00, 17.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 4 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.001067095436155796\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 4 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 4 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0009728221339173615\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 4 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87% 26/30 [00:01<00:00, 17.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 4 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0013818114530295134\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 4 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 4 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.001872400171123445\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 4 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93% 28/30 [00:01<00:00, 17.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 4 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0010282264556735754\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 4 | train 8 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 4 | train 9 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.00012729957234114408\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 4 | train 9 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 30/30 [00:01<00:00, 17.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | -->\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737477462.0709064 | End: 1737477463.8268924 | Duration: 1.76 seconds\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Eval Post | wlen 17\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14% 1/7 [00:01<00:06,  1.05s/it]\u001b[A\n",
      " 43% 3/7 [00:01<00:01,  3.10it/s]\u001b[A\n",
      "100% 7/7 [00:01<00:00,  5.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737477463.82923 | End: 1737477465.2167413 | Duration: 1.39 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single_ | Evaluation summary\n",
      "[5]  [ fine_tune_moment_single ] Eval pre: \n",
      "mse: {'mse': 0.053732890570543285}\n",
      "rmse: {'mse': 0.0029476201092852572}\n",
      "mae: {'mae': 0.03946589066267938}\n",
      "smape: {'smape': 1.3945297692180116}\n",
      "[5]  [ fine_tune_moment_single ] Eval post: \n",
      "mse: {'mse': 0.053732890570543285}\n",
      "rmse: {'mse': 0.0029476201092852572}\n",
      "mae: {'mae': 0.03946589066267938}\n",
      "smape: {'smape': 1.3945297692180116}\n",
      "[5] [fine_tune_moment_single_ --> ]\n",
      "[5]  [ set_fine_tune_ ] Processing wlen 17\n",
      "[5] [ --> fine_tune_moment_single ]\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Prepare the dataset | X ~ (429, 1, 12)\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting ds train | 103 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting validation train | 103 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | Random windows\n",
      "[4] [ --> fine_tune_moment_single | prepare_train_and_eval_dataloaders | random_windows ]\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] N windows: None\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] n_windows: 83\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] windows~torch.Size([83, 1, 12])\n",
      "[4] [fine_tune_moment_single | prepare_train_and_eval_dataloaders --> ]\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | DataLoader\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Validation DataLoader\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n",
      "[5]  [ fine_tune_moment_single ] Train | wlen 12\n",
      "[4] fine_tune_moment_train_ | Training loop\n",
      "[4] fine_tune_moment_train | Fine tune loop | print_to_path False | batch_masks~tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0% 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | num_epochs 5 | n_batches 6\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 0 | train 0 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0014727013185620308\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 0 | train 0 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 0 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.001667373231612146\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 0 | train 1 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7% 2/30 [00:00<00:02, 11.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 0 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.002110543427988887\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 0 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 0 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0012528621591627598\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 0 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13% 4/30 [00:00<00:02, 11.84it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 0 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0018341713584959507\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 0 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 0 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0009439687128178775\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 0 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20% 6/30 [00:00<00:01, 12.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 1 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0008925134898163378\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 1 | train 1 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 1 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0021087350323796272\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 1 | train 2 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27% 8/30 [00:00<00:01, 12.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 1 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0016046322416514158\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 1 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 1 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0019303662702441216\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 1 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33% 10/30 [00:00<00:01, 12.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 1 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0010932403383776546\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 1 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 1 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.002974573988467455\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 1 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40% 12/30 [00:00<00:01, 13.38it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 2 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0016697924584150314\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 2 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 2 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0018662706715986133\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 2 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47% 14/30 [00:01<00:01, 14.92it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 2 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0005438629304990172\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 2 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 2 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0012527934741228819\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 2 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53% 16/30 [00:01<00:00, 16.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 2 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0027065665926784277\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 2 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 2 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0015818936517462134\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 2 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60% 18/30 [00:01<00:00, 16.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 3 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.001188801834359765\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 3 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 3 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0013839824823662639\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 3 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 3 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0018321179086342454\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 3 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70% 21/30 [00:01<00:00, 17.91it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 3 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.001162007451057434\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 3 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 3 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0026157251559197903\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 3 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 77% 23/30 [00:01<00:00, 18.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 3 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0020239283330738544\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 3 | train 8 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 4 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.001691240817308426\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 4 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83% 25/30 [00:01<00:00, 18.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 4 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0019086578395217657\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 4 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 4 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0011023252736777067\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 4 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 4 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0010426570661365986\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 4 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93% 28/30 [00:01<00:00, 19.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 4 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0026141873095184565\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 4 | train 8 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 4 | train 9 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0010349059011787176\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 4 | train 9 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 30/30 [00:01<00:00, 16.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | -->\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737477465.446323 | End: 1737477467.320553 | Duration: 1.87 seconds\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Eval Post | wlen 17\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14% 1/7 [00:01<00:06,  1.06s/it]\u001b[A\n",
      "100% 7/7 [00:01<00:00,  5.60it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737477467.3238356 | End: 1737477468.6390686 | Duration: 1.32 seconds\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single_ | Evaluation summary\n",
      "[5]  [ fine_tune_moment_single ] Eval post: \n",
      "mse: {'mse': 0.05464786522408429}\n",
      "rmse: {'mse': 0.0030411378618556244}\n",
      "mae: {'mae': 0.04058488292743348}\n",
      "smape: {'smape': 1.519132180334581}\n",
      "[5] [fine_tune_moment_single_ --> ]\n",
      "[5]  [ set_fine_tune_ ] Processing wlen 17\n",
      "[5] [ --> fine_tune_moment_single ]\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Prepare the dataset | X ~ (437, 1, 4)\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting ds train | 105 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting validation train | 105 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | Random windows\n",
      "[4] [ --> fine_tune_moment_single | prepare_train_and_eval_dataloaders | random_windows ]\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] N windows: None\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] n_windows: 84\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] windows~torch.Size([84, 1, 4])\n",
      "[4] [fine_tune_moment_single | prepare_train_and_eval_dataloaders --> ]\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | DataLoader\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Validation DataLoader\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n",
      "[5]  [ fine_tune_moment_single ] Train | wlen 4\n",
      "[4] fine_tune_moment_train_ | Training loop\n",
      "[4] fine_tune_moment_train | Fine tune loop | print_to_path False | batch_masks~tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0% 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | num_epochs 5 | n_batches 6\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 0 | train 0 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 0 | train 0 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 0 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 0 | train 1 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "  7% 2/30 [00:00<00:01, 15.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 0 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 0 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 0 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 0 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      " 13% 4/30 [00:00<00:01, 17.12it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 0 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 0 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 0 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([4, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([4, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 0 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      " 20% 6/30 [00:00<00:01, 16.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 1 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 1 | train 1 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 1 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 1 | train 2 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      " 27% 8/30 [00:00<00:01, 15.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 1 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 1 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 1 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 1 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33% 10/30 [00:00<00:01, 14.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 1 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 1 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 1 | train 6 of 30 | Before loop step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([4, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([4, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([4, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 1 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40% 12/30 [00:00<00:01, 14.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 2 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 2 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 2 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 2 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      " 47% 14/30 [00:00<00:01, 14.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 2 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 2 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 2 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 2 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      " 53% 16/30 [00:01<00:01, 13.96it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 2 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 2 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 2 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([4, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([4, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 2 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      " 60% 18/30 [00:01<00:00, 12.97it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 3 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 3 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 3 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 3 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      " 67% 20/30 [00:01<00:00, 12.71it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 3 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 3 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 3 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 3 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      " 73% 22/30 [00:01<00:00, 11.75it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 3 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 3 | train 7 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 3 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([4, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([4, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 3 | train 8 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      " 80% 24/30 [00:01<00:00, 12.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 4 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 4 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 4 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 4 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      " 87% 26/30 [00:01<00:00, 12.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 4 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 4 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 4 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 4 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      " 93% 28/30 [00:02<00:00, 13.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 4 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 4 | train 8 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 4 | train 9 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([4, 1, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([4, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 1 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([4, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 2 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 3 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[4] sure_eval_moment | Trial 4 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] sure_eval_moment | Trial 5 | y ~ torch.Size([4, 1, 4])\n",
      "[4] Not the usual error. No padding, just fail\n",
      "[4] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[4] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 4 | train 9 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "100% 30/30 [00:02<00:00, 13.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | -->\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737477468.8054008 | End: 1737477471.004766 | Duration: 2.20 seconds\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Eval Post | wlen 17\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0% 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "maximum size for tensor at dimension 2 is 4 but size is 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--> epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, dataset_percent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_percent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mask \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaskared_percent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sizes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc_learn\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_learner_small\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_mask_percent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmaskared_percent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_percent\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset_percent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_percent\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#1-dataset_percent if 1-dataset_percent != 0 else 0.3,\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_window_sizes\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcommon_args\u001b[49m\u001b[43m    \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m: n_epochs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: result[\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     27\u001b[0m })\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, dataset_percent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_percent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mask \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaskared_percent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/work/dvats/encoder.py:3629\u001b[0m, in \u001b[0;36mfine_tune\u001b[0;34m(X, stride, batch_size, n_windows, n_windows_percent, validation_percent, training_percent, window_mask_percent, window_sizes, n_window_sizes, window_sizes_offset, windows_min_distance, full_dataset, enc_input, optim, criterion, optimizer, lr, lr_scheduler_flag, lr_scheduler_name, lr_scheduler_num_warmup_steps, verbose, print_to_path, print_path, print_mode, mssg, enc, num_epochs, enc_learn, cpu, to_numpy, use_moment_masks, mask_stateful, mask_future, mask_sync, time_flag, shot, eval_pre, eval_post, use_wandb, analysis_mode, norm_by_sample, norm_use_single_batch, show_plot, metrics, metrics_names, metrics_args, metrics_dict, scheduler_specific_kwargs)\u001b[0m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfine_tune_moment_\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3625\u001b[0m     enc\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse fine_tune_moment parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3626\u001b[0m     ( \n\u001b[1;32m   3627\u001b[0m         lossess, eval_results_pre, eval_results_post, \n\u001b[1;32m   3628\u001b[0m         t_shots, t_shot, t_evals, t_eval, enc\u001b[38;5;241m.\u001b[39mmodel \n\u001b[0;32m-> 3629\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43menc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tune_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3630\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_post\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_flag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_moment_masks\u001b[49m\n\u001b[1;32m   3631\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3632\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfine_tune_mvp_\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3633\u001b[0m     enc\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse fine_tune_mvp parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/work/dvats/encoder.py:2733\u001b[0m, in \u001b[0;36mfine_tune_moment_\u001b[0;34m(self, eval_pre, eval_post, shot, time_flag, use_moment_masks)\u001b[0m\n\u001b[1;32m   2729\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39msize):\n\u001b[1;32m   2730\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing wlen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2731\u001b[0m     ( \n\u001b[1;32m   2732\u001b[0m         losses, eval_results_pre_, eval_results_post_, t_shot_, t_eval_1, t_eval_2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m-> 2733\u001b[0m     ) \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tune_moment_single_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_post\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_moment_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2734\u001b[0m     lossess\u001b[38;5;241m.\u001b[39mappend(losses)\n\u001b[1;32m   2735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (eval_pre): eval_results_pre \u001b[38;5;241m=\u001b[39m eval_results_pre_\n",
      "File \u001b[0;32m~/work/dvats/encoder.py:2672\u001b[0m, in \u001b[0;36mfine_tune_moment_single_\u001b[0;34m(self, eval_pre, eval_post, shot, sample_id, use_moment_masks)\u001b[0m\n\u001b[1;32m   2670\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfine_tune_moment_single | Eval Post | wlen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_flag: timer\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m-> 2672\u001b[0m eval_results_post \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune_moment_eval_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2673\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc_learn\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_eval\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdl_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_flag:\n\u001b[1;32m   2678\u001b[0m     timer\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m~/work/dvats/encoder.py:2345\u001b[0m, in \u001b[0;36mfine_tune_moment_eval_\u001b[0;34m(enc_learn, dl_eval, cpu)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dl_eval:\n\u001b[1;32m   2344\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m-> 2345\u001b[0m     mse_metric, rmse_metric, mae_metric, smape_metric \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune_moment_eval_step_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2346\u001b[0m \u001b[43m        \u001b[49m\u001b[43menc_learn\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_learn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   2348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmse_metric\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmse_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   2349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrmse_metric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrmse_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmae_metric\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmae_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2351\u001b[0m \u001b[43m        \u001b[49m\u001b[43msmape_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msmape_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2353\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2354\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/work/dvats/encoder.py:2303\u001b[0m, in \u001b[0;36mfine_tune_moment_eval_step_\u001b[0;34m(enc_learn, batch, mse_metric, rmse_metric, mae_metric, smape_metric, cpu, verbose, print_to_path, print_path, print_mode)\u001b[0m\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfine_tune_moment_eval_step_\u001b[39m(\n\u001b[1;32m   2289\u001b[0m     enc_learn : Learner,\n\u001b[1;32m   2290\u001b[0m     batch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2300\u001b[0m     print_mode      : \u001b[38;5;28mstr\u001b[39m           \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2301\u001b[0m ):\n\u001b[1;32m   2302\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m-> 2303\u001b[0m         output, enc_learn \u001b[38;5;241m=\u001b[39m \u001b[43msure_eval_moment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2304\u001b[0m \u001b[43m            \u001b[49m\u001b[43menc_learn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_learn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   2305\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2306\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\n\u001b[1;32m   2307\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   2308\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpadd_step\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   2311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   2312\u001b[0m \u001b[43m            \u001b[49m\u001b[43macts_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprint_to_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprint_to_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2315\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mreconstruction\n\u001b[1;32m   2316\u001b[0m         references \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m~/work/dvats/encoder.py:794\u001b[0m, in \u001b[0;36msure_eval_moment\u001b[0;34m(enc_learn, cpu, verbose, y, input_mask, mask, padd_step, retry, max_trials, acts_indices, print_to_path, print_path, print_mode, continue_if_fail)\u001b[0m\n\u001b[1;32m    792\u001b[0m     ut\u001b[38;5;241m.\u001b[39mprint_flush(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msure_eval_moment | Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | device \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | mask device~\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mmask\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, print_to_path \u001b[38;5;241m=\u001b[39m print_to_path, print_path \u001b[38;5;241m=\u001b[39m print_path, print_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m verbose, print_time \u001b[38;5;241m=\u001b[39m print_to_path)\n\u001b[1;32m    793\u001b[0m     ut\u001b[38;5;241m.\u001b[39mprint_flush(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msure_eval_moment | Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | device \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | y~\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, print_to_path \u001b[38;5;241m=\u001b[39m print_to_path, print_path \u001b[38;5;241m=\u001b[39m print_path, print_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m verbose, print_time \u001b[38;5;241m=\u001b[39m print_to_path)\n\u001b[0;32m--> 794\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43menc_learn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_enc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m acts_indices \u001b[38;5;241m==\u001b[39m [\u001b[38;5;241m0\u001b[39m] : \n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py:227\u001b[0m, in \u001b[0;36mMOMENT.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TimeseriesOutputs:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py:566\u001b[0m, in \u001b[0;36mMOMENT.forward\u001b[0;34m(self, x_enc, input_mask, mask, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m     input_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(x_enc[:, \u001b[38;5;241m0\u001b[39m, :])\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_name \u001b[38;5;241m==\u001b[39m TASKS\u001b[38;5;241m.\u001b[39mRECONSTRUCTION:\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_enc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_name \u001b[38;5;241m==\u001b[39m TASKS\u001b[38;5;241m.\u001b[39mEMBED:\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(x_enc\u001b[38;5;241m=\u001b[39mx_enc, input_mask\u001b[38;5;241m=\u001b[39minput_mask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py:292\u001b[0m, in \u001b[0;36mMOMENT.reconstruction\u001b[0;34m(self, x_enc, input_mask, mask, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m batch_size, n_channels, _ \u001b[38;5;241m=\u001b[39m x_enc\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mto(x_enc\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# mask: [batch_size x seq_len]\u001b[39;00m\n\u001b[1;32m    295\u001b[0m x_enc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalizer(x\u001b[38;5;241m=\u001b[39mx_enc, mask\u001b[38;5;241m=\u001b[39mmask \u001b[38;5;241m*\u001b[39m input_mask, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/utils/masking.py:59\u001b[0m, in \u001b[0;36mMasking.generate_mask\u001b[0;34m(self, x, input_mask)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_patch_view(x, input_mask\u001b[38;5;241m=\u001b[39minput_mask)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mask_seq_view\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/utils/masking.py:113\u001b[0m, in \u001b[0;36mMasking._mask_seq_view\u001b[0;34m(self, x, input_mask)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mask_seq_view\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, input_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    105\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    Input:\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m        x : torch.Tensor of shape\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m        mask : torch.Tensor of shape [batch_size x seq_len]\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask_patch_view(x, input_mask\u001b[38;5;241m=\u001b[39minput_mask)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_patch_to_seq_view(mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_len)\u001b[38;5;241m.\u001b[39mlong()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: maximum size for tensor at dimension 2 is 4 but size is 8"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for n_epochs in [5]:\n",
    "    for dataset_percent in [0.3]:\n",
    "        for maskared_percent in [0.4]:\n",
    "            for sizes in [3]:\n",
    "                print(f\"--> epoch {n_epochs}, dataset_percent {dataset_percent}, mask {maskared_percent}\")\n",
    "                print(f\" sizes {sizes}\")\n",
    "                result = fine_tune(\n",
    "                    enc_learn           = enc_learner_small,\n",
    "                    window_mask_percent = maskared_percent,\n",
    "                    training_percent    = dataset_percent,\n",
    "                    validation_percent  = 0.3, #1-dataset_percent if 1-dataset_percent != 0 else 0.3,\n",
    "                    num_epochs          = n_epochs,\n",
    "                    n_window_sizes      = sizes,\n",
    "                    verbose             = 5,\n",
    "                    **common_args    \n",
    "                )\n",
    "                results.append({\n",
    "                    'model_size': \"small\",\n",
    "                    'n_epochs': n_epochs,\n",
    "                    'dataset_percent': dataset_percent,\n",
    "                    'maskared_percent': maskared_percent,\n",
    "                    'losses': result[0],\n",
    "                    'eval_results_pre': result[1],\n",
    "                    'eval_results_post': result[2],\n",
    "                    'time': result[4]\n",
    "                })\n",
    "                print(f\"epoch {n_epochs}, dataset_percent {dataset_percent}, mask {maskared_percent}\")\n",
    "                print(f\" sizes {sizes} | time: {result[4]} -->\")\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a24fb-4416-4345-a1c8-131bed978e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"Execution ended\")\n",
    "from dvats.imports import beep\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca0597-64fb-4bc5-946f-2ae110b3cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
