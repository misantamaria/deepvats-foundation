{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de2cd87-7d93-45ec-bd92-d97a85cf73b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Getting the embeddings\n",
    "\n",
    "> This notebook gets the embeddings (or latent space) from a multivariate time series \n",
    "given by a encoder (e.g., autoencoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816ae963-a2d2-467a-90ee-2be0f383c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_patch_size = 8\n",
    "verbose          = 0\n",
    "reset_kernel     = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db2cd5f-dd8d-42a3-bdc1-afc12ff80afb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7f33c6b6a350>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "from dvats.all import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from yaml import load, FullLoader\n",
    "import dvats.utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6774bdd-fc22-4e8e-96c4-c29417380137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280e30d-8195-4f39-898a-495d9253778b",
   "metadata": {},
   "source": [
    "## Config parameters\n",
    "> Configuration parameters are obtained from 'config\\03-embeddings.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fd16b-1ca7-4bed-9173-642cabdbe9bb",
   "metadata": {},
   "source": [
    "### Get configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47519e96-4dd2-4096-8189-d735f88155ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, job_type = get_artifact_config_embeddings(verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515769be-e06d-4ae2-b3ab-1636642a158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/zeroshot-moment-small-embedding:latest\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372ce1e-f3c8-4df4-a802-1250bc9a80cb",
   "metadata": {},
   "source": [
    "### Show configuration artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08922829-19f7-4cdc-97b1-86f5a3b4f3d2",
   "metadata": {},
   "source": [
    "### Get the model from W&B\n",
    "> Restore the encoder model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15b94a4-19cb-47c0-a000-b0890d303ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'mi-santamaria'\n",
    "project = 'deepvats'\n",
    "folder = entity+'/'+project+'/'\n",
    "model_family = 'zeroshot-moment'\n",
    "task = 'embedding'\n",
    "dataset = 'gtrends_kohls'\n",
    "dataset_version = 'v2'\n",
    "enc_artifact_dataset = folder + dataset + ':' + dataset_version\n",
    "enc_artifact_small = folder + model_family + '-small-' + task + ':v0'\n",
    "enc_artifact_base  =  folder + model_family + '-base-' + task + ':v0'\n",
    "enc_artifact_large = folder + model_family + '-large-' + task + ':v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e978658-78de-4dff-9679-d2ed1453dec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataset artifact:  mi-santamaria/deepvats/gtrends_kohls:v2\n",
      "Getting small artifact:  mi-santamaria/deepvats/zeroshot-moment-small-embedding:v0\n",
      "Getting base artifact:  mi-santamaria/deepvats/zeroshot-moment-base-embedding:v0\n",
      "Getting large artifact:  mi-santamaria/deepvats/zeroshot-moment-large-embedding:v0\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting dataset artifact: \", enc_artifact_dataset)\n",
    "df_artifact = wandb_api.artifact(enc_artifact_dataset, type = 'dataset')\n",
    "print(\"Getting small artifact: \", enc_artifact_small)\n",
    "enc_artifact_small = wandb_api.artifact(enc_artifact_small, type='learner')\n",
    "print(\"Getting base artifact: \", enc_artifact_base)\n",
    "enc_artifact_base  = wandb_api.artifact(enc_artifact_base, type='learner')\n",
    "print(\"Getting large artifact: \", enc_artifact_large)\n",
    "enc_artifact_large = wandb_api.artifact(enc_artifact_large, type='learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dfcdf28-2518-49af-8c64-c2305ba71a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtrends_kohls:v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of               volume\n",
       "2004-01-01  0.010417\n",
       "2004-01-08  0.010417\n",
       "2004-01-15  0.010417\n",
       "2004-01-22  0.000000\n",
       "2004-01-29  0.000000\n",
       "...              ...\n",
       "2012-05-03  0.322917\n",
       "2012-05-10  0.312500\n",
       "2012-05-17  0.281250\n",
       "2012-05-24  0.291667\n",
       "2012-05-31  0.322917\n",
       "\n",
       "[440 rows x 1 columns]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440, 1)\n"
     ]
    }
   ],
   "source": [
    "print(df_artifact.name)\n",
    "df = df_artifact.to_df()\n",
    "display(df.head)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e24131d-d4f7-4931-88ca-df2680838050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeroshot-moment-small-embedding:v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact zeroshot-moment-small-embedding:v0, 144.63MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n"
     ]
    }
   ],
   "source": [
    "print(enc_artifact_small.name)\n",
    "enc_learner_small = enc_artifact_small.to_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b60372-ee00-443e-a0e8-f95f10422c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeroshot-moment-base-embedding:v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact zeroshot-moment-base-embedding:v0, 432.97MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.3\n"
     ]
    }
   ],
   "source": [
    "print(enc_artifact_base.name)\n",
    "enc_learner_base  = enc_artifact_base.to_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fbe313-d3b6-4793-aaf3-34d4b858065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeroshot-moment-large-embedding:v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact zeroshot-moment-large-embedding:v0, 1321.42MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:4.0\n"
     ]
    }
   ],
   "source": [
    "print(enc_artifact_large.name)\n",
    "enc_learner_large = enc_artifact_large.to_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c96a07c9-7211-4d2a-ab1b-50838d630b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35341512\n",
      "109641608\n",
      "341248520\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    #return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "print(count_parameters(enc_learner_small))\n",
    "print(count_parameters(enc_learner_base))\n",
    "print(count_parameters(enc_learner_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff3d78e0-5847-4606-9cab-b9c9e02c0a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341248520"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "count_parameters(enc_learner_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a05c5be8-47c7-45f9-8ba9-43201e704a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.losses import MSELossFlat\n",
    "from dvats.encoder import MAELossFlat, EvalMSE, EvalRMSE, EvalMAE, EvalSMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49908f03-6875-4e27-8050-09af41dc62bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 1, 17)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input, _ = SlidingWindow(window_len=17, stride=2, get_y=[])(df)\n",
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f66dd47-58ad-4067-81ea-3282eff61a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import dvats.config as cfg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d77cb4e-da4b-4f01-a30c-c145b97d1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, project, version, data, config, job_type = cfg_.get_artifact_config_MVP(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04301513-8b67-47a5-8140-96f4381e64e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "0.4\n",
      "online\n"
     ]
    }
   ],
   "source": [
    "print(config['batch_size'])\n",
    "print(config['r'])\n",
    "print(config['analysis_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fafa294-2aca-4448-a6c9-c5b67a2668f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args = {\n",
    "    \"X\": df,\n",
    "    \"stride\": 1,\n",
    "    \"batch_size\": config['batch_size'],\n",
    "    \"cpu\": False,\n",
    "    \"to_numpy\": False,\n",
    "    \"time_flag\": True,\n",
    "    \"n_windows\": None,\n",
    "    \"n_windows_percent\": 0.8, # Comprobando si el None es el problema\n",
    "    \"shot\": True,\n",
    "    \"eval_pre\": True,\n",
    "    \"eval_post\": True,\n",
    "    \"lr\": config['r'], #use enc_run lr,\n",
    "    \"lr_scheduler_flag\": False,\n",
    "    \"lr_scheduler_name\": \"cosine_with_restarts\",\n",
    "    \"lr_scheduler_num_warmup_steps\": None,\n",
    "    \"window_sizes\": None,\n",
    "    \"full_dataset\": True,\n",
    "    \"window_sizes_offset\": 0.05,\n",
    "    \"windows_min_distance\": 5, #2.5*enc_input.shape[0]/100,\n",
    "    \"print_to_path\": False,\n",
    "    \"print_path\": \"~/data/logs.txt\",\n",
    "    \"print_mode\": \"w\",\n",
    "    \"use_moment_masks\": False,\n",
    "    \"mask_stateful\": config['mask_stateful'],\n",
    "    \"mask_future\": config['mask_future'],\n",
    "    \"mask_sync\": config['mask_sync'],\n",
    "    \"analysis_mode\": config['analysis_mode'],\n",
    "    \"use_wandb\": config['use_wandb'],\n",
    "    \"norm_by_sample\": config['norm_by_sample'],\n",
    "    \"norm_use_single_batch\": config['norm_use_single_batch'],\n",
    "    \"show_plot\": True,\n",
    "    \"metrics\": [EvalMSE, EvalRMSE, EvalMAE, EvalSMAPE],\n",
    "    \"metrics_args\": [{'squared': False}, {'squared': True}, {}, {}],\n",
    "    \"metrics_names\":[\"mse\", \"rmse\", \"mae\", \"smape\"],\n",
    "    \"metrics_dict\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "983727b7-d41a-4ed1-be07-fe381be1b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame(\n",
    "    columns = [\n",
    "        'model size',\n",
    "        'n_epochs',\n",
    "        'dataset_percent',\n",
    "        'maskared_percent',\n",
    "        'losses',\n",
    "        'eval_results_pre',\n",
    "        'eval_results_post',\n",
    "        'time'\n",
    "    ]\n",
    ")\n",
    "\n",
    "errors = pd.DataFrame(\n",
    "    columns = [\n",
    "        'model size',\n",
    "        'n_epochs',\n",
    "        'dataset_percent',\n",
    "        'maskared_percent',\n",
    "        'error'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c505452b-ab49-464f-856c-46288048c233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> epoch 5, dataset_percent 0.3, mask 0.4\n",
      " sizes 3\n",
      "[4] [ --> _get_encoder ]\n",
      "[4]  [ _get_encoder ] About to exec _get_enc_input\n",
      "[4] [ --> _get_enc_input ]\n",
      "[4]  [ _get_enc_input ] is none enc_input? True\n",
      "[4]  [ _get_enc_input ] About to get the windows\n",
      "[4] [ --> windowed_dataset ]\n",
      "[4]  [ _get_enc_input ] X is a DataFrame, X~(440, 1) | window_sizes 0, n_window_sizes 3\n",
      "[4]  [ _get_enc_input ] X is a DataFrame | Selecting Fourier's dominant frequences\n",
      "[4] [ --> Find_dominant_window_sizes_list ]\n",
      "[4]  [ Find_dominant_window_sizes_list ] X ~ (440, 1)\n",
      "[4]  [ Find_dominant_window_sizes_list ] Grouping sizes\n",
      "[4] [Find_dominant_window_sizes_list --> ]\n",
      "[4]  [ windowed_dataset ] X is a DataFrame | Window sizes: 3\n",
      "[4]  [ windowed_dataset ] Building the windows\n",
      "[4]  [ windowed_dataset ] w = 17\n",
      "[4]  [ windowed_dataset ] w 17 | enc_input~(424, 1, 17) | dss~1\n",
      "[4]  [ windowed_dataset ] w = 12\n",
      "[4]  [ windowed_dataset ] w 12 | enc_input~(429, 1, 12) | dss~2\n",
      "[4]  [ windowed_dataset ] w = 4\n",
      "[4]  [ windowed_dataset ] w 4 | enc_input~(437, 1, 4) | dss~3\n",
      "[4]  [ windowed_dataset ] Number of windows: 3\n",
      "[4] [windowed_dataset --> ]\n",
      "[4]  [ _get_enc_input ] About to get the encoder input | windows~3\n",
      "[4]  [ _get_enc_input ] Enc input obtained | enc_input~(424, 1, 17)\n",
      "[4] [_get_encoder --> ]\n",
      "[4]  [ _get_encoder ] enc_input~(424, 1, 17)\n",
      "[4]  [ _get_encoder ] About to exec _get_optimizer\n",
      "[4] [ --> _get_optimizer ]\n",
      "[4] [_get_encoder --> ]\n",
      "[4] [_get_encoder --> ]\n",
      "[4] [ --> set_fine_tune_ ]\n",
      "[4]  [ set_fine_tune_ ] Model class: momentfm.models.moment.MOMENTPipeline\n",
      "[4]  [ set_fine_tune_ ] Moment\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4] [_get_encoder --> ]\n",
      "[4] [ --> fine_tune ]\n",
      "[4]  [ fine_tune ] Original enc_learn MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")  | Final model MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")\n",
      "[4] [ --> set_fine_tune_ ]\n",
      "[4]  [ set_fine_tune_ ] Model class: momentfm.models.moment.MOMENTPipeline\n",
      "[4]  [ set_fine_tune_ ] Moment\n",
      "[4] [set_fine_tune_ --> ]\n",
      "[4]  [ set_fine_tune_ ] Use fine_tune_moment parameters\n",
      "[4] [ --> fine_tune_moment_ ]\n",
      "[4]  [ set_fine_tune_ ] Processing 3 datasets : (424, 1, 17)\n",
      "[4]  [ set_fine_tune_ ] Setting up optimizer as AdamW\n",
      "[4]  [ set_fine_tune_ ] Processing wlen 17\n",
      "[4] [ --> fine_tune_moment_single ]\n",
      "[4]  [ fine_tune_moment_single ] fine_tune_moment_single | Prepare the dataset | X ~ (424, 1, 17)\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting ds train | 102 windows\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting validation train | 102 windows\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | Random windows\n",
      "[3] [ --> fine_tune_moment_single | prepare_train_and_eval_dataloaders | random_windows ]\n",
      "[3]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] N windows: None\n",
      "[3]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] n_windows: 82\n",
      "[3]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] windows~torch.Size([82, 1, 17])\n",
      "[3] [fine_tune_moment_single | prepare_train_and_eval_dataloaders --> ]\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | DataLoader\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Validation DataLoader\n",
      "[4]  [ fine_tune_moment_single ] Eval Pre | wlen 17\n",
      "[4]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14% 1/7 [00:01<00:06,  1.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57% 4/7 [00:01<00:00,  4.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100% 7/7 [00:01<00:00,  5.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]  [ fine_tune_moment_single ] End timer -->\n",
      "[4]  [ fine_tune_moment_single ] Start: 1737480032.1250749 | End: 1737480033.5149786 | Duration: 1.39 seconds\n",
      "[4]  [ fine_tune_moment_single ] Start timer\n",
      "[4]  [ fine_tune_moment_single ] Train | wlen 17\n",
      "[3] fine_tune_moment_train_ | Training loop\n",
      "[3] fine_tune_moment_train | Fine tune loop | print_to_path False | batch_masks~tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0% 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | num_epochs 5 | n_batches 6\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 0 | train 0 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0021257749758660793\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 0 | train 0 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 0 | train 1 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0014993725344538689\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 0 | train 1 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  7% 2/30 [00:00<00:01, 18.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 0 | train 2 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0009672329179011285\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 0 | train 2 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 0 | train 3 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.001093081315048039\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 0 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 13% 4/30 [00:00<00:01, 18.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 0 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0017517615342512727\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 0 | train 4 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 0 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0011795483296737075\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 0 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 20% 6/30 [00:00<00:01, 19.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 1 | train 1 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.001737315789796412\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 1 | train 1 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 1 | train 2 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0011541105341166258\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 1 | train 2 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 27% 8/30 [00:00<00:01, 18.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 1 | train 3 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0018233266891911626\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 1 | train 3 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 1 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0012360115069895983\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 1 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 33% 10/30 [00:00<00:01, 18.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 1 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.00138386944308877\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 1 | train 5 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 1 | train 6 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0001404689101036638\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 1 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 40% 12/30 [00:00<00:00, 18.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 2 | train 2 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0008707559900358319\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 2 | train 2 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 2 | train 3 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.001940178801305592\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 2 | train 3 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 2 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0019438378512859344\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 2 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 50% 15/30 [00:00<00:00, 19.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 2 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0019112084992229939\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 2 | train 5 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 2 | train 6 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0005147104384377599\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 2 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 57% 17/30 [00:00<00:00, 18.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 2 | train 7 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.003061263356357813\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 2 | train 7 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 3 | train 3 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0009556032600812614\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 3 | train 3 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 3 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0019521466456353664\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 3 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 67% 20/30 [00:01<00:00, 20.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 3 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0014983844012022018\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 3 | train 5 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 3 | train 6 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0012692423770204186\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 3 | train 6 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 3 | train 7 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0015655203023925424\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 3 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 77% 23/30 [00:01<00:00, 20.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 3 | train 8 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.00016772891103755683\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 3 | train 8 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 4 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0015554048586636782\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 4 | train 4 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 4 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0008990341448225081\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 4 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 87% 26/30 [00:01<00:00, 21.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 4 | train 6 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0016178804216906428\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 4 | train 6 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 4 | train 7 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0009820762788876891\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 4 | train 7 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 4 | train 8 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.002196427434682846\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 4 | train 8 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 97% 29/30 [00:01<00:00, 21.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 4 | train 9 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0001148091905633919\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 4 | train 9 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 30/30 [00:01<00:00, 20.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | -->\n",
      "[4]  [ fine_tune_moment_single ] End timer -->\n",
      "[4]  [ fine_tune_moment_single ] Start: 1737480033.5170424 | End: 1737480035.0110576 | Duration: 1.49 seconds\n",
      "[4]  [ fine_tune_moment_single ] fine_tune_moment_single | Eval Post | wlen 17\n",
      "[4]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14% 1/7 [00:01<00:06,  1.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57% 4/7 [00:01<00:00,  4.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100% 7/7 [00:01<00:00,  5.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]  [ fine_tune_moment_single ] End timer -->\n",
      "[4]  [ fine_tune_moment_single ] Start: 1737480035.0131636 | End: 1737480036.3425074 | Duration: 1.33 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]  [ fine_tune_moment_single ] fine_tune_moment_single_ | Evaluation summary\n",
      "[4]  [ fine_tune_moment_single ] Eval pre: \n",
      "mse: {'mse': 0.053732890570543285}\n",
      "rmse: {'mse': 0.0029476201092852572}\n",
      "mae: {'mae': 0.03946589066267938}\n",
      "smape: {'smape': 1.3945297692180116}\n",
      "[4]  [ fine_tune_moment_single ] Eval post: \n",
      "mse: {'mse': 0.053732890570543285}\n",
      "rmse: {'mse': 0.0029476201092852572}\n",
      "mae: {'mae': 0.03946589066267938}\n",
      "smape: {'smape': 1.3945297692180116}\n",
      "[4] [fine_tune_moment_single_ --> ]\n",
      "[4]  [ set_fine_tune_ ] Processing wlen 17\n",
      "[4] [ --> fine_tune_moment_single ]\n",
      "[4]  [ fine_tune_moment_single ] fine_tune_moment_single | Prepare the dataset | X ~ (429, 1, 12)\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting ds train | 103 windows\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting validation train | 103 windows\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | Random windows\n",
      "[3] [ --> fine_tune_moment_single | prepare_train_and_eval_dataloaders | random_windows ]\n",
      "[3]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] N windows: None\n",
      "[3]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] n_windows: 83\n",
      "[3]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] windows~torch.Size([83, 1, 12])\n",
      "[3] [fine_tune_moment_single | prepare_train_and_eval_dataloaders --> ]\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | DataLoader\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Validation DataLoader\n",
      "[4]  [ fine_tune_moment_single ] Start timer\n",
      "[4]  [ fine_tune_moment_single ] Train | wlen 12\n",
      "[3] fine_tune_moment_train_ | Training loop\n",
      "[3] fine_tune_moment_train | Fine tune loop | print_to_path False | batch_masks~tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0% 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | num_epochs 5 | n_batches 6\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 0 | train 0 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0011929112952202559\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 0 | train 0 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 0 | train 1 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0009473706013523042\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 0 | train 1 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 0 | train 2 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0009529499802738428\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 0 | train 2 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 10% 3/30 [00:00<00:01, 23.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 0 | train 3 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 0 | train 3 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 0 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0011088969185948372\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 0 | train 4 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 0 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.00038845406379550695\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 0 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 20% 6/30 [00:00<00:01, 23.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 1 | train 1 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0008446717984043062\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 1 | train 1 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 1 | train 2 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0007710476056672633\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 1 | train 2 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 1 | train 3 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0011432291939854622\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 1 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 30% 9/30 [00:00<00:00, 23.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 1 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0006938963197171688\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 1 | train 4 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 1 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0019026515074074268\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 1 | train 5 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 1 | train 6 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0012845195597037673\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 1 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 40% 12/30 [00:00<00:00, 23.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 2 | train 2 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.001240970566868782\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 2 | train 2 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 2 | train 3 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0006441199802793562\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 2 | train 3 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 2 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0012479303404688835\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 2 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 50% 15/30 [00:00<00:00, 23.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 2 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0011517306556925178\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 2 | train 5 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 2 | train 6 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.001557758660055697\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 2 | train 6 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 2 | train 7 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0003766984445974231\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 2 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 60% 18/30 [00:00<00:00, 23.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 3 | train 3 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0011942542623728514\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 3 | train 3 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 3 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0011833840981125832\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 3 | train 4 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 3 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0015400298871099949\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 3 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 70% 21/30 [00:00<00:00, 23.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 3 | train 6 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.00023966691514942795\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 3 | train 6 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 3 | train 7 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.001031603547744453\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 3 | train 7 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 3 | train 8 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 5.815565600642003e-05\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 3 | train 8 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 80% 24/30 [00:01<00:00, 23.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 4 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.001019155140966177\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 4 | train 4 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 4 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.001687214826233685\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 4 | train 5 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 4 | train 6 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0009026407497003675\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 4 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 90% 27/30 [00:01<00:00, 23.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 4 | train 7 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0009963324991986156\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 4 | train 7 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 4 | train 8 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0004927068948745728\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 4 | train 8 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 4 | train 9 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[3] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[3] --> fine_tune_moment_compute_loss\n",
      "[3] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[3]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[3] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[3] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[3] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[3] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[3] Loss type: <class 'torch.Tensor'>\n",
      "[3] fine_tune_moment_compute_loss | loss: 0.0020677337888628244\n",
      "[3] fine_tune_moment_compute_loss -->\n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 4 | train 9 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "100% 30/30 [00:01<00:00, 23.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | -->\n",
      "[4]  [ fine_tune_moment_single ] End timer -->\n",
      "[4]  [ fine_tune_moment_single ] Start: 1737480036.5658827 | End: 1737480037.8570526 | Duration: 1.29 seconds\n",
      "[4]  [ fine_tune_moment_single ] fine_tune_moment_single | Eval Post | wlen 17\n",
      "[4]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14% 1/7 [00:01<00:06,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100% 7/7 [00:01<00:00,  5.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]  [ fine_tune_moment_single ] End timer -->\n",
      "[4]  [ fine_tune_moment_single ] Start: 1737480037.8589282 | End: 1737480039.1337018 | Duration: 1.27 seconds\n",
      "[4]  [ fine_tune_moment_single ] fine_tune_moment_single_ | Evaluation summary\n",
      "[4]  [ fine_tune_moment_single ] Eval post: \n",
      "mse: {'mse': 0.05464786522408429}\n",
      "rmse: {'mse': 0.0030411378618556244}\n",
      "mae: {'mae': 0.04058488292743348}\n",
      "smape: {'smape': 1.519132180334581}\n",
      "[4] [fine_tune_moment_single_ --> ]\n",
      "[4]  [ set_fine_tune_ ] Processing wlen 17\n",
      "[4] [ --> fine_tune_moment_single ]\n",
      "[4]  [ fine_tune_moment_single ] fine_tune_moment_single | Prepare the dataset | X ~ (437, 1, 4)\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting ds train | 105 windows\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting validation train | 105 windows\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | Random windows\n",
      "[3] [ --> fine_tune_moment_single | prepare_train_and_eval_dataloaders | random_windows ]\n",
      "[3]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] N windows: None\n",
      "[3]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] n_windows: 84\n",
      "[3]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] windows~torch.Size([84, 1, 4])\n",
      "[3] [fine_tune_moment_single | prepare_train_and_eval_dataloaders --> ]\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | DataLoader\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Validation DataLoader\n",
      "[4]  [ fine_tune_moment_single ] Start timer\n",
      "[4]  [ fine_tune_moment_single ] Train | wlen 4\n",
      "[3] fine_tune_moment_train_ | Training loop\n",
      "[3] fine_tune_moment_train | Fine tune loop | print_to_path False | batch_masks~tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0% 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | num_epochs 5 | n_batches 6\n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 0 | train 0 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 0 | train 0 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 0 | train 1 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 0 | train 1 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7% 2/30 [00:00<00:01, 18.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 0 | train 2 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 0 | train 2 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 0 | train 3 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 0 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13% 4/30 [00:00<00:01, 18.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 0 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 0 | train 4 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 0 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([4, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([4, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([4, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 0 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20% 6/30 [00:00<00:01, 18.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 1 | train 1 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 1 | train 1 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 1 | train 2 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 1 | train 2 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27% 8/30 [00:00<00:01, 18.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 1 | train 3 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 1 | train 3 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 1 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 1 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33% 10/30 [00:00<00:01, 18.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 1 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 1 | train 5 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 1 | train 6 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([4, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([4, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 1 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40% 12/30 [00:00<00:00, 18.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 2 | train 2 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 2 | train 2 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 2 | train 3 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 2 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47% 14/30 [00:00<00:00, 18.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 2 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 2 | train 4 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 2 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 2 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53% 16/30 [00:00<00:00, 18.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 2 | train 6 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 2 | train 6 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 2 | train 7 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([4, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([4, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 2 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60% 18/30 [00:00<00:00, 18.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 3 | train 3 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 3 | train 3 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 3 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 3 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 67% 20/30 [00:01<00:00, 18.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 3 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 3 | train 5 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 3 | train 6 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 3 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73% 22/30 [00:01<00:00, 18.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 3 | train 7 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 3 | train 7 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 3 | train 8 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([4, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([4, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 3 | train 8 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80% 24/30 [00:01<00:00, 17.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 4 | train 4 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 4]) | epoch 4 | train 4 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 4 | train 5 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 4]) | epoch 4 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 87% 26/30 [00:01<00:00, 17.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 4 | train 6 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 4]) | epoch 4 | train 6 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 4 | train 7 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 4]) | epoch 4 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93% 28/30 [00:01<00:00, 17.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 4 | train 8 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 4]) | batch_masks ~ torch.Size([16, 4]) | mask ~ torch.Size([16, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([16, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([16, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([16, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([16, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([16, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([16, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([16, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 4]) | epoch 4 | train 8 of 30 | Loss backward | After loop step \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 4 | train 9 of 30 | Before loop step\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([4, 1, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([4, 4]) | stateful = False | sync = False | r = 0.4\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([4, 1, 4]) | batch_masks ~ torch.Size([4, 4]) | mask ~ torch.Size([4, 4])\n",
      "[3] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[3] ---> sure_eval_moment\n",
      "[3] sure_eval_moment | cpu | False | device | 0\n",
      "[3] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 1 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 2 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([4, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 3 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 3 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([4, 1, 4])\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 4 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([4, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] sure_eval_moment | Trial 5 | device 0 | input_mask~torch.Size([4, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | mask device~torch.Size([4, 4]): cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | device 0 | y~torch.Size([4, 1, 4]) device: cuda:0\n",
      "[3] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception maximum size for tensor at dimension 2 is 4 but size is 8 | padd step: 100\n",
      "[3] sure_eval_moment | Trial 5 | y ~ torch.Size([4, 1, 4])\n",
      "[3] Not the usual error. No padding, just fail\n",
      "[3] sure_eval_moment | output <class 'NoneType'> -->\n",
      "[3] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[3] fine_tune_moment_train | batch 5 ~ torch.Size([4, 1, 4]) | epoch 4 | train 9 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 794, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100% 30/30 [00:01<00:00, 18.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] fine_tune_moment_train | -->\n",
      "[4]  [ fine_tune_moment_single ] End timer -->\n",
      "[4]  [ fine_tune_moment_single ] Start: 1737480039.26312 | End: 1737480040.9276917 | Duration: 1.66 seconds\n",
      "[4]  [ fine_tune_moment_single ] fine_tune_moment_single | Eval Post | wlen 17\n",
      "[4]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0% 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure, see errors dataset\n",
      "epoch 5, dataset_percent 0.3, mask 0.4\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "i = 0\n",
    "for n_epochs in [5]:\n",
    "    for dataset_percent in [0.3]:\n",
    "        for maskared_percent in [0.4]:\n",
    "            for sizes in [3]:\n",
    "                print(f\"--> epoch {n_epochs}, dataset_percent {dataset_percent}, mask {maskared_percent}\")\n",
    "                print(f\" sizes {sizes}\")\n",
    "                result_dict = {'model_size': \"small\",\n",
    "                        'n_epochs': n_epochs,\n",
    "                        'dataset_percent': dataset_percent,\n",
    "                        'maskared_percent': maskared_percent,\n",
    "                       }\n",
    "                error_dict = deepcopy(result_dict)\n",
    "                result_dict.update({\n",
    "                        'losses': np.nan,\n",
    "                        'eval_results_pre': np.nan, 'eval_results_post': np.nan,\n",
    "                        'time': np.nan\n",
    "                    })\n",
    "                error = False\n",
    "                error_dict.update({'error': \"\"})\n",
    "                try:\n",
    "                    result = fine_tune(\n",
    "                        enc_learn           = enc_learner_small,\n",
    "                        window_mask_percent = maskared_percent,\n",
    "                        training_percent    = dataset_percent,\n",
    "                        validation_percent  = 0.3, #1-dataset_percent if 1-dataset_percent != 0 else 0.3,\n",
    "                        num_epochs          = n_epochs,\n",
    "                        n_window_sizes      = sizes,\n",
    "                        verbose             = 4,\n",
    "                        **common_args    \n",
    "                    )\n",
    "                    result_dict['losses'] = result[0]\n",
    "                    result_dict['eval_results_pre'] = result[1]\n",
    "                    result_dict['eval_results_post'] = result[2]\n",
    "                    result_dict['time'] = result[4]\n",
    "                except Exception as e:\n",
    "                    error = True\n",
    "                    print(\"Failure, see errors dataset\")\n",
    "                    error_dict['error'] = e\n",
    "                    errors = pd.concat([errors, pd.DataFrame([error_dict])], ignore_index=True)                \n",
    "                results = pd.concat([results, pd.DataFrame([result_dict])], ignore_index=True)                \n",
    "                print(f\"epoch {n_epochs}, dataset_percent {dataset_percent}, mask {maskared_percent}\")\n",
    "                if not error: print(f\" sizes {sizes} | time: {result[4]} -->\")\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0380011c-20bb-4b1d-9384-5cd66b5a5366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>dataset_percent</th>\n",
       "      <th>maskared_percent</th>\n",
       "      <th>losses</th>\n",
       "      <th>eval_results_pre</th>\n",
       "      <th>eval_results_post</th>\n",
       "      <th>time</th>\n",
       "      <th>model_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model size n_epochs  dataset_percent  maskared_percent  losses  \\\n",
       "0        NaN        5              0.3               0.4     NaN   \n",
       "1        NaN        5              0.3               0.4     NaN   \n",
       "\n",
       "   eval_results_pre  eval_results_post  time model_size  \n",
       "0               NaN                NaN   NaN      small  \n",
       "1               NaN                NaN   NaN      small  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b211e9f2-bc64-41a9-b9be-3b2ed97bafab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>dataset_percent</th>\n",
       "      <th>maskared_percent</th>\n",
       "      <th>error</th>\n",
       "      <th>model_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>maximum size for tensor at dimension 2 is 4 but size is 8</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>maximum size for tensor at dimension 2 is 4 but size is 8</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model size n_epochs  dataset_percent  maskared_percent  \\\n",
       "0        NaN        5              0.3               0.4   \n",
       "1        NaN        5              0.3               0.4   \n",
       "\n",
       "                                                       error model_size  \n",
       "0  maximum size for tensor at dimension 2 is 4 but size is 8      small  \n",
       "1  maximum size for tensor at dimension 2 is 4 but size is 8      small  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad5a24fb-4416-4345-a1c8-131bed978e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"Execution ended\")\n",
    "from dvats.imports import beep\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dca0597-64fb-4bc5-946f-2ae110b3cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
