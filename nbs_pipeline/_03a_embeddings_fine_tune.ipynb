{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de2cd87-7d93-45ec-bd92-d97a85cf73b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Getting the embeddings\n",
    "\n",
    "> This notebook gets the embeddings (or latent space) from a multivariate time series \n",
    "given by a encoder (e.g., autoencoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816ae963-a2d2-467a-90ee-2be0f383c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_patch_size = 8\n",
    "verbose          = 0\n",
    "reset_kernel     = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db2cd5f-dd8d-42a3-bdc1-afc12ff80afb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7fe511424be0>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "from dvats.all import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from yaml import load, FullLoader\n",
    "import dvats.utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6774bdd-fc22-4e8e-96c4-c29417380137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280e30d-8195-4f39-898a-495d9253778b",
   "metadata": {},
   "source": [
    "## Config parameters\n",
    "> Configuration parameters are obtained from 'config\\03-embeddings.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fd16b-1ca7-4bed-9173-642cabdbe9bb",
   "metadata": {},
   "source": [
    "### Get configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47519e96-4dd2-4096-8189-d735f88155ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, job_type = get_artifact_config_embeddings(verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515769be-e06d-4ae2-b3ab-1636642a158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/mvp:latest\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372ce1e-f3c8-4df4-a802-1250bc9a80cb",
   "metadata": {},
   "source": [
    "### Show configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5f95d2-f07a-4e39-bfed-ade6555641bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/mvp:latest\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe624f-f4ff-4310-9d3c-23099381ed91",
   "metadata": {},
   "source": [
    "## Build W&B artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67704d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 03a_embeddings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"03a_embeddings\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "print(\"runname: \"+runname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa46f602-bbf9-4d2d-ae68-771adae56199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20250114_183745-e3ik10fr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/e3ik10fr' target=\"_blank\">03a_embeddings</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/e3ik10fr' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/e3ik10fr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    entity      = config.wandb_entity,\n",
    "    project     = config.wandb_project if config.use_wandb else 'work-nbs', \n",
    "    group       = config.wandb_group,\n",
    "    job_type    = job_type,\n",
    "    mode        = 'online' if config.use_wandb else 'disabled',\n",
    "    anonymous   = 'never'  if config.use_wandb else 'must',\n",
    "    config      = config,\n",
    "    resume      = 'allow',\n",
    "    name        = runname\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b68a48-1629-4ad4-940b-2abc310ad942",
   "metadata": {},
   "source": [
    "## Get trained model artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa21e68-a1fd-4bf5-b3fc-84f5295f4ad1",
   "metadata": {},
   "source": [
    "### Build artifact selector\n",
    "> Botch to use artifacts offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26dac90a-ed13-4f50-b95e-fc78c635e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08922829-19f7-4cdc-97b1-86f5a3b4f3d2",
   "metadata": {},
   "source": [
    "### Get the model from W&B\n",
    "> Restore the encoder model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e978658-78de-4dff-9679-d2ed1453dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_artifact = artifacts_gettr(config.enc_artifact, type='learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fbe313-d3b6-4793-aaf3-34d4b858065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "# TODO: This only works when you run it two timeS! WTF?\n",
    "try:\n",
    "    enc_learner = enc_artifact.to_obj()\n",
    "except:\n",
    "    enc_learner = enc_artifact.to_obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb98d5-9ba2-4cc9-a033-91282bdab376",
   "metadata": {},
   "source": [
    "## Get dataset artifact from W&B\n",
    "### Restore the dataset artifact used for training the encoder. \n",
    "> Even if we do not compute the dimensionality reduction over this dataset, we need to know the metadata of the encoder training set, to check that it matches with the dataset that we want to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4335e626-5faa-4d27-845c-015f23ab9375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gtrends_khols-normalized_yearly:v0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run            = enc_artifact.logged_by()\n",
    "enc_artifact_train = artifacts_gettr(\n",
    "                        enc_run.config['train_artifact'], \n",
    "                        type='dataset'\n",
    "                    )\n",
    "enc_artifact_train.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b5100a8-f044-4337-8731-4e7a76854a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: 0.4\n",
      "w: 17\n",
      "MVP: {'r': 0.4, 'lm': 3, 'crit': None, 'sync': False, 'fname': 'encoder_MVP', 'dropout': 0.1, 'verbose': False, 'stateful': False, 'save_best': True, 'nan_to_num': 0, 'custom_mask': None, 'future_mask': True, 'weights_path': None, 'variable_mask': False, 'subsequence_mask': True}\n",
      "alias: gtrends_khols-normalized_yearly\n",
      "n_inp: 1\n",
      "device: cuda\n",
      "epochs: 200\n",
      "frozen: False\n",
      "mvp_ws: [12, 17]\n",
      "stride: 1\n",
      "Learner: {'lr': 0.001, 'wd': None, 'arch': 'tsai.models.InceptionTimePlus.InceptionTimePlus', 'moms': [0.95, 0.85, 0.95], 'path': '.', '_name': '<fastai.learner.Learner object at 0x7f811e636110>', 'metrics': None, 'opt_func': 'fastai.optimizer.Adam', 'splitter': 'tsai.models.utils.ts_splitter', 'train_bn': True, 'loss_func': {'axis': -1, '_name': {'axis': -1, '_name': 'FlattenedLoss of MSELoss()', 'is_2d': False, 'flatten': True, 'floatify': True}, 'is_2d': False, 'flatten': True, 'floatify': True}, 'model_dir': 'models', 'wd_bn_bias': False, 'default_cbs': True}\n",
      "Recorder: {'add_time': True, 'train_metrics': False, 'valid_metrics': True}\n",
      "ShowGraph: {'perc': 0.5, 'final_losses': True, 'plot_metrics': True}\n",
      "mask_sync: False\n",
      "use_wandb: True\n",
      "batch size: 16\n",
      "batch_size: 16\n",
      "frozen idx: 0\n",
      "valid_size: 0.2\n",
      "mask_future: True\n",
      "wandb_group: None\n",
      "CastToTensor: True\n",
      "dataset.tfms: [ToFloat:\n",
      "encodes: (Tensor,object) -> encodes\n",
      "(object,object) -> encodes\n",
      "decodes: (object,object) -> decodes\n",
      ", None]\n",
      "WandbCallback: {'log': None, 'seed': 12345, 'n_preds': 36, 'reorder': True, 'valid_dl': None, 'log_model': False, 'log_preds': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'log_preds_every_epoch': False}\n",
      "analysis_mode: online\n",
      "input 1 dim 1: 16\n",
      "input 1 dim 2: 1\n",
      "input 1 dim 3: 17\n",
      "mask_stateful: False\n",
      "ParamScheduler: True\n",
      "dls.after_item: Pipeline: \n",
      "norm_by_sample: False\n",
      "train_artifact: mi-santamaria/deepvats/gtrends_khols-normalized_yearly:v0\n",
      "valid_artifact: None\n",
      "batch per epoch: 21\n",
      "dls.after_batch: Pipeline: TSStandardize\n",
      "ProgressCallback: True\n",
      "dls.before_batch: Pipeline: \n",
      "model parameters: 454977\n",
      "TrainEvalCallback: True\n",
      "EarlyStoppingCallback: True\n",
      "norm_use_single_batch: False\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(enc_run.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918829a-dd1f-4ddb-915c-cebf41665160",
   "metadata": {},
   "source": [
    "### Specify the dataset artifact that we want to get the embeddings from\n",
    "> If no artifact is defined, the artifact to reduce will be the one used for validate the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b394f66-6b1d-4c39-a4c8-6786c4f9b493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run.config['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ff4ef9-cabd-41cb-84c8-ec86cadf5848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gtrends_khols-normalized_yearly:v0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ar_name = ifnone(\n",
    "    config.input_ar, \n",
    "    f'{enc_artifact_train.entity}/{enc_artifact_train.project}/{enc_artifact_train.name}'\n",
    ")\n",
    "wandb.config.update({'input_ar': input_ar_name}, allow_val_change=True)\n",
    "input_ar = artifacts_gettr(input_ar_name)\n",
    "input_ar.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a84cf086-f6ee-4f04-a234-581a738fc338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>0.090912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>0.090912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-15</th>\n",
       "      <td>0.090912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-22</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-29</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              volume\n",
       "2004-01-01  0.090912\n",
       "2004-01-08  0.090912\n",
       "2004-01-15  0.090912\n",
       "2004-01-22  0.000000\n",
       "2004-01-29  0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = input_ar.to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46c6bb02-9a43-4917-93a9-0832ee98b5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a22dbdb5-8f92-4f56-bc4f-286bcd453986",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_run.config['w'] = 54\n",
    "enc_run.config['stride'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49908f03-6875-4e27-8050-09af41dc62bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 1, 54)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input, _ = SlidingWindow(window_len=enc_run.config['w'], \n",
    "                             stride=enc_run.config['stride'], \n",
    "                             get_y=[])(df)\n",
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf910313-b689-45f2-b405-5c4b3ef66012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1736879894.4466426"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = ut.Time()\n",
    "timer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97d09238-e62c-4135-baf7-4b7d38e3c19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mi-santamaria/deepvats/mvp:latest'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.enc_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9dcf6e5-a338-4638-b0bc-2ecfc12eadf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fastai.learner.Learner object at 0x7fe6560e3d60>\n"
     ]
    }
   ],
   "source": [
    "print(enc_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5b5fc61-1e0b-4cba-a4aa-d80b26c32edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_learn_class = str(enc_learner.__class__)[8:-2]\n",
    "\n",
    "match enc_learn_class:\n",
    "    case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"fastai.learner.Learner\":\n",
    "        get_embs_kwargs = {\n",
    "            \"stride\": enc_run.config['stride'],\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1,\n",
    "            \"patch_size\": 8, #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"size\": \"small\", #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"time\": True\n",
    "        }\n",
    "    case _:\n",
    "        print(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa815efc-5050-4e6f-b6b4-c1cbd78223d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fastai.learner.Learner'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_learn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f6ea32a-0d67-48de-95a3-401a13faa72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fastai.learner.Learner'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_learn_class = str(enc_learner.__class__)[8:-2]\n",
    "enc_learn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb74d900-463d-4f2c-8a6b-bbfafb69ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc learn class fastai.learner.Learner\n",
      "kwargs: {'stride': 1, 'cpu': False, 'to_numpy': True, 'batch_size': 16, 'average_seq_dim': True, 'verbose': 4}\n"
     ]
    }
   ],
   "source": [
    "match enc_learn_class:\n",
    "    case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "        get_embs_kwargs = {\n",
    "            \"batch_size\": enc_input.shape[0],\n",
    "            \"cpu\"       : config.cpu,\n",
    "            \"to_numpy\"  : True,\n",
    "            \"verbose\"   : 1,\n",
    "            \"padd_step\" : 10\n",
    "        }\n",
    "    case \"fastai.learner.Learner\":\n",
    "        get_embs_kwargs = {\n",
    "            \"stride\"         : 1,\n",
    "            \"cpu\"            : config.cpu,\n",
    "            \"to_numpy\"       : True,\n",
    "            \"batch_size\"     : enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\"        : 4\n",
    "        }\n",
    "    case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\"            : config.cpu,\n",
    "            \"to_numpy\"       : True,\n",
    "            \"batch_size\"     : enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\"        : 2,\n",
    "            \"patch_size\"     : model_patch_size, #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"time\"           : True\n",
    "        }\n",
    "    case _:\n",
    "        print(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\")\n",
    "print(f\"Enc learn class {enc_learn_class}\\nkwargs: {get_embs_kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b897b59-63c4-480c-8395-71c49e30bab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 0.4,\n",
       " 'w': 54,\n",
       " 'MVP': {'r': 0.4,\n",
       "  'lm': 3,\n",
       "  'crit': None,\n",
       "  'sync': False,\n",
       "  'fname': 'encoder_MVP',\n",
       "  'dropout': 0.1,\n",
       "  'verbose': False,\n",
       "  'stateful': False,\n",
       "  'save_best': True,\n",
       "  'nan_to_num': 0,\n",
       "  'custom_mask': None,\n",
       "  'future_mask': True,\n",
       "  'weights_path': None,\n",
       "  'variable_mask': False,\n",
       "  'subsequence_mask': True},\n",
       " 'alias': 'gtrends_khols-normalized_yearly',\n",
       " 'n_inp': 1,\n",
       " 'device': 'cuda',\n",
       " 'epochs': 200,\n",
       " 'frozen': False,\n",
       " 'mvp_ws': [12, 17],\n",
       " 'stride': 2,\n",
       " 'Learner': {'lr': 0.001,\n",
       "  'wd': None,\n",
       "  'arch': 'tsai.models.InceptionTimePlus.InceptionTimePlus',\n",
       "  'moms': [0.95, 0.85, 0.95],\n",
       "  'path': '.',\n",
       "  '_name': '<fastai.learner.Learner object at 0x7f811e636110>',\n",
       "  'metrics': None,\n",
       "  'opt_func': 'fastai.optimizer.Adam',\n",
       "  'splitter': 'tsai.models.utils.ts_splitter',\n",
       "  'train_bn': True,\n",
       "  'loss_func': {'axis': -1,\n",
       "   '_name': {'axis': -1,\n",
       "    '_name': 'FlattenedLoss of MSELoss()',\n",
       "    'is_2d': False,\n",
       "    'flatten': True,\n",
       "    'floatify': True},\n",
       "   'is_2d': False,\n",
       "   'flatten': True,\n",
       "   'floatify': True},\n",
       "  'model_dir': 'models',\n",
       "  'wd_bn_bias': False,\n",
       "  'default_cbs': True},\n",
       " 'Recorder': {'add_time': True, 'train_metrics': False, 'valid_metrics': True},\n",
       " 'ShowGraph': {'perc': 0.5, 'final_losses': True, 'plot_metrics': True},\n",
       " 'mask_sync': False,\n",
       " 'use_wandb': True,\n",
       " 'batch size': 16,\n",
       " 'batch_size': 16,\n",
       " 'frozen idx': 0,\n",
       " 'valid_size': 0.2,\n",
       " 'mask_future': True,\n",
       " 'wandb_group': None,\n",
       " 'CastToTensor': True,\n",
       " 'dataset.tfms': '[ToFloat:\\nencodes: (Tensor,object) -> encodes\\n(object,object) -> encodes\\ndecodes: (object,object) -> decodes\\n, None]',\n",
       " 'WandbCallback': {'log': None,\n",
       "  'seed': 12345,\n",
       "  'n_preds': 36,\n",
       "  'reorder': True,\n",
       "  'valid_dl': None,\n",
       "  'log_model': False,\n",
       "  'log_preds': False,\n",
       "  'model_name': None,\n",
       "  'log_dataset': False,\n",
       "  'dataset_name': None,\n",
       "  'log_preds_every_epoch': False},\n",
       " 'analysis_mode': 'online',\n",
       " 'input 1 dim 1': 16,\n",
       " 'input 1 dim 2': 1,\n",
       " 'input 1 dim 3': 17,\n",
       " 'mask_stateful': False,\n",
       " 'ParamScheduler': True,\n",
       " 'dls.after_item': 'Pipeline: ',\n",
       " 'norm_by_sample': False,\n",
       " 'train_artifact': 'mi-santamaria/deepvats/gtrends_khols-normalized_yearly:v0',\n",
       " 'valid_artifact': None,\n",
       " 'batch per epoch': 21,\n",
       " 'dls.after_batch': 'Pipeline: TSStandardize',\n",
       " 'ProgressCallback': True,\n",
       " 'dls.before_batch': 'Pipeline: ',\n",
       " 'model parameters': 454977,\n",
       " 'TrainEvalCallback': True,\n",
       " 'EarlyStoppingCallback': True,\n",
       " 'norm_use_single_batch': False}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05befd70-6604-4170-8d69-03afd9af5d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.learner.Learner"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_learner.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "053ef114-84d5-45fe-aba7-2714edd3bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import math\n",
    "from dvats.memory import *\n",
    "import dvats.utils as ut\n",
    "from dvats.config import show_attrdict\n",
    "from copy import deepcopy\n",
    "## -- Classes & types\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional, Tuple, Callable, Union, Any\n",
    "\n",
    "# Fastai\n",
    "#| export\n",
    "from fastai.learner import Learner\n",
    "from tsai.data.core import TSDataLoaders\n",
    "# Moirai\n",
    "import uni2ts.model.moirai.module as moirai\n",
    "import uni2ts.model.moirai.forecast as moirai_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e2a7e66-2ec0-4379-be07-6af0c6481913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.all import *\n",
    "from tsai.callback.MVP import *\n",
    "from tsai.imports import *\n",
    "from tsai.models.InceptionTimePlus import InceptionTimePlus\n",
    "from tsai.models.explainability import get_acts_and_grads\n",
    "from tsai.models.layers import *\n",
    "from tsai.data.validation import combine_split_data\n",
    "from tsai.basics import *\n",
    "from fastai.callback.hook import hook_outputs\n",
    "from momentfm import MOMENTPipeline\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from tsai.data.validation import TimeSplitter\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.progress import ShowGraphCallback\n",
    "from fastai.callback.schedule import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback\n",
    "from fastai.callback.tracker import SaveModelCallback\n",
    "import time\n",
    "import einops\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62be69bd-ee05-4665-af10-4ad6a2a4058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def windowed_dataset(\n",
    "    X                               : Union [ List [ List [ List [ float ]]], List [ float ], pd.DataFrame ],\n",
    "    stride                          : int           = 1,\n",
    "    window_sizes                    : List [int]    = None,\n",
    "    n_window_sizes                  : int           = 1,\n",
    "    window_sizes_offset             : int           = 0.05,\n",
    "    windows_min_distance            : int           = 1,\n",
    "    full_dataset                    : bool          = False,\n",
    "    mssg                            : ut.Mssg       = ut.Mssg()\n",
    "): \n",
    "    stride = 1 if stride is None else stride \n",
    "    n_window_sizes = 1 if n_window_sizes is None else n_window_sizes\n",
    "    window_sizes_offset = 0.05 if window_sizes_offset is None else window_sizes_offset\n",
    "    windows_min_distance = 1 if windows_min_distance is None else windows_min_distance\n",
    "    full_dataset = False if full_dataset is None else full_dataset\n",
    "    mssg = ut.Mssg() if mssg is None else mssg\n",
    "\n",
    "    mssg_ = deepcopy(mssg)\n",
    "    mssg_.level -= 1\n",
    "    mssg_.initial(ut.funcname())\n",
    "    dss = []\n",
    "    if isinstance(X, list):\n",
    "        mssg_.print(\"X is a list. Converting to dataFrame\")\n",
    "        X = np.array(X)\n",
    "        X = pd.DataFrame(X)        \n",
    "    if ( isinstance(X,pd.DataFrame) or full_dataset): \n",
    "        mssg_.print(f\"X is a DataFrame, X~{X.shape} | window_sizes {len(window_sizes) if window_sizes is not None else 0}, n_window_sizes {n_window_sizes}\")\n",
    "        if window_sizes is None or n_window_sizes > len(window_sizes):\n",
    "            mssg.print(\"X is a DataFrame | Selecting Fourier's dominant frequences\")\n",
    "            # Select Fourier's dominant frequences\n",
    "            window_sizes_ = find_dominant_window_sizes_list(\n",
    "                X               = X, \n",
    "                nsizes          = n_window_sizes, \n",
    "                offset          = window_sizes_offset, \n",
    "                min_distance    = windows_min_distance,\n",
    "                mssg            = mssg_\n",
    "            )\n",
    "            window_sizes = window_sizes_ if window_sizes is None else list(set(window_sizes + window_sizes_))[:n_window_sizes]\n",
    "            mssg_.print(f\"X is a DataFrame | Window sizes: {len(window_sizes)}\")\n",
    "        mssg_.print(f\"Building the windows\")\n",
    "        for w in window_sizes:\n",
    "            mssg_.print(f\"w = {w}\", verbose_level = mssg_.level+1)\n",
    "            enc_input, _ = SlidingWindow(window_len = w, stride = stride, get_y=[])(X)\n",
    "            dss.append(enc_input)\n",
    "            mssg_.print(f\"w {w} | enc_input~{enc_input.shape} | dss~{len(dss)}\",  verbose_level = mssg_.level+1)\n",
    "    else: \n",
    "        mssg_.print(\"X is already windowed\")\n",
    "        dss = [X]\n",
    "    mssg_.print(f\"Number of windows: {len(dss)}\")\n",
    "    mssg_.final()\n",
    "    return dss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "758497f3-a9b8-4192-b807-583622e61a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class EncoderInput:\n",
    "    # Data\n",
    "    _data               : Union [ pd.DataFrame, List [ List [ List [ float ]]] ] = None\n",
    "    _size               : int                               = None\n",
    "    _shape              : Optional [ Tuple [ int, ... ] ]   = None\n",
    "    _shapes             : List [ Tuple [ int, ...]]         = None\n",
    "    stride              : int                               = None\n",
    "    batch_size          : int                               = None\n",
    "    _update_size        : bool                              = True\n",
    "    _update_shape       : bool                              = True\n",
    "    # Windows                   \n",
    "    n_windows           : int                               = None\n",
    "    n_windows_percent   : float                             = None\n",
    "    validation_percent  : float                             = None\n",
    "    training_percent    : float                             = None\n",
    "    window_mask_percent : float                             = None\n",
    "    # Time                  \n",
    "    time_flag           : bool                              = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self._update_size       = True\n",
    "        self._update_shape      = True\n",
    "        #Todo: check how to validate the input dataset allowing both windowed or not\n",
    "        # --- Not working\n",
    "        ###self._data              = ut._check_value(self.data, None, \"_data\", pd.DataFrame, allow_none = True )\n",
    "        ###if self._data is None: \n",
    "        ###    self._data = ut._validate_nested_list(self._data, None, \"_data\", [float, int], 3, False, False, False)\n",
    "        self.stride,_               = ut._check_value(self.stride, 1, \"stride\", int, positive = True)\n",
    "        self.batch_size,_           = ut._check_value(self.batch_size, 32, \"batch_size\", int,  )\n",
    "        self.validation_percent,_   = ut._check_value(self.validation_percent, 0.2, \"validation_percent\", percent = True)\n",
    "        self.training_percent,_     = ut._check_value(self.training_percent, 0.2, \"training_percent\", percent = True)\n",
    "        self.window_mask_percent,_  = ut._check_value(self.window_mask_percent, 0.3, \"training_percent\", percent = True)\n",
    "        self.time_flag,_            = ut._check_value(self.time_flag, \"time_flag\", bool)\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        if self._data is not None and ( self._update_size or self._size is None or self._size == 0):\n",
    "            self._size          = len(self._data)\n",
    "            self._update_size   = False\n",
    "            self._size,_ = ut._check_value(self._size, 0, \"_size\", int)\n",
    "            self._size = max(self._size, 0)\n",
    "        elif self._update_size: \n",
    "            self._size = 0\n",
    "            self._update_size = True\n",
    "        return self._size\n",
    "    \n",
    "    @property\n",
    "    def shape(self) -> Tuple[int, ...]:\n",
    "        if (\n",
    "                self._data is not None and \n",
    "                ( self._update_shape or self._shape is None or self._shape == 0 )\n",
    "        ):\n",
    "            try: \n",
    "                self._shape     = self._data.shape\n",
    "                self._shapes    = [ self._shape ]\n",
    "            except:\n",
    "                self._shape  = self._data[0].shape\n",
    "                self._shapes = [ self._data[i].shape for i in range(len(self._data))]\n",
    "            self._update_shape = False\n",
    "        elif self._update_shape: \n",
    "            self._shape = 0,\n",
    "            self._shapes = []\n",
    "            self._update_shape = True\n",
    "        return self._shape\n",
    "    @property\n",
    "    def shapes(self) -> List [ Tuple [ int, ... ]]:\n",
    "        if (\n",
    "            self._data is not None and \n",
    "            ( self._update_shape or self._shapes is None or self._shapes ==[])\n",
    "        ):\n",
    "            try: \n",
    "                self._shape     = self._data.shape\n",
    "                self._shapes    = [ self._shape ]\n",
    "            except:\n",
    "                self._shape     = self._data[0].shape\n",
    "                self._shapes    = [ self._data[i].shape for i in range(len(self._data))]\n",
    "            self._update_shape  = False\n",
    "        elif self._update_shape: \n",
    "            self._shape         = 0,\n",
    "            self._shapes        = []\n",
    "            self._update_shape  = True\n",
    "        return self._shapes\n",
    "            \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "    \n",
    "    @data.setter\n",
    "    def data(self, value):\n",
    "        self._data          = value\n",
    "        self._update_size   = True\n",
    "        self._update_shape  = True\n",
    "@dataclass\n",
    "class LRScheduler:\n",
    "    lr              : float = None\n",
    "    flag            : bool  = None\n",
    "    name            : str   = None\n",
    "    num_warmup_steps: int   = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.lr                 = self._check_lr(self.lr, 1e-5)\n",
    "        self.flag               = self._check_flag(self.flag, False)\n",
    "        self.name               = self._check_name(self.name, \"OneCycleR\")\n",
    "        self.num_warmup_steps   = self._check_steps(self.num_warmup_steps, 0)\n",
    "\n",
    "    # Validation methods\n",
    "    def _check_lr(self, value, default):\n",
    "        if not isinstance(value, (float, int)) or not math.isfinite(value) or value <= 0:\n",
    "            warnings.warn(f\"Invalid learning rate 'lr' ({value}). Using default: {default}\")\n",
    "            return default\n",
    "        return float(value)\n",
    "\n",
    "    def _check_flag(self, value, default):\n",
    "        if not isinstance(value, bool):\n",
    "            warnings.warn(f\"Invalid type for 'flag' ({type(value)}). Using default: {default}\")\n",
    "            return default\n",
    "        return value\n",
    "\n",
    "    def _check_name(self, value, default):\n",
    "        if not isinstance(value, str):\n",
    "            warnings.warn(f\"Invalid type for 'name' ({type(value)}). Using default: {default}\")\n",
    "            return default\n",
    "        return value\n",
    "\n",
    "    def _check_steps(self, value, default):\n",
    "        if not isinstance(value, int) or value < 0:\n",
    "            warnings.warn(f\"Invalid type or negative value for 'num_warmup_steps' ({value}). Using default: {default}\")\n",
    "            return default\n",
    "        return value\n",
    "@dataclass\n",
    "class EncoderOptimizer():\n",
    "    criterion   : Optional   [ torch.nn.Module ]          = torch.nn.MSELoss\n",
    "    optimizer   : Optional   [ torch.optim.Optimizer ]    = None\n",
    "    lr          : Union      [ float, LRScheduler ]       = 1e-5\n",
    "\n",
    "    def _post__init__(self):\n",
    "        self.lr,_ = ut._check_value( self.lr, 1e-5, \"lr\", [ int, float ], False, True, False )    \n",
    "#| export\n",
    "@dataclass\n",
    "class Encoder():\n",
    "    model               : Tuple [ \n",
    "                            MOMENTPipeline,\n",
    "                            Learner,\n",
    "                            moirai.MoiraiModule\n",
    "                        ]                   = None\n",
    "    input               : EncoderInput      = EncoderInput()\n",
    "    mssg                : ut.Mssg           = ut.Mssg()\n",
    "    cpu                 : bool              = False\n",
    "    to_numpy            : bool              = False\n",
    "    num_epochs          : int               = 1\n",
    "    optim               : EncoderOptimizer  = EncoderOptimizer()\n",
    "    mask_stateful       : bool              = False\n",
    "    mask_future         : bool              = False\n",
    "    mask_sync           : bool              = False\n",
    "    eval_stats_pre      : AttrDict          = None\n",
    "    eval_stats_post     : AttrDict          = None\n",
    "    use_moment_masks    : bool              = False\n",
    "    model_class         : str               = None\n",
    "    time_flag           : bool              = False\n",
    "    use_wandb           : bool              = False\n",
    "    analysis_mode       : str               = 'online'\n",
    "    splits              : Tuple             = None\n",
    "    show_plot           : bool              = False\n",
    "    norm_by_sample      : bool              = True\n",
    "    norm_use_single_batch : bool            = True\n",
    "    \n",
    "    #mvp_ws              : Tuple [ int, int ]= 0,0\n",
    "    def __post_init__(self):\n",
    "        self.model          , _ = ut._check_value(self.model, None, \"model\", [ MOMENTPipeline, Learner, moirai.MoiraiModule ], True, False, False, mssg = self.mssg)\n",
    "        self.model              = self.set_model_(self.model)\n",
    "        ## TODO: check how to do this check\n",
    "        #self.input          , _ = ut._check_value(self.input, EncoderInput(), \"input\", EncoderInput, True)\n",
    "        self.mssg           , _ = ut._check_value(self.mssg, ut.Mssg(), \"mssg\", ut.Mssg, mssg = self.mssg)\n",
    "        self.cpu            , _ = ut._check_value(self.cpu, False, \"cpu\", bool, mssg = self.mssg)\n",
    "        self.to_numpy       , _ = ut._check_value(self.to_numpy, False, \"to_numpy\", bool,  mssg = self.mssg)\n",
    "        self.num_epochs     , _ = ut._check_value(self.num_epochs, 1, \"num_epochs\", int, False, True,  mssg = self.mssg)\n",
    "        ## TODO: check how to do this check\n",
    "        #self.optim          , _ = ut._check_value(self.optim, EncoderOptimizer(), \"optim\", EncoderOptimizer)\n",
    "        self.mask_stateful  , _ = ut._check_value(self.mask_stateful, False, \"mask_statefull\", bool,  mssg = self.mssg)\n",
    "        self.mask_future    , _ = ut._check_value(self.mask_future, False, \"mask_future\", bool,  mssg = self.mssg)\n",
    "        self.mask_sync      , _ = ut._check_value(self.mask_sync, False, \"mask_sync\", bool,  mssg = self.mssg)\n",
    "        self.eval_stats_pre , _ = ut._check_value(self.eval_stats_pre, None, \"eval_stats_pre\", AttrDict, True,  mssg = self.mssg)\n",
    "        self.eval_stats_post, _ = ut._check_value(self.eval_stats_post, None, \"eval_stats_post\", AttrDict, True,  mssg = self.mssg)\n",
    "        self.use_moment_masks, _= ut._check_value(self.use_moment_masks, False, \"use_moment_masks\", bool,  mssg = self.mssg)\n",
    "        self.model_class        = None # Must be computed through get_model_class to avoid errors\n",
    "        self.time_flag      , _ = ut._check_value(self.time_flag, False, \"time_flag\", bool,  mssg = self.mssg)\n",
    "        self.show_plot      , _ = ut._check_value(self.show_plot, False, \"show_plot\", bool, mssg = self.mssg)\n",
    "    \n",
    "    def print(self, **kwargs):\n",
    "        self.mssg.print(**kwargs)\n",
    "\n",
    "    def get_model_class(self, force : bool = False): \n",
    "        if force or self.model_class is None:\n",
    "            self.model_class = str(self.model.__class__)[8:-2]\n",
    "        return self.model_class\n",
    "    def set_model_(self, model):\n",
    "        if model is not None:\n",
    "            self.model          = model\n",
    "            self.model_class    = self.get_model_class() \n",
    "            try: # Initially it may not be defined and that would result in an execution error\n",
    "                self.fine_tune_     = self.set_fine_tune_()\n",
    "            except:\n",
    "                self.fine_tune_ = None\n",
    "        return self.model\n",
    "    \n",
    "    def get_splits_(self, n_sample: int = None):\n",
    "        self.mssg.initial_(ut.funcname())\n",
    "        #TODO: add checks for datatype to ensure the dataset is not already windowed\n",
    "        assert self.analysis_mode in [ 'ofline', 'online'], 'Invalid analysis mode'\n",
    "        X = self.input.data if n_sample is None else self.input.data[n_sample]\n",
    "        self.mssg.print(f\"len(X)={len(X)}\")\n",
    "        match self.analysis_mode:\n",
    "            case 'online':\n",
    "                self.mssg.print(\"Online analysis\", verbose_level = self.mssg.level+1)\n",
    "                self.splits = TimeSplitter(valid_size = 0.2, show_plot = self.show_plot)(X)\n",
    "            case 'offline':\n",
    "                self.mssg.print(\"Offline analysis\", verbose_level = self.mssg.level+1)\n",
    "                self.splits = get_splits(np.arange(len(X)), valid_size=self.valid_size, show_plot = self.show_plot)\n",
    "            case _:\n",
    "                raise NotImplementedError(f\"Encoderl{ut.funcname()} | Case {self.analysis_mode} not implemented. Use one of the following options: <online|offline>.\")\n",
    "        self.mssg.print(f\"X~{X.shape}\")\n",
    "        self.mssg.print(f\"Train: {len(self.splits[0])} | Test { len(self.splits[1])}\")\n",
    "        self.mssg.final()\n",
    "        return X\n",
    "\n",
    "    #TODO: poner los equivalentes para train, eval, get_embeddings, get_acts, etc.\n",
    "    \n",
    "    # Fine_tune_single_\n",
    "    def fine_tune_moment_single_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_mvp_single_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moirai_single_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_single_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "\n",
    "    # Fine_tune_\n",
    "    def fine_tune_moment_(self, eval_pre = False, eval_post = False, shot = True, time_flag = False, use_moment_masks = False): \n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_mvp_(self, eval_pre = False, eval_post = False, shot = True, time_flag = False): \n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_moirai_(self, eval_pre = False, eval_post = False, shot = True, time_flag = False): \n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def fine_tune_(self, eval_pre = False, eval_post = False, shot = True, time_flag = False):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def set_fine_tune_(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")\n",
    "    def show_eval_stats(self):\n",
    "        raise NotImplementedError(f\"Encoder.{ut.funcname()} not yet implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3872fada-2782-4f61-a1fd-a48ab8b69f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def set_fine_tune_single_(\n",
    "    self: Encoder\n",
    ") -> Callable:\n",
    "    self.mssg.initial_(ut.funcname())\n",
    "    model_class = self.get_model_class()\n",
    "    self.mssg.print(f\"Model class: {model_class}\")\n",
    "    match model_class:\n",
    "        case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "            self.fine_tune_single_ = self.fine_tune_moment_single_\n",
    "        case \"fastai.learner.Learner\":\n",
    "            self.fine_tune_single_ = self.fine_tune_mvp_single_\n",
    "        case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "            self.fine_tune_single_ = self.fine_tune_moirai_single_\n",
    "        case _:\n",
    "            self.mssg.print(f\"Fine-tune single shot implementation is not yet implemented for {self.model_class}.\", verbose_level = self.mssg.level+1)\n",
    "            raise NotImplementedError(f\"fine_tune_single_ | Not yet implemented for {self.model_class}\")\n",
    "    self.mssg.final(ut.funcname())\n",
    "    return(self.fine_tune_single_)\n",
    "Encoder.set_fine_tune_single_ = set_fine_tune_single_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa8d8153-eb21-480b-83b2-2054ce981a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def set_fine_tune_(\n",
    "    self: Encoder\n",
    ") -> Callable:\n",
    "    self.mssg.initial_(\"set_fine_tune_\")\n",
    "    model_class = self.get_model_class()\n",
    "    self.mssg.print(f\"Model class: {model_class}\")\n",
    "    match model_class:\n",
    "        case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "            self.mssg.print(f\"Moment\")\n",
    "            self.fine_tune_ = self.fine_tune_moment_\n",
    "        case \"fastai.learner.Learner\":\n",
    "            self.mssg.print(f\"MVP\")\n",
    "            self.fine_tune_ = self.fine_tune_mvp_\n",
    "        case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "            self.mssg.print(f\"Moirai\")\n",
    "            self.fine_tune_ = self.fine_tune_moirai_\n",
    "        case _:\n",
    "            self.mssg.print(f\"Fine-tune implementation is not yet implemented for {self.model_class}.\", verbose_level = self.mssg.level+1)\n",
    "            raise NotImplementedError(f\"fine_tune | Not yet implemented for {self.model_class}\")\n",
    "    self.mssg.final(ut.funcname())\n",
    "    return(self.fine_tune_)\n",
    "Encoder.set_fine_tune_ = set_fine_tune_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d720b4b-5d9c-40ab-a118-47ab3fc25026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.metrics import mae\n",
    "def rmse(preds, targets):\n",
    "    print(\"--> rmse\")\n",
    "    res = torch.sqrt(torch.nn.functional.mse_loss(preds, targets))\n",
    "    print(\"rmses -->\")\n",
    "    return res\n",
    "\n",
    "def smape(preds, targets):\n",
    "    print(\"--> smape\")\n",
    "    res = 100 * torch.mean(2 * torch.abs(preds - targets) / (torch.abs(preds) + torch.abs(targets)))\n",
    "    print(\"smape -->\")\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a150df82-c11a-44db-b253-d0c5c718b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_eval_stats(\n",
    "    self            : Encoder, \n",
    "    print_to_path   : bool      = None, \n",
    "    print_path      : str       = None, \n",
    "    print_mode      : str       = None,\n",
    "    eval_pre        : bool = False,\n",
    "    eval_post       : bool = False,\n",
    "    eval_stats_pre  : AttrDict = None,\n",
    "    eval_stats_post : AttrDict = None,\n",
    "    func_name       : str = \"\"\n",
    "):\n",
    "    self.mssg.print(f\"{func_name} | Evaluation summary\")\n",
    "    self.eval_stats_pre = self.eval_stats_pre if eval_stats_pre is None else eval_stats_pre\n",
    "    self.eval_stats_post = self.eval_stats_post if eval_stats_post is None else eval_stats_post\n",
    "    self.mssg.to_path = self.mssg.to_path if print_to_path is None else print_to_path\n",
    "    self.mssg.path = self.mssg.path if print_path is None else print_path\n",
    "    self.mssg.mode = self.mssg.mode if print_mode is None else print_mode        \n",
    "    if (eval_pre):\n",
    "        self.mssg.print(f\"Eval pre: \")\n",
    "        show_attrdict(\n",
    "            self.eval_stats_pre,\n",
    "            print_to_path   = self.mssg.to_path,\n",
    "            print_path      = self.mssg.path,\n",
    "            print_mode      = self.mssg.mode\n",
    "        )\n",
    "    if eval_post:\n",
    "        self.mssg.print(f\"Eval post: \")\n",
    "        show_attrdict(\n",
    "            self.eval_stats_post,\n",
    "            print_to_path   = self.mssg.to_path,\n",
    "            print_path      = self.mssg.path,\n",
    "            print_mode      = self.mssg.mode \n",
    "        )\n",
    "Encoder.show_eval_stats = show_eval_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4305beb-41a8-4c04-ad55-7ab37e42d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#TODO: Check. Adding lr_scheduler & optimizer to mvp\n",
    "from fastai.callback.core import Callback\n",
    "\n",
    "class CustomOptimizerCallback(Callback):\n",
    "    def __init__(self, optimizer, scheduler):\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "\n",
    "    def before_fit(self):\n",
    "        # Reemplazar el optimizador de FastAI con el personalizado\n",
    "        self.learn.opt = self.optimizer\n",
    "\n",
    "    def after_batch(self):\n",
    "        # Actualizar el scheduler después de cada batch\n",
    "        if self.scheduler is not None:\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def after_fit(self):\n",
    "        # Restaurar el optimizador original si es necesario\n",
    "        del self.learn.opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82275a05-a9ab-4b11-81dd-c2b89178e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.losses import MSELossFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90f4aac7-84d3-478d-8b74-f742bd4d9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def validate_with_metrics(learner, metrics):\n",
    "    results = []\n",
    "    for metric in metrics:\n",
    "        learner.crit = metric\n",
    "        result = learner.validate()\n",
    "        results.append(result.item() if hasattr(result, 'item') else result)\n",
    "    learner.crit=MSELossFlat\n",
    "    return results\n",
    "\n",
    "def fine_tune_mvp_single_(\n",
    "    self            : Encoder,\n",
    "    eval_pre        : bool  = False,\n",
    "    eval_post       : bool  = False,\n",
    "    shot            : bool  = False,\n",
    "    show_plot       : bool  = False,\n",
    "    sample_id       : int   = 0    \n",
    "):\n",
    "    self.show_plot = self.show_plot if show_plot is None else show_plot\n",
    "    t_shot = 0\n",
    "    t_eval_1 = 0\n",
    "    t_eval_2 = 0\n",
    "    losses = [],\n",
    "    eval_results_pre = \"\",\n",
    "    eval_results_post = \"\"\n",
    "    if self.time_flag : timer = ut.Time(mssg = self.mssg)\n",
    "    self.mssg.initial(\"fine_tune_mvp_single_\")   \n",
    "    X = self.get_splits_(sample_id)\n",
    "    self.mssg.print(\"About to set callbacks\", func_name = ut.funcname())\n",
    "    cbs = L(WandbCallback(log_preds=False)) if self.use_wandb else L()\n",
    "    cbs2 = [\n",
    "        EarlyStoppingCallback(\n",
    "            monitor='valid_loss', \n",
    "            min_delta=0.000001, \n",
    "            patience=10\n",
    "        )\n",
    "        #SaveModelCallback(\n",
    "        #    monitor = 'valid_loss', \n",
    "        #    fname = 'best_model'\n",
    "        #),\n",
    "    ]\n",
    "    \n",
    "\n",
    "    self.mssg.print(\"About to set batch tfms\")\n",
    "    tfms = [ToFloat(), None]\n",
    "    batch_tfms = [\n",
    "        TSStandardize(\n",
    "            by_sample       = self.norm_by_sample, \n",
    "            use_single_batch= self.norm_use_single_batch\n",
    "        )\n",
    "    ]\n",
    "    dls = get_ts_dls(X, splits = self.splits, tfms = tfms, bs = self.input.batch_size, batch_tfms = batch_tfms)\n",
    "\n",
    "    ### \n",
    "    # Optimizer  ### TODO: CHECK\n",
    "    #### if not ( isinstance(self.optim.lr, float) or isinstance(self.optim.lr, int)):\n",
    "    ####     if self.optim.lr.flag:\n",
    "    ####         scheduler = setup_scheduler(\n",
    "    ####             dl_train = dls.train,\n",
    "    ####             lr_scheduler_flag = True,\n",
    "    ####             lr_scheduler_name = self.optim.lr.name,\n",
    "    ####             optimizer         = self.optim.optimizer,\n",
    "    ####             num_epochs        = self.num_epochs,\n",
    "    ####             lr_scheduler_num_warmup_steps = self.optim.lr.num_warmup_steps,\n",
    "    ####             lr_scheduler_max_lr = None, #TODO: Think\n",
    "    ####             lr                  = self.optim.lr.lr\n",
    "    ####         )\n",
    "    ####         custom_opt_cb = CustomOptimizerCallback(optimizer = self.optim.optimizer, scheduler = scheduler)\n",
    "    ####         cbs2 += [custom_opt_cb]\n",
    "    ###\n",
    "    #metrics = [torch.nn.functional.mse_loss, rmse, mae, smape]\n",
    "    #metrics = [ MSELossFlat, MSELossFlat, MSELossFlat, MSELossFlat ]\n",
    "    metrics = [ MSELossFlat, RMSELossFlat, MAELossFlat, SMAPELossFlat ] \n",
    "    self.mssg.print(f\"Metrics: {metrics}\")\n",
    "    if self.show_plot: \n",
    "        self.mssg.print(\"Show plot\")\n",
    "        display(dls.show_at(0))\n",
    "        sgc = ShowGraphCallback2()\n",
    "        self.model = ts_learner(\n",
    "            dls, \n",
    "            InceptionTimePlus,\n",
    "            cbs = cbs + sgc + MVP(\n",
    "                r           = self.optim.lr if isinstance(self.optim.lr, float) else self.optim.lr.lr,\n",
    "                window_size = X.shape[2]-1,\n",
    "                future_mask = self.mask_future,\n",
    "                target_dir  = './models',\n",
    "                sync        = self.mask_sync,\n",
    "                stateful    = self.mask_stateful,\n",
    "                fname       = f'encoder_MVP'\n",
    "            ),\n",
    "            y_range = [X.min(), X.max()],\n",
    "            metrics = metrics\n",
    "        )\n",
    "    else:\n",
    "        self.mssg.print(\"Don't show plot\")\n",
    "        self.model = ts_learner(\n",
    "            dls, \n",
    "            InceptionTimePlus,\n",
    "            cbs = cbs + MVP(\n",
    "                r           = self.optim.lr if ( isinstance(self.optim.lr, float) or isinstance(self.optim.lr, int)) else self.optim.lr.lr,\n",
    "                window_size = X.shape[2]-1,\n",
    "                future_mask = self.mask_future,\n",
    "                target_dir  = './models',\n",
    "                sync        = self.mask_sync,\n",
    "                stateful    = self.mask_stateful,\n",
    "                fname       = f'encoder_MVP'\n",
    "            ),\n",
    "            y_range = [X.min(), X.max()],\n",
    "            metrics = metrics\n",
    "        )\n",
    "        self.mssg.print(f\"Model Class {self.model.__class__} | Type: {type(self.model)}\")\n",
    "\n",
    "    device = \"cpu\" if self.cpu else torch.cuda.current_device()\n",
    "    self.model.to(device)\n",
    "    self.mssg.print(f\"Model Class {self.model.__class__} | Type: {type(self.model)}\")\n",
    "    \n",
    "    # Eval - pre \n",
    "    if eval_pre:\n",
    "        if self.time_flag: timer.start()\n",
    "        self.mssg.print(f\"Eval Pre | wlen {X.shape[2]} | Model: {self.model.__class__} | {type(self.model)} \")\n",
    "        self.mssg.print(f\"Model metrics: {self.model.metrics}\")\n",
    "        self.model.eval()\n",
    "        self.mssg.print(f\"Model metrics after eval: {self.model.metrics}\")\n",
    "        results = validate_with_metrics(self.model, metrics)\n",
    "        self.mssg.print(f\"Model metrics after validate: {self.model.metrics}\")\n",
    "        self.mssg.print(f\"results~{len(results)}\")\n",
    "        eval_results_pre = mvp_format_results(results)\n",
    "        if self.time_flag:\n",
    "            timer.end()\n",
    "            t_eval_1 = timer.duration()\n",
    "            timer.show(verbose = self.mssg.verbose)\n",
    "    # Train \n",
    "    if shot:\n",
    "        if self.time_flag: timer.start()\n",
    "        self.model.train()\n",
    "        self.mssg.print(f\"Training the model | window size {X.shape[2]} | X ~ {X.shape}\")\n",
    "        lr_valley, lr_steep = self.model.lr_find(suggest_funcs=(valley, steep), show_plot=show_plot)\n",
    "        self.model.fit_one_cycle(\n",
    "            n_epoch = self.num_epochs, \n",
    "            lr_max  = lr_valley,  \n",
    "            cbs     = cbs2\n",
    "        )\n",
    "        losses = self.model.recorder.losses\n",
    "        if self.time_flag:\n",
    "            timer.end()\n",
    "            t_shot= timer.duration()\n",
    "            timer.show(verbose = self.mssg.verbose)\n",
    "\n",
    "    # Eval - post\n",
    "    if eval_post:\n",
    "        if self.time_flag: timer.start()\n",
    "        self.mssg.print(f\"Eval Pre | wlen {X.shape[2]}\")\n",
    "        self.model.eval()\n",
    "        results = validate_with_metrics(self.model, metrics)\n",
    "        self.mssg.print(f\"Format results | results~{len(results)}\")\n",
    "        eval_results_post = mvp_format_results(results)\n",
    "        if self.time_flag:\n",
    "            timer.end()\n",
    "            t_eval_2 = timer.duration()\n",
    "            timer.show(verbose = self.mssg.verbose)\n",
    "    self.mssg.final()\n",
    "    return losses, eval_results_pre, eval_results_post, t_shot, t_eval_1, t_eval_2, self.model\n",
    "Encoder.fine_tune_mvp_single_ = fine_tune_mvp_single_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9daab28-a768-4d8f-a45b-0db51546a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# TODO: Revisar inclusion del optimizer en fine_tune_mvp_\n",
    "def mvp_format_results(results):\n",
    "    return {\n",
    "        \"mse\":  results[0],\n",
    "        \"rmse\": results[1],\n",
    "        \"mae\":  results[2],\n",
    "        \"smape\":results[3]\n",
    "    }\n",
    "def fine_tune_mvp_(\n",
    "    self                    : Encoder,\n",
    "    eval_pre                : bool  = True,\n",
    "    eval_post               : bool  = True,\n",
    "    shot                    : bool  = False,\n",
    "    time_flag               : bool  = None,\n",
    "    use_wandb               : bool  = None,\n",
    "    analysis_mode           : str   = None,\n",
    "    norm_by_sample          : bool  = None,\n",
    "    norm_use_single_batch   : bool  = None,\n",
    "    show_plot               : bool  = None\n",
    "):\n",
    "    self.mssg.initial_(\"fine_tune_mvp_\")\n",
    "    self.time_flag      = self.time_flag if time_flag is None else time_flag\n",
    "    self.use_wandb      = self.use_wandb if use_wandb is None else use_wandb\n",
    "    self.analysis_mode  = self.analysis_mode if analysis_mode is None else analysis_mode\n",
    "    self.norm_by_sample = self.norm_by_sample if norm_by_sample is None else norm_by_sample\n",
    "    self.norm_use_single_batch = self.norm_use_single_batch if norm_use_single_batch is None else norm_use_single_batch\n",
    "    \n",
    "    self.mssg.print(f\"time_flag: {self.time_flag}\")\n",
    "    # Return values\n",
    "    lossess             = []\n",
    "    eval_results_pre    = []\n",
    "    eval_results_post   = []\n",
    "    t_shots             = []\n",
    "    t_shot              = 0\n",
    "    t_evals             = []\n",
    "    t_eval              = 0\n",
    "\n",
    "    if self.input.size is None:\n",
    "        self.mssg.print(f\"Windows: {len(self.input._data)}\")\n",
    "        raise ValueError(f\"Invalid number of windows: {self.input.size}\")\n",
    "    self.mssg.print(f\"Processing {self.input.size} datasets: {self.input.shapes}\")\n",
    "    # Build optimizer\n",
    "    if self.optim.optimizer is None: \n",
    "        self.mssg.print(f\"Setting up optimizer as AdamW\")\n",
    "        if (not isinstance(self.optim.lr, float)):\n",
    "            self.optim.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.optim.lr.lr)\n",
    "        else:\n",
    "            self.optim.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.optim.lr)\n",
    "    # Compute model for each window in the windowed dataset\n",
    "    for i in range(self.input.size):\n",
    "        self.mssg.print(f\"Processing wlen {self.input.shape[2]}\")\n",
    "        ( \n",
    "            losses, eval_results_pre_, eval_results_post_, t_shot_, t_eval_1, t_eval_2, self.model\n",
    "        ) =  self.fine_tune_mvp_single_(eval_pre, eval_post, shot, sample_id = i, show_plot = show_plot)\n",
    "        lossess.append(losses)\n",
    "        if (eval_pre): eval_results_pre = eval_results_pre_\n",
    "        eval_results_post.append(eval_results_post_)\n",
    "        print(\"t_shot_:\", t_shot_)\n",
    "        t_shots.append(t_shot_)\n",
    "        if eval_pre: t_evals.append(t_eval_1)\n",
    "        if eval_post: t_evals.append(t_eval_2)\n",
    "        eval_pre = False\n",
    "    t_shot = sum(t_shots)\n",
    "    t_eval = sum(t_evals)\n",
    "    self.mssg.final(ut.funcname())\n",
    "    return lossess, eval_results_pre, eval_results_post, t_shots, t_shot, t_evals, t_eval, self.model\n",
    "\n",
    "Encoder.fine_tune_mvp_ = fine_tune_mvp_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1729350-a95a-499b-a67c-2f2c6e5b9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import get_scheduler\n",
    "import evaluate\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from dvats.utils import find_dominant_window_sizes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3761a8b-0b6c-4182-b2aa-a079f0bc314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_mssg(\n",
    "    mssg : ut.Mssg = None,\n",
    "    verbose                         : int           = 0, \n",
    "    print_to_path                   : bool          = False,\n",
    "    print_path                      : str           = \"~/data/logs/logs.txt\",\n",
    "    print_mode                      : str           = 'a',\n",
    "):\n",
    "    mssg,_ = ut._check_value(mssg, None, \"mssg\", ut.Mssg)\n",
    "    if mssg is None:\n",
    "        mssg = ut.Mssg(\n",
    "            to_path = print_to_path,\n",
    "            path    = print_path,\n",
    "            mode    = print_mode,\n",
    "            level   = 0,\n",
    "            verbose = verbose\n",
    "        ) \n",
    "    return mssg\n",
    "\n",
    "def _get_enc_input(\n",
    "    mssg                            : ut.Mssg,\n",
    "    # Encoder Input\n",
    "    ## -- Using all parammeters\n",
    "    X                               : Optional [ Union [ List [ List [ List [ float ]]], List [ float ], pd.DataFrame ] ],\n",
    "    stride                          : Optional [ int ]          = None,\n",
    "    batch_size                      : Optional [ int ]          = None,\n",
    "    n_windows                       : Optional [ int ]          = None,\n",
    "    n_windows_percent               : Optional [ float ]        = None,\n",
    "    validation_percent              : Optional [ float ]        = None, \n",
    "    training_percent                : Optional [ float ]        = None,\n",
    "    window_mask_percent             : Optional [ float ]        = None,\n",
    "    window_sizes                    : Optional [ List [int] ]   = None,\n",
    "    n_window_sizes                  : Optional [ int ]          = 1,\n",
    "    window_sizes_offset             : Optional [ int ]          = 0.05,\n",
    "    windows_min_distance            : Optional [ int ]          = 1,\n",
    "    full_dataset                    : Optional [ bool ]         = False,\n",
    "    ## -- Using Type\n",
    "    enc_input                       : Optional [ EncoderInput ] = None\n",
    "): \n",
    "    mssg.initial_(func_name = ut.funcname())\n",
    "    enc_input, _ = ut._check_value(enc_input, None, \"enc_input\", EncoderInput, True, False, False)\n",
    "    mssg.print(f\"is none enc_input? {enc_input is None}\")\n",
    "    if enc_input is None:\n",
    "        mssg.print(f\"About to get the windows\")\n",
    "        enc_input = windowed_dataset(\n",
    "            X                       = X,\n",
    "            stride                  = stride,\n",
    "            window_sizes            = window_sizes,\n",
    "            n_window_sizes          = n_window_sizes,\n",
    "            window_sizes_offset     = window_sizes_offset,\n",
    "            windows_min_distance    = windows_min_distance,\n",
    "            full_dataset            = full_dataset,\n",
    "            mssg                    = mssg\n",
    "        )\n",
    "        mssg.print(f\"About to get the encoder input | windows~{len(enc_input)}\")\n",
    "        enc_input = EncoderInput(\n",
    "            _data               = enc_input, \n",
    "            stride              = stride,\n",
    "            batch_size          = batch_size,\n",
    "            n_windows           = n_windows,\n",
    "            n_windows_percent   = n_windows_percent,\n",
    "            validation_percent  = validation_percent,\n",
    "            training_percent    = training_percent,\n",
    "            window_mask_percent = window_mask_percent,\n",
    "        )\n",
    "        mssg.print(f\"Enc input obtained | enc_input~{enc_input.shape}\")\n",
    "    mssg.final()\n",
    "    return enc_input\n",
    "\n",
    "def _get_optimizer(\n",
    "    mssg                            : ut.Mssg,\n",
    "    optim                           : EncoderOptimizer = None,\n",
    "    criterion                       : _Loss         = torch.nn.MSELoss, \n",
    "    optimizer                                       = None, \n",
    "    lr                              : float         = 5e-5, #1e-4, \n",
    "    lr_scheduler_flag               : bool          = False, \n",
    "    lr_scheduler_name               : str           = \"linear\",\n",
    "    lr_scheduler_num_warmup_steps   : int           = None\n",
    "):\n",
    "    mssg.initial(ut.funcname())\n",
    "    optim,_ = ut._check_value(optim, None, \"optim\", EncoderOptimizer, True)\n",
    "    if optim is None:\n",
    "        optim = EncoderOptimizer(\n",
    "            criterion   = criterion,\n",
    "            optimizer   = optimizer,\n",
    "            lr          = LRScheduler (\n",
    "                            lr              = lr,\n",
    "                            flag            = lr_scheduler_flag,\n",
    "                            name            = lr_scheduler_name,\n",
    "                            num_warmup_steps= lr_scheduler_num_warmup_steps\n",
    "            ),\n",
    "        )\n",
    "    mssg.final()\n",
    "    return optim\n",
    "\n",
    "def _get_encoder(\n",
    "    ## -- Using all parammeters\n",
    "    X                               : Optional [ Union [ List [ List [ List [ float ]]], List [ float ], pd.DataFrame ] ],\n",
    "    stride                          : Optional [ int ]          = None,\n",
    "    batch_size                      : Optional [ int ]          = None,\n",
    "    n_windows                       : Optional [ int ]          = None,\n",
    "    n_windows_percent               : Optional [ float ]        = None,\n",
    "    validation_percent              : Optional [ float ]        = None, \n",
    "    training_percent                : Optional [ float ]        = None,\n",
    "    window_mask_percent             : Optional [ float ]        = None,\n",
    "    window_sizes                    : Optional [ List [int] ]   = None,\n",
    "    n_window_sizes                  : Optional [ int ]          = 1,\n",
    "    window_sizes_offset             : Optional [ int ]          = 0.05,\n",
    "    windows_min_distance            : Optional [ int ]          = 1,\n",
    "    full_dataset                    : Optional [ bool ]         = False,\n",
    "    ##-- Given by Type \n",
    "    enc_input                       : Optional [ EncoderInput ] = None,\n",
    "    # Optimizer\n",
    "    optim                           : Optional [ EncoderOptimizer ] = None,\n",
    "    ## -- Using all parameters\n",
    "    criterion                       : Optional [ _Loss ]            = torch.nn.MSELoss, \n",
    "    optimizer                                                       = None, \n",
    "    lr                              : Optional [ float ]            = 5e-5, #1e-4, \n",
    "    lr_scheduler_flag               : Optional [ bool ]             = False, \n",
    "    lr_scheduler_name               : Optional [ str ]              = \"linear\",\n",
    "    lr_scheduler_num_warmup_steps   : Optional [ int ]              = None,\n",
    "    # Mssg\n",
    "    ## -- Using all parameters\n",
    "    verbose                         : Optional[ int ]               = 0, \n",
    "    print_to_path                   : Optional[ bool ]              = False,\n",
    "    print_path                      : Optional[ str ]               = \"~/data/logs/logs.txt\",\n",
    "    print_mode                      : Optional[ str ]               = 'a',\n",
    "    ## -- Using Type\n",
    "    mssg                            : Optional [ ut.Mssg ]          = None,\n",
    "    ## Encoder \n",
    "    enc                             : Optional [ Encoder ]          = None,\n",
    "    ## -- Using all parameters\n",
    "    num_epochs                      : Optional [ int]               = 3,\n",
    "    enc_learn                       : Optional [Learner]            = None, \n",
    "    cpu                             : Optional [ bool ]             = False,\n",
    "    to_numpy                        : Optional [ bool ]             = True,\n",
    "    #- Masking options \n",
    "    \n",
    "    mask_stateful                   : Optional [ bool ]             = False,\n",
    "    mask_future                     : Optional [ bool ]             = False,\n",
    "    mask_sync                       : Optional [ bool ]             = False\n",
    "):\n",
    "    enc,_ = ut._check_value(enc, None, \"enc\", Encoder, True)\n",
    "    \n",
    "    if enc is None: \n",
    "        mssg = _get_mssg(mssg, verbose, print_to_path, print_path, print_mode)\n",
    "        mssg.initial(ut.funcname())\n",
    "        mssg.print(\"About to exec _get_enc_input\")\n",
    "        enc_input = _get_enc_input(mssg, X, stride, batch_size, n_windows, n_windows_percent, validation_percent, training_percent, window_mask_percent, window_sizes, n_window_sizes, window_sizes_offset, windows_min_distance, full_dataset, enc_input)\n",
    "        mssg.print(f\"enc_input~{enc_input.shape}\")\n",
    "        mssg.print(\"About to exec _get_optimizer\")\n",
    "        optim = _get_optimizer(mssg, optim, criterion, optimizer, lr, lr_scheduler_flag, lr_scheduler_name, lr_scheduler_num_warmup_steps)\n",
    "        enc = Encoder(\n",
    "            model           = enc_learn,\n",
    "            input           = enc_input,\n",
    "            mssg            = mssg,\n",
    "            cpu             = cpu,\n",
    "            to_numpy        = to_numpy, \n",
    "            num_epochs      = num_epochs, \n",
    "            optim           = optim,\n",
    "            mask_stateful   = mask_stateful,\n",
    "            mask_future     = mask_future,\n",
    "            mask_sync       = mask_sync,\n",
    "            eval_stats_pre  = None,\n",
    "            eval_stats_post = None\n",
    "        )\n",
    "    enc.mssg.final(ut.funcname())\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ddf0aa1-d082-499a-a537-e1bf72adc97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [ --> windowed_dataset ]\n",
      "[0]  [ _get_enc_input ] X is a DataFrame, X~(440, 1) | window_sizes 1, n_window_sizes 3\n",
      "[0] [ --> Find_dominant_window_sizes_list ]\n",
      "[0]  [ Find_dominant_window_sizes_list ] X ~ (440, 1)\n",
      "[0]  [ Find_dominant_window_sizes_list ] Grouping sizes\n",
      "[0] [Find_dominant_window_sizes_list --> ]\n",
      "[0]  [ Find_dominant_window_sizes_list ] X is a DataFrame | Window sizes: 3\n",
      "[0]  [ Find_dominant_window_sizes_list ] Building the windows\n",
      "[0]  [ Find_dominant_window_sizes_list ] Number of windows: 3\n",
      "[0] [Find_dominant_window_sizes_list --> ]\n"
     ]
    }
   ],
   "source": [
    "enc = _get_encoder(\n",
    "    X                   = df,\n",
    "    stride              = enc_run.config['stride'],\n",
    "    n_windows           = None,\n",
    "    n_windows_percent   = 50,\n",
    "    validation_percent  = 0.2,\n",
    "    training_percent    = 1,\n",
    "    window_mask_percent = 0.75,\n",
    "    window_sizes        = [17],\n",
    "    n_window_sizes      = 3,\n",
    "    window_sizes_offset = None,\n",
    "    windows_min_distance = 5,\n",
    "    full_dataset         = True,\n",
    "    enc_input            = None,\n",
    "    optim                = None,\n",
    "    criterion            = None,\n",
    "    optimizer            = None,\n",
    "    lr                   = None,\n",
    "    lr_scheduler_flag    = None,\n",
    "    lr_scheduler_num_warmup_steps = None,\n",
    "    verbose              = 0,\n",
    "    print_to_path        = False,\n",
    "    print_path           = \"~/data/logs.txt\",\n",
    "    print_mode           = 'w',\n",
    "    mssg                 = None,\n",
    "    enc                  = None,\n",
    "    num_epochs           = 10,\n",
    "    enc_learn            = enc_learner,\n",
    "    cpu                  = False,\n",
    "    to_numpy             = False,\n",
    "    mask_stateful        = False,\n",
    "    mask_future          = False,\n",
    "    mask_sync            = False\n",
    ")\n",
    "enc.mask_sync     = enc_run.config['mask_sync']\n",
    "enc.mask_stateful = enc_run.config['mask_stateful']\n",
    "enc.mask_future   = enc_run.config['mask_future']\n",
    "enc.optim.lr      = enc_run.config['r']\n",
    "enc.time_flag     = True\n",
    "enc.show_plot     = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b97aba6b-8776-4de8-a73f-79d825bb817e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] [ --> fine_tune_mvp_ ]\n",
      "[5]  [ fine_tune_mvp_ ] time_flag: True\n",
      "[5]  [ fine_tune_mvp_ ] Processing 3 datasets: [(212, 1, 17), (212, 1, 18), (215, 1, 12)]\n",
      "[5]  [ fine_tune_mvp_ ] Setting up optimizer as AdamW\n",
      "[5]  [ fine_tune_mvp_ ] Processing wlen 17\n",
      "[5] [ --> fine_tune_mvp_single_ ]\n",
      "[5] [ --> get_splits_ ]\n",
      "[5]  [ get_splits_ ] len(X)=212\n",
      "[5]  [ get_splits_ ] Online analysis\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]  [ get_splits_ ] X~(212, 1, 17)\n",
      "[5]  [ get_splits_ ] Train: 170 | Test 42\n",
      "[5] [get_splits_ --> ]\n",
      "[5]  [ fine_tune_mvp_single_ ] About to set callbacks\n",
      "[5]  [ fine_tune_mvp_single_ ] About to set batch tfms\n",
      "[5]  [ fine_tune_mvp_single_ ] Metrics: [<function MSELossFlat at 0x7fe6ccb13010>, <function RMSELossFlat at 0x7fe511419750>, <function L1LossFlat at 0x7fe6ccb130a0>, <function SMAPELossFlat at 0x7fe511419990>]\n",
      "[5]  [ fine_tune_mvp_single_ ] Show plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]  [ fine_tune_mvp_single_ ] Model Class <class 'fastai.learner.Learner'> | Type: <class 'fastai.learner.Learner'>\n",
      "[5]  [ fine_tune_mvp_ ] Start timer\n",
      "[5]  [ fine_tune_mvp_single_ ] Eval Pre | wlen 17 | Model: <class 'fastai.learner.Learner'> | <class 'fastai.learner.Learner'> \n",
      "[5]  [ fine_tune_mvp_single_ ] Model metrics: [<fastai.learner.AvgMetric object at 0x7fe5066bb910>, <fastai.learner.AvgMetric object at 0x7fe5066bb9d0>, <fastai.learner.AvgMetric object at 0x7fe5066bba30>, <fastai.learner.AvgMetric object at 0x7fe5066bba90>]\n",
      "[5]  [ fine_tune_mvp_single_ ] Model metrics after eval: [<fastai.learner.AvgMetric object at 0x7fe5066bb910>, <fastai.learner.AvgMetric object at 0x7fe5066bb9d0>, <fastai.learner.AvgMetric object at 0x7fe5066bba30>, <fastai.learner.AvgMetric object at 0x7fe5066bba90>]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch:   0  val_loss: 0.885952 - pretrained weights_path='models/encoder_MVP.pth'\n",
      "not enough values to plot a chart\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Exception occured in `WandbCallback` when calling event `before_fit`:\\n\\tepoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m enc\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      2\u001b[0m ( \n\u001b[1;32m      3\u001b[0m     lossess, eval_results_pre, eval_results_post, \n\u001b[1;32m      4\u001b[0m     t_shots, t_shot, t_evals, t_eval, enc\u001b[38;5;241m.\u001b[39mmodel \n\u001b[0;32m----> 5\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43menc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tune_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_pre\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_post\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshot\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_flag\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_wandb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43manalysis_mode\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manalysis_mode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_by_sample\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnorm_by_sample\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_use_single_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnorm_use_single_batch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_plot\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 55\u001b[0m, in \u001b[0;36mfine_tune_mvp_\u001b[0;34m(self, eval_pre, eval_post, shot, time_flag, use_wandb, analysis_mode, norm_by_sample, norm_use_single_batch, show_plot)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39msize):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing wlen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m     ( \n\u001b[1;32m     54\u001b[0m         losses, eval_results_pre_, eval_results_post_, t_shot_, t_eval_1, t_eval_2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m---> 55\u001b[0m     ) \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tune_mvp_single_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_post\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_plot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshow_plot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     lossess\u001b[38;5;241m.\u001b[39mappend(losses)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (eval_pre): eval_results_pre \u001b[38;5;241m=\u001b[39m eval_results_pre_\n",
      "Cell \u001b[0;32mIn[39], line 124\u001b[0m, in \u001b[0;36mfine_tune_mvp_single_\u001b[0;34m(self, eval_pre, eval_post, shot, show_plot, sample_id)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel metrics after eval: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_with_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel metrics after validate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults~\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m, in \u001b[0;36mvalidate_with_metrics\u001b[0;34m(learner, metrics)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[1;32m      5\u001b[0m     learner\u001b[38;5;241m.\u001b[39mcrit \u001b[38;5;241m=\u001b[39m metric\n\u001b[0;32m----> 6\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m result)\n\u001b[1;32m      8\u001b[0m learner\u001b[38;5;241m.\u001b[39mcrit\u001b[38;5;241m=\u001b[39mMSELossFlat\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastai/learner.py:278\u001b[0m, in \u001b[0;36mLearner.validate\u001b[0;34m(self, ds_idx, dl, cbs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m, ds_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cbs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: dl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls[ds_idx]\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_context(cbs\u001b[38;5;241m=\u001b[39mcbs): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate(ds_idx, dl)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_record\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastcore/xtras.py:547\u001b[0m, in \u001b[0;36mContextManagers.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m--> 547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menter_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastcore/foundation.py:156\u001b[0m, in \u001b[0;36mL.map\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[43mmap_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastcore/basics.py:840\u001b[0m, in \u001b[0;36mmap_ex\u001b[0;34m(iterable, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(g, iterable)\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gen: \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m--> 840\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastcore/basics.py:825\u001b[0m, in \u001b[0;36mbind.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v,_Arg): kwargs[k] \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mpop(v\u001b[38;5;241m.\u001b[39mi)\n\u001b[1;32m    824\u001b[0m fargs \u001b[38;5;241m=\u001b[39m [args[x\u001b[38;5;241m.\u001b[39mi] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _Arg) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpargs] \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/contextlib.py:492\u001b[0m, in \u001b[0;36m_BaseExitStack.enter_context\u001b[0;34m(self, cm)\u001b[0m\n\u001b[1;32m    490\u001b[0m _cm_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(cm)\n\u001b[1;32m    491\u001b[0m _exit \u001b[38;5;241m=\u001b[39m _cm_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m\n\u001b[0;32m--> 492\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_cm_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_push_cm_exit(cm, _exit)\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastai/learner.py:267\u001b[0m, in \u001b[0;36mLearner.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_before_epoch\u001b[49m\u001b[43m)\u001b[49m; \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastai/learner.py:172\u001b[0m, in \u001b[0;36mLearner.__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name): \u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastcore/foundation.py:156\u001b[0m, in \u001b[0;36mL.map\u001b[0;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[43mmap_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastcore/basics.py:840\u001b[0m, in \u001b[0;36mmap_ex\u001b[0;34m(iterable, f, gen, *args, **kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(g, iterable)\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gen: \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m--> 840\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastcore/basics.py:825\u001b[0m, in \u001b[0;36mbind.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v,_Arg): kwargs[k] \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mpop(v\u001b[38;5;241m.\u001b[39mi)\n\u001b[1;32m    824\u001b[0m fargs \u001b[38;5;241m=\u001b[39m [args[x\u001b[38;5;241m.\u001b[39mi] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _Arg) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpargs] \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastai/learner.py:176\u001b[0m, in \u001b[0;36mLearner._call_one\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_one\u001b[39m(\u001b[38;5;28mself\u001b[39m, event_name):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(event, event_name): \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcbs\u001b[38;5;241m.\u001b[39msorted(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[43mcb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastai/callback/core.py:62\u001b[0m, in \u001b[0;36mCallback.__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m getcallable(\u001b[38;5;28mself\u001b[39m, event_name)()\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (CancelBatchException, CancelBackwardException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \u001b[38;5;28;01mraise\u001b[39;00m modify_exception(e, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mException occured in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` when calling event `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event_name\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_fit\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m#Reset self.run to True at each end of fit\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastai/callback/core.py:60\u001b[0m, in \u001b[0;36mCallback.__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     58\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mand\u001b[39;00m _run: \n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m \u001b[43mgetcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (CancelBatchException, CancelBackwardException, CancelEpochException, CancelFitException, CancelStepException, CancelTrainException, CancelValidException): \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \u001b[38;5;28;01mraise\u001b[39;00m modify_exception(e, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mException occured in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` when calling event `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/fastai/callback/wandb.py:57\u001b[0m, in \u001b[0;36mWandbCallback.before_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# W&B log step\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb_step \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# -1 except if the run has previously logged data (incremented at each batch)\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wandb_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m(wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mstep) \u001b[38;5;28;01melse\u001b[39;00m math\u001b[38;5;241m.\u001b[39mceil(\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;66;03m# continue to next epoch\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_finder\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgather_preds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m rank_distrib()\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun: \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_summary.py:35\u001b[0m, in \u001b[0;36mSummaryDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 35\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;66;03m# this nested dict needs to be wrapped:\u001b[39;00m\n\u001b[1;32m     39\u001b[0m         wrapped_item \u001b[38;5;241m=\u001b[39m SummarySubDict()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Exception occured in `WandbCallback` when calling event `before_fit`:\\n\\tepoch'"
     ]
    }
   ],
   "source": [
    "enc.mssg.verbose = 5\n",
    "( \n",
    "    lossess, eval_results_pre, eval_results_post, \n",
    "    t_shots, t_shot, t_evals, t_eval, enc.model \n",
    ") = enc.fine_tune_(\n",
    "    eval_pre              = True, \n",
    "    eval_post             = True, \n",
    "    shot                  = True, \n",
    "    time_flag             = True, \n",
    "    use_wandb             = enc_run.config['use_wandb'], \n",
    "    analysis_mode         = enc_run.config ['analysis_mode'], \n",
    "    norm_by_sample        = enc_run.config['norm_by_sample'], \n",
    "    norm_use_single_batch = enc_run.config['norm_use_single_batch'], \n",
    "    show_plot             = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f0dee-f9d6-4942-bfd5-39579349b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.model.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c8c7d-4867-425f-a7f5-3ef84c1b77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_results_pre)\n",
    "print(eval_results_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1618da-3afb-4cee-9954-d7b980ec2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [torch.nn.functional.mse_loss, rmse, mae, smape]\n",
    "enc.model.metrics = metrics\n",
    "enc.model.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06db886a-6aab-468c-a2bd-94c2143cbbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.model.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e6c0a-9cfb-4cff-b886-6f7f2767418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc.model.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a24fb-4416-4345-a1c8-131bed978e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"Execution ended\")\n",
    "from dvats.imports import beep\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca0597-64fb-4bc5-946f-2ae110b3cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
