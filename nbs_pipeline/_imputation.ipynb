{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1> Using MOMENT for Imputation </h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "### 1. A Quick Introduction to Imputation\n",
    "### 2. Loading MOMENT\n",
    "### 3. Inputs and Outputs\n",
    "### 4. Zero-shot Imputation\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.1 Masking Time Series Patches\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.2 Imputation using MOMENT\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.3 Results\n",
    "### 5. Example Code to Fine-tune MOMENT for Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A Quick Introduction to Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate time series are prevalent in real world applications such as finance, meteorology and healthcare. These time series often contain missing values due to various reasons, including equipment malfunctions and human errors. Missing values can impede the meaningful analyis of time series, and hence numerous studies have focused on the task of imputing these missing values using machine learning methodologies. In this tutorial, we will use MOMENT to address the issue of missing values. Formally, the imputation task can be defined as follows:\n",
    "\n",
    "**Problem**: We are given a time series $T = [x_1, ..., x_L], \\ x_i \\in \\mathbb{R}^{C}$ of length $L$ with $C$ channels (sensors or variables), and a boolean mask of same length $mask = [m_1, ..., m_L]$ indicating missing values. The objective of the imputation problem is to infer missing values and recover the original time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading MOMENT\n",
    "\n",
    "We will first install the MOMENT package, load some essential packages and the pre-trained model. \n",
    "\n",
    "MOMENT can be loaded in 4 modes: (1) `reconstruction`, (2) `embedding`, (3) `forecasting`, and (4) `classification`.\n",
    "\n",
    "In the `reconstruction` mode, MOMENT reconstructs input time series, potentially containing missing values. We can solve imputation and anomaly detection problems in this mode. This mode is suitable for solving imputation and anomaly detection tasks. During pre-training, MOMENT is trained to predict the missing values within uniformly randomly masked patches (disjoint sub-sequences) of the input time series, leveraging information from observed data in other patches. As a result, MOMENT comes equipped with a pre-trained reconstruction head, enabling it to address imputation and anomaly detection challenges in a zero-shot manner! Check out the `anomaly_detection.ipynb` notebook for more details!\n",
    "\n",
    "In the `embedding` model, MOMENT learns a $d$-dimensional embedding (e.g., $d=1024$ for `MOMENT-1-large`) for each input time series. These embeddings can be used for clustering and classification. MOMENT can learn embeddings in a zero-shot setting! Check out `representation_learning.ipynb` and `classification.ipynb` notebooks for more details! \n",
    "\n",
    "The `forecasting` and `classification` modes are used for forecasting and classification tasks, respectively. In these modes, MOMENT learns representations which are subsequently mapped to the forecast horizon or the number of classes, using linear forecasting and classification heads. Both the forecasting and classification head are randomly initialized, and therefore must be fine-tuned before use. Check out the `forecasting.ipynb` and `classification.ipynb` notebooks for more details!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (1.25.2)\n",
      "Requirement already satisfied: pandas in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (4.66.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/moment-timeseries-foundation-model/moment.git\n",
      "  Cloning https://github.com/moment-timeseries-foundation-model/moment.git to /tmp/pip-req-build-o7mr28d4\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/moment-timeseries-foundation-model/moment.git /tmp/pip-req-build-o7mr28d4\n",
      "  Resolved https://github.com/moment-timeseries-foundation-model/moment.git to commit fb620934ef6b67f878bc21b8640b22d117dbffa6\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub==0.24.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from momentfm==0.1.2) (0.24.0)\n",
      "Requirement already satisfied: numpy==1.25.2 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from momentfm==0.1.2) (1.25.2)\n",
      "Requirement already satisfied: torch~=2.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from momentfm==0.1.2) (2.5.0)\n",
      "Requirement already satisfied: transformers==4.33.3 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from momentfm==0.1.2) (4.33.3)\n",
      "Requirement already satisfied: filelock in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from huggingface-hub==0.24.0->momentfm==0.1.2) (4.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from transformers==4.33.3->momentfm==0.1.2) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from transformers==4.33.3->momentfm==0.1.2) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from transformers==4.33.3->momentfm==0.1.2) (0.4.4)\n",
      "Requirement already satisfied: networkx in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from torch~=2.0->momentfm==0.1.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from sympy==1.13.1->torch~=2.0->momentfm==0.1.2) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from jinja2->torch~=2.0->momentfm==0.1.2) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from requests->huggingface-hub==0.24.0->momentfm==0.1.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from requests->huggingface-hub==0.24.0->momentfm==0.1.2) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from requests->huggingface-hub==0.24.0->momentfm==0.1.2) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages (from requests->huggingface-hub==0.24.0->momentfm==0.1.2) (2024.12.14)\n",
      "Building wheels for collected packages: momentfm\n",
      "  Building wheel for momentfm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for momentfm: filename=momentfm-0.1.2-py3-none-any.whl size=33793 sha256=0dbe7763fb439739d5c2fceccd6dade8d18e25c53ac61c76ece231408f6070da\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ykkcx6gr/wheels/6e/62/da/a5752a90276fbaebe0da5c0d02272f6549f43e9ceaac72907e\n",
      "Successfully built momentfm\n",
      "Installing collected packages: momentfm\n",
      "Successfully installed momentfm-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas scikit-learn matplotlib tqdm\n",
    "!pip install git+https://github.com/moment-timeseries-foundation-model/moment.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from momentfm.utils.utils import control_randomness\n",
    "control_randomness(seed=13) # Set random seeds for PyTorch, Numpy etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c83a790af641df8960a2e3874dd607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/951 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a645cf4c7c2d44e79c7009a735ebb078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from momentfm import MOMENTPipeline\n",
    "\n",
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-large\",\n",
    "    model_kwargs={'task_name': 'reconstruction'} # For imputation, we will load MOMENT in `reconstruction` mode\n",
    "    # local_files_only=True,  # Whether or not to only look at local files (i.e., do not try to download the model).\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=1024, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 1024)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 16)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-23): 23 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (o): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wi_1): Linear(in_features=1024, out_features=2816, bias=False)\n",
      "              (wo): Linear(in_features=2816, out_features=1024, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=1024, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.init()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 341231104\n"
     ]
    }
   ],
   "source": [
    "# Number of parameters in the encoder\n",
    "num_params = sum(p.numel() for p in model.encoder.parameters())\n",
    "print(f\"Number of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inputs and Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by performing a forward pass through MOMENT and examining its outputs!\n",
    "\n",
    "MOMENT takes 3 inputs: \n",
    "1. An input time series of length $T=512$ timesteps and $C$ channels, and \n",
    "2. Two optional masks, both of length $T=512$. \n",
    "    - The input mask is utilized to regulate the time steps or patches that the model should attend to. For instance, in the case of shorter time series, you may opt not to attend to padding. To implement this, you can provide an input mask with zeros in the padded locations.  \n",
    "    - The second mask, referred to simply as mask, denotes masked or unobserved values. We employ mask tokens to replace all patches containing any masked time step (for further details, refer to Section 3.2 in our [paper](https://arxiv.org/abs/2402.03885)). MOMENT can attend to these mask tokens during reconstruction.\n",
    "    - By default, all time steps are observed and attended to.\n",
    "\n",
    "MOMENT returns a `TimeseriesOutputs` object. Since this is a reconstruction task, it returns a `reconstruction` of the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeseriesOutputs(forecast=None,\n",
      "                  anomaly_scores=None,\n",
      "                  logits=None,\n",
      "                  labels=None,\n",
      "                  input_mask=tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]]),\n",
      "                  pretrain_mask=tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]),\n",
      "                  reconstruction=tensor([[[-0.0437, -0.0208,  0.2231,  ...,  0.2506, -0.0512,  0.0481]],\n",
      "\n",
      "        [[-0.0950,  0.0425,  0.0427,  ..., -0.0169, -0.0334, -0.1129]],\n",
      "\n",
      "        [[ 0.0962, -0.0044,  0.0703,  ..., -0.0681,  0.0438, -0.1940]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2346, -0.0597,  0.0352,  ...,  0.2396,  0.1217,  0.0563]],\n",
      "\n",
      "        [[-0.1372, -0.1501, -0.0997,  ...,  0.3575, -0.3306,  0.1226]],\n",
      "\n",
      "        [[ 0.1931,  0.0617,  0.1928,  ...,  0.2467, -0.1810,  0.0082]]],\n",
      "       grad_fn=<AddBackward0>),\n",
      "                  embeddings=None,\n",
      "                  metadata=None,\n",
      "                  illegal_output=None)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import torch\n",
    "\n",
    "# takes in tensor of shape [batch_size, n_channels, context_length]\n",
    "x = torch.randn(16, 1, 512)\n",
    "output = model(x_enc=x)\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Zero-shot Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll show you how to use MOMENT to do zero-shot imputation!\n",
    "\n",
    "In these experiments, we will use Hourly Electricity Transformer Temperature (ETTh1) dataset introduced by [Zhou et al., 2020](https://arxiv.org/abs/2012.07436). Check out [ETDataset](https://github.com/zhouhaoyi/ETDataset) for more information! We will use the ETTh1 dataset since missing values are common in this domain!\n",
    "\n",
    "We'll start by reading and pre-processing this dataset using the `InformerDataset` class. Since we can do zero-shot imputation, we will just load the testing part of this data. Note that MOMENT was not exposed to the testing part of this dataset during pre-training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import functools\n",
    "from momentfm.data.informer_dataset import InformerDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         patch_dataframe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)  \u001b[38;5;66;03m# Parche en la instancia del DataFrame\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Usa la versión parcheada\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mPatchedInformerDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimputation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_stride_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/momentfm/data/informer_dataset.py:43\u001b[0m, in \u001b[0;36mInformerDataset.__init__\u001b[0;34m(self, forecast_horizon, data_split, data_stride_len, task_name, random_seed)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_seed \u001b[38;5;241m=\u001b[39m random_seed\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Read data\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m, in \u001b[0;36mPatchedInformerDataset._read_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     patch_dataframe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/momentfm/data/informer_dataset.py:67\u001b[0m, in \u001b[0;36mInformerDataset._read_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_channels \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     66\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 67\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39minterpolate(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcubic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m data_splits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_borders()\n\u001b[1;32m     71\u001b[0m train_data \u001b[38;5;241m=\u001b[39m df[data_splits[\u001b[38;5;241m0\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m, in \u001b[0;36msafe_infer_objects\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msafe_infer_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m, copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m, in \u001b[0;36msafe_infer_objects\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msafe_infer_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m, copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: safe_infer_objects at line 5 (2965 times)]\u001b[0m\n",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m, in \u001b[0;36msafe_infer_objects\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msafe_infer_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m, copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "# Función de parche sin 'copy'\n",
    "def infer_objects_fixed(df):\n",
    "    return pd.DataFrame.infer_objects(df)  # Sin el argumento copy\n",
    "\n",
    "# Hook temporal para modificar el DataFrame antes de su uso\n",
    "def patch_dataframe(df):\n",
    "    if hasattr(df, \"infer_objects\"):  \n",
    "        df.infer_objects = lambda: infer_objects_fixed(df)  # Reemplaza solo en esta instancia\n",
    "\n",
    "# Hook en `InformerDataset`\n",
    "class PatchedInformerDataset(InformerDataset):\n",
    "    def _read_data(self):\n",
    "        super()._read_data()\n",
    "        patch_dataframe(self.data)  # Parche en la instancia del DataFrame\n",
    "\n",
    "# Usa la versión parcheada\n",
    "test_dataset = PatchedInformerDataset(\n",
    "    data_split='test', \n",
    "    task_name='imputation', \n",
    "    data_stride_len=512\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_channels = test_dataset[0][0].shape[0]\n",
    "idx = np.random.randint(0, len(test_dataset))\n",
    "channel_idx = np.random.randint(0, n_channels)\n",
    "plt.plot(test_dataset[idx][0][channel_idx, :].squeeze(), c='darkblue')\n",
    "plt.title(f'idx={idx}  | channel={channel_idx}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Masking Time Series Patches\n",
    "\n",
    "Since there are no missing values in this dataset, we will randomly mask time series subsequences to evaluate MOMENT's ability to reason about missing values. Instead of masking individual time steps at random, we will mask time series patches uniformly at random using the `Masking` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from momentfm.utils.masking import Masking\n",
    "\n",
    "mask_generator = Masking(mask_ratio=0.25) # Mask 25% of patches randomly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Imputation using MOMENT\n",
    "\n",
    "Since there are no missing values in this dataset, we will randomly mask time series subsequences to evaluate MOMENT's ability to reason about missing values. Instead of masking individual time steps at random, we will mask time series patches uniformly at random using the `Masking` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device).float()\n",
    "\n",
    "trues, preds, masks = [], [], []\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_masks in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "        trues.append(batch_x.numpy())\n",
    "        \n",
    "        batch_x = batch_x.to(device).float()\n",
    "        n_channels = batch_x.shape[1]\n",
    "        \n",
    "        # Reshape to [batch_size * n_channels, 1, window_size]\n",
    "        batch_x = batch_x.reshape((-1, 1, 512)) \n",
    "        \n",
    "        batch_masks = batch_masks.to(device).long()\n",
    "        batch_masks = batch_masks.repeat_interleave(n_channels, axis=0)\n",
    "        \n",
    "        mask = mask_generator.generate_mask(\n",
    "            x=batch_x, input_mask=batch_masks).to(device).long()\n",
    "\n",
    "        output = model(x_enc=batch_x, input_mask=batch_masks, mask=mask) # [batch_size, n_channels, window_size]\n",
    "        \n",
    "        reconstruction = output.reconstruction.detach().cpu().numpy()\n",
    "        mask = mask.detach().squeeze().cpu().numpy()\n",
    "        \n",
    "        # Reshape back to [batch_size, n_channels, window_size]\n",
    "        reconstruction = reconstruction.reshape((-1, n_channels, 512)) \n",
    "        mask = mask.reshape((-1, n_channels, 512))\n",
    "                \n",
    "        preds.append(reconstruction)\n",
    "        masks.append(mask)\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "trues = np.concatenate(trues)\n",
    "masks = np.concatenate(masks)\n",
    "\n",
    "print(f\"Shapes: preds={preds.shape} | trues={trues.shape} | masks={masks.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Results\n",
    "\n",
    "Since there are no missing values in this dataset, we will randomly mask time series subsequences to evaluate MOMENT's ability to reason about missing values. Instead of masking individual time steps at random, we will mask time series patches uniformly at random using the `Masking` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from momentfm.utils.forecasting_metrics import mse, mae\n",
    "\n",
    "print(f\"Mean Squarred Error (MSE)={mse(y=trues[masks==0], y_hat=preds[masks==0], reduction='mean')}\")\n",
    "print(f\"Mean Absolute Error (MAE)={mae(y=trues[masks==0], y_hat=preds[masks==0], reduction='mean')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize random time series windows! White patches are masked and black patches are observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(trues.shape[0])\n",
    "channel_idx = np.random.randint(trues.shape[1])\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "axs[0].set_title(f\"Channel={channel_idx}\")\n",
    "axs[0].plot(trues[idx, channel_idx, :].squeeze(), label='Ground Truth', c='darkblue')\n",
    "axs[0].plot(preds[idx, channel_idx, :].squeeze(), label='Predictions', c='red')\n",
    "axs[0].legend(fontsize=16)\n",
    "\n",
    "axs[1].imshow(np.tile(masks[np.newaxis, idx, channel_idx], reps=(8, 1)), cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example Code to Fine-tune MOMENT for Imputation\n",
    "\n",
    "To improve MOMENT's imputation performance, you can fine-tune it on any dataset. In our [paper](https://arxiv.org/abs/2402.03885), we fine-tune the final reconstruction head, but you can also fine-tune the entire model on your data. Here is some example code:\n",
    "\n",
    "```python\n",
    "\n",
    "# Optimize Mean Squarred Error using your favourite optimizer\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "mask_generator = Masking(mask_ratio=0.3) # Mask 30% of patches randomly \n",
    "\n",
    "for batch_x, batch_masks in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "    n_channels = batch_x.shape[1]\n",
    "    \n",
    "    # Reshape to [batch_size * n_channels, 1, window_size]\n",
    "    batch_x = batch_x.reshape((-1, 1, 512)) \n",
    "    \n",
    "    batch_masks = batch_masks.to(device).long()\n",
    "    batch_masks = batch_masks.repeat_interleave(n_channels, axis=0)\n",
    "    \n",
    "    # Randomly mask some patches of data\n",
    "    mask = mask_generator.generate_mask(\n",
    "        x=batch_x, input_mask=batch_masks).to(device).long()\n",
    "\n",
    "    # Forward\n",
    "    output = model(x_enc=batch_x, input_mask=batch_masks, mask=mask) \n",
    "    \n",
    "    # Compute loss\n",
    "    recon_loss = criterion(output.reconstruction, original)\n",
    "    observed_mask = batch_masks * (1 - mask)\n",
    "    masked_loss = observed_mask * recon_loss\n",
    "    \n",
    "    loss = masked_loss.nansum() / (observed_mask.nansum() + 1e-7)\n",
    "    \n",
    "    print(f\"loss: {loss.item()}\")\n",
    "    \n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
