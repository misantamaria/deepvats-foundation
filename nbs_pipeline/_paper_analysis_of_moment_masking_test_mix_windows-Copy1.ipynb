{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de2cd87-7d93-45ec-bd92-d97a85cf73b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Moment models fine-tune analysis | Mask test\n",
    "> This notebook is the pre-analysis of moment models to select the cases used in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56a9cd9-f767-4fcd-93b2-2134bb45f4c4",
   "metadata": {},
   "source": [
    "# RECORDATORIO \n",
    "1) Conseguir que compilen de nuevo\n",
    "2) Enmascarar también en evaluación, no solo en training, majaretilla..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816ae963-a2d2-467a-90ee-2be0f383c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "model_patch_size = 8\n",
    "verbose          = 0\n",
    "reset_kernel     = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401ff0c4-38c2-44de-953e-23581b731c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install --no-deps ydata_profiling\n",
    "#! pip install --no-deps dacite\n",
    "#! pip install --no-deps multimethod\n",
    "#! pip install --no-deps visions\n",
    "#! pip install --no-deps wordcloud\n",
    "#! pip install --no-deps imagehash\n",
    "#! pip install --no-deps htmlmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db2cd5f-dd8d-42a3-bdc1-afc12ff80afb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcWriteOptions size changed, may indicate binary incompatibility. Expected 72 from C header, got 88 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcReadOptions size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Tensor size changed, may indicate binary incompatibility. Expected 64 from C header, got 80 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.ChunkedArray size changed, may indicate binary incompatibility. Expected 64 from C header, got 72 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Table size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.NativeFile size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7fbbccd73b20>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from dvats.all import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from yaml import load, FullLoader\n",
    "import dvats.utils as ut\n",
    "from dvats.imports import beep\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import ydata_profiling as ydp\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6774bdd-fc22-4e8e-96c4-c29417380137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.cuda.set_device(0)\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13a26bc-3ff6-4167-9f7c-1dba7d10ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.losses import MSELossFlat\n",
    "from dvats.encoder import MAELossFlat, EvalMSE, EvalRMSE, EvalMAE, EvalSMAPE\n",
    "import dvats.config as cfg_\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08922829-19f7-4cdc-97b1-86f5a3b4f3d2",
   "metadata": {},
   "source": [
    "### Setting up Weight & Biases information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d0b55c5-b182-420e-9935-724879313e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User and project\n",
    "entity = os.environ.get(\"WANDB_ENTITY\")\n",
    "project = os.environ.get(\"WANDB_PROJECT\")\n",
    "folder = entity+'/'+project+'/'\n",
    "\n",
    "# Dataset\n",
    "dataset = 'gtrends_kohls'\n",
    "dataset_version = 'v2'\n",
    "enc_artifact_dataset = folder + dataset + ':' + dataset_version\n",
    "\n",
    "# Models\n",
    "model_family = 'zeroshot-moment'\n",
    "task = 'embedding'\n",
    "enc_artifact_small_name = folder + model_family + '-small-' + task + ':v0'\n",
    "enc_artifact_base_name  =  folder + model_family + '-base-' + task + ':v0'\n",
    "enc_artifact_large_name = folder + model_family + '-large-' + task + ':v0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d81c7-d4fd-4949-a5bf-2edd041fcbee",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15b94a4-19cb-47c0-a000-b0890d303ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataset artifact:  mi-santamaria/deepvats/gtrends_kohls:v2\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting dataset artifact: \", enc_artifact_dataset)\n",
    "df_artifact = wandb_api.artifact(enc_artifact_dataset, type = 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dfcdf28-2518-49af-8c64-c2305ba71a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtrends_kohls:v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-15</th>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-22</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-29</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              volume\n",
       "2004-01-01  0.010417\n",
       "2004-01-08  0.010417\n",
       "2004-01-15  0.010417\n",
       "2004-01-22  0.000000\n",
       "2004-01-29  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(440, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_artifact.name)\n",
    "df = df_artifact.to_df()\n",
    "display(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1794082-ba18-4bde-acc2-07e57a0e4fae",
   "metadata": {},
   "source": [
    "### Encoder Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49908f03-6875-4e27-8050-09af41dc62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc_input, _ = SlidingWindow(window_len=17, stride=2, get_y=[])(df)\n",
    "#enc_input.shape\n",
    "enc_input = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01342017-6520-4040-8c44-44266672bb1c",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c96a07c9-7211-4d2a-ab1b-50838d630b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    #return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def greater_than(lst, val):\n",
    "    vals = []\n",
    "    for x in lst:\n",
    "        try:\n",
    "            x = int(x)\n",
    "            if (x > val): \n",
    "                vals.append(x)\n",
    "        except:\n",
    "            continue\n",
    "    return vals\n",
    "    #return [ x for x in lst if isinstance(x, int) and x > val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e6b413-774f-4cbe-bb24-10380277bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_multiple_secondary_y(df, primary_vars, secondary_vars, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    Plots multiple variables with different scales on primary and secondary y-axes.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing the data.\n",
    "    - primary_vars (list): Variables to plot on the primary y-axis.\n",
    "    - secondary_vars (list): Variables to plot on the secondary y-axis.\n",
    "    - figsize (tuple): Size of the figure.\n",
    "\n",
    "    Returns:\n",
    "    - None: Displays the plot.\n",
    "    \"\"\"\n",
    "    ax = df[primary_vars + secondary_vars].plot(\n",
    "        secondary_y=secondary_vars, figsize=figsize\n",
    "    )\n",
    "    ax.set_title(\"Variables with Primary and Secondary Axes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "591ecfec-8a92-4c89-b0c2-2e55ce81e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation(profile, figsize=(8, 6)):\n",
    "    correlation_matrix = profile.corr()\n",
    "    # Crear el heatmap con seaborn\n",
    "    plt.figure(figsize = figsize)  # Ajusta el tamaño si es necesario\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
    "    plt.title(\"Correlation Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655a007-a52e-4dd9-9c4d-b9efdf975997",
   "metadata": {},
   "source": [
    "### Common Fine-tune args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d77cb4e-da4b-4f01-a30c-c145b97d1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, project, version, data, config, job_type = cfg_.get_artifact_config_MVP(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04301513-8b67-47a5-8140-96f4381e64e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "0.4\n",
      "online\n"
     ]
    }
   ],
   "source": [
    "print(config['batch_size'])\n",
    "print(config['r'])\n",
    "print(config['analysis_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "551d968d-841a-45bf-9344-59aa9f7b3f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['r'] = 1e-6\n",
    "config['r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14063f3e-f810-4906-89b7-76f73ba93ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['norm_use_single_batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fafa294-2aca-4448-a6c9-c5b67a2668f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args = {\n",
    "    \"X\": df,\n",
    "    \"stride\": 1,\n",
    "    \"batch_size\": config['batch_size'],\n",
    "    \"cpu\": False,\n",
    "    \"to_numpy\": False,\n",
    "    \"time_flag\": True,\n",
    "    \"n_windows\": None,\n",
    "    \"n_windows_percent\": None,\n",
    "    \"shot\": True,\n",
    "    \"eval_pre\": True,\n",
    "    \"eval_post\": True,\n",
    "    \"lr\": config['r'], #use enc_run lr,\n",
    "    \"lr_scheduler_flag\": False,\n",
    "    \"lr_scheduler_name\": \"cosine_with_restarts\",\n",
    "    \"lr_scheduler_num_warmup_steps\": None,\n",
    "    \"window_sizes\": [12],\n",
    "    \"full_dataset\": True,\n",
    "    \"window_sizes_offset\": 0.05,\n",
    "    \"windows_min_distance\": 0, #int(np.ceil(1.5*enc_input.shape[0]/100)),\n",
    "    \"print_to_path\": True,\n",
    "    \"print_both\": False,\n",
    "    \"print_path\": \"./logs.txt\",\n",
    "    \"print_mode\": \"a\",\n",
    "    \"use_moment_masks\": True,\n",
    "    \"mask_stateful\": config['mask_stateful'],\n",
    "    \"mask_future\": config['mask_future'],\n",
    "    \"mask_sync\": config['mask_sync'],\n",
    "    \"analysis_mode\": config['analysis_mode'],\n",
    "    \"use_wandb\": config['use_wandb'],\n",
    "    \"norm_by_sample\": config['norm_by_sample'],\n",
    "    \"norm_use_single_batch\": config['norm_use_single_batch'],\n",
    "    \"show_plot\": True,\n",
    "    \"metrics\": [EvalMSE, EvalRMSE, EvalMAE, EvalSMAPE],\n",
    "    \"metrics_args\": [{'squared': False}, {'squared': True}, {}, {}],\n",
    "    \"metrics_names\":[\"mse\", \"rmse\", \"mae\", \"smape\"],\n",
    "    \"metrics_dict\": None,\n",
    "    \"criterion\": torch.nn.MSELoss(),\n",
    "    \"mix_windows\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f48c132c-9054-483c-a858-b60ef36b016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_args[\"windows_min_distance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78871a0-aaa8-4efd-98d0-02465d07e787",
   "metadata": {},
   "source": [
    "### Cases execution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b16aa004-1d43-4ea6-a598-9eb1b332e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from momentfm.utils.masking import Masking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c505452b-ab49-464f-856c-46288048c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cases_loop(\n",
    "    model, \n",
    "    n_epochs_list, \n",
    "    dataset_percents, \n",
    "    masked_percents, \n",
    "    n_sizes_list, \n",
    "    summarized = True, \n",
    "    do_beep = True, \n",
    "    verbose = 1,\n",
    "    save = True,\n",
    "    file_errors = \"\",\n",
    "    file_results = \"\"\n",
    "):\n",
    "    mssg = ut.Mssg(verbose = verbose, level = -1)\n",
    "    result_columns = [\n",
    "        'model_size','n_epochs','dataset_percent','masked_percent','n_windows', \n",
    "        'time',\n",
    "        'first_train_loss','first_mse','first_rmse','first_mae','first_smape', \n",
    "        'last_train_loss','last_mse','last_rmse','last_mae','last_smape'\n",
    "    ]\n",
    "    result_columns = result_columns if summarized else result_columns + ['losses','eval_results_pre','eval_results_post']\n",
    "    results = pd.DataFrame(columns = result_columns)\n",
    "    \n",
    "    errors = pd.DataFrame(\n",
    "        columns = [\n",
    "            'model_size',\n",
    "            'n_epochs',\n",
    "            'dataset_percent',\n",
    "            'masked_percent',\n",
    "            'n_windows',\n",
    "            'windows',\n",
    "            'error'\n",
    "        ]\n",
    "    )\n",
    "    model_backup = deepcopy(model)\n",
    "    i = 0\n",
    "    for n_epochs in n_epochs_list:\n",
    "        for dataset_percent in dataset_percents:\n",
    "            print(dataset_percent)\n",
    "            for masked_percent in masked_percents:\n",
    "                model.mask_generator = Masking(mask_ratio = masked_percent)\n",
    "                for sizes in n_sizes_list:\n",
    "                    print(f\"--> epoch {n_epochs}, dataset_percent {dataset_percent}, mask {masked_percent}\")\n",
    "                    redmssg = f\" sizes {sizes}\"\n",
    "                    redmssg = f\"\\033[91m{redmssg}\\033[0m\"\n",
    "                    print(redmssg)\n",
    "\n",
    "                    print(f\"Cuda memmory allocated: {torch.cuda.memory_allocated()}\")\n",
    "                    model_case = deepcopy(model_backup)\n",
    "                    case = {\n",
    "                            'model_size': \"small\",\n",
    "                            'n_epochs': n_epochs,\n",
    "                            'dataset_percent': dataset_percent,\n",
    "                            'masked_percent': masked_percent,\n",
    "                            'n_windows': sizes,\n",
    "                            'windows': None\n",
    "                           }\n",
    "                    result_dict = deepcopy(case)\n",
    "                    error_dict = deepcopy(case)\n",
    "                    error = False\n",
    "                    print(1-dataset_percent)\n",
    "                    torch.cuda.synchronize()\n",
    "                    result = fine_tune(\n",
    "                        enc_learn           = model_case,\n",
    "                        window_mask_percent = masked_percent,\n",
    "                        training_percent    = dataset_percent,\n",
    "                        validation_percent  = 0.3,\n",
    "                        num_epochs          = n_epochs,\n",
    "                        n_window_sizes      = sizes,\n",
    "                        verbose             = verbose,\n",
    "                        register_errors     = True,\n",
    "                        save_best_or_last   = True, # only available for moment\n",
    "                        **common_args    \n",
    "                    )\n",
    "                    common_args['print_mode']='a'\n",
    "\n",
    "                    try:\n",
    "                        internal_errors = result[10]\n",
    "                    except:\n",
    "                        internal_errors = pd.DataFrame(columns=[\"window\", \"error\"])\n",
    "                        \n",
    "                    print(\"Check:\", result[0])\n",
    "                    if len(result[0]) > 0:\n",
    "                    \n",
    "                        result_dict.update({\n",
    "                            'time'             : result[4],\n",
    "                            'windows'          : result[8].cpu() if isinstance(result[8], torch.Tensor) else result[8],\n",
    "                            'first_train_loss' : result[0][0][0].cpu().item() if torch.is_tensor(result[0][0][0]) else result[0][0][0],\n",
    "                            'last_train_loss'  : result[0][-1][-1].cpu().item() if torch.is_tensor(result[0][-1][-1]) else result[0][-1][-1],\n",
    "                            'best_epochs'       : result[9],\n",
    "                            'train_losses'      : result[0][0],\n",
    "                            'eval_pre'          : result[1],\n",
    "                            'eval_post'         : result[2],\n",
    "                            'full_result'       : result\n",
    "                        })\n",
    "                        if result[1] == {}:\n",
    "                            result_dict.update({\n",
    "                                'first_eval_loss'  : np.nan,\n",
    "                                'first_mse'        : np.nan,\n",
    "                                'first_rmse'       : np.nan,\n",
    "                                'first_mae'        : np.nan\n",
    "                            })\n",
    "                        else:\n",
    "                            print(\"N windows: \", len(result[8]))\n",
    "                            print(\"Loss: \", result[1]['loss'])\n",
    "                            result_dict.update({\n",
    "                                'first_eval_loss'  : result[1]['loss'][-1].cpu().item() if torch.is_tensor(result[1]['loss']) else result[1]['loss'][-1],\n",
    "                                'first_mse'        : result[1]['mse'][-1].cpu().item() if torch.is_tensor(result[1]['mse']) else result[1]['mse'][-1],    \n",
    "                                'first_rmse'       : result[1]['rmse'][-1].cpu().item() if torch.is_tensor(result[1]['rmse']) else result[1]['rmse'][-1],\n",
    "                                'first_mae'        : result[1]['mae'][-1].cpu().item() if torch.is_tensor(result[1]['mae']) else result[1]['mae'][-1],                                \n",
    "                                'first_smape'      : result[1]['smape'].cpu().item() if torch.is_tensor(result[1]['smape']) else result[1]['smape']\n",
    "                            })\n",
    "                        if result[2] == {}:\n",
    "                            result_dict.update({\n",
    "                                'last_eval_loss'  : np.nan,\n",
    "                                'last_mse'        : np.nan,\n",
    "                                'last_rmse'       : np.nan,\n",
    "                                'last_mae'        : np.nan\n",
    "                            })\n",
    "                        else:\n",
    "                            result_dict.update({\n",
    "                                'last_eval_loss'   : result[2]['loss'][-1].cpu().item() if torch.is_tensor(result[2]['loss'][-1]) else result[2]['loss'][-1],\n",
    "                                'last_mse'         : result[2]['mse'][-1].cpu().item() if torch.is_tensor(result[2]['mse'][-1]) else result[2]['mse'][-1],\n",
    "                                'last_rmse'        : result[2]['rmse'][-1].cpu().item() if torch.is_tensor(result[2]['rmse'][-1]) else result[2]['rmse'][-1],\n",
    "                                'last_mae'         : result[2]['mae'][-1].cpu().item() if torch.is_tensor(result[2]['mae'][-1]) else result[2]['mae'][-1],\n",
    "                                'last_smape'       : result[2]['smape'][-1].cpu().item() if torch.is_tensor(result[2]['smape'][-1]) else result[2]['smape'][-1]\n",
    "                            })\n",
    "                            \n",
    "        \n",
    "                        if not summarized:\n",
    "                            result_dict.update({\n",
    "                                'losses'           : [[v.cpu().item() if torch.is_tensor(v) else v for v in loss] for loss in result[0]],\n",
    "                                'eval_results_pre' : {k: v.cpu().item() if torch.is_tensor(v) else v for k, v in result[1].items()},\n",
    "                                'eval_results_post': {k: v.cpu().item() if torch.is_tensor(v) else v for k, v in result[2].items()},\n",
    "                                })  \n",
    "                        results = pd.concat([results, pd.DataFrame([result_dict])], ignore_index=True)\n",
    "                    else:\n",
    "                        print(\"Failed case\")\n",
    "                        # Attach possible errors\n",
    "                        internal_errors['model_size'] = case['model_size']\n",
    "                        internal_errors['n_epochs'] = case['n_epochs']\n",
    "                        internal_errors['dataset_percent'] = case['dataset_percent']\n",
    "                        internal_errors['masked_percent'] = case['masked_percent']\n",
    "                        internal_errors['windows'] = [result[8]]*len(internal_errors)\n",
    "                        errors = pd.concat([errors, internal_errors])\n",
    "                        display(internal_errors)\n",
    "                    if not error: mssg.print_error(f\" case {case} | time: {result[4]}\")\n",
    "                    before = torch.cuda.memory_allocated()\n",
    "                    model_case = None\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    display(results)\n",
    "                    if do_beep:\n",
    "                        beep(1)\n",
    "                    mssg.print(f\"epoch {n_epochs}, dataset_percent {dataset_percent}, mask {masked_percent}, sizes {sizes} -->\")\n",
    "                if save:\n",
    "                    mssg.print(f\"Update results into {file_results}\")\n",
    "                    results.to_csv(file_results, index = False, header = True)\n",
    "                    mssg.print(f\"Update errors into {file_errors}\")\n",
    "                    errors.to_csv(file_errors, index = False, header = True)\n",
    "                if do_beep:\n",
    "                    beep(2)\n",
    "                    beep(2)\n",
    "                mssg.print(f\"epoch {n_epochs}, dataset_percent {dataset_percent}, mask {masked_percent} -->\")\n",
    "            if do_beep:\n",
    "                beep(3)\n",
    "                beep(3)\n",
    "                beep(3)\n",
    "            mssg.print(f\"epoch {n_epochs}, dataset_percent {dataset_percent}-->\")\n",
    "        if do_beep:\n",
    "            beep(4)\n",
    "            beep(4)\n",
    "            beep(4)\n",
    "            beep(4)\n",
    "        mssg.print(f\"epoch {n_epochs}-->\")\n",
    "    if do_beep:\n",
    "        beep(1000)\n",
    "        beep(1000)\n",
    "        beep(1000)\n",
    "        beep(1000)\n",
    "        beep(1000)\n",
    "    model_backup = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return results, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6126b-0442-4bc2-b26f-8b99438bef69",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7bde6a-184c-4af7-934a-db50ae3a7007",
   "metadata": {},
   "source": [
    "## Defining full reasonable values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40312054-0683-48e1-b5bf-4001712086e6",
   "metadata": {},
   "source": [
    "The following parameters are modified within the fine-tuning:\n",
    "- `n_epochs_list` is used to set up the number of epochs used in the training step.\n",
    "- `dataset_percents` is used to select the percentage of the dataset used for each case fine-tuning.\n",
    "- `masked_percents` is used to select the  percentage of the training dataset we want to mask for the model to fill it up.\n",
    "- `sizes` is used to select the number of window sizes we want to use for the fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "562cdb03-6396-4cc4-a13d-ee32443794bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases: 72\n"
     ]
    }
   ],
   "source": [
    "n_epochs_list     = [5, 10, 20]\n",
    "dataset_percents  = [0.25, 0.5, 0.75, 1] #1 No tendría sentido porque sería como hacer lo mismo que con mvp. entrenar con todo el dataset.\n",
    "masked_percents = [0.25, 0.5, 0.75]\n",
    "sizes             = [1, 5]\n",
    "total_cases_small = len(n_epochs_list)*len(dataset_percents)*len(masked_percents)*len(sizes)\n",
    "print(f\"Total cases: {total_cases_small}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5202de7-4348-4917-850f-4eb6d5cfa4c9",
   "metadata": {},
   "source": [
    "### Moment-Small\n",
    "Getting the results for moment small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240aa3c-f6ee-4889-aa48-d7a890bc2289",
   "metadata": {},
   "source": [
    "#### Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9d25c39-4297-43bc-9923-3cce3d60b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_computed_small = False\n",
    "#file_errors_small  = 'errors_small_29012025_1.csv'\n",
    "#file_results_small = 'results_small_29012025_1.csv'\n",
    "#file_errors_small  = 'errors_small_03022025_2.csv'\n",
    "#file_results_small = 'results_small_03022025_2.csv'\n",
    "#file_errors_small  = 'errors_small_06022025_1.csv'\n",
    "#file_results_small = 'results_small_06022025_1.csv'\n",
    "file_errors_small  = 'errors_small_07022025_1.csv'\n",
    "file_results_small = 'results_small_07022025_1.csv'\n",
    "file_errors_small  = 'errors_small_10022025_1.csv'\n",
    "file_results_small = 'results_small_10022025_1.csv'\n",
    "file_errors_small  = 'errors_small_11022025_2.csv'\n",
    "file_results_small = 'results_small_11022025_2.csv'\n",
    "file_errors_small  = 'errors_small_11022025_3.csv'\n",
    "file_results_small = 'results_small_11022025_3.csv'\n",
    "file_errors_small  = 'errors_small_11022025_4.csv'\n",
    "file_results_small = 'results_small_11022025_4.csv'\n",
    "file_errors_small  = 'errors_small_12022025_1.csv'\n",
    "file_results_small = 'results_small_12022025_1.csv'\n",
    "file_errors_small  = 'errors_small_12022025_2.csv'\n",
    "file_results_small = 'results_small_12022025_2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e67fa64-342d-47b4-98fc-13aa0835aa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting small artifact:  mi-santamaria/deepvats/zeroshot-moment-small-embedding:v0\n",
      "zeroshot-moment-small-embedding:v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact zeroshot-moment-small-embedding:v0, 144.63MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting small artifact: \", enc_artifact_small_name)\n",
    "enc_artifact_small = wandb_api.artifact(enc_artifact_small_name, type='learner')\n",
    "print(enc_artifact_small.name)\n",
    "moment_small = enc_artifact_small.to_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b31530c3-abd3-44f2-ab94-4e9eabdf3b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moment_small.head.linear.out_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3abcc-b6a3-4f38-9870-1a6104931cac",
   "metadata": {},
   "source": [
    "### Specific parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b0f1dd2-3514-4892-89fb-071cd6616bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases: 72\n"
     ]
    }
   ],
   "source": [
    "#n_epochs_list_small    = [1, 10, 20]\n",
    "n_epochs_list_small    = [10, 20]\n",
    "dataset_percents_small = [0.15, 0.2,0.25, 0.3]\n",
    "masked_percents_small  = [0.25, 0.5, 0.75]\n",
    "#sizes_small            = [1, 2, 4, 6, 8, 10]\n",
    "sizes_small            = [6, 8, 10]\n",
    "total_cases_small      = len(n_epochs_list_small)*len(dataset_percents_small)*len(masked_percents_small)*len(sizes_small)\n",
    "print(f\"Total cases: {total_cases_small}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf500d-7a75-4cdc-9554-0dd050a05918",
   "metadata": {},
   "source": [
    "### Execute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6996b-a8db-4d7e-b320-cdf16220abd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n",
      "--> epoch 10, dataset_percent 0.15, mask 0.25\n",
      "\u001b[91m sizes 6\u001b[0m\n",
      "Cuda memmory allocated: 472724480\n",
      "0.85\n",
      "Initialize Windowed Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 1/18 [00:01<00:26,  1.57s/it]\u001b[A\n",
      " 11% 2/18 [00:02<00:15,  1.02it/s]\u001b[A\n",
      " 17% 3/18 [00:02<00:11,  1.27it/s]\u001b[A\n",
      " 22% 4/18 [00:03<00:09,  1.43it/s]\u001b[A\n",
      " 28% 5/18 [00:03<00:08,  1.54it/s]\u001b[A\n",
      " 33% 6/18 [00:04<00:07,  1.61it/s]\u001b[A\n",
      " 39% 7/18 [00:04<00:06,  1.66it/s]\u001b[A\n",
      " 44% 8/18 [00:05<00:05,  1.69it/s]\u001b[A\n",
      " 50% 9/18 [00:06<00:05,  1.71it/s]\u001b[A\n",
      " 56% 10/18 [00:06<00:04,  1.73it/s]\u001b[A\n",
      " 61% 11/18 [00:07<00:03,  1.75it/s]\u001b[A\n",
      " 67% 12/18 [00:07<00:03,  1.76it/s]\u001b[A\n",
      " 72% 13/18 [00:08<00:02,  1.77it/s]\u001b[A\n",
      " 78% 14/18 [00:08<00:02,  1.78it/s]\u001b[A\n",
      " 83% 15/18 [00:09<00:01,  1.78it/s]\u001b[A\n",
      " 89% 16/18 [00:09<00:01,  1.79it/s]\u001b[A\n",
      " 94% 17/18 [00:10<00:00,  1.79it/s]\u001b[A\n",
      "100% 18/18 [00:11<00:00,  1.62it/s]\u001b[A\n",
      "\n",
      "  0% 0/90 [00:00<?, ?it/s]\u001b[A\n",
      "  1% 1/90 [00:00<00:55,  1.60it/s]\u001b[A\n",
      "  2% 2/90 [00:01<00:48,  1.83it/s]\u001b[A\n",
      "  3% 3/90 [00:01<00:46,  1.89it/s]\u001b[A\n",
      "  4% 4/90 [00:02<00:44,  1.94it/s]\u001b[A\n",
      "  6% 5/90 [00:02<00:43,  1.96it/s]\u001b[A\n",
      "  7% 6/90 [00:03<00:42,  1.97it/s]\u001b[A\n",
      "  8% 7/90 [00:03<00:41,  1.99it/s]\u001b[A\n",
      "  9% 8/90 [00:04<00:41,  2.00it/s]\u001b[A\n",
      " 10% 9/90 [00:04<00:40,  2.02it/s]\u001b[A\n",
      " 11% 10/90 [00:05<00:43,  1.83it/s]\u001b[A\n",
      " 12% 11/90 [00:05<00:41,  1.89it/s]\u001b[A\n",
      " 13% 12/90 [00:06<00:40,  1.92it/s]\u001b[A\n",
      " 14% 13/90 [00:06<00:39,  1.96it/s]\u001b[A\n",
      " 16% 14/90 [00:07<00:38,  1.97it/s]\u001b[A\n",
      " 17% 15/90 [00:07<00:37,  1.98it/s]\u001b[A\n",
      " 18% 16/90 [00:08<00:37,  2.00it/s]\u001b[A\n",
      " 19% 17/90 [00:08<00:36,  2.01it/s]\u001b[A\n",
      " 20% 18/90 [00:09<00:35,  2.02it/s]\u001b[A\n",
      " 21% 19/90 [00:09<00:35,  2.01it/s]\u001b[A\n",
      " 22% 20/90 [00:10<00:34,  2.01it/s]\u001b[A\n",
      " 23% 21/90 [00:10<00:34,  2.01it/s]\u001b[A\n",
      " 24% 22/90 [00:11<00:33,  2.02it/s]\u001b[A\n",
      " 26% 23/90 [00:11<00:33,  2.02it/s]\u001b[A\n",
      " 27% 24/90 [00:12<00:32,  2.02it/s]\u001b[A\n",
      " 28% 25/90 [00:12<00:32,  2.02it/s]\u001b[A\n",
      " 29% 26/90 [00:13<00:31,  2.03it/s]\u001b[A\n",
      " 30% 27/90 [00:13<00:31,  2.01it/s]\u001b[A\n",
      " 31% 28/90 [00:14<00:30,  2.00it/s]\u001b[A\n",
      " 32% 29/90 [00:14<00:30,  2.01it/s]\u001b[A\n",
      " 33% 30/90 [00:15<00:29,  2.01it/s]\u001b[A\n",
      " 34% 31/90 [00:15<00:29,  2.01it/s]\u001b[A\n",
      " 36% 32/90 [00:16<00:28,  2.01it/s]\u001b[A\n",
      " 37% 33/90 [00:16<00:28,  2.02it/s]\u001b[A\n",
      " 38% 34/90 [00:17<00:27,  2.02it/s]\u001b[A\n",
      " 39% 35/90 [00:17<00:27,  2.03it/s]\u001b[A\n",
      " 40% 36/90 [00:18<00:26,  2.03it/s]\u001b[A\n",
      " 41% 37/90 [00:18<00:26,  2.03it/s]\u001b[A\n",
      " 42% 38/90 [00:19<00:25,  2.04it/s]\u001b[A\n",
      " 43% 39/90 [00:19<00:25,  2.03it/s]\u001b[A\n",
      " 44% 40/90 [00:20<00:24,  2.03it/s]\u001b[A\n",
      " 46% 41/90 [00:20<00:24,  2.02it/s]\u001b[A\n",
      " 47% 42/90 [00:21<00:23,  2.02it/s]\u001b[A\n",
      " 48% 43/90 [00:21<00:23,  2.03it/s]\u001b[A\n",
      " 49% 44/90 [00:22<00:22,  2.03it/s]\u001b[A\n",
      " 50% 45/90 [00:22<00:22,  2.04it/s]\u001b[A\n",
      " 51% 46/90 [00:23<00:21,  2.03it/s]\u001b[A\n",
      " 52% 47/90 [00:23<00:21,  2.03it/s]\u001b[A\n",
      " 53% 48/90 [00:24<00:20,  2.02it/s]\u001b[A\n",
      " 54% 49/90 [00:24<00:20,  2.02it/s]\u001b[A\n",
      " 56% 50/90 [00:25<00:19,  2.02it/s]\u001b[A\n",
      " 57% 51/90 [00:25<00:19,  2.00it/s]\u001b[A\n",
      " 58% 52/90 [00:26<00:18,  2.01it/s]\u001b[A\n",
      " 59% 53/90 [00:26<00:18,  2.01it/s]\u001b[A\n",
      " 60% 54/90 [00:27<00:17,  2.02it/s]\u001b[A\n",
      " 61% 55/90 [00:27<00:17,  2.01it/s]\u001b[A\n",
      " 62% 56/90 [00:28<00:16,  2.02it/s]\u001b[A\n",
      " 63% 57/90 [00:28<00:16,  2.02it/s]\u001b[A\n",
      " 64% 58/90 [00:29<00:15,  2.02it/s]\u001b[A\n",
      " 66% 59/90 [00:29<00:15,  2.02it/s]\u001b[A\n",
      " 67% 60/90 [00:30<00:14,  2.02it/s]\u001b[A\n",
      " 68% 61/90 [00:30<00:14,  2.02it/s]\u001b[A\n",
      " 69% 62/90 [00:30<00:13,  2.03it/s]\u001b[A\n",
      " 70% 63/90 [00:31<00:13,  2.03it/s]\u001b[A\n",
      " 71% 64/90 [00:31<00:12,  2.03it/s]\u001b[A\n",
      " 72% 65/90 [00:32<00:12,  2.03it/s]\u001b[A\n",
      " 73% 66/90 [00:32<00:11,  2.02it/s]\u001b[A\n",
      " 74% 67/90 [00:33<00:11,  2.02it/s]\u001b[A\n",
      " 76% 68/90 [00:33<00:10,  2.02it/s]\u001b[A\n",
      " 77% 69/90 [00:34<00:10,  2.01it/s]\u001b[A\n",
      " 78% 70/90 [00:34<00:09,  2.02it/s]\u001b[A\n",
      " 79% 71/90 [00:35<00:09,  2.02it/s]\u001b[A\n",
      " 80% 72/90 [00:35<00:08,  2.03it/s]\u001b[A\n",
      " 81% 73/90 [00:36<00:09,  1.87it/s]\u001b[A\n",
      " 82% 74/90 [00:37<00:08,  1.91it/s]\u001b[A\n",
      " 83% 75/90 [00:37<00:07,  1.94it/s]\u001b[A\n",
      " 84% 76/90 [00:38<00:07,  1.96it/s]\u001b[A\n",
      " 86% 77/90 [00:38<00:06,  1.98it/s]\u001b[A\n",
      " 87% 78/90 [00:39<00:06,  1.99it/s]\u001b[A\n",
      " 88% 79/90 [00:39<00:05,  1.99it/s]\u001b[A\n",
      " 89% 80/90 [00:40<00:04,  2.01it/s]\u001b[A\n",
      " 90% 81/90 [00:40<00:04,  2.01it/s]\u001b[A\n",
      " 91% 82/90 [00:41<00:03,  2.00it/s]\u001b[A\n",
      " 92% 83/90 [00:41<00:03,  2.01it/s]\u001b[A\n",
      " 93% 84/90 [00:42<00:02,  2.01it/s]\u001b[A\n",
      " 94% 85/90 [00:42<00:02,  2.01it/s]\u001b[A\n",
      " 96% 86/90 [00:43<00:01,  2.02it/s]\u001b[A\n",
      " 97% 87/90 [00:43<00:01,  2.02it/s]\u001b[A\n",
      " 98% 88/90 [00:43<00:00,  2.03it/s]\u001b[A\n",
      " 99% 89/90 [00:44<00:00,  2.04it/s]\u001b[A\n",
      "100% 90/90 [00:44<00:00,  2.00it/s]\u001b[A\n",
      "\n",
      "  0% 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 1/18 [00:00<00:09,  1.77it/s]\u001b[A\n",
      " 11% 2/18 [00:01<00:09,  1.78it/s]\u001b[A\n",
      " 17% 3/18 [00:01<00:08,  1.79it/s]\u001b[A\n",
      " 22% 4/18 [00:02<00:07,  1.79it/s]\u001b[A\n",
      " 28% 5/18 [00:02<00:07,  1.79it/s]\u001b[A\n",
      " 33% 6/18 [00:03<00:06,  1.80it/s]\u001b[A\n",
      " 39% 7/18 [00:03<00:06,  1.79it/s]\u001b[A\n",
      " 44% 8/18 [00:04<00:05,  1.79it/s]\u001b[A\n",
      " 50% 9/18 [00:05<00:05,  1.79it/s]\u001b[A\n",
      " 56% 10/18 [00:05<00:04,  1.79it/s]\u001b[A\n",
      " 61% 11/18 [00:06<00:03,  1.79it/s]\u001b[A\n",
      " 67% 12/18 [00:06<00:03,  1.80it/s]\u001b[A\n",
      " 72% 13/18 [00:07<00:02,  1.80it/s]\u001b[A\n",
      " 78% 14/18 [00:07<00:02,  1.80it/s]\u001b[A\n",
      " 83% 15/18 [00:08<00:01,  1.80it/s]\u001b[A\n",
      " 89% 16/18 [00:08<00:01,  1.80it/s]\u001b[A\n",
      " 94% 17/18 [00:09<00:00,  1.80it/s]\u001b[A\n",
      "100% 18/18 [00:10<00:00,  1.79it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check: [[0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]]\n",
      "N windows:  6\n",
      "Loss:  [0.005754325803233466]\n",
      "[1] \u001b[91m [ cases_loop ]  case {'model_size': 'small', 'n_epochs': 10, 'dataset_percent': 0.15, 'masked_percent': 0.25, 'n_windows': 6, 'windows': None} | time: 45.12921953201294\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9% 8/90 [2:22:49<24:23:59, 1071.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>dataset_percent</th>\n",
       "      <th>masked_percent</th>\n",
       "      <th>n_windows</th>\n",
       "      <th>time</th>\n",
       "      <th>first_train_loss</th>\n",
       "      <th>first_mse</th>\n",
       "      <th>first_rmse</th>\n",
       "      <th>first_mae</th>\n",
       "      <th>...</th>\n",
       "      <th>last_mae</th>\n",
       "      <th>last_smape</th>\n",
       "      <th>windows</th>\n",
       "      <th>best_epochs</th>\n",
       "      <th>train_losses</th>\n",
       "      <th>eval_pre</th>\n",
       "      <th>eval_post</th>\n",
       "      <th>full_result</th>\n",
       "      <th>first_eval_loss</th>\n",
       "      <th>last_eval_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "      <td>45.12922</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8, 10, 12, 13, 16, 17]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]</td>\n",
       "      <td>{'loss': [0.005754325803233466], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>{'loss': [0.005735521149795709], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>([[0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]], {'loss': [0.005754325803233466], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.005735521149795709], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [45.12921953201294], 45.12921953201294, [11.123744249343872, 10.048526525497437], 21.17227077484131, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (tokenize...</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>0.005736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_size n_epochs  dataset_percent  masked_percent n_windows      time  \\\n",
       "0      small       10             0.15            0.25         6  45.12922   \n",
       "\n",
       "   first_train_loss first_mse first_rmse first_mae  ... last_mae  last_smape  \\\n",
       "0          0.005754       NaN        NaN       NaN  ...      NaN         NaN   \n",
       "\n",
       "                   windows best_epochs  \\\n",
       "0  [8, 10, 12, 13, 16, 17]         [7]   \n",
       "\n",
       "                                                                                                                                                                                                                                                  train_losses  \\\n",
       "0  [0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]   \n",
       "\n",
       "                                                                                      eval_pre  \\\n",
       "0  {'loss': [0.005754325803233466], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "\n",
       "                                                                                     eval_post  \\\n",
       "0  {'loss': [0.005735521149795709], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               full_result  \\\n",
       "0  ([[0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]], {'loss': [0.005754325803233466], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.005735521149795709], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [45.12921953201294], 45.12921953201294, [11.123744249343872, 10.048526525497437], 21.17227077484131, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (tokenize...   \n",
       "\n",
       "  first_eval_loss last_eval_loss  \n",
       "0        0.005754       0.005736  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  [ cases_loop ] epoch 10, dataset_percent 0.15, mask 0.25, sizes 6 -->\n",
      "--> epoch 10, dataset_percent 0.15, mask 0.25\n",
      "\u001b[91m sizes 8\u001b[0m\n",
      "Cuda memmory allocated: 320780288\n",
      "0.85\n",
      "Initialize Windowed Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61% 11/18 [00:07<00:04,  1.74it/s]Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 972, in moment_safe_forward_pass\n",
      "    output  = self.model(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "NoneType: None\n",
      " 78% 14/18 [00:08<00:02,  1.83it/s]Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 972, in moment_safe_forward_pass\n",
      "    output  = self.model(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "NoneType: None\n",
      " 94% 17/18 [00:10<00:00,  1.89it/s]Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 972, in moment_safe_forward_pass\n",
      "    output  = self.model(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "NoneType: None\n",
      "100% 18/18 [00:10<00:00,  1.69it/s]\n",
      "  3% 3/100 [00:01<00:49,  1.95it/s]Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 972, in moment_safe_forward_pass\n",
      "    output  = self.model(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "NoneType: None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 3601, in fine_tune_moment_mix_windows\n",
      "    losses, self.model = self.fine_tune_moment_train_mix_windows_(use_moment_masks, save_best_or_last, loss_pre = loss_pre)\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 3509, in fine_tune_moment_train_mix_windows_\n",
      "    loss  = self.fine_tune_moment_train_loop_step_(\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 3151, in fine_tune_moment_train_loop_step_\n",
      "    raise ValueError(f\"Execution failed: Output is None.\")\n",
      "ValueError: Execution failed: Output is None.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [window, error]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check: []\n",
      "Failed case\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>error</th>\n",
       "      <th>model_size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>dataset_percent</th>\n",
       "      <th>masked_percent</th>\n",
       "      <th>windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [window, error, model_size, n_epochs, dataset_percent, masked_percent, windows]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \u001b[91m [ cases_loop ]  case {'model_size': 'small', 'n_epochs': 10, 'dataset_percent': 0.15, 'masked_percent': 0.25, 'n_windows': 8, 'windows': None} | time: 0.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% 3/100 [00:02<01:20,  1.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>dataset_percent</th>\n",
       "      <th>masked_percent</th>\n",
       "      <th>n_windows</th>\n",
       "      <th>time</th>\n",
       "      <th>first_train_loss</th>\n",
       "      <th>first_mse</th>\n",
       "      <th>first_rmse</th>\n",
       "      <th>first_mae</th>\n",
       "      <th>...</th>\n",
       "      <th>last_mae</th>\n",
       "      <th>last_smape</th>\n",
       "      <th>windows</th>\n",
       "      <th>best_epochs</th>\n",
       "      <th>train_losses</th>\n",
       "      <th>eval_pre</th>\n",
       "      <th>eval_post</th>\n",
       "      <th>full_result</th>\n",
       "      <th>first_eval_loss</th>\n",
       "      <th>last_eval_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "      <td>45.12922</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8, 10, 12, 13, 16, 17]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]</td>\n",
       "      <td>{'loss': [0.005754325803233466], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>{'loss': [0.005735521149795709], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>([[0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]], {'loss': [0.005754325803233466], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.005735521149795709], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [45.12921953201294], 45.12921953201294, [11.123744249343872, 10.048526525497437], 21.17227077484131, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (tokenize...</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>0.005736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_size n_epochs  dataset_percent  masked_percent n_windows      time  \\\n",
       "0      small       10             0.15            0.25         6  45.12922   \n",
       "\n",
       "   first_train_loss first_mse first_rmse first_mae  ... last_mae  last_smape  \\\n",
       "0          0.005754       NaN        NaN       NaN  ...      NaN         NaN   \n",
       "\n",
       "                   windows best_epochs  \\\n",
       "0  [8, 10, 12, 13, 16, 17]         [7]   \n",
       "\n",
       "                                                                                                                                                                                                                                                  train_losses  \\\n",
       "0  [0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]   \n",
       "\n",
       "                                                                                      eval_pre  \\\n",
       "0  {'loss': [0.005754325803233466], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "\n",
       "                                                                                     eval_post  \\\n",
       "0  {'loss': [0.005735521149795709], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               full_result  \\\n",
       "0  ([[0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]], {'loss': [0.005754325803233466], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.005735521149795709], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [45.12921953201294], 45.12921953201294, [11.123744249343872, 10.048526525497437], 21.17227077484131, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (tokenize...   \n",
       "\n",
       "  first_eval_loss last_eval_loss  \n",
       "0        0.005754       0.005736  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  [ cases_loop ] epoch 10, dataset_percent 0.15, mask 0.25, sizes 8 -->\n",
      "--> epoch 10, dataset_percent 0.15, mask 0.25\n",
      "\u001b[91m sizes 10\u001b[0m\n",
      "Cuda memmory allocated: 472650752\n",
      "0.85\n",
      "Initialize Windowed Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56% 10/18 [00:05<00:04,  1.80it/s]Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 972, in moment_safe_forward_pass\n",
      "    output  = self.model(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "NoneType: None\n",
      " 94% 17/18 [00:09<00:00,  1.82it/s]Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 972, in moment_safe_forward_pass\n",
      "    output  = self.model(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "NoneType: None\n",
      "100% 18/18 [00:09<00:00,  1.85it/s]\n",
      "  5% 4/80 [00:02<00:38,  1.99it/s]Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 972, in moment_safe_forward_pass\n",
      "    output  = self.model(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 299, in reconstruction\n",
      "    x_enc = self.tokenizer(x=x_enc)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/embed.py\", line 249, in forward\n",
      "    x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
      "RuntimeError: maximum size for tensor at dimension 2 is 4 but size is 8\n",
      "NoneType: None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 3601, in fine_tune_moment_mix_windows\n",
      "    losses, self.model = self.fine_tune_moment_train_mix_windows_(use_moment_masks, save_best_or_last, loss_pre = loss_pre)\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 3509, in fine_tune_moment_train_mix_windows_\n",
      "    loss  = self.fine_tune_moment_train_loop_step_(\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 3151, in fine_tune_moment_train_loop_step_\n",
      "    raise ValueError(f\"Execution failed: Output is None.\")\n",
      "ValueError: Execution failed: Output is None.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [window, error]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check: []\n",
      "Failed case\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>error</th>\n",
       "      <th>model_size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>dataset_percent</th>\n",
       "      <th>masked_percent</th>\n",
       "      <th>windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [window, error, model_size, n_epochs, dataset_percent, masked_percent, windows]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \u001b[91m [ cases_loop ]  case {'model_size': 'small', 'n_epochs': 10, 'dataset_percent': 0.15, 'masked_percent': 0.25, 'n_windows': 10, 'windows': None} | time: 0.0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% 4/80 [00:02<00:56,  1.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>dataset_percent</th>\n",
       "      <th>masked_percent</th>\n",
       "      <th>n_windows</th>\n",
       "      <th>time</th>\n",
       "      <th>first_train_loss</th>\n",
       "      <th>first_mse</th>\n",
       "      <th>first_rmse</th>\n",
       "      <th>first_mae</th>\n",
       "      <th>...</th>\n",
       "      <th>last_mae</th>\n",
       "      <th>last_smape</th>\n",
       "      <th>windows</th>\n",
       "      <th>best_epochs</th>\n",
       "      <th>train_losses</th>\n",
       "      <th>eval_pre</th>\n",
       "      <th>eval_post</th>\n",
       "      <th>full_result</th>\n",
       "      <th>first_eval_loss</th>\n",
       "      <th>last_eval_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "      <td>45.12922</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8, 10, 12, 13, 16, 17]</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]</td>\n",
       "      <td>{'loss': [0.005754325803233466], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>{'loss': [0.005735521149795709], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>([[0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]], {'loss': [0.005754325803233466], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.005735521149795709], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [45.12921953201294], 45.12921953201294, [11.123744249343872, 10.048526525497437], 21.17227077484131, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (tokenize...</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>0.005736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_size n_epochs  dataset_percent  masked_percent n_windows      time  \\\n",
       "0      small       10             0.15            0.25         6  45.12922   \n",
       "\n",
       "   first_train_loss first_mse first_rmse first_mae  ... last_mae  last_smape  \\\n",
       "0          0.005754       NaN        NaN       NaN  ...      NaN         NaN   \n",
       "\n",
       "                   windows best_epochs  \\\n",
       "0  [8, 10, 12, 13, 16, 17]         [7]   \n",
       "\n",
       "                                                                                                                                                                                                                                                  train_losses  \\\n",
       "0  [0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]   \n",
       "\n",
       "                                                                                      eval_pre  \\\n",
       "0  {'loss': [0.005754325803233466], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "\n",
       "                                                                                     eval_post  \\\n",
       "0  {'loss': [0.005735521149795709], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               full_result  \\\n",
       "0  ([[0.005754325803233466, 0.0005655890620093689, 0.0005889112985136712, 0.0006162445254934331, 0.000608000304863607, 0.0006319372603482205, 0.0005721979614463635, 0.0005882293909154315, 0.0005540337701353969, 0.0005877768421164041, 0.0005574002344575194]], {'loss': [0.005754325803233466], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.005735521149795709], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [45.12921953201294], 45.12921953201294, [11.123744249343872, 10.048526525497437], 21.17227077484131, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (tokenize...   \n",
       "\n",
       "  first_eval_loss last_eval_loss  \n",
       "0        0.005754       0.005736  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  [ cases_loop ] epoch 10, dataset_percent 0.15, mask 0.25, sizes 10 -->\n",
      "[1]  [ cases_loop ] Update results into results_small_12022025_2.csv\n",
      "[1]  [ cases_loop ] Update errors into errors_small_12022025_2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,UklGRvQHAABXQVZFZm10IBAAAAABAAEAECcAACBOAAACABAAZGF0YdAHAAAAAIj46g6w6aEdJ9vxKx7NpznGv5RGT7OLUuOnYl2rnfJmypQcb1+NwnWEh816TYMsfsqA0n8CgLp/+YDlfauDWHoPiCB1Fo5QbqqV/2WxnkpcDKlTUZa0QEUnwTs4lM5yKq3cFRxB61cNHvpq/g4Jgu/fF9TgXiaS0lY078SYQRq49U1ArEJZiqFXYx6YEmwckFRzoYkDecOEDH2TgWF/G4D5f2OA035ngvJ7IoZgd4aLLnGAknJp+ZpFYNKkyFXpryBKGLx2PTPJ9C8O18wheOUuEz70TAQsA131ERKS5rYgH9jpLjjKeDwMvTVJyrDyVJ2lhl+rm81oFpOncP6L93Z7hql7oIKqfnqA8n8RgHx/Z4FIfXaEYHk1ic9zko+rbHeXDGTJoA9aZ6vZTi23j0Lww101hdFwJ73f+hhl7i0KSv09+zgMXez8GsLdYimezzg3I8JNRH+1c1DgqYFbbZ9QZUuWvW2ajqt0dYgCevGDsH0egaZ/BYDgf6uAW34Ogx17JIcyduCMqm8ulJ1n9JwmXhOnZlNpsoRHzr6oOhbM/ywT2rkelegIEGj3IAFZBjTyNBV348UjHtXZMVvHQD9duspLUq5LV2SjnGG6mZhqdJEgcrCKGniFhXF8BoIVfz6A/n81gCl/6YGYfFWFVHhtimxyH5H1alSZCWLwosdX0K1STM+50z/DxnYyftRoJNLi2xWL8QIHdgAS+GAPPOkVHrXaYCyxzBE6YL/3RvCy5VKOp7JdX505Z4mUV28qjfB1XIfuejODP369gNh/A4CyfwiBz33IgzV6OYjwdEyOFG7slbdl/p74W2Op91D2tNxEjsHRNwHPAyof3aIbtuvhDJT69P2ECQ3vVBhh4M8mJNLCNIbE/UG4t1NO56uWWTuhomPZl1Fs44+Hc3SJKXmjhCV9gIFsfxeA9n9sgMJ+foLUe0aGNXe3i/dwvpIuaUKb918lpXBVRbDASXy8Dj2eyYcvftdaIezluBK09NYDowPn9IYSHuYoIa/XVy/NyeA8qLyWSW2wSlVJpdVfYZsRadiS33DNiyN3VobHe4iCu35wgPV/FYBxf3iBMH2VhDp5YYmdc8qPbGy7l8JjGKG7WcCre06OtylCWcTxNPTR/yYv4IYY2u63CcD9x/quDOjrcBtQ3dIpMM+iN7vBsUQftc9QianUWyCfmGUJlvptZI7cdEuIJnrUg8Z9DoGvfwSA2n+3gEh+J4P8ekuHBHYUjXBvbpRXZz+d1V1ppwxTx7IhRzS/PjqCzJAshNpGHgnpkw/e96kAzwa+8akVBOM3JK/URjLxxqc/+rkpTPetoVcTo+hhc5nZajmRVXKBikJ4Y4WMfPGBI383gP9/O4Abf/2BfXx3hSt4nIo3clqRtGqbmb1hQaNwVyuu80syumw/LccJMu7U9iNF42YVAfKMBuwAm/fWD8foiB5E2s8sRcx6Ovq+WUeSsj9TOKcDXhSdfmdJlJFv9owedjWHD3sZg1N+sIDdfwSAqn8Xgbl95IMSemOIwHSDjtdtL5ZvZUyfpVu6qZtQVrV4RPbBZjduz5Mpkd0uGyvsawwK+339+gmX7sgY7t8/J7XRLjUexGNCV7ewTo6r61nroOxjlJeQbKqPunNIiU95hIQ+fW6Bd38TgPR/doCyfpaCtntrhgp36Yu/cPyS62iLm6hfeKUYVaKwX0nhvKU8CcoZL+/X5yBf5kMSKvVgAxkEcfT7EqrlmiE/18UvYclJPUO89kkRsKJV9qQjYBibVWmbkhZxm4tOdzKG5Xtxgsx+Z4D4fxmAZn+LgRd9tYQUeY6JanMDkC1sAJh3Y2ihZlkZrB1O8LfEQcLEhTRi0o8mouASGE/vQQk3/lH6Iw106+Mb3txCKsPODThUwRVFv7QrUTKpJlzTnuBlx5U2bi2ODHUhiEl6uIPbff+At38CgNV/xIA0fkKD23pzh9Z1SI01b66UEWeKnYVdvqeyUiazv0aav9U578whLPba0x1+6R0PVfgzAEUHSPEdFpHiqCQ/1LMyh8YNQJe5iEycrfdXwqI0YiyZGmv9kIpyUopreEGFp3zdgTF/MYD+f0OADX8SgmF8mYUCeMuKAXKWkXJq4plwYZOjGleGrpNLlboFP5fHnDFd1YUjuePyFHbyFgZjASX3SxBT6Poe09k+LdnL4zqUvrtHNLKZU+OmU17JnMRnCpTLb8OMS3YOhy97/4JlfqSA4n8GgKF/J4GjfQKE7nmNiI90uo6abXGWJ2WZn1JbEqo/ULa1FERewvs23M8jKQPeuhqg7PULgfsH/XAKIu48GXzfsCdH0Zk1tcPIQvW2DU81qz9anKA2ZFCXz2xyj+xzHIl1eWWEVn1dgYJ/D4Dwf4CAoX6tgpd7kIbedhuMh3A6k6do1JtZX8ylv1T/sP5IRr09PHXKqi5f2HUg1ObOEaD16QKPBPvzcBM25Q0iztYzMPfIsD3fu1dKta/6VaOkcWDQmphpXZJOcWqLeHcNhgJ8WoLcfl6A+n8egFp/nYH+fNWE7Xi7iTZzPZDua0WYLWO4oRJZc6zATVK4XkErxRk00dIeJhXhnhfF78sIrf7b+ZkN/+pXHGzcsipWznc47cB4RWC0hlHbqHhchp4nZoWVcm73jTt1+IdsepuD8X3xgL5/AoDOf9GAIH5cgw==\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]  [ cases_loop ] epoch 10, dataset_percent 0.15, mask 0.25 -->\n",
      "--> epoch 10, dataset_percent 0.15, mask 0.5\n",
      "\u001b[91m sizes 6\u001b[0m\n",
      "Cuda memmory allocated: 472650752\n",
      "0.85\n",
      "Initialize Windowed Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 18/18 [00:11<00:00,  1.62it/s]\n",
      " 68% 61/90 [00:30<00:14,  2.01it/s]"
     ]
    }
   ],
   "source": [
    "results_small      = None\n",
    "errors_small       = None\n",
    "if already_computed_small:\n",
    "    results_small = pd.read_csv(file_results_small, index_col=None, header=0)\n",
    "    errors_small  = pd.read_csv(file_errors_small, index_col=None, header=0)\n",
    "else:\n",
    "    results_small, errors_small = cases_loop(\n",
    "        model             = moment_small, \n",
    "        n_epochs_list     = n_epochs_list_small, \n",
    "        dataset_percents  = dataset_percents_small, \n",
    "        masked_percents = masked_percents_small, \n",
    "        n_sizes_list      = sizes_small, \n",
    "        verbose           = 1,\n",
    "        summarized        = True,\n",
    "        save              = True,\n",
    "        file_errors       = file_errors_small,\n",
    "        file_results      = file_results_small\n",
    "    )\n",
    "    #already_computed_small = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f346201-9c7c-4ef4-963e-0b81c7eaa6a8",
   "metadata": {},
   "source": [
    "Observaciones:\n",
    "- El número de épocas más pequeño a partir de los "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6731b-5fd5-41c5-9e33-9aa7a2f91d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_small = pd.read_csv(file_results_small, index_col=None, header=0)\n",
    "#errors_small  = pd.read_csv(file_errors_small, index_col=None, header=0)\n",
    "print(errors_small.shape)\n",
    "print(results_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c7ad033-b134-45c5-b124-8261c59f562b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- ERRORS -----\n",
      "Total error cases: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>dataset_percent</th>\n",
       "      <th>masked_percent</th>\n",
       "      <th>n_windows</th>\n",
       "      <th>windows</th>\n",
       "      <th>error</th>\n",
       "      <th>window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_size, n_epochs, dataset_percent, masked_percent, n_windows, windows, error, window]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>dataset_percent</th>\n",
       "      <th>masked_percent</th>\n",
       "      <th>n_windows</th>\n",
       "      <th>time</th>\n",
       "      <th>first_train_loss</th>\n",
       "      <th>first_mse</th>\n",
       "      <th>first_rmse</th>\n",
       "      <th>first_mae</th>\n",
       "      <th>...</th>\n",
       "      <th>last_mae</th>\n",
       "      <th>last_smape</th>\n",
       "      <th>windows</th>\n",
       "      <th>best_epochs</th>\n",
       "      <th>train_losses</th>\n",
       "      <th>eval_pre</th>\n",
       "      <th>eval_post</th>\n",
       "      <th>full_result</th>\n",
       "      <th>first_eval_loss</th>\n",
       "      <th>last_eval_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "      <td>40.073948</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8, 10, 12, 13, 16, 17]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[0.007736432538984124, 0.0005128225830048905, 0.0005199603820074117, 0.0005422921303761541, 0.0004997859355171386, 0.0004974375515303109, 0.00045875614750912064, 0.0004734527446998982, 0.000530040863850445, 0.0005426633420029248, 0.0004998219824301486]</td>\n",
       "      <td>{'loss': [0.007736432538984124], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>{'loss': [0.007721100093262708], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>([[0.007736432538984124, 0.0005128225830048905, 0.0005199603820074117, 0.0005422921303761541, 0.0004997859355171386, 0.0004974375515303109, 0.00045875614750912064, 0.0004734527446998982, 0.000530040863850445, 0.0005426633420029248, 0.0004998219824301486]], {'loss': [0.007736432538984124], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.007721100093262708], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [40.07394766807556], 40.07394766807556, [10.538601160049438, 9.383227825164795], 19.921828985214233, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (tokeniz...</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>0.007721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6</td>\n",
       "      <td>44.403908</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8, 10, 12, 13, 16, 17]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0.006430488714078606, 0.000524085031631532, 0.0005355071815655618, 0.0005009601663914509, 0.0005013609976837566, 0.0005612900616445889, 0.0005486514621427179, 0.000550172260166922, 0.0005089502002293658, 0.0005758699492920035, 0.0005521416019797067]</td>\n",
       "      <td>{'loss': [0.006430488714078606], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>{'loss': [0.006421495916369809], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>([[0.006430488714078606, 0.000524085031631532, 0.0005355071815655618, 0.0005009601663914509, 0.0005013609976837566, 0.0005612900616445889, 0.0005486514621427179, 0.000550172260166922, 0.0005089502002293658, 0.0005758699492920035, 0.0005521416019797067]], {'loss': [0.006430488714078606], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.006421495916369809], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [44.403908252716064], 44.403908252716064, [10.55851125717163, 9.44180154800415], 20.00031280517578, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (tokenizer)...</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>0.006421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>small</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>6</td>\n",
       "      <td>40.350376</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8, 10, 12, 13, 16, 17]</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[0.006271722936718207, 0.0006348706265271176, 0.0005985666475680773, 0.0005996766253701935, 0.0006450319833675167, 0.0005909442588745151, 0.000589421743825369, 0.0006564614027411153, 0.000747456906537991, 0.0006651581325058942, 0.0006324679097815533]</td>\n",
       "      <td>{'loss': [0.006271722936718207], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>{'loss': [0.0062546565241063945], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>([[0.006271722936718207, 0.0006348706265271176, 0.0005985666475680773, 0.0005996766253701935, 0.0006450319833675167, 0.0005909442588745151, 0.000589421743825369, 0.0006564614027411153, 0.000747456906537991, 0.0006651581325058942, 0.0006324679097815533]], {'loss': [0.006271722936718207], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.0062546565241063945], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [40.35037589073181], 40.35037589073181, [10.994718074798584, 9.992429256439209], 20.987147331237793, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (tokenize...</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>0.006255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>small</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6</td>\n",
       "      <td>54.582109</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8, 10, 12, 13, 16, 17]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.005750537991201889, 0.00035821853155291387, 0.0003467421626158863, 0.00039354360276113516, 0.0003589894873915579, 0.0003678229689037173, 0.0003760189326633488, 0.000406864230833228, 0.00037007326946794905, 0.0003714876517981545, 0.00035982841522623363]</td>\n",
       "      <td>{'loss': [0.005750537991201889], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>{'loss': [0.0057909790236461796], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>([[0.005750537991201889, 0.00035821853155291387, 0.0003467421626158863, 0.00039354360276113516, 0.0003589894873915579, 0.0003678229689037173, 0.0003760189326633488, 0.000406864230833228, 0.00037007326946794905, 0.0003714876517981545, 0.00035982841522623363]], {'loss': [0.005750537991201889], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.0057909790236461796], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [54.58210873603821], 54.58210873603821, [10.48008108139038, 9.488317251205444], 19.968398332595825, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (toke...</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.005791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6</td>\n",
       "      <td>59.702652</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8, 10, 12, 13, 16, 17]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.0055591320350585095, 0.00040115872828512994, 0.00037240337860566797, 0.00038632616239434964, 0.0004131425678982244, 0.000381480607757112, 0.0004053853596512151, 0.00040979710865940433, 0.00041176033058339573, 0.0004032611362466317, 0.0003834772696791333]</td>\n",
       "      <td>{'loss': [0.0055591320350585095], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>{'loss': [0.005544954960189191], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}</td>\n",
       "      <td>([[0.0055591320350585095, 0.00040115872828512994, 0.00037240337860566797, 0.00038632616239434964, 0.0004131425678982244, 0.000381480607757112, 0.0004053853596512151, 0.00040979710865940433, 0.00041176033058339573, 0.0004032611362466317, 0.0003834772696791333]], {'loss': [0.0055591320350585095], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.005544954960189191], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [59.70265173912048], 59.70265173912048, [11.059320211410522, 10.140296459197998], 21.19961667060852, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (t...</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>0.005545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_size n_epochs  dataset_percent  masked_percent n_windows       time  \\\n",
       "0      small       10             0.15            0.25         6  40.073948   \n",
       "1      small       10             0.15            0.50         6  44.403908   \n",
       "2      small       10             0.15            0.75         6  40.350376   \n",
       "3      small       10             0.20            0.25         6  54.582109   \n",
       "4      small       10             0.20            0.50         6  59.702652   \n",
       "\n",
       "   first_train_loss first_mse first_rmse first_mae  ... last_mae  last_smape  \\\n",
       "0          0.007736       NaN        NaN       NaN  ...      NaN         NaN   \n",
       "1          0.006430       NaN        NaN       NaN  ...      NaN         NaN   \n",
       "2          0.006272       NaN        NaN       NaN  ...      NaN         NaN   \n",
       "3          0.005751       NaN        NaN       NaN  ...      NaN         NaN   \n",
       "4          0.005559       NaN        NaN       NaN  ...      NaN         NaN   \n",
       "\n",
       "                   windows best_epochs  \\\n",
       "0  [8, 10, 12, 13, 16, 17]         [5]   \n",
       "1  [8, 10, 12, 13, 16, 17]         [2]   \n",
       "2  [8, 10, 12, 13, 16, 17]         [5]   \n",
       "3  [8, 10, 12, 13, 16, 17]         [1]   \n",
       "4  [8, 10, 12, 13, 16, 17]         [1]   \n",
       "\n",
       "                                                                                                                                                                                                                                                        train_losses  \\\n",
       "0       [0.007736432538984124, 0.0005128225830048905, 0.0005199603820074117, 0.0005422921303761541, 0.0004997859355171386, 0.0004974375515303109, 0.00045875614750912064, 0.0004734527446998982, 0.000530040863850445, 0.0005426633420029248, 0.0004998219824301486]   \n",
       "1         [0.006430488714078606, 0.000524085031631532, 0.0005355071815655618, 0.0005009601663914509, 0.0005013609976837566, 0.0005612900616445889, 0.0005486514621427179, 0.000550172260166922, 0.0005089502002293658, 0.0005758699492920035, 0.0005521416019797067]   \n",
       "2         [0.006271722936718207, 0.0006348706265271176, 0.0005985666475680773, 0.0005996766253701935, 0.0006450319833675167, 0.0005909442588745151, 0.000589421743825369, 0.0006564614027411153, 0.000747456906537991, 0.0006651581325058942, 0.0006324679097815533]   \n",
       "3    [0.005750537991201889, 0.00035821853155291387, 0.0003467421626158863, 0.00039354360276113516, 0.0003589894873915579, 0.0003678229689037173, 0.0003760189326633488, 0.000406864230833228, 0.00037007326946794905, 0.0003714876517981545, 0.00035982841522623363]   \n",
       "4  [0.0055591320350585095, 0.00040115872828512994, 0.00037240337860566797, 0.00038632616239434964, 0.0004131425678982244, 0.000381480607757112, 0.0004053853596512151, 0.00040979710865940433, 0.00041176033058339573, 0.0004032611362466317, 0.0003834772696791333]   \n",
       "\n",
       "                                                                                       eval_pre  \\\n",
       "0   {'loss': [0.007736432538984124], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "1   {'loss': [0.006430488714078606], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "2   {'loss': [0.006271722936718207], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "3   {'loss': [0.005750537991201889], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "4  {'loss': [0.0055591320350585095], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "\n",
       "                                                                                      eval_post  \\\n",
       "0   {'loss': [0.007721100093262708], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "1   {'loss': [0.006421495916369809], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "2  {'loss': [0.0062546565241063945], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "3  {'loss': [0.0057909790236461796], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "4   {'loss': [0.005544954960189191], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               full_result  \\\n",
       "0  ([[0.007736432538984124, 0.0005128225830048905, 0.0005199603820074117, 0.0005422921303761541, 0.0004997859355171386, 0.0004974375515303109, 0.00045875614750912064, 0.0004734527446998982, 0.000530040863850445, 0.0005426633420029248, 0.0004998219824301486]], {'loss': [0.007736432538984124], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.007721100093262708], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [40.07394766807556], 40.07394766807556, [10.538601160049438, 9.383227825164795], 19.921828985214233, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (tokeniz...   \n",
       "1  ([[0.006430488714078606, 0.000524085031631532, 0.0005355071815655618, 0.0005009601663914509, 0.0005013609976837566, 0.0005612900616445889, 0.0005486514621427179, 0.000550172260166922, 0.0005089502002293658, 0.0005758699492920035, 0.0005521416019797067]], {'loss': [0.006430488714078606], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.006421495916369809], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [44.403908252716064], 44.403908252716064, [10.55851125717163, 9.44180154800415], 20.00031280517578, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (tokenizer)...   \n",
       "2  ([[0.006271722936718207, 0.0006348706265271176, 0.0005985666475680773, 0.0005996766253701935, 0.0006450319833675167, 0.0005909442588745151, 0.000589421743825369, 0.0006564614027411153, 0.000747456906537991, 0.0006651581325058942, 0.0006324679097815533]], {'loss': [0.006271722936718207], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.0062546565241063945], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [40.35037589073181], 40.35037589073181, [10.994718074798584, 9.992429256439209], 20.987147331237793, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (tokenize...   \n",
       "3  ([[0.005750537991201889, 0.00035821853155291387, 0.0003467421626158863, 0.00039354360276113516, 0.0003589894873915579, 0.0003678229689037173, 0.0003760189326633488, 0.000406864230833228, 0.00037007326946794905, 0.0003714876517981545, 0.00035982841522623363]], {'loss': [0.005750537991201889], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.0057909790236461796], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [54.58210873603821], 54.58210873603821, [10.48008108139038, 9.488317251205444], 19.968398332595825, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (toke...   \n",
       "4  ([[0.0055591320350585095, 0.00040115872828512994, 0.00037240337860566797, 0.00038632616239434964, 0.0004131425678982244, 0.000381480607757112, 0.0004053853596512151, 0.00040979710865940433, 0.00041176033058339573, 0.0004032611362466317, 0.0003834772696791333]], {'loss': [0.0055591320350585095], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, {'loss': [0.005544954960189191], 'mse': [nan], 'rmse': [nan], 'mae': [nan], 'smape': [nan]}, [59.70265173912048], 59.70265173912048, [11.059320211410522, 10.140296459197998], 21.19961667060852, MOMENTPipeline(\\n  (normalizer): RevIN()\\n  (t...   \n",
       "\n",
       "  first_eval_loss last_eval_loss  \n",
       "0        0.007736       0.007721  \n",
       "1        0.006430       0.006421  \n",
       "2        0.006272       0.006255  \n",
       "3        0.005751       0.005791  \n",
       "4        0.005559       0.005545  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"----- ERRORS -----\")\n",
    "print(f\"Total error cases: {len(errors_small)}\")\n",
    "display(errors_small.head())\n",
    "print(f\"Total results: {len(results_small)}\")\n",
    "display(results_small.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6948d68-3057-4deb-92f2-fca5c71a7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_small[\"best_epochs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871178b3-e64f-452f-b2da-12ab89a66604",
   "metadata": {},
   "source": [
    "#### Checking the errors\n",
    "Checking the error cases to see if they can be fixed within the code for the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f44688-12d2-416b-ad35-844e48610ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if already_computed_small:\n",
    "    display(results_small['windows'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ab241-fcae-430d-8384-bc8858b64399",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (already_computed_small):\n",
    "    errors_small['n_epochs'] = pd.to_numeric(errors_small['n_epochs'], errors='coerce').astype('Int64')\n",
    "    errors_small['n_windows'] = pd.to_numeric(errors_small['n_windows'], errors='coerce').astype('Int64')\n",
    "    errors_small['masked_percent'] = pd.to_numeric(errors_small['masked_percent'], errors='coerce').astype(float)\n",
    "    errors_small['error'] = errors_small['error'].astype(str)\n",
    "    print(results_small.dtypes)\n",
    "    results_small['model_size'] = results_small['model_size'].astype(pd.StringDtype())\n",
    "    print(\"--- Second check ---\")\n",
    "    print(results_small.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3216fb-52f5-4fe4-9075-a731c0220c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if already_computed_small:\n",
    "    display(results_small['windows'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aad8ff-8319-4fb3-a01f-24a288f20955",
   "metadata": {},
   "outputs": [],
   "source": [
    "if errors_small.shape[0] > 0:\n",
    "    error_small_window_sizes = list(errors_small['window'].drop_duplicates())\n",
    "    display(error_small_window_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe3ff8-644b-4801-9705-2eadd1e775f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if errors_small.shape[0] > 0:\n",
    "    error_small_mssg =errors_small['error'].astype(str).drop_duplicates()\n",
    "    display(error_small_mssg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928eb16-704e-44fb-8c10-a4925c50679f",
   "metadata": {},
   "source": [
    "We see two failures to check within the failures:\n",
    "1) Windows do no respect the requested distance between sepparated windows (only one with ne next). TODO: check\n",
    "2) This dataset needs windows bigger than 4 for MOMENT - Small. => \n",
    "    => We need:\n",
    "\n",
    "   - A minimum and maximum variate allowing to ask for windows sizes inside an interval\n",
    "   - Control within the windows sizes. If we all like this log table, we can save an unique variate (not saving the windows part) just to check if a window has already failed with this error so it does not execute again.\n",
    "   - ¿Buen TFG un SQL de gestión de errores para DeepVATS? -> Hablar con Víctor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe89c04-a249-499c-b584-3103b816f405",
   "metadata": {},
   "source": [
    "First valid window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b868c9-678f-47b5-854e-27f17d1faf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_windows = results_small['windows'].drop_duplicates()\n",
    "print(small_windows.shape)\n",
    "display(small_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5709c-d730-4c30-b478-caad93a822fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_windows = small_windows.apply(lambda x: greater_than(x, 5)).apply(sorted)\n",
    "filtered_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ac0b6-9384-461d-8183-12e5aab827c5",
   "metadata": {},
   "source": [
    "A futuros, se observa que, cuando analicemos este dataset, deberemos:\n",
    "- Usar ventanas mayores que 5, preferiblemente, >= 8.\n",
    "- Corregir la función de ventanas para que indique en un warning y en una variable el número de ventanas devuelto realmente. Gestionar para que si no se ha devuelto el número de ventanas esperado, se corte el loop ahí en lugar de repetir los mismos expserimentos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f45167-ecb9-4d7f-a4a5-bed6f7718b98",
   "metadata": {},
   "source": [
    "#### Time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479b3ed-397e-4f55-999e-5e54eafd6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = results_small['time'].sum()\n",
    "print(f\"{total_time} seconds\")\n",
    "print(f\"{total_time/60} minutes\")\n",
    "print(f\"{total_time/60/60} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c250e-744d-4f6b-96f4-cc2e0aa83016",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_small.plot(figsize = (10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b570d05-f109-470e-bd9f-99fd19e4e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_analysis_small = results_small[[\n",
    "    \"time\", \n",
    "    \"n_epochs\", \n",
    "    \"dataset_percent\", \n",
    "    \"masked_percent\", \n",
    "    \"n_windows\", \n",
    "    \"last_eval_loss\", \n",
    "    \"last_mse\"\n",
    "]]\n",
    "df_time_analysis_small.plot(figsize = (10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571287dd-432d-43e5-aebf-d82afc0a8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_multiple_secondary_y(df_time_analysis_small, [\"n_epochs\", \"time\", \"n_windows\"], [\"last_eval_loss\", \"dataset_percent\", \"masked_percent\", 'last_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29a068-d558-4fe5-ab0f-34dd838b55f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_df = df_time_analysis_small.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd2a715-9d57-4ae6-874c-114b47235e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile_small.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266a665-905a-4425-bc40-efd55eda91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ad28f-ce59-42d5-a85d-a8213857a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(profile_small_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e389d-d4fd-4b75-b50d-99cfbcbfec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir n_epochs y n_windows a enteros, manejando posibles errores\n",
    "profile_small_df['n_epochs'] = pd.to_numeric(profile_small_df['n_epochs'], errors='coerce').astype('Int64')\n",
    "profile_small_df['n_windows'] = pd.to_numeric(profile_small_df['n_windows'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convertir masked_percent a float, manejando posibles errores\n",
    "profile_small_df['masked_percent'] = pd.to_numeric(profile_small_df['masked_percent'], errors='coerce').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b1bea-9ce9-4804-8dc5-f2dee6ba1d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small = ydp.ProfileReport(profile_small_df, title=\"Pandas Profiling Report for 'df_time_analysis_small'\", explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15508ae-83cc-40f6-8db7-d1bca329aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    " plot_correlation(profile_small_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd32bfe-8b8f-46f4-949e-debb93bff6c9",
   "metadata": {},
   "source": [
    "A nivel de tiempo, se observa que:\n",
    "\n",
    "- Apenas afecta el enmascarado, con una correlación negativa con el last loss. Lo mismo ocurre con el n_epochs\n",
    "- Más tiempo parece hacer crecer el last_loss\n",
    "- Lo que más influye es el porcentaje de dataset utilizado para el fine_tuning. Más dataset parece hacer empeorar por alguna razón\n",
    "- El last loss está bastante relacionado con el tiempo dedicado al fine-tuning, como es de esperar. Pero. La correlación es positiva => más last loss => más tiempo.\n",
    "- El número de ventanas parece ir en contra de bajar el loss.. quizá porque va de la mano del número de ventanas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec05dc-3a5e-4865-8011-8115c572304e",
   "metadata": {},
   "source": [
    "### Loss & metrics analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf1e241-448c-4493-b1dd-bef35659f986",
   "metadata": {},
   "source": [
    "A nivel de losses, se observa (sin tener en cuenta mse, rmse, mae, smape): \n",
    "- Muy poca relación con el enmascarado, cosa que de primeras sorprende\n",
    "- Mucha relación con el % de dataset utilizado en el fine-tuning\n",
    "Por lo tanto,\n",
    "    - vamos a filtrar el dataset para tener tiempos menores a 8 segundos\n",
    "y buenos losses.\n",
    "    - Veamos a partir de qué momento se obtienen unos losses razonables  en %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71cfd22-7c55-4dd1-829b-581acca07ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674ee6d-c393-4174-81fa-c2fd7a107096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_small = results_small[[\n",
    "    \"time\", \"n_epochs\", \"dataset_percent\", \"masked_percent\", \"n_windows\", \n",
    "    \"first_eval_loss\", \"last_eval_loss\", \"first_mse\", \"last_mse\"\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c082720-0fb6-442d-a2bf-c9fa57baf26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_loss_small[[\"first_eval_loss\", \"last_eval_loss\"]])\n",
    "display(df_loss_small[[\"first_mse\", \"last_mse\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8614b42-f7d3-4f03-85c1-a9530afb5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_small[\"loss_percent\"] = (df_loss_small['first_eval_loss']-df_loss_small['last_eval_loss'])*100/(df_loss_small['first_eval_loss'])\n",
    "df_loss_small[\"loss_percent\"].plot()\n",
    "df_loss_small[\"mse_percent\"] = (df_loss_small['first_mse']-df_loss_small['last_mse'])*100/(df_loss_small['first_mse'])\n",
    "df_loss_small[\"mse_percent\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e4a33e-f451-4f88-a162-fb98ad97c8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_small[df_loss_small[\"loss_percent\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ded77-45ff-4b7a-b449-2bd25a39d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_small[df_loss_small[\"time\"] < 8][\"loss_percent\"].plot()\n",
    "df_loss_small[df_loss_small[\"time\"] < 8][\"mse_percent\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338a8e8-e958-4aff-8929-063f70e4e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde \"time\" es menor a 8 segundos\n",
    "df_loss_small_best_cases = df_loss_small[df_loss_small[\"time\"] < 8].copy()\n",
    "\n",
    "print(\"--------------------- Train -----------------\")\n",
    "# Filtrar los 5 mejores loss_percents\n",
    "display(df_loss_small_best_cases.sort_values('loss_percent', ascending = False)[:5])\n",
    "# Filtrar los 5 mejores loss_percent con dataset percent <= 0.25\n",
    "display(df_loss_small_best_cases[df_loss_small_best_cases['dataset_percent'] < 0.50].sort_values('loss_percent', ascending = False)[:5])\n",
    "print(\"---------------------- Eval ------------------\")\n",
    "# Filtrar los 5 mejores loss_percents\n",
    "display(df_loss_small_best_cases.sort_values('mse_percent', ascending = False)[:5])\n",
    "# Filtrar los 5 mejores loss_percent con dataset percent <= 0.25\n",
    "display(df_loss_small_best_cases[df_loss_small_best_cases['dataset_percent'] < 0.50].sort_values('loss_percent', ascending = False)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c0d7b-e069-46ca-8ac9-afaa0565fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir n_epochs y n_windows a enteros, manejando posibles errores\n",
    "profile_small_df = df_loss_small[['time', 'n_epochs', 'dataset_percent', 'masked_percent', 'n_windows', 'loss_train_percent', 'mse_percent']].copy()\n",
    "profile_small_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b039a2b-569e-4a64-8e17-0797749b1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir n_epochs y n_windows a enteros, manejando posibles errores\n",
    "profile_small_df['n_epochs'] = pd.to_numeric(profile_small_df['n_epochs'], errors='coerce').astype('Int64')\n",
    "profile_small_df['n_windows'] = pd.to_numeric(profile_small_df['n_windows'], errors='coerce').astype('Int64')\n",
    "# Convertir masked_percent a float, manejando posibles errores\n",
    "profile_small_df['masked_percent'] = pd.to_numeric(profile_small_df['masked_percent'], errors='coerce').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de9fc0a-74b7-4afa-b259-96e542ed405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small = ydp.ProfileReport(profile_small_df, title=\"Pandas Profiling Report for 'df_loss_small'\", explorative=True)\n",
    "plot_correlation(profile_small_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee757ab3-9f6c-43f0-939e-44511b1723ce",
   "metadata": {},
   "source": [
    "#### What if I focus on 0.25 dataset percent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f3829f-585e-4f62-ae40-04190252ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_df_2 = df_time_analysis_small[df_time_analysis_small['dataset_percent'] == 0.25].drop(columns=['dataset_percent', 'time']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227fedd-463d-47bc-ac11-f7f3e768f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_df_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6accfe3a-e970-46c5-ac48-240b4f498c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir n_epochs y n_windows a enteros, manejando posibles errores\n",
    "profile_small_df_2['n_epochs'] = pd.to_numeric(profile_small_df_2['n_epochs'], errors='coerce').astype('Int64')\n",
    "profile_small_df_2['n_windows'] = pd.to_numeric(profile_small_df_2['n_windows'], errors='coerce').astype('Int64')\n",
    "# Convertir masked_percent a float, manejando posibles errores\n",
    "profile_small_df_2['masked_percent'] = pd.to_numeric(profile_small_df_2['masked_percent'], errors='coerce').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ffeda-f910-43d9-b660-f625e55a444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_2 = ydp.ProfileReport(profile_small_df_2, title=\"Pandas Profiling Report for 'df_time_analysis_small' for < 0.25 dataset percent\", explorative=True)\n",
    "plot_correlation(profile_small_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ebb4b-0caa-4c6f-bfb6-c1e87e6654bf",
   "metadata": {},
   "source": [
    "* Correlación inversa entre masked percent y last loss * => Aumentar masked percent baja last_loss\n",
    "* => Es parte de lo que queremos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4803b-74c7-43d8-831d-6cfef0984baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ls errors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d2079-9853-403a-861d-d643b7ff0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406e592-2fff-49cb-b9fc-adb652e58a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(before)\n",
    "moment_small.to('cpu')\n",
    "for param in moment_small.parameters():\n",
    "    param.to('cpu')\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "print(\"Mejorado: \", after-before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414fd389-fa05-4d7e-8f59-b850b537e09d",
   "metadata": {},
   "source": [
    "## Moment-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264a4e8-012f-4dbc-9ab7-0a5f164e2f83",
   "metadata": {},
   "source": [
    "### Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54bbfd3-3512-4acc-b98b-aed6f483fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting base artifact: \", enc_artifact_base_name)\n",
    "enc_artifact_base  = wandb_api.artifact(enc_artifact_base_name, type='learner')\n",
    "moment_base  = enc_artifact_base.to_obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e29b9-7cae-4254-af20-381cfe1d868e",
   "metadata": {},
   "source": [
    "### Select parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613fad1a-dc25-4747-83e8-96a40f5f47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases_small      = len(n_epochs_list)*len(dataset_percents)*len(masked_percents)*len(sizes)\n",
    "print(f\"Total cases: {total_cases_small}\")\n",
    "n_epochs_list_base= [5, 10, 20]\n",
    "dataset_percents_base  = [0.25, 0.5]\n",
    "masked_percents_base = [ 0.25, 0.5, 0.75]\n",
    "sizes_base             = [1, 5, 10]\n",
    "total_cases_base = len(n_epochs_list_base)*len(dataset_percents_base)*len(masked_percents_base)*len(sizes)\n",
    "print(f\"Total cases: {total_cases_base}\")\n",
    "expected_time = total_time*total_cases_base/total_cases_small\n",
    "print(f\"Expected time: {expected_time} seconds | {expected_time/60} minutes | {expected_time/60/60} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf86a99-372a-4b35-829c-70d92f2da2e9",
   "metadata": {},
   "source": [
    "### Configure files and wether already computed or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7084c9a-ee98-4912-b20a-5045f256057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_computed_base = True\n",
    "results_base = None\n",
    "errors_base = None\n",
    "file_errors_base = 'errors_base_24012025_1.csv'\n",
    "file_results_base = 'results_base_24012025_1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc441508-e2bb-4d8e-8399-80cf99759965",
   "metadata": {},
   "source": [
    "### Execute cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7e89a-c9e1-4c9b-9024-a8351af8c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base = None\n",
    "errors_base = None\n",
    "if already_computed_base:\n",
    "    results_base = pd.read_csv(file_results_base, index_col=None, header=0)\n",
    "    errors_base = pd.read_csv(file_errors_base, index_col=None, header=0)\n",
    "else:\n",
    "    results_base, errors_base = cases_loop(\n",
    "        model             = moment_base, \n",
    "        n_epochs_list     = n_epochs_list_base, \n",
    "        dataset_percents  = dataset_percents_base, \n",
    "        masked_percents = masked_percents_base,\n",
    "        n_sizes_list      = sizes_base, \n",
    "        summarized        = True,\n",
    "        verbose           = 8\n",
    "    )\n",
    "    results_base.to_csv(file_results_base, index=False, header=True)\n",
    "    errors_base.to_csv(file_errors_base, index=False, header=True)\n",
    "    already_computed_base = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb2dca-5bbc-49ac-bffa-66e4b9f3cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----- ERRORS -----\")\n",
    "print(f\"Total error cases: {len(errors_base)}\")\n",
    "display(errors_base.head())\n",
    "print(f\"Total results: {len(results_base)}\")\n",
    "display(results_base.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d358d9-271a-4052-bd5d-077f40b4eb30",
   "metadata": {},
   "source": [
    "### Checking the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f5e13d-72a7-4821-8001-aad46880643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7e028-5461-40aa-9b04-27d03ce897de",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_base_window_sizes = list(errors_base['windows'].drop_duplicates())\n",
    "error_base_window_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7801e-3ab1-42bb-bc18-5d220f88e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_base_mssg = errors_base['error'].astype(str).drop_duplicates()\n",
    "error_base_mssg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b7fc3-25e2-4f5b-a411-cf318ef67b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_windows = results_base['windows'].drop_duplicates()\n",
    "filtered_windows_base = base_windows.apply(lambda x: greater_than(x, 5)).apply(sorted)\n",
    "filtered_windows_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eeddc4-025c-441b-9ff2-dff26bec2947",
   "metadata": {},
   "source": [
    "#### Time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ee0da-4944-4820-b347-2390ac17b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_analysis_base = results_base[[\"time\", \"n_epochs\", \"dataset_percent\", \"masked_percent\", \"n_windows\", \"last_train_loss\", \"last_mse\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a910969-f110-44e6-93bb-7392a57ab008",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_multiple_secondary_y(df_time_analysis_base, [\"n_epochs\", \"time\", \"n_windows\"], [\"last_train_loss\", \"dataset_percent\", \"masked_percent\", \"last_mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3e45e-7c4f-4d4a-8a7f-72b6798ea237",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_base_df = df_time_analysis_base.copy(deep = True)\n",
    "profile_base = ydp.ProfileReport(profile_base_df, title=\"Pandas Profiling Report for 'df_time_analysis_base'\", explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81dedec-a5d7-4602-a9cf-474912ad762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(profile_base_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978762e0-dd22-42de-931c-32eb839e41fe",
   "metadata": {},
   "source": [
    "#### Loss & metrics analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f15fb2-2ece-4d25-baed-1f4f8080ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_base = results_base[[\"time\", \"n_epochs\", \"dataset_percent\", \"masked_percent\", \"n_windows\", \"first_train_loss\", \"last_train_loss\", \"first_mse\", \"last_mse\"]].copy()\n",
    "df_loss_base[\"loss_percent\"] = (df_loss_base['first_train_loss']-df_loss_base['first_train_loss'])*100/(df_loss_base['first_train_loss'])\n",
    "df_loss_base[\"loss_percent\"].plot()\n",
    "df_loss_base[\"mse_percent\"] = (df_loss_base['first_mse']-df_loss_base['last_mse'])*100/(df_loss_base['first_mse'])\n",
    "df_loss_base[\"mse_percent\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b2cef-b539-4733-b898-5c326f215192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_base[df_loss_base[\"time\"] < 8][\"loss_percent\"].plot()\n",
    "df_loss_base[df_loss_base[\"time\"] < 8][\"mse_percent\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba834381-5c97-433c-9f10-2913e5874ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_base[df_loss_base[\"time\"] < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ebec6-c4f6-4510-8a7c-a340c080b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde \"time\" es menor a 8 segundos\n",
    "df_loss_base_best_cases = df_loss_base[df_loss_base[\"time\"] < 8].copy()\n",
    "\n",
    "print(\"---- Mejoras en el entrenamiento ----\")\n",
    "# Filtrar los 5 mejores loss_percents\n",
    "display(df_loss_base_best_cases.sort_values('loss_percent', ascending = False)[:5])\n",
    "# Filtrar los 5 mejores loss_percent con dataset percent <= 0.25\n",
    "display(df_loss_base_best_cases[df_loss_base_best_cases['dataset_percent'] < 0.50].sort_values('loss_percent', ascending = False)[:5])\n",
    "print(\"---- Mejoras en la validación  ----\")\n",
    "# Filtrar los 5 mejores loss_percents\n",
    "display(df_loss_base_best_cases.sort_values('mse_percent', ascending = False)[:5])\n",
    "# Filtrar los 5 mejores loss_percent con dataset percent <= 0.25\n",
    "display(df_loss_base_best_cases[df_loss_base_best_cases['dataset_percent'] < 0.50].sort_values('mse_percent', ascending = False)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f489bb7-5683-41f7-8f29-c12aac60110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1988ef9-ae17-4e6b-b8b1-4a440f5666d9",
   "metadata": {},
   "source": [
    "## Moment-large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdd297a-e26f-4686-a5ef-1da8fb9bd656",
   "metadata": {},
   "source": [
    "### Download de large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c25e22-b9c4-4afd-b1d4-eb619d6b5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_computed_large = True\n",
    "file_errors_large = 'errors_large_03022025_1.csv'\n",
    "file_results_large = 'results_large_03022025_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b62983-c152-4aa1-b294-d47babd15499",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not already_computed_large:\n",
    "    print(\"Getting large artifact: \", enc_artifact_large_name)\n",
    "    enc_artifact_large = wandb_api.artifact(enc_artifact_large_name, type='learner')\n",
    "    print(enc_artifact_large.name)\n",
    "    moment_large = enc_artifact_large.to_obj()\n",
    "    print(count_parameters(moment_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064fe3c-dc39-4603-a616-a8e2192d747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases_small      = len(n_epochs_list)*len(dataset_percents)*len(masked_percents)*len(sizes)\n",
    "print(f\"Total cases: {total_cases_small}\")\n",
    "total_cases_base = len(n_epochs_list_base)*len(dataset_percents_base)*len(masked_percents_base)*len(sizes)\n",
    "print(f\"Total cases: {total_cases_base}\")\n",
    "expected_time = total_time*total_cases_base/total_cases_small\n",
    "print(f\"Expected time: {expected_time} seconds | {expected_time/60} minutes | {expected_time/60/60} hours\")\n",
    "\n",
    "n_epochs_list_large     = [5, 10, 20]\n",
    "dataset_percents_large  = [0.25, 0.5] # No tendría sentido porque sería como hacer lo mismo que con mvp\n",
    "masked_percents_large = [0.25, 0.5, 0.75]\n",
    "sizes_large             = [1, 5, 10]\n",
    "print(f\"Total cases: {len(n_epochs_list)*len(dataset_percents)*len(masked_percents)*len(sizes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b1888-2643-400f-8993-0d6fa42404bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated()\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50efcd6-3202-471c-818c-0c70be3bc40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_large = None\n",
    "errors_large = None\n",
    "if already_computed_large:\n",
    "    results_large = pd.read_csv(file_results_large, index_col=None, header=0)\n",
    "    errors_large = pd.read_csv(file_errors_large, index_col=None, header=0)\n",
    "else:\n",
    "    results_large, errors_large = cases_loop(\n",
    "        model             = moment_large, \n",
    "        n_epochs_list     = n_epochs_list_large,\n",
    "        dataset_percents  = dataset_percents_large, \n",
    "        masked_percents = masked_percents_large, \n",
    "        n_sizes_list      = sizes_large, \n",
    "        summarized        = True,\n",
    "        save              = True,\n",
    "        file_errors       =  file_errors_large,\n",
    "        file_results      = file_results_large\n",
    "    )\n",
    "    already_computed_large = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490ad9c-ea47-48a3-acd6-1a233fd56886",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----- ERRORS -----\")\n",
    "print(f\"Total error cases: {len(errors_large)}\")\n",
    "display(errors_large.head())\n",
    "print(f\"Total results: {len(results_large)}\")\n",
    "display(results_large.head())\n",
    "print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1de1e-1ca4-4463-956d-4ee3d872e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----- ERRORS -----\")\n",
    "print(f\"Total error cases: {len(errors_large)}\")\n",
    "display(errors_large.head())\n",
    "print(f\"Total results: {len(results_large)}\")\n",
    "display(results_large.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad3529-6850-4209-8dae-277d647f7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(before)\n",
    "moment_large.to('cpu')\n",
    "for param in moment_large.parameters():\n",
    "    param.to('cpu')\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "gc.collect()\n",
    "print(\"Mejorado: \", after-before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcfb4e5-af9b-4601-b4b4-56ba1f43fe4e",
   "metadata": {},
   "source": [
    "#### Errors analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f048de-9dec-4abd-a867-360914ea3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(errors_large) > 0:\n",
    "    error_large_window_sizes = list(errors_large['window'].drop_duplicates())\n",
    "    error_large_window_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeda773-9f48-493d-b7b5-3635b875c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    error_large_mssg = errors_large['error'].astype(str).drop_duplcates()\n",
    "    display(error_large_mssg)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1acc3d-6c22-4bc0-8ee7-b9a0ec9298dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_windows = results_large['windows'].drop_duplicates()\n",
    "print(large_windows.shape)\n",
    "display(large_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb41ed4c-988d-4e5e-be58-753870384cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_windows_large = large_windows.apply(lambda x: greater_than(x, 5)).apply(sorted)\n",
    "display(filtered_windows_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a19ffd-2f73-4e57-9644-eac0b3146f2c",
   "metadata": {},
   "source": [
    "#### Time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed948f8-9858-4137-b5fe-848b44896f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_analysis_large = results_large[[\"time\", \"n_epochs\", \"dataset_percent\", \"masked_percent\", \"n_windows\", \"last_train_loss\", 'last_mse']]\n",
    "df_time_analysis_large.plot(figsize = (10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8bb44c-87a0-4c8d-ac90-5ab25b6fb616",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_multiple_secondary_y(df_time_analysis_large, [\"n_epochs\", \"time\", \"n_windows\"], [\"last_train_loss\", 'last_mse', \"dataset_percent\", \"masked_percent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c0454-c417-4ad3-bc10-a0bf38638133",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_large_df = df_time_analysis_large.copy(deep = True)\n",
    "profile_large = ydp.ProfileReport(profile_large_df, title = \"Pandas Profiling Report for 'df_time_analysis_large'\", explorative = True)\n",
    "#profile_large.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d528e-e13e-4cc8-9164-3e60e03d580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(profile_large_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab34016-1741-41b0-9106-0b9489877774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_large = results_large[[\"time\", \"n_epochs\", \"dataset_percent\", \"masked_percent\", \"n_windows\", \"first_train_loss\", \"last_train_loss\", \"first_mse\", \"last_mse\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979c8e1-251b-42a9-9c80-5ce7a3be554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_large[\"loss_train_percent\"] = (df_loss_large['first_train_loss']-df_loss_large['last_train_loss'])*100/(df_loss_large['first_train_loss'])\n",
    "df_loss_large[\"mse_percent\"] = (df_loss_large['first_mse']-df_loss_large['last_mse'])*100/(df_loss_large['first_mse'])\n",
    "df_loss_large[\"loss_train_percent\"].plot()\n",
    "df_loss_large[\"mse_percent\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea9672-cd80-4310-ad7d-5a8e943db0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_large_best_cases = df_loss_large[df_loss_large[\"time\"] < 8].copy()\n",
    "display(df_loss_large_best_cases)\n",
    "print(\"--- train ---\")\n",
    "display(df_loss_large_best_cases[df_loss_large_best_cases[\"loss_train_percent\"] > 0])\n",
    "print(\"--- eval ---\")\n",
    "display(df_loss_large_best_cases[df_loss_large_best_cases[\"mse_percent\"] > 0])\n",
    "display(df_loss_large_best_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb8c4c1-42e0-456b-9be5-43e69e6f2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_loss_large_best_cases.sort_values('loss_train_percent', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0cb48-97e4-49d6-bf6c-24ad950430b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(before)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "print(after-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed36ec-df77-4665-a3cd-e68ec70c7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_tensors = []\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_cuda:\n",
    "            gpu_tensors.append(obj)\n",
    "    except ReferenceError:\n",
    "        continue # Omitir los objetos que ya han sido recolectados\n",
    "print(len(gpu_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddd7d94-c94b-4877-8317-1e33854fba45",
   "metadata": {},
   "source": [
    "#### Loss & metrics analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a24fb-4416-4345-a1c8-131bed978e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"Execution ended\")\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca0597-64fb-4bc5-946f-2ae110b3cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if reset_kernel:\n",
    "    os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90638374-ae0b-4278-ba27-94ed52d3c57d",
   "metadata": {},
   "source": [
    "# Memory checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1265415-2bed-4ef2-8358-ae5ab0d43cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = torch.cuda.memory_snapshot()\n",
    "gpu_tensors = [obj['tensor'] for obj in snapshot if 'tensor' in obj]\n",
    "for tensor_info in gpu_tensors:\n",
    "    print(f\"Size: {tensor_info['size']}, Device: {tensor_info['device']}, Data type: {tensor_info['dtype']}\")\n",
    "print(gpu_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa9143-19c1-4d0a-a697-7ceee18a1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_types = set()\n",
    "for obj in snapshot:\n",
    "    for key in obj.keys():\n",
    "        object_types.add(key)\n",
    "print(\"Tipos de objetos encontrados en el snapshot:\")\n",
    "for obj_type in sorted(object_types):\n",
    "    print(obj_type)\n",
    "heavier_obj = None\n",
    "for obj in snapshot:\n",
    "    if heavier_obj is None or obj['total_size'] > heavier_obj['total_size']: heavier_obj = obj\n",
    "print(heavier_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a09491-9ae1-41d2-b03e-ccef4b6cdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(torch.cuda.memory_allocated())\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated())\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "print(\"Mejorado: \", after-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381e0c7-52f0-43f4-a69c-430643e58131",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(before)\n",
    "moment_small.to('cpu')\n",
    "for param in moment_small.parameters():\n",
    "    param.to('cpu')\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "print(\"Mejorado: \", after-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d99125-ae8a-4d90-8cc1-1e08d15300a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(before)\n",
    "moment_base.to('cpu')\n",
    "for param in moment_base.parameters():\n",
    "    param.to('cpu')\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "print(\"Mejorado: \", after-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18604ec4-f939-44aa-b69a-540389e63fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(before)\n",
    "moment_large.to('cpu')\n",
    "for param in moment_large.parameters():\n",
    "    param.to('cpu')\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "print(\"Mejorado: \", after-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f606e-0b0a-4f14-9317-8134bab45c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10511640-eb29-42a0-aff2-e7582bffb687",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_small_window_sizes = list(errors_small_hoy['windows'].drop_duplicates())\n",
    "error_small_window_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8598826-072b-44cb-a858-9ee1c4f17112",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_small_hoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d515610-ff36-4e65-a426-c7e429d7db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = results_small_hoy['time'].sum()\n",
    "print(f\"{total_time} seconds\")\n",
    "print(f\"{total_time/60} minutes\")\n",
    "print(f\"{total_time/60/60} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab3b72-dad5-4951-8a5e-71d911947728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_analysis_small = results_small_hoy[[\"time\", \"n_epochs\", \"dataset_percent\", \"masked_percent\", \"last_train_loss\", 'last_mse']]\n",
    "df_time_analysis_small.plot(figsize = (10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff0031-97a3-4a1a-9f71-20df7d4ed541",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_multiple_secondary_y(df_time_analysis_small, [\"n_epochs\", \"time\"], [\"last_train_loss\", \"dataset_percent\", \"masked_percent\", 'last_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be06cac-fd1f-44b9-8f44-bd1f3cad3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_df = df_time_analysis_small.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4fac3b-8fc3-48dd-8588-44918008f2d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"--- Cases ---\")\n",
    "print(\"--- Number of epochs ---\")\n",
    "print(profile_small_df[\"n_epochs\"].unique())\n",
    "print(\"--- Dataset percent ---\")\n",
    "print(profile_small_df[\"dataset_percent\"].unique())\n",
    "print(\"--- Dataset masked percent ---\")\n",
    "print(profile_small_df[\"masked_percent\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587a8e1-5ef5-48b5-8531-f11e8fb33412",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c133071-376c-4d58-bb9f-cb48c0b9cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(profile_small_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a014e16-28cc-4d71-9622-b083266c7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir n_epochs y n_windows a enteros, manejando posibles errores\n",
    "profile_small_df['n_epochs'] = pd.to_numeric(profile_small_df['n_epochs'], errors='coerce').astype('Int64')\n",
    "#profile_small_df['n_windows'] = pd.to_numeric(profile_small_df['n_windows'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convertir masked_percent a float, manejando posibles errores\n",
    "profile_small_df['masked_percent'] = pd.to_numeric(profile_small_df['masked_percent'], errors='coerce').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f271e-45a8-41a8-85fc-8e1c4784c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small = ydp.ProfileReport(profile_small_df, title=\"Pandas Profiling Report for 'df_time_analysis_small'\", explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d04f5-6bab-4080-addb-46ddcff2cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    " plot_correlation(profile_small_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
