{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de2cd87-7d93-45ec-bd92-d97a85cf73b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Moment models fine-tune analysis | Mask test\n",
    "> This notebook is the pre-analysis of moment models to select the cases used in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56a9cd9-f767-4fcd-93b2-2134bb45f4c4",
   "metadata": {},
   "source": [
    "# RECORDATORIO \n",
    "1) Conseguir que compilen de nuevo\n",
    "2) Enmascarar también en evaluación, no solo en training, majaretilla..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816ae963-a2d2-467a-90ee-2be0f383c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "model_patch_size = 8\n",
    "verbose          = 0\n",
    "reset_kernel     = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401ff0c4-38c2-44de-953e-23581b731c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install --no-deps ydata_profiling\n",
    "#! pip install --no-deps dacite\n",
    "#! pip install --no-deps multimethod\n",
    "#! pip install --no-deps visions\n",
    "#! pip install --no-deps wordcloud\n",
    "#! pip install --no-deps imagehash\n",
    "#! pip install --no-deps htmlmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db2cd5f-dd8d-42a3-bdc1-afc12ff80afb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcWriteOptions size changed, may indicate binary incompatibility. Expected 72 from C header, got 88 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcReadOptions size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Tensor size changed, may indicate binary incompatibility. Expected 64 from C header, got 80 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.ChunkedArray size changed, may indicate binary incompatibility. Expected 64 from C header, got 72 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Table size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.NativeFile size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7f886ce08e50>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from dvats.all import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from yaml import load, FullLoader\n",
    "import dvats.utils as ut\n",
    "from dvats.imports import beep\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import ydata_profiling as ydp\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6774bdd-fc22-4e8e-96c4-c29417380137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#torch.cuda.set_device(0)\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13a26bc-3ff6-4167-9f7c-1dba7d10ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.losses import MSELossFlat\n",
    "from dvats.encoder import MAELossFlat, EvalMSE, EvalRMSE, EvalMAE, EvalSMAPE\n",
    "import dvats.config as cfg_\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08922829-19f7-4cdc-97b1-86f5a3b4f3d2",
   "metadata": {},
   "source": [
    "### Setting up Weight & Biases information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d0b55c5-b182-420e-9935-724879313e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User and project\n",
    "entity = os.environ.get(\"WANDB_ENTITY\")\n",
    "project = os.environ.get(\"WANDB_PROJECT\")\n",
    "folder = entity+'/'+project+'/'\n",
    "\n",
    "# Dataset\n",
    "dataset = 'gtrends_kohls'\n",
    "dataset_version = 'v2'\n",
    "enc_artifact_dataset = folder + dataset + ':' + dataset_version\n",
    "\n",
    "# Models\n",
    "model_family = 'zeroshot-moment'\n",
    "task = 'embedding'\n",
    "enc_artifact_small_name = folder + model_family + '-small-' + task + ':v0'\n",
    "enc_artifact_base_name  =  folder + model_family + '-base-' + task + ':v0'\n",
    "enc_artifact_large_name = folder + model_family + '-large-' + task + ':v0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d81c7-d4fd-4949-a5bf-2edd041fcbee",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15b94a4-19cb-47c0-a000-b0890d303ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataset artifact:  mi-santamaria/deepvats/gtrends_kohls:v2\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting dataset artifact: \", enc_artifact_dataset)\n",
    "df_artifact = wandb_api.artifact(enc_artifact_dataset, type = 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dfcdf28-2518-49af-8c64-c2305ba71a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtrends_kohls:v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-15</th>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-22</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-29</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              volume\n",
       "2004-01-01  0.010417\n",
       "2004-01-08  0.010417\n",
       "2004-01-15  0.010417\n",
       "2004-01-22  0.000000\n",
       "2004-01-29  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(440, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_artifact.name)\n",
    "df = df_artifact.to_df()\n",
    "display(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1794082-ba18-4bde-acc2-07e57a0e4fae",
   "metadata": {},
   "source": [
    "### Encoder Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49908f03-6875-4e27-8050-09af41dc62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc_input, _ = SlidingWindow(window_len=17, stride=2, get_y=[])(df)\n",
    "#enc_input.shape\n",
    "enc_input = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01342017-6520-4040-8c44-44266672bb1c",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c96a07c9-7211-4d2a-ab1b-50838d630b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    #return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def greater_than(lst, val):\n",
    "    vals = []\n",
    "    for x in lst:\n",
    "        try:\n",
    "            x = int(x)\n",
    "            if (x > val): \n",
    "                vals.append(x)\n",
    "        except:\n",
    "            continue\n",
    "    return vals\n",
    "    #return [ x for x in lst if isinstance(x, int) and x > val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e6b413-774f-4cbe-bb24-10380277bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_multiple_secondary_y(df, primary_vars, secondary_vars, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    Plots multiple variables with different scales on primary and secondary y-axes.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing the data.\n",
    "    - primary_vars (list): Variables to plot on the primary y-axis.\n",
    "    - secondary_vars (list): Variables to plot on the secondary y-axis.\n",
    "    - figsize (tuple): Size of the figure.\n",
    "\n",
    "    Returns:\n",
    "    - None: Displays the plot.\n",
    "    \"\"\"\n",
    "    ax = df[primary_vars + secondary_vars].plot(\n",
    "        secondary_y=secondary_vars, figsize=figsize\n",
    "    )\n",
    "    ax.set_title(\"Variables with Primary and Secondary Axes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "591ecfec-8a92-4c89-b0c2-2e55ce81e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation(profile, figsize=(8, 6)):\n",
    "    correlation_matrix = profile.corr()\n",
    "    # Crear el heatmap con seaborn\n",
    "    plt.figure(figsize = figsize)  # Ajusta el tamaño si es necesario\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
    "    plt.title(\"Correlation Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655a007-a52e-4dd9-9c4d-b9efdf975997",
   "metadata": {},
   "source": [
    "### Common Fine-tune args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d77cb4e-da4b-4f01-a30c-c145b97d1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "user, project, version, data, config, job_type = cfg_.get_artifact_config_MVP(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04301513-8b67-47a5-8140-96f4381e64e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "0.4\n",
      "online\n"
     ]
    }
   ],
   "source": [
    "print(config['batch_size'])\n",
    "print(config['r'])\n",
    "print(config['analysis_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "551d968d-841a-45bf-9344-59aa9f7b3f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['r'] = 1e-6\n",
    "config['r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14063f3e-f810-4906-89b7-76f73ba93ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['norm_use_single_batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fafa294-2aca-4448-a6c9-c5b67a2668f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args = {\n",
    "    \"X\": df,\n",
    "    \"stride\": 1,\n",
    "    \"batch_size\": config['batch_size'],\n",
    "    \"cpu\": False,\n",
    "    \"to_numpy\": False,\n",
    "    \"time_flag\": True,\n",
    "    \"n_windows\": None,\n",
    "    \"n_windows_percent\": None,\n",
    "    \"shot\": True,\n",
    "    \"eval_pre\": True,\n",
    "    \"eval_post\": True,\n",
    "    \"lr\": config['r'], #use enc_run lr,\n",
    "    \"lr_scheduler_flag\": False,\n",
    "    \"lr_scheduler_name\": \"cosine_with_restarts\",\n",
    "    \"lr_scheduler_num_warmup_steps\": None,\n",
    "    \"window_sizes\": [12],\n",
    "    \"full_dataset\": True,\n",
    "    \"window_sizes_offset\": 0.05,\n",
    "    \"windows_min_distance\": 0, #int(np.ceil(1.5*enc_input.shape[0]/100)),\n",
    "    \"print_to_path\": False,\n",
    "    \"print_both\": True,\n",
    "    \"print_path\": \"./logs.txt\",\n",
    "    \"print_mode\": \"w\",\n",
    "    \"use_moment_masks\": True,\n",
    "    \"mask_stateful\": config['mask_stateful'],\n",
    "    \"mask_future\": config['mask_future'],\n",
    "    \"mask_sync\": config['mask_sync'],\n",
    "    \"analysis_mode\": config['analysis_mode'],\n",
    "    \"use_wandb\": config['use_wandb'],\n",
    "    \"norm_by_sample\": config['norm_by_sample'],\n",
    "    \"norm_use_single_batch\": config['norm_use_single_batch'],\n",
    "    \"show_plot\": True,\n",
    "    \"metrics\": [EvalMSE, EvalRMSE, EvalMAE, EvalSMAPE],\n",
    "    \"metrics_args\": [{'squared': False}, {'squared': True}, {}, {}],\n",
    "    \"metrics_names\":[\"mse\", \"rmse\", \"mae\", \"smape\"],\n",
    "    \"metrics_dict\": None,\n",
    "    \"criterion\": torch.nn.MSELoss(),\n",
    "    \"mix_windows\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f48c132c-9054-483c-a858-b60ef36b016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_args[\"windows_min_distance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78871a0-aaa8-4efd-98d0-02465d07e787",
   "metadata": {},
   "source": [
    "### Cases execution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b16aa004-1d43-4ea6-a598-9eb1b332e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from momentfm.utils.masking import Masking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c505452b-ab49-464f-856c-46288048c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cases_loop(\n",
    "    model, \n",
    "    n_epochs_list, \n",
    "    dataset_percents, \n",
    "    masked_percents, \n",
    "    n_sizes_list, \n",
    "    summarized = True, \n",
    "    do_beep = True, \n",
    "    verbose = 1,\n",
    "    save = True,\n",
    "    file_errors = \"\",\n",
    "    file_results = \"\"\n",
    "):\n",
    "    mssg = ut.Mssg(verbose = verbose, level = -1)\n",
    "    result_columns = [\n",
    "        'model_size','n_epochs','dataset_percent','masked_percent','n_windows', \n",
    "        'time',\n",
    "        'first_train_loss','first_mse','first_rmse','first_mae','first_smape', \n",
    "        'last_train_loss','last_mse','last_rmse','last_mae','last_smape'\n",
    "    ]\n",
    "    result_columns = result_columns if summarized else result_columns + ['losses','eval_results_pre','eval_results_post']\n",
    "    results = pd.DataFrame(columns = result_columns)\n",
    "    \n",
    "    errors = pd.DataFrame(\n",
    "        columns = [\n",
    "            'model_size',\n",
    "            'n_epochs',\n",
    "            'dataset_percent',\n",
    "            'masked_percent',\n",
    "            'n_windows',\n",
    "            'windows',\n",
    "            'error'\n",
    "        ]\n",
    "    )\n",
    "    model_backup = deepcopy(model)\n",
    "    i = 0\n",
    "    for n_epochs in n_epochs_list:\n",
    "        for dataset_percent in dataset_percents:\n",
    "            print(dataset_percent)\n",
    "            for masked_percent in masked_percents:\n",
    "                model.mask_generator = Masking(mask_ratio = masked_percent)\n",
    "                for sizes in n_sizes_list:\n",
    "                    print(f\"--> epoch {n_epochs}, dataset_percent {dataset_percent}, mask {masked_percent}\")\n",
    "                    print(f\" sizes {sizes}\")\n",
    "                    print(f\"Cuda memmory allocated: {torch.cuda.memory_allocated()}\")\n",
    "                    model_case = deepcopy(model_backup)\n",
    "                    case = {\n",
    "                            'model_size': \"small\",\n",
    "                            'n_epochs': n_epochs,\n",
    "                            'dataset_percent': dataset_percent,\n",
    "                            'masked_percent': masked_percent,\n",
    "                            'n_windows': sizes,\n",
    "                            'windows': None\n",
    "                           }\n",
    "                    result_dict = deepcopy(case)\n",
    "                    error_dict = deepcopy(case)\n",
    "                    error = False\n",
    "                    print(1-dataset_percent)\n",
    "                    torch.cuda.synchronize()\n",
    "                    result = fine_tune(\n",
    "                        enc_learn           = model_case,\n",
    "                        window_mask_percent = masked_percent,\n",
    "                        training_percent    = dataset_percent,\n",
    "                        validation_percent  = 0.3,\n",
    "                        num_epochs          = n_epochs,\n",
    "                        n_window_sizes      = sizes,\n",
    "                        verbose             = verbose,\n",
    "                        register_errors     = False,\n",
    "                        save_best_or_last   = True, # only available for moment\n",
    "                        **common_args    \n",
    "                    )\n",
    "                    common_args['print_mode']='a'\n",
    "\n",
    "                    try:\n",
    "                        internal_errors = result[10]\n",
    "                    except:\n",
    "                        internal_errors = pd.DataFrame(columns=[\"window\", \"error\"])\n",
    "                        \n",
    "                    \n",
    "                    if len(result[0]) > 0:\n",
    "                    \n",
    "                        result_dict.update({\n",
    "                            'time'             : result[4],\n",
    "                            'windows'          : result[8].cpu() if isinstance(result[8], torch.Tensor) else result[8],\n",
    "                            'first_train_loss' : result[0][0][0].cpu().item() if torch.is_tensor(result[0][0][0]) else result[0][0][0],\n",
    "                            'last_train_loss'  : result[0][-1][-1].cpu().item() if torch.is_tensor(result[0][-1][-1]) else result[0][-1][-1],\n",
    "                            'best_epochs'       : result[9],\n",
    "                            'train_losses'      : result[0][0],\n",
    "                            'eval_pre'          : result[1],\n",
    "                            'eval_post'         : result[2],\n",
    "                            'full_result'       : result\n",
    "                        })\n",
    "                        if result[1] == {}:\n",
    "                            raise ValueError(\"No evaluation pre!\")\n",
    "                            result_dict.update({\n",
    "                                'first_eval_loss'  : np.nan,\n",
    "                                'first_mse'        : np.nan,\n",
    "                                'first_rmse'       : np.nan,\n",
    "                                'first_mae'        : np.nan\n",
    "                            })\n",
    "                        else:\n",
    "                            print(\"N windows: \", len(result[8]))\n",
    "                            print(\"Loss: \", result[1]['loss'])\n",
    "                            result_dict.update({\n",
    "                                'first_eval_loss'  : result[1]['loss'][-1].cpu().item() if torch.is_tensor(result[1]['loss']) else result[1]['loss'][-1],\n",
    "                                'first_mse'        : result[1]['mse'][-1].cpu().item() if torch.is_tensor(result[1]['mse']) else result[1]['mse'][-1],    \n",
    "                                'first_rmse'       : result[1]['rmse'][-1].cpu().item() if torch.is_tensor(result[1]['rmse']) else result[1]['rmse'][-1],\n",
    "                                'first_mae'        : result[1]['mae'][-1].cpu().item() if torch.is_tensor(result[1]['mae']) else result[1]['mae'][-1],                                'first_smape'      : result[1]['smape'].cpu().item() if torch.is_tensor(result[1]['smape']) else result[1]['smape'],\n",
    "\n",
    "                            })\n",
    "                        if result[2] == {}:\n",
    "                            result_dict.update({\n",
    "                                'last_eval_loss'  : np.nan,\n",
    "                                'last_mse'        : np.nan,\n",
    "                                'last_rmse'       : np.nan,\n",
    "                                'last_mae'        : np.nan\n",
    "                            })\n",
    "                        else:\n",
    "                            result_dict.update({\n",
    "                                'last_eval_loss'   : result[2]['loss'][-1].cpu().item() if torch.is_tensor(result[2]['loss'][-1]) else result[2]['loss'][-1],\n",
    "                                'last_mse'         : result[2]['mse'][-1].cpu().item() if torch.is_tensor(result[2]['mse'][-1]) else result[2]['mse'][-1],\n",
    "                                'last_rmse'        : result[2]['rmse'][-1].cpu().item() if torch.is_tensor(result[2]['rmse'][-1]) else result[2]['rmse'][-1],\n",
    "                                'last_mae'         : result[2]['mae'][-1].cpu().item() if torch.is_tensor(result[2]['mae'][-1]) else result[2]['mae'][-1],\n",
    "                                'last_smape'       : result[2]['smape'][-1].cpu().item() if torch.is_tensor(result[2]['smape'][-1]) else result[2]['smape'][-1],\n",
    "                            \n",
    "                            })\n",
    "                            \n",
    "        \n",
    "                        if not summarized:\n",
    "                            result_dict.update({\n",
    "                                'losses'           : [[v.cpu().item() if torch.is_tensor(v) else v for v in loss] for loss in result[0]],\n",
    "                                'eval_results_pre' : {k: v.cpu().item() if torch.is_tensor(v) else v for k, v in result[1].items()},\n",
    "                                'eval_results_post': {k: v.cpu().item() if torch.is_tensor(v) else v for k, v in result[2].items()},\n",
    "                                })  \n",
    "                        results = pd.concat([results, pd.DataFrame([result_dict])], ignore_index=True)\n",
    "                    else:\n",
    "                        print(\"Failed case\")\n",
    "                        # Attach possible errors\n",
    "                        internal_errors['model_size'] = case['model_size']\n",
    "                        internal_errors['n_epochs'] = case['n_epochs']\n",
    "                        internal_errors['dataset_percent'] = case['dataset_percent']\n",
    "                        internal_errors['masked_percent'] = case['masked_percent']\n",
    "                        internal_errors['windows'] = [result[8]]*len(internal_errors)\n",
    "                        errors = pd.concat([errors, internal_errors])\n",
    "                        display(internal_errors)\n",
    "                        raise internal_errors[0][\"error\"]\n",
    "                    if not error: mssg.print_error(f\" case {case} | time: {result[4]}\")\n",
    "                    before = torch.cuda.memory_allocated()\n",
    "                    model_case = None\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    display(results)\n",
    "                    if do_beep:\n",
    "                        beep(1)\n",
    "                    mssg.print(f\"epoch {n_epochs}, dataset_percent {dataset_percent}, mask {masked_percent}, sizes {sizes} -->\")\n",
    "                if save:\n",
    "                    mssg.print(f\"Update results into {file_results}\")\n",
    "                    results.to_csv(file_results, index = False, header = True)\n",
    "                    mssg.print(f\"Update errors into {file_errors}\")\n",
    "                    errors.to_csv(file_errors, index = False, header = True)\n",
    "                if do_beep:\n",
    "                    beep(2)\n",
    "                    beep(2)\n",
    "                mssg.print(f\"epoch {n_epochs}, dataset_percent {dataset_percent}, mask {masked_percent} -->\")\n",
    "            if do_beep:\n",
    "                beep(3)\n",
    "                beep(3)\n",
    "                beep(3)\n",
    "            mssg.print(f\"epoch {n_epochs}, dataset_percent {dataset_percent}-->\")\n",
    "        if do_beep:\n",
    "            beep(4)\n",
    "            beep(4)\n",
    "            beep(4)\n",
    "            beep(4)\n",
    "        mssg.print(f\"epoch {n_epochs}-->\")\n",
    "    if do_beep:\n",
    "        beep(1000)\n",
    "        beep(1000)\n",
    "        beep(1000)\n",
    "        beep(1000)\n",
    "        beep(1000)\n",
    "    model_backup = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return results, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e6126b-0442-4bc2-b26f-8b99438bef69",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7bde6a-184c-4af7-934a-db50ae3a7007",
   "metadata": {},
   "source": [
    "## Defining full reasonable values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40312054-0683-48e1-b5bf-4001712086e6",
   "metadata": {},
   "source": [
    "The following parameters are modified within the fine-tuning:\n",
    "- `n_epochs_list` is used to set up the number of epochs used in the training step.\n",
    "- `dataset_percents` is used to select the percentage of the dataset used for each case fine-tuning.\n",
    "- `masked_percents` is used to select the  percentage of the training dataset we want to mask for the model to fill it up.\n",
    "- `sizes` is used to select the number of window sizes we want to use for the fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "562cdb03-6396-4cc4-a13d-ee32443794bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases: 72\n"
     ]
    }
   ],
   "source": [
    "n_epochs_list     = [5, 10, 20]\n",
    "dataset_percents  = [0.25, 0.5, 0.75, 1] #1 No tendría sentido porque sería como hacer lo mismo que con mvp.. entrenar con todo el dataset.\n",
    "masked_percents = [0.25, 0.5, 0.75]\n",
    "sizes             = [1, 5]\n",
    "total_cases_small = len(n_epochs_list)*len(dataset_percents)*len(masked_percents)*len(sizes)\n",
    "print(f\"Total cases: {total_cases_small}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5202de7-4348-4917-850f-4eb6d5cfa4c9",
   "metadata": {},
   "source": [
    "### Moment-Small\n",
    "Getting the results for moment small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240aa3c-f6ee-4889-aa48-d7a890bc2289",
   "metadata": {},
   "source": [
    "#### Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9d25c39-4297-43bc-9923-3cce3d60b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_computed_small = False\n",
    "#file_errors_small  = 'errors_small_29012025_1.csv'\n",
    "#file_results_small = 'results_small_29012025_1.csv'\n",
    "#file_errors_small  = 'errors_small_03022025_2.csv'\n",
    "#file_results_small = 'results_small_03022025_2.csv'\n",
    "file_errors_small  = 'errors_small_04022025_1.csv'\n",
    "file_results_small = 'results_small_04022025_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e67fa64-342d-47b4-98fc-13aa0835aa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting small artifact:  mi-santamaria/deepvats/zeroshot-moment-small-embedding:v0\n",
      "zeroshot-moment-small-embedding:v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact zeroshot-moment-small-embedding:v0, 144.63MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting small artifact: \", enc_artifact_small_name)\n",
    "enc_artifact_small = wandb_api.artifact(enc_artifact_small_name, type='learner')\n",
    "print(enc_artifact_small.name)\n",
    "moment_small = enc_artifact_small.to_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b31530c3-abd3-44f2-ab94-4e9eabdf3b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moment_small.head.linear.out_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3abcc-b6a3-4f38-9870-1a6104931cac",
   "metadata": {},
   "source": [
    "### Specific parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b0f1dd2-3514-4892-89fb-071cd6616bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases: 72\n"
     ]
    }
   ],
   "source": [
    "n_epochs_list_small    = [1, 5, 10] # [1, 5, 10, 20, 40, 80, 100]\n",
    "dataset_percents_small = [0.25, 0.5, 0.75, 1] #1 No tendría sentido porque sería como hacer lo mismo que con mvp... entrenar con todo el dataset.\n",
    "masked_percents_small= [0.25, 0.5, 0.75] #[0, 0.25, 0.5, 0.75, 1]  #1 debería devolver fatal el loss\n",
    "sizes_small            = [1, 5]\n",
    "total_cases_small      = len(n_epochs_list_small)*len(dataset_percents_small)*len(masked_percents_small)*len(sizes_small)\n",
    "print(f\"Total cases: {total_cases_small}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf500d-7a75-4cdc-9554-0dd050a05918",
   "metadata": {},
   "source": [
    "### Execute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5be6996b-a8db-4d7e-b320-cdf16220abd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "--> epoch 1, dataset_percent 0.25, mask 0.25\n",
      " sizes 1\n",
      "Cuda memmory allocated: 0\n",
      "0.75\n",
      "[1] [ --> _set_encoder ]\n",
      "[1]  [ _set_encoder ] About to exec _set_enc_input\n",
      "total:  440\n",
      "Validation: 0.3*440 = 132\n",
      "Training: 0.25*(440-132) = 110\n",
      "[1]  [ _set_encoder ] enc_input~(0,)\n",
      "[1]  [ _set_encoder ] About to exec _set_optimizer\n",
      "[1] [_set_encoder --> ]\n",
      "[1] [ --> fine_tune ][ --> fine_tune ] | ./logs.txt\n",
      "[1]  [ fine_tune ] Use fine_tune_moment parameters\n",
      "[1] \u001b[91m [ fine_tune_moment_mix_windows ] COMPUTING FINE TUNE MOMENT EVAL\u001b[0m\n",
      "available 132 | current 308 | window_sizes [12]\n",
      "available 132 | current 308\n",
      "available 124 | current 316\n",
      "available 116 | current 324\n",
      "available 108 | current 332\n",
      "available 100 | current 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 132 | current 308 | window_sizes [12]\n",
      "available 132 | current 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 1/5 [00:02<00:11,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 124 | current 316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 2/5 [00:03<00:04,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 116 | current 324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 3/5 [00:03<00:02,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 108 | current 332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 4/5 [00:04<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 100 | current 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 5/5 [00:04<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \u001b[91m [ fine_tune_moment_mix_windows ] Eval results: {'loss': 0.001987535480293445, 'mse': 0.0417908039156296, 'rmse': 0.0019875355732741438, 'mae': 0.025321383657865227, 'smape': 0.13027258359919605}.\u001b[0m\n",
      "available 110 | current 0 | window_sizes [12]\n",
      "available 110 | current 0\n",
      "available 102 | current 8\n",
      "[1] \u001b[91m [ fine_tune_moment_train_mix_windows_ ] Num training steps: 1*2 = 2\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0% 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 110 | current 0 | window_sizes [12]\n",
      "available 110 | current 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 1/2 [00:00<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 102 | current 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 2/2 [00:01<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \u001b[91m [ fine_tune_moment_train_mix_windows_ ] Best Loss inf -> 6.388108340615872e-05\u001b[0m\n",
      "[1] \u001b[91m [ fine_tune_moment_train_mix_windows_ ] Best epoch 0\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 2/2 [00:01<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \u001b[91m [ fine_tune_moment_train_mix_windows_ ] Best epoch: 0\u001b[0m\n",
      "[1] \u001b[91m [ fine_tune_moment_mix_windows ] COMPUTING FINE TUNE MOMENT EVAL\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 132 | current 308 | window_sizes [12]\n",
      "available 132 | current 308\n",
      "available 124 | current 316\n",
      "available 116 | current 324\n",
      "available 108 | current 332\n",
      "available 100 | current 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 132 | current 308 | window_sizes [12]\n",
      "available 132 | current 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 1/5 [00:01<00:06,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 124 | current 316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 2/5 [00:02<00:02,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 116 | current 324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 3/5 [00:02<00:01,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 108 | current 332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 4/5 [00:03<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available 100 | current 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 5/5 [00:03<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \u001b[91m [ fine_tune_moment_mix_windows ] Eval results: {'loss': 0.0021873185731237756, 'mse': 0.04492454640054962, 'rmse': 0.0021873185350289254, 'mae': 0.026467767730355262, 'smape': 0.13423083726139207}.\u001b[0m\n",
      "[1] [fine_tune --> ]\n",
      "Failed case\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window</th>\n",
       "      <th>error</th>\n",
       "      <th>model_size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>dataset_percent</th>\n",
       "      <th>masked_percent</th>\n",
       "      <th>windows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [window, error, model_size, n_epochs, dataset_percent, masked_percent, windows]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     errors_small  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_errors_small, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     results_small, errors_small \u001b[38;5;241m=\u001b[39m \u001b[43mcases_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmoment_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs_list\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_epochs_list_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_percents\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset_percents_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmasked_percents\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmasked_percents_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_sizes_list\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msizes_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43msummarized\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_errors\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile_errors_small\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_results\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile_results_small\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#already_computed_small = True\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 146\u001b[0m, in \u001b[0;36mcases_loop\u001b[0;34m(model, n_epochs_list, dataset_percents, masked_percents, n_sizes_list, summarized, do_beep, verbose, save, file_errors, file_results)\u001b[0m\n\u001b[1;32m    144\u001b[0m     errors \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([errors, internal_errors])\n\u001b[1;32m    145\u001b[0m     display(internal_errors)\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43minternal_errors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error: mssg\u001b[38;5;241m.\u001b[39mprint_error(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m case \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    148\u001b[0m before \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_allocated()\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "results_small      = None\n",
    "errors_small       = None\n",
    "if already_computed_small:\n",
    "    results_small = pd.read_csv(file_results_small, index_col=None, header=0)\n",
    "    errors_small  = pd.read_csv(file_errors_small, index_col=None, header=0)\n",
    "else:\n",
    "    results_small, errors_small = cases_loop(\n",
    "        model             = moment_small, \n",
    "        n_epochs_list     = n_epochs_list_small, \n",
    "        dataset_percents  = dataset_percents_small, \n",
    "        masked_percents = masked_percents_small, \n",
    "        n_sizes_list      = sizes_small, \n",
    "        verbose           = 1,\n",
    "        summarized        = True,\n",
    "        save              = True,\n",
    "        file_errors       = file_errors_small,\n",
    "        file_results      = file_results_small\n",
    "    )\n",
    "    #already_computed_small = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f346201-9c7c-4ef4-963e-0b81c7eaa6a8",
   "metadata": {},
   "source": [
    "Observaciones:\n",
    "- El número de épocas más pequeño a partir de los "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bfe0c0-1b03-439a-b3a2-7d34ae701856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6731b-5fd5-41c5-9e33-9aa7a2f91d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_small = pd.read_csv(file_results_small, index_col=None, header=0)\n",
    "#errors_small  = pd.read_csv(file_errors_small, index_col=None, header=0)\n",
    "print(errors_small.shape)\n",
    "print(results_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ad033-b134-45c5-b124-8261c59f562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----- ERRORS -----\")\n",
    "print(f\"Total error cases: {len(errors_small)}\")\n",
    "display(errors_small.head())\n",
    "print(f\"Total results: {len(results_small)}\")\n",
    "display(results_small.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6948d68-3057-4deb-92f2-fca5c71a7205",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_small[\"best_epochs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871178b3-e64f-452f-b2da-12ab89a66604",
   "metadata": {},
   "source": [
    "#### Checking the errors\n",
    "Checking the error cases to see if they can be fixed within the code for the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f44688-12d2-416b-ad35-844e48610ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if already_computed_small:\n",
    "    display(results_small['windows'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ab241-fcae-430d-8384-bc8858b64399",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (already_computed_small):\n",
    "    errors_small['n_epochs'] = pd.to_numeric(errors_small['n_epochs'], errors='coerce').astype('Int64')\n",
    "    errors_small['n_windows'] = pd.to_numeric(errors_small['n_windows'], errors='coerce').astype('Int64')\n",
    "    errors_small['masked_percent'] = pd.to_numeric(errors_small['masked_percent'], errors='coerce').astype(float)\n",
    "    errors_small['error'] = errors_small['error'].astype(str)\n",
    "    print(results_small.dtypes)\n",
    "    results_small['model_size'] = results_small['model_size'].astype(pd.StringDtype())\n",
    "    print(\"--- Second check ---\")\n",
    "    print(results_small.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3216fb-52f5-4fe4-9075-a731c0220c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if already_computed_small:\n",
    "    display(results_small['windows'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aad8ff-8319-4fb3-a01f-24a288f20955",
   "metadata": {},
   "outputs": [],
   "source": [
    "if errors_small.shape[0] > 0:\n",
    "    error_small_window_sizes = list(errors_small['window'].drop_duplicates())\n",
    "    display(error_small_window_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe3ff8-644b-4801-9705-2eadd1e775f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if errors_small.shape[0] > 0:\n",
    "    error_small_mssg =errors_small['error'].astype(str).drop_duplicates()\n",
    "    display(error_small_mssg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928eb16-704e-44fb-8c10-a4925c50679f",
   "metadata": {},
   "source": [
    "We see two failures to check within the failures:\n",
    "1) Windows do no respect the requested distance between sepparated windows (only one with ne next). TODO: check\n",
    "2) This dataset needs windows bigger than 4 for MOMENT - Small. => \n",
    "    => We need:\n",
    "\n",
    "   - A minimum and maximum variate allowing to ask for windows sizes inside an interval\n",
    "   - Control within the windows sizes. If we all like this log table, we can save an unique variate (not saving the windows part) just to check if a window has already failed with this error so it does not execute again.\n",
    "   - ¿Buen TFG un SQL de gestión de errores para DeepVATS? -> Hablar con Víctor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe89c04-a249-499c-b584-3103b816f405",
   "metadata": {},
   "source": [
    "First valid window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b868c9-678f-47b5-854e-27f17d1faf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_windows = results_small['windows'].drop_duplicates()\n",
    "print(small_windows.shape)\n",
    "display(small_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5709c-d730-4c30-b478-caad93a822fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_windows = small_windows.apply(lambda x: greater_than(x, 5)).apply(sorted)\n",
    "filtered_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ac0b6-9384-461d-8183-12e5aab827c5",
   "metadata": {},
   "source": [
    "A futuros, se observa que, cuando analicemos este dataset, deberemos:\n",
    "- Usar ventanas mayores que 5, preferiblemente, >= 8.\n",
    "- Corregir la función de ventanas para que indique en un warning y en una variable el número de ventanas devuelto realmente. Gestionar para que si no se ha devuelto el número de ventanas esperado, se corte el loop ahí en lugar de repetir los mismos expserimentos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f45167-ecb9-4d7f-a4a5-bed6f7718b98",
   "metadata": {},
   "source": [
    "#### Time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479b3ed-397e-4f55-999e-5e54eafd6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = results_small['time'].sum()\n",
    "print(f\"{total_time} seconds\")\n",
    "print(f\"{total_time/60} minutes\")\n",
    "print(f\"{total_time/60/60} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c250e-744d-4f6b-96f4-cc2e0aa83016",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_small.plot(figsize = (10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b570d05-f109-470e-bd9f-99fd19e4e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_analysis_small = results_small[[\n",
    "    \"time\", \n",
    "    \"n_epochs\", \n",
    "    \"dataset_percent\", \n",
    "    \"masked_percent\", \n",
    "    \"n_windows\", \n",
    "    \"last_eval_loss\", \n",
    "    \"last_mse\"\n",
    "]]\n",
    "df_time_analysis_small.plot(figsize = (10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571287dd-432d-43e5-aebf-d82afc0a8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_multiple_secondary_y(df_time_analysis_small, [\"n_epochs\", \"time\", \"n_windows\"], [\"last_eval_loss\", \"dataset_percent\", \"masked_percent\", 'last_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29a068-d558-4fe5-ab0f-34dd838b55f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_df = df_time_analysis_small.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd2a715-9d57-4ae6-874c-114b47235e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile_small.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266a665-905a-4425-bc40-efd55eda91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ad28f-ce59-42d5-a85d-a8213857a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(profile_small_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e389d-d4fd-4b75-b50d-99cfbcbfec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir n_epochs y n_windows a enteros, manejando posibles errores\n",
    "profile_small_df['n_epochs'] = pd.to_numeric(profile_small_df['n_epochs'], errors='coerce').astype('Int64')\n",
    "profile_small_df['n_windows'] = pd.to_numeric(profile_small_df['n_windows'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convertir masked_percent a float, manejando posibles errores\n",
    "profile_small_df['masked_percent'] = pd.to_numeric(profile_small_df['masked_percent'], errors='coerce').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b1bea-9ce9-4804-8dc5-f2dee6ba1d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small = ydp.ProfileReport(profile_small_df, title=\"Pandas Profiling Report for 'df_time_analysis_small'\", explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15508ae-83cc-40f6-8db7-d1bca329aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    " plot_correlation(profile_small_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd32bfe-8b8f-46f4-949e-debb93bff6c9",
   "metadata": {},
   "source": [
    "A nivel de tiempo, se observa que:\n",
    "\n",
    "- Apenas afecta el enmascarado, con una correlación negativa con el last loss. Lo mismo ocurre con el n_epochs\n",
    "- Más tiempo parece hacer crecer el last_loss\n",
    "- Lo que más influye es el porcentaje de dataset utilizado para el fine_tuning. Más dataset parece hacer empeorar por alguna razón\n",
    "- El last loss está bastante relacionado con el tiempo dedicado al fine-tuning, como es de esperar. Pero. La correlación es positiva => más last loss => más tiempo.\n",
    "- El número de ventanas parece ir en contra de bajar el loss.. quizá porque va de la mano del número de ventanas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ec05dc-3a5e-4865-8011-8115c572304e",
   "metadata": {},
   "source": [
    "### Loss & metrics analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf1e241-448c-4493-b1dd-bef35659f986",
   "metadata": {},
   "source": [
    "A nivel de losses, se observa (sin tener en cuenta mse, rmse, mae, smape): \n",
    "- Muy poca relación con el enmascarado, cosa que de primeras sorprende\n",
    "- Mucha relación con el % de dataset utilizado en el fine-tuning\n",
    "Por lo tanto,\n",
    "    - vamos a filtrar el dataset para tener tiempos menores a 8 segundos\n",
    "y buenos losses.\n",
    "    - Veamos a partir de qué momento se obtienen unos losses razonables  en %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71cfd22-7c55-4dd1-829b-581acca07ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674ee6d-c393-4174-81fa-c2fd7a107096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_small = results_small[[\n",
    "    \"time\", \"n_epochs\", \"dataset_percent\", \"masked_percent\", \"n_windows\", \n",
    "    \"first_eval_loss\", \"last_eval_loss\", \"first_mse\", \"last_mse\"\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c082720-0fb6-442d-a2bf-c9fa57baf26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_loss_small[[\"first_eval_loss\", \"last_eval_loss\"]])\n",
    "display(df_loss_small[[\"first_mse\", \"last_mse\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8614b42-f7d3-4f03-85c1-a9530afb5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_small[\"loss_percent\"] = (df_loss_small['first_eval_loss']-df_loss_small['last_eval_loss'])*100/(df_loss_small['first_eval_loss'])\n",
    "df_loss_small[\"loss_percent\"].plot()\n",
    "df_loss_small[\"mse_percent\"] = (df_loss_small['first_mse']-df_loss_small['last_mse'])*100/(df_loss_small['first_mse'])\n",
    "df_loss_small[\"mse_percent\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e4a33e-f451-4f88-a162-fb98ad97c8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_small[df_loss_small[\"loss_percent\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ded77-45ff-4b7a-b449-2bd25a39d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_small[df_loss_small[\"time\"] < 8][\"loss_percent\"].plot()\n",
    "df_loss_small[df_loss_small[\"time\"] < 8][\"mse_percent\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338a8e8-e958-4aff-8929-063f70e4e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde \"time\" es menor a 8 segundos\n",
    "df_loss_small_best_cases = df_loss_small[df_loss_small[\"time\"] < 8].copy()\n",
    "\n",
    "print(\"--------------------- Train -----------------\")\n",
    "# Filtrar los 5 mejores loss_percents\n",
    "display(df_loss_small_best_cases.sort_values('loss_percent', ascending = False)[:5])\n",
    "# Filtrar los 5 mejores loss_percent con dataset percent <= 0.25\n",
    "display(df_loss_small_best_cases[df_loss_small_best_cases['dataset_percent'] < 0.50].sort_values('loss_percent', ascending = False)[:5])\n",
    "print(\"---------------------- Eval ------------------\")\n",
    "# Filtrar los 5 mejores loss_percents\n",
    "display(df_loss_small_best_cases.sort_values('mse_percent', ascending = False)[:5])\n",
    "# Filtrar los 5 mejores loss_percent con dataset percent <= 0.25\n",
    "display(df_loss_small_best_cases[df_loss_small_best_cases['dataset_percent'] < 0.50].sort_values('loss_percent', ascending = False)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c0d7b-e069-46ca-8ac9-afaa0565fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir n_epochs y n_windows a enteros, manejando posibles errores\n",
    "profile_small_df = df_loss_small[['time', 'n_epochs', 'dataset_percent', 'masked_percent', 'n_windows', 'loss_train_percent', 'mse_percent']].copy()\n",
    "profile_small_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b039a2b-569e-4a64-8e17-0797749b1d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir n_epochs y n_windows a enteros, manejando posibles errores\n",
    "profile_small_df['n_epochs'] = pd.to_numeric(profile_small_df['n_epochs'], errors='coerce').astype('Int64')\n",
    "profile_small_df['n_windows'] = pd.to_numeric(profile_small_df['n_windows'], errors='coerce').astype('Int64')\n",
    "# Convertir masked_percent a float, manejando posibles errores\n",
    "profile_small_df['masked_percent'] = pd.to_numeric(profile_small_df['masked_percent'], errors='coerce').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de9fc0a-74b7-4afa-b259-96e542ed405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small = ydp.ProfileReport(profile_small_df, title=\"Pandas Profiling Report for 'df_loss_small'\", explorative=True)\n",
    "plot_correlation(profile_small_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee757ab3-9f6c-43f0-939e-44511b1723ce",
   "metadata": {},
   "source": [
    "#### What if I focus on 0.25 dataset percent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f3829f-585e-4f62-ae40-04190252ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_df_2 = df_time_analysis_small[df_time_analysis_small['dataset_percent'] == 0.25].drop(columns=['dataset_percent', 'time']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6227fedd-463d-47bc-ac11-f7f3e768f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_df_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6accfe3a-e970-46c5-ac48-240b4f498c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir n_epochs y n_windows a enteros, manejando posibles errores\n",
    "profile_small_df_2['n_epochs'] = pd.to_numeric(profile_small_df_2['n_epochs'], errors='coerce').astype('Int64')\n",
    "profile_small_df_2['n_windows'] = pd.to_numeric(profile_small_df_2['n_windows'], errors='coerce').astype('Int64')\n",
    "# Convertir masked_percent a float, manejando posibles errores\n",
    "profile_small_df_2['masked_percent'] = pd.to_numeric(profile_small_df_2['masked_percent'], errors='coerce').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ffeda-f910-43d9-b660-f625e55a444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_2 = ydp.ProfileReport(profile_small_df_2, title=\"Pandas Profiling Report for 'df_time_analysis_small' for < 0.25 dataset percent\", explorative=True)\n",
    "plot_correlation(profile_small_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ebb4b-0caa-4c6f-bfb6-c1e87e6654bf",
   "metadata": {},
   "source": [
    "* Correlación inversa entre masked percent y last loss * => Aumentar masked percent baja last_loss\n",
    "* => Es parte de lo que queremos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4803b-74c7-43d8-831d-6cfef0984baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! ls errors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51d2079-9853-403a-861d-d643b7ff0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406e592-2fff-49cb-b9fc-adb652e58a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(before)\n",
    "moment_small.to('cpu')\n",
    "for param in moment_small.parameters():\n",
    "    param.to('cpu')\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "print(\"Mejorado: \", after-before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414fd389-fa05-4d7e-8f59-b850b537e09d",
   "metadata": {},
   "source": [
    "## Moment-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264a4e8-012f-4dbc-9ab7-0a5f164e2f83",
   "metadata": {},
   "source": [
    "### Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54bbfd3-3512-4acc-b98b-aed6f483fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting base artifact: \", enc_artifact_base_name)\n",
    "enc_artifact_base  = wandb_api.artifact(enc_artifact_base_name, type='learner')\n",
    "moment_base  = enc_artifact_base.to_obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e29b9-7cae-4254-af20-381cfe1d868e",
   "metadata": {},
   "source": [
    "### Select parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613fad1a-dc25-4747-83e8-96a40f5f47ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases_small      = len(n_epochs_list)*len(dataset_percents)*len(masked_percents)*len(sizes)\n",
    "print(f\"Total cases: {total_cases_small}\")\n",
    "n_epochs_list_base= [5, 10, 20]\n",
    "dataset_percents_base  = [0.25, 0.5]\n",
    "masked_percents_base = [ 0.25, 0.5, 0.75]\n",
    "sizes_base             = [1, 5, 10]\n",
    "total_cases_base = len(n_epochs_list_base)*len(dataset_percents_base)*len(masked_percents_base)*len(sizes)\n",
    "print(f\"Total cases: {total_cases_base}\")\n",
    "expected_time = total_time*total_cases_base/total_cases_small\n",
    "print(f\"Expected time: {expected_time} seconds | {expected_time/60} minutes | {expected_time/60/60} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf86a99-372a-4b35-829c-70d92f2da2e9",
   "metadata": {},
   "source": [
    "### Configure files and wether already computed or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7084c9a-ee98-4912-b20a-5045f256057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_computed_base = True\n",
    "results_base = None\n",
    "errors_base = None\n",
    "file_errors_base = 'errors_base_24012025_1.csv'\n",
    "file_results_base = 'results_base_24012025_1.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc441508-e2bb-4d8e-8399-80cf99759965",
   "metadata": {},
   "source": [
    "### Execute cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f7e89a-c9e1-4c9b-9024-a8351af8c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base = None\n",
    "errors_base = None\n",
    "if already_computed_base:\n",
    "    results_base = pd.read_csv(file_results_base, index_col=None, header=0)\n",
    "    errors_base = pd.read_csv(file_errors_base, index_col=None, header=0)\n",
    "else:\n",
    "    results_base, errors_base = cases_loop(\n",
    "        model             = moment_base, \n",
    "        n_epochs_list     = n_epochs_list_base, \n",
    "        dataset_percents  = dataset_percents_base, \n",
    "        masked_percents = masked_percents_base,\n",
    "        n_sizes_list      = sizes_base, \n",
    "        summarized        = True,\n",
    "        verbose           = 8\n",
    "    )\n",
    "    results_base.to_csv(file_results_base, index=False, header=True)\n",
    "    errors_base.to_csv(file_errors_base, index=False, header=True)\n",
    "    already_computed_base = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb2dca-5bbc-49ac-bffa-66e4b9f3cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----- ERRORS -----\")\n",
    "print(f\"Total error cases: {len(errors_base)}\")\n",
    "display(errors_base.head())\n",
    "print(f\"Total results: {len(results_base)}\")\n",
    "display(results_base.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d358d9-271a-4052-bd5d-077f40b4eb30",
   "metadata": {},
   "source": [
    "### Checking the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f5e13d-72a7-4821-8001-aad46880643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7e028-5461-40aa-9b04-27d03ce897de",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_base_window_sizes = list(errors_base['windows'].drop_duplicates())\n",
    "error_base_window_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7801e-3ab1-42bb-bc18-5d220f88e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_base_mssg = errors_base['error'].astype(str).drop_duplicates()\n",
    "error_base_mssg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b7fc3-25e2-4f5b-a411-cf318ef67b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_windows = results_base['windows'].drop_duplicates()\n",
    "filtered_windows_base = base_windows.apply(lambda x: greater_than(x, 5)).apply(sorted)\n",
    "filtered_windows_base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eeddc4-025c-441b-9ff2-dff26bec2947",
   "metadata": {},
   "source": [
    "#### Time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ee0da-4944-4820-b347-2390ac17b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_analysis_base = results_base[[\"time\", \"n_epochs\", \"dataset_percent\", \"masked_percent\", \"n_windows\", \"last_train_loss\", \"last_mse\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a910969-f110-44e6-93bb-7392a57ab008",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_multiple_secondary_y(df_time_analysis_base, [\"n_epochs\", \"time\", \"n_windows\"], [\"last_train_loss\", \"dataset_percent\", \"masked_percent\", \"last_mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3e45e-7c4f-4d4a-8a7f-72b6798ea237",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_base_df = df_time_analysis_base.copy(deep = True)\n",
    "profile_base = ydp.ProfileReport(profile_base_df, title=\"Pandas Profiling Report for 'df_time_analysis_base'\", explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81dedec-a5d7-4602-a9cf-474912ad762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(profile_base_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978762e0-dd22-42de-931c-32eb839e41fe",
   "metadata": {},
   "source": [
    "#### Loss & metrics analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f15fb2-2ece-4d25-baed-1f4f8080ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_base = results_base[[\"time\", \"n_epochs\", \"dataset_percent\", \"masked_percent\", \"n_windows\", \"first_train_loss\", \"last_train_loss\", \"first_mse\", \"last_mse\"]].copy()\n",
    "df_loss_base[\"loss_percent\"] = (df_loss_base['first_train_loss']-df_loss_base['first_train_loss'])*100/(df_loss_base['first_train_loss'])\n",
    "df_loss_base[\"loss_percent\"].plot()\n",
    "df_loss_base[\"mse_percent\"] = (df_loss_base['first_mse']-df_loss_base['last_mse'])*100/(df_loss_base['first_mse'])\n",
    "df_loss_base[\"mse_percent\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693b2cef-b539-4733-b898-5c326f215192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_base[df_loss_base[\"time\"] < 8][\"loss_percent\"].plot()\n",
    "df_loss_base[df_loss_base[\"time\"] < 8][\"mse_percent\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba834381-5c97-433c-9f10-2913e5874ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_base[df_loss_base[\"time\"] < 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ebec6-c4f6-4510-8a7c-a340c080b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde \"time\" es menor a 8 segundos\n",
    "df_loss_base_best_cases = df_loss_base[df_loss_base[\"time\"] < 8].copy()\n",
    "\n",
    "print(\"---- Mejoras en el entrenamiento ----\")\n",
    "# Filtrar los 5 mejores loss_percents\n",
    "display(df_loss_base_best_cases.sort_values('loss_percent', ascending = False)[:5])\n",
    "# Filtrar los 5 mejores loss_percent con dataset percent <= 0.25\n",
    "display(df_loss_base_best_cases[df_loss_base_best_cases['dataset_percent'] < 0.50].sort_values('loss_percent', ascending = False)[:5])\n",
    "print(\"---- Mejoras en la validación  ----\")\n",
    "# Filtrar los 5 mejores loss_percents\n",
    "display(df_loss_base_best_cases.sort_values('mse_percent', ascending = False)[:5])\n",
    "# Filtrar los 5 mejores loss_percent con dataset percent <= 0.25\n",
    "display(df_loss_base_best_cases[df_loss_base_best_cases['dataset_percent'] < 0.50].sort_values('mse_percent', ascending = False)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f489bb7-5683-41f7-8f29-c12aac60110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1988ef9-ae17-4e6b-b8b1-4a440f5666d9",
   "metadata": {},
   "source": [
    "## Moment-large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdd297a-e26f-4686-a5ef-1da8fb9bd656",
   "metadata": {},
   "source": [
    "### Download de large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c25e22-b9c4-4afd-b1d4-eb619d6b5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "already_computed_large = True\n",
    "file_errors_large = 'errors_large_03022025_1.csv'\n",
    "file_results_large = 'results_large_03022025_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b62983-c152-4aa1-b294-d47babd15499",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not already_computed_large:\n",
    "    print(\"Getting large artifact: \", enc_artifact_large_name)\n",
    "    enc_artifact_large = wandb_api.artifact(enc_artifact_large_name, type='learner')\n",
    "    print(enc_artifact_large.name)\n",
    "    moment_large = enc_artifact_large.to_obj()\n",
    "    print(count_parameters(moment_large))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064fe3c-dc39-4603-a616-a8e2192d747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cases_small      = len(n_epochs_list)*len(dataset_percents)*len(masked_percents)*len(sizes)\n",
    "print(f\"Total cases: {total_cases_small}\")\n",
    "total_cases_base = len(n_epochs_list_base)*len(dataset_percents_base)*len(masked_percents_base)*len(sizes)\n",
    "print(f\"Total cases: {total_cases_base}\")\n",
    "expected_time = total_time*total_cases_base/total_cases_small\n",
    "print(f\"Expected time: {expected_time} seconds | {expected_time/60} minutes | {expected_time/60/60} hours\")\n",
    "\n",
    "n_epochs_list_large     = [5, 10, 20]\n",
    "dataset_percents_large  = [0.25, 0.5] # No tendría sentido porque sería como hacer lo mismo que con mvp\n",
    "masked_percents_large = [0.25, 0.5, 0.75]\n",
    "sizes_large             = [1, 5, 10]\n",
    "print(f\"Total cases: {len(n_epochs_list)*len(dataset_percents)*len(masked_percents)*len(sizes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b1888-2643-400f-8993-0d6fa42404bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated()\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50efcd6-3202-471c-818c-0c70be3bc40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_large = None\n",
    "errors_large = None\n",
    "if already_computed_large:\n",
    "    results_large = pd.read_csv(file_results_large, index_col=None, header=0)\n",
    "    errors_large = pd.read_csv(file_errors_large, index_col=None, header=0)\n",
    "else:\n",
    "    results_large, errors_large = cases_loop(\n",
    "        model             = moment_large, \n",
    "        n_epochs_list     = n_epochs_list_large,\n",
    "        dataset_percents  = dataset_percents_large, \n",
    "        masked_percents = masked_percents_large, \n",
    "        n_sizes_list      = sizes_large, \n",
    "        summarized        = True,\n",
    "        save              = True,\n",
    "        file_errors       =  file_errors_large,\n",
    "        file_results      = file_results_large\n",
    "    )\n",
    "    already_computed_large = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490ad9c-ea47-48a3-acd6-1a233fd56886",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----- ERRORS -----\")\n",
    "print(f\"Total error cases: {len(errors_large)}\")\n",
    "display(errors_large.head())\n",
    "print(f\"Total results: {len(results_large)}\")\n",
    "display(results_large.head())\n",
    "print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1de1e-1ca4-4463-956d-4ee3d872e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----- ERRORS -----\")\n",
    "print(f\"Total error cases: {len(errors_large)}\")\n",
    "display(errors_large.head())\n",
    "print(f\"Total results: {len(results_large)}\")\n",
    "display(results_large.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad3529-6850-4209-8dae-277d647f7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(before)\n",
    "moment_large.to('cpu')\n",
    "for param in moment_large.parameters():\n",
    "    param.to('cpu')\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "gc.collect()\n",
    "print(\"Mejorado: \", after-before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcfb4e5-af9b-4601-b4b4-56ba1f43fe4e",
   "metadata": {},
   "source": [
    "#### Errors analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f048de-9dec-4abd-a867-360914ea3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(errors_large) > 0:\n",
    "    error_large_window_sizes = list(errors_large['window'].drop_duplicates())\n",
    "    error_large_window_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeda773-9f48-493d-b7b5-3635b875c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    error_large_mssg = errors_large['error'].astype(str).drop_duplcates()\n",
    "    display(error_large_mssg)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1acc3d-6c22-4bc0-8ee7-b9a0ec9298dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_windows = results_large['windows'].drop_duplicates()\n",
    "print(large_windows.shape)\n",
    "display(large_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb41ed4c-988d-4e5e-be58-753870384cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_windows_large = large_windows.apply(lambda x: greater_than(x, 5)).apply(sorted)\n",
    "display(filtered_windows_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a19ffd-2f73-4e57-9644-eac0b3146f2c",
   "metadata": {},
   "source": [
    "#### Time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed948f8-9858-4137-b5fe-848b44896f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_analysis_large = results_large[[\"time\", \"n_epochs\", \"dataset_percent\", \"masked_percent\", \"n_windows\", \"last_train_loss\", 'last_mse']]\n",
    "df_time_analysis_large.plot(figsize = (10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8bb44c-87a0-4c8d-ac90-5ab25b6fb616",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_multiple_secondary_y(df_time_analysis_large, [\"n_epochs\", \"time\", \"n_windows\"], [\"last_train_loss\", 'last_mse', \"dataset_percent\", \"masked_percent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c0454-c417-4ad3-bc10-a0bf38638133",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_large_df = df_time_analysis_large.copy(deep = True)\n",
    "profile_large = ydp.ProfileReport(profile_large_df, title = \"Pandas Profiling Report for 'df_time_analysis_large'\", explorative = True)\n",
    "#profile_large.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d528e-e13e-4cc8-9164-3e60e03d580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation(profile_large_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab34016-1741-41b0-9106-0b9489877774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_large = results_large[[\"time\", \"n_epochs\", \"dataset_percent\", \"masked_percent\", \"n_windows\", \"first_train_loss\", \"last_train_loss\", \"first_mse\", \"last_mse\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979c8e1-251b-42a9-9c80-5ce7a3be554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_large[\"loss_train_percent\"] = (df_loss_large['first_train_loss']-df_loss_large['last_train_loss'])*100/(df_loss_large['first_train_loss'])\n",
    "df_loss_large[\"mse_percent\"] = (df_loss_large['first_mse']-df_loss_large['last_mse'])*100/(df_loss_large['first_mse'])\n",
    "df_loss_large[\"loss_train_percent\"].plot()\n",
    "df_loss_large[\"mse_percent\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea9672-cd80-4310-ad7d-5a8e943db0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss_large_best_cases = df_loss_large[df_loss_large[\"time\"] < 8].copy()\n",
    "display(df_loss_large_best_cases)\n",
    "print(\"--- train ---\")\n",
    "display(df_loss_large_best_cases[df_loss_large_best_cases[\"loss_train_percent\"] > 0])\n",
    "print(\"--- eval ---\")\n",
    "display(df_loss_large_best_cases[df_loss_large_best_cases[\"mse_percent\"] > 0])\n",
    "display(df_loss_large_best_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb8c4c1-42e0-456b-9be5-43e69e6f2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_loss_large_best_cases.sort_values('loss_train_percent', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0cb48-97e4-49d6-bf6c-24ad950430b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(before)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "print(after-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed36ec-df77-4665-a3cd-e68ec70c7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_tensors = []\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.Tensor) and obj.is_cuda:\n",
    "            gpu_tensors.append(obj)\n",
    "    except ReferenceError:\n",
    "        continue # Omitir los objetos que ya han sido recolectados\n",
    "print(len(gpu_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddd7d94-c94b-4877-8317-1e33854fba45",
   "metadata": {},
   "source": [
    "#### Loss & metrics analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a24fb-4416-4345-a1c8-131bed978e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"Execution ended\")\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca0597-64fb-4bc5-946f-2ae110b3cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if reset_kernel:\n",
    "    os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90638374-ae0b-4278-ba27-94ed52d3c57d",
   "metadata": {},
   "source": [
    "# Memory checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1265415-2bed-4ef2-8358-ae5ab0d43cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = torch.cuda.memory_snapshot()\n",
    "gpu_tensors = [obj['tensor'] for obj in snapshot if 'tensor' in obj]\n",
    "for tensor_info in gpu_tensors:\n",
    "    print(f\"Size: {tensor_info['size']}, Device: {tensor_info['device']}, Data type: {tensor_info['dtype']}\")\n",
    "print(gpu_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa9143-19c1-4d0a-a697-7ceee18a1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_types = set()\n",
    "for obj in snapshot:\n",
    "    for key in obj.keys():\n",
    "        object_types.add(key)\n",
    "print(\"Tipos de objetos encontrados en el snapshot:\")\n",
    "for obj_type in sorted(object_types):\n",
    "    print(obj_type)\n",
    "heavier_obj = None\n",
    "for obj in snapshot:\n",
    "    if heavier_obj is None or obj['total_size'] > heavier_obj['total_size']: heavier_obj = obj\n",
    "print(heavier_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a09491-9ae1-41d2-b03e-ccef4b6cdee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(torch.cuda.memory_allocated())\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated())\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "print(\"Mejorado: \", after-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381e0c7-52f0-43f4-a69c-430643e58131",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(before)\n",
    "moment_small.to('cpu')\n",
    "for param in moment_small.parameters():\n",
    "    param.to('cpu')\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "print(\"Mejorado: \", after-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d99125-ae8a-4d90-8cc1-1e08d15300a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(before)\n",
    "moment_base.to('cpu')\n",
    "for param in moment_base.parameters():\n",
    "    param.to('cpu')\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "print(\"Mejorado: \", after-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18604ec4-f939-44aa-b69a-540389e63fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "before = torch.cuda.memory_allocated()\n",
    "print(before)\n",
    "moment_large.to('cpu')\n",
    "for param in moment_large.parameters():\n",
    "    param.to('cpu')\n",
    "after = torch.cuda.memory_allocated()\n",
    "print(after)\n",
    "print(\"Mejorado: \", after-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f606e-0b0a-4f14-9317-8134bab45c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10511640-eb29-42a0-aff2-e7582bffb687",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_small_window_sizes = list(errors_small_hoy['windows'].drop_duplicates())\n",
    "error_small_window_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8598826-072b-44cb-a858-9ee1c4f17112",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_small_hoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d515610-ff36-4e65-a426-c7e429d7db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = results_small_hoy['time'].sum()\n",
    "print(f\"{total_time} seconds\")\n",
    "print(f\"{total_time/60} minutes\")\n",
    "print(f\"{total_time/60/60} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab3b72-dad5-4951-8a5e-71d911947728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_analysis_small = results_small_hoy[[\"time\", \"n_epochs\", \"dataset_percent\", \"masked_percent\", \"last_train_loss\", 'last_mse']]\n",
    "df_time_analysis_small.plot(figsize = (10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff0031-97a3-4a1a-9f71-20df7d4ed541",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_multiple_secondary_y(df_time_analysis_small, [\"n_epochs\", \"time\"], [\"last_train_loss\", \"dataset_percent\", \"masked_percent\", 'last_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be06cac-fd1f-44b9-8f44-bd1f3cad3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_df = df_time_analysis_small.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4fac3b-8fc3-48dd-8588-44918008f2d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"--- Cases ---\")\n",
    "print(\"--- Number of epochs ---\")\n",
    "print(profile_small_df[\"n_epochs\"].unique())\n",
    "print(\"--- Dataset percent ---\")\n",
    "print(profile_small_df[\"dataset_percent\"].unique())\n",
    "print(\"--- Dataset masked percent ---\")\n",
    "print(profile_small_df[\"masked_percent\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587a8e1-5ef5-48b5-8531-f11e8fb33412",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c133071-376c-4d58-bb9f-cb48c0b9cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(profile_small_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a014e16-28cc-4d71-9622-b083266c7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir n_epochs y n_windows a enteros, manejando posibles errores\n",
    "profile_small_df['n_epochs'] = pd.to_numeric(profile_small_df['n_epochs'], errors='coerce').astype('Int64')\n",
    "#profile_small_df['n_windows'] = pd.to_numeric(profile_small_df['n_windows'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convertir masked_percent a float, manejando posibles errores\n",
    "profile_small_df['masked_percent'] = pd.to_numeric(profile_small_df['masked_percent'], errors='coerce').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f271e-45a8-41a8-85fc-8e1c4784c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_small = ydp.ProfileReport(profile_small_df, title=\"Pandas Profiling Report for 'df_time_analysis_small'\", explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d04f5-6bab-4080-addb-46ddcff2cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    " plot_correlation(profile_small_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
