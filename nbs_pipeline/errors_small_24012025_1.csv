model_size,n_epochs,dataset_percent,maskared_percent,n_windows,windows,error,window
small,1,0.25,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,1,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,1,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,1,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,1,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,1,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,1,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,1,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,1,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,1,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,1,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,1,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,1,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,1,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,1,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,1,0.5,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,1,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,1,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,1,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,1,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,1,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,1,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,1,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,1,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,1,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,1,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,1,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,1,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,1,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,1,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,1,0.75,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,1,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,1,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,1,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,1,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,1,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,1,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,1,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,1,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,1,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,1,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,1,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,1,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,1,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,1,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,1,1.0,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,1,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,1,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,1,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,1,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,1,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,1,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,1,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,1,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,1,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,1,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,1,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,1,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,1,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,1,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,5,0.25,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,5,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,5,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,5,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,5,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,5,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,5,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,5,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,5,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,5,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,5,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,5,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,5,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,5,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,5,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,5,0.5,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,5,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,5,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,5,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,5,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,5,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,5,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,5,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,5,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,5,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,5,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,5,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,5,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,5,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,5,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,5,0.75,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,5,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,5,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,5,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,5,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,5,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,5,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,5,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,5,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,5,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,5,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,5,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,5,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,5,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,5,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,5,1.0,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,5,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,5,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,5,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,5,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,5,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,5,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,5,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,5,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,5,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,5,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,5,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,5,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,5,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,5,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,10,0.25,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,10,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,10,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,10,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,10,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,10,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,10,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,10,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,10,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,10,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,10,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,10,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,10,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,10,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,10,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,10,0.5,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,10,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,10,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,10,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,10,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,10,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,10,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,10,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,10,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,10,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,10,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,10,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,10,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,10,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,10,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,10,0.75,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,10,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,10,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,10,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,10,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,10,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,10,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,10,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,10,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,10,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,10,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,10,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,10,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,10,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,10,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,10,1.0,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,10,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,10,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,10,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,10,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,10,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,10,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,10,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,10,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,10,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,10,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,10,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,10,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,10,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,10,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,20,0.25,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,20,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,20,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,20,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,20,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,20,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,20,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,20,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,20,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,20,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,20,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,20,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,20,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,20,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,20,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,20,0.5,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,20,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,20,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,20,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,20,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,20,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,20,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,20,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,20,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,20,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,20,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,20,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,20,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,20,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,20,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,20,0.75,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,20,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,20,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,20,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,20,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,20,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,20,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,20,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,20,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,20,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,20,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,20,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,20,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,20,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,20,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,20,1.0,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,20,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,20,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,20,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,20,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,20,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,20,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,20,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,20,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,20,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,20,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,20,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,20,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,20,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,20,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,40,0.25,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,40,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,40,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,40,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,40,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,40,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,40,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,40,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,40,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,40,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,40,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,40,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,40,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,40,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,40,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,40,0.5,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,40,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,40,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,40,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,40,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,40,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,40,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,40,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,40,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,40,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,40,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,40,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,40,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,40,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,40,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,40,0.75,1.0,,[17],"""binomial_cpu"" not implemented for 'Long'",17
small,40,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",17
small,40,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,40,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,40,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,40,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,40,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",17
small,40,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,40,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,40,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,40,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,40,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,40,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,40,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,40,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,40,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 64.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 37.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.84 GiB memory in use. Of the allocated memory 19.40 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,40,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 64.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 37.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.84 GiB memory in use. Of the allocated memory 19.40 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,40,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 64.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 37.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.84 GiB memory in use. Of the allocated memory 19.40 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,40,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 64.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 37.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.84 GiB memory in use. Of the allocated memory 19.40 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,40,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 64.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 37.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.84 GiB memory in use. Of the allocated memory 19.40 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,40,1.0,1.0,,[17],"CUDA out of memory. Tried to allocate 64.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.41 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,40,1.0,1.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 64.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,40,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,40,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,40,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,40,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,40,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,40,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,40,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,40,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,40,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,40,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,40,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,40,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,40,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,80,0.25,0.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.25,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.25,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.25,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,0.25,0.25,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.25,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.25,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.25,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,0.25,0.5,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.25,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.25,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.25,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,0.25,0.75,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.25,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.25,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.25,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,0.25,1.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,1.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,80,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,80,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,80,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,80,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,80,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,80,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,80,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,80,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,80,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,80,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,80,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,80,0.5,0.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.5,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.5,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.5,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,0.5,0.25,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.5,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.5,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.5,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,0.5,0.5,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.5,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.5,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.5,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,0.5,0.75,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.5,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.5,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.5,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,0.5,1.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,1.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,80,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,80,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,80,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,80,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,80,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,80,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,80,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,80,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,80,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,80,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,80,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,80,0.75,0.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.75,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.75,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.75,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,0.75,0.25,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.75,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.75,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.75,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,0.75,0.5,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.75,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.75,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.75,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,0.75,0.75,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.75,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.75,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.75,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,0.75,1.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,1.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,80,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,80,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,80,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,80,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,80,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,80,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,80,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,80,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,80,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,80,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,80,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,80,1.0,0.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,1.0,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,1.0,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,1.0,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,1.0,0.25,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,1.0,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,1.0,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,1.0,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,1.0,0.5,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,1.0,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,1.0,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,1.0,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,1.0,0.75,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,80,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,80,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,80,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,80,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,80,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,80,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,80,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,80,1.0,1.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,1.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,80,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,80,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,80,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,80,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,80,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,80,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,80,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,80,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,80,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,80,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,80,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,80,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,100,0.25,0.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.25,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.25,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.25,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,0.25,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,0.25,0.25,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.25,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.25,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.25,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,0.25,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,0.25,0.5,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.25,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.25,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.25,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,0.25,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,0.25,0.75,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.25,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.25,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.25,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,0.25,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,0.25,1.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,1.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,100,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,100,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,100,0.25,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,100,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,100,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,100,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,100,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,100,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,100,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,100,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,100,0.25,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,100,0.5,0.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.5,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.5,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.5,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,0.5,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,0.5,0.25,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.5,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.5,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.5,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,0.5,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,0.5,0.5,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.5,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.5,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.5,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,0.5,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,0.5,0.75,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.5,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.5,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.5,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,0.5,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,0.5,1.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,1.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,100,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,100,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,100,0.5,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,100,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,100,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,100,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,100,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,100,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,100,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,100,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,100,0.5,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,100,0.75,0.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.75,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.75,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.75,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,0.75,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,0.75,0.25,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.75,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.75,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.75,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,0.75,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,0.75,0.5,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.75,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.75,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.75,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,0.75,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,0.75,0.75,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.75,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.75,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.75,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,0.75,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,0.75,1.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,1.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,100,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,100,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,100,0.75,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,100,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,100,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,100,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,100,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,100,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,100,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,100,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,100,0.75,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
small,100,1.0,0.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,1.0,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,1.0,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,1.0,0.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,1.0,0.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,1.0,0.25,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,1.0,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,1.0,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,1.0,0.25,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,1.0,0.25,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,1.0,0.5,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,1.0,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,1.0,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,1.0,0.5,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,1.0,0.5,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,1.0,0.75,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,1.0,0.75,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",12
small,100,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",10
small,100,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",16
small,100,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",8
small,100,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",13
small,100,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",4
small,100,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",19
small,100,1.0,0.75,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",20
small,100,1.0,1.0,,[17],"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,1.0,,"[17, 12, 10, 16, 8]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",12
small,100,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",10
small,100,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",16
small,100,1.0,1.0,,"[17, 12, 10, 16, 8]","""binomial_cpu"" not implemented for 'Long'",8
small,100,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 17.50 MiB is free. Process 3983873 has 6.01 GiB memory in use. Process 2302509 has 164.00 MiB memory in use. Process 2380410 has 20.40 GiB memory in use. Process 2461175 has 20.86 GiB memory in use. Of the allocated memory 19.42 GiB is allocated by PyTorch, and 1.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",17
small,100,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",12
small,100,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",10
small,100,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",16
small,100,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",8
small,100,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",13
small,100,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",4
small,100,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",19
small,100,1.0,1.0,,"[17, 12, 10, 16, 8, 13, 4, 19, 20]","""binomial_cpu"" not implemented for 'Long'",20
