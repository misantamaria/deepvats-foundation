{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6f89d6-c995-45d0-b5a4-abb31ca571eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "import sys\n",
    "import dvats.utils as ut\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import uni2ts\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.eval_util.plot import plot_next_multi\n",
    "import pyarrow.feather as ft\n",
    "from gluonts.transform.split import TFTInstanceSplitter\n",
    "from gluonts.transform.sampler import TestSplitSampler\n",
    "import numpy as np\n",
    "import einops\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ec04a6-9907-4000-8665-8f67ab19b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52586e3d-e3cf-4c1f-aa49-023efbbe987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_id(batch_size, seq_len):\n",
    "    # Creamos un tensor con valores [0, 1, ..., batch_size - 1]\n",
    "    # Luego lo repetimos seq_len veces a lo largo de la dimensión 1\n",
    "    return einops.repeat(torch.arange(batch_size), 'b -> b seq', seq=seq_len)\n",
    "    \n",
    "def get_variate_id(batch_size, seq_len, n_vars):\n",
    "    total_repeats = seq_len // n_vars  # Cantidad de veces que cada variate_id debe repetirse para llenar seq_len\n",
    "    remaining = seq_len % n_vars  # Resto que no completa una división exacta\n",
    "    var_ids = torch.arange(n_vars).repeat_interleave(total_repeats)\n",
    "    if remaining > 0:\n",
    "        var_ids = torch.cat((var_ids, torch.arange(remaining)))\n",
    "    return var_ids.unsqueeze(0).repeat(batch_size, 1)\n",
    "    \n",
    "def get_time_id(batch_size, seq_len, patches_per_var):\n",
    "    patches_per_var = int (patches_per_var)\n",
    "    # Creamos un tensor que repite una secuencia de 0 a patches_per_var-1\n",
    "    time_ids = torch.arange(patches_per_var).repeat(seq_len // patches_per_var + 1)[:seq_len]\n",
    "    # Repetimos este patrón para cada muestra en el batch\n",
    "    return time_ids.unsqueeze(0).repeat(batch_size, 1)\n",
    "def padd_tensor(X, window_len, patch_size, num_variates):\n",
    "    # Calcular el número total de parches necesarios para una sola variable\n",
    "    n_patches_single_var = int(np.ceil(window_len / patch_size))\n",
    "    total_length_needed = n_patches_single_var * patch_size  # Longitud total requerida con padding\n",
    "\n",
    "    # Calcular el padding necesario si existe\n",
    "    padding_size = total_length_needed - window_len\n",
    "\n",
    "    # Añadir padding a X si es necesario\n",
    "    x_padd = X\n",
    "    if padding_size > 0:\n",
    "        x_padd = F.pad(X, (0, padding_size), mode='constant', value=0)  # Pad al final de la última dimensión\n",
    "\n",
    "    # Ajustar n_patches considerando todas las variables\n",
    "    n_patches = n_patches_single_var * num_variates\n",
    "    return x_padd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a5d4da-33d8-4291-b69c-c34e20e685d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_windows, num_variates, window_len = shape = (521, 3, 30) \n",
    "X = torch.rand(shape)\n",
    "batch_size = num_windows\n",
    "patch_size = 128 #Porque 8 no le gusta y parece que está hecho a 64\n",
    "max_patch = patch_size \n",
    "n_patches = int(np.ceil(window_len/patch_size))*num_variates\n",
    "x_padded = padd_tensor(X, window_len, patch_size, num_variates)\n",
    "target = einops.rearrange(\n",
    "    x_padded,\n",
    "    'batch_size n_vars (n_patches p) -> batch_size (n_vars n_patches) p',\n",
    "    p = patch_size\n",
    ")\n",
    "batch, seq_len, max_patch = target.shape\n",
    "observed_mask = torch.ones_like(target, dtype = bool)\n",
    "prediction_mask = torch.zeros((batch_size, n_patches), dtype = bool)\n",
    "sample_id = get_sample_id(batch_size, n_patches)\n",
    "variate_id = get_variate_id(batch_size, n_patches, num_variates)\n",
    "time_id = get_time_id(batch_size, seq_len, 1)\n",
    "patch_size_tensor =  torch.zeros((batch_size, n_patches, patch_size))+patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bab675f-118b-439b-a8be-57c5790ddc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target ~ torch.Size([521, 3, 128])\n",
      "observed_mask ~ torch.Size([521, 3, 128])\n",
      "prediction_mask ~ torch.Size([521, 3])\n",
      "sample_id ~ torch.Size([521, 3])\n",
      "time_id ~ torch.Size([521, 3])\n",
      "variate_id ~ torch.Size([521, 3])\n",
      "patch_size ~ torch.Size([521, 3, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 3, 128])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Target ~ {target.shape}\")\n",
    "print(f\"observed_mask ~ {observed_mask.shape}\")\n",
    "print(f\"prediction_mask ~ {prediction_mask.shape}\")\n",
    "print(f\"sample_id ~ {sample_id.shape}\")\n",
    "print(f\"time_id ~ {time_id.shape}\")\n",
    "print(f\"variate_id ~ {variate_id.shape}\")\n",
    "print(f\"patch_size ~ {patch_size_tensor.shape}\")\n",
    "patch_size_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db0b67c-1806-4490-b0c6-789f3fbb163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#module=MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.0-R-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d2e5a2d-7402-4b53-b829-6c6fd7bfa4c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mMoiraiModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistr_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_sizes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn_patches\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_dropout_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/model/moirai/module.py:106\u001b[0m, in \u001b[0;36mMoiraiModule.__init__\u001b[0;34m(self, distr_output, d_model, num_layers, patch_sizes, max_seq_len, attn_dropout_p, dropout_p, scaling)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m PackedStdScaler() \u001b[38;5;28;01mif\u001b[39;00m scaling \u001b[38;5;28;01melse\u001b[39;00m PackedNOPScaler()\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj \u001b[38;5;241m=\u001b[39m MultiInSizeLinear(\n\u001b[1;32m    103\u001b[0m     in_features_ls\u001b[38;5;241m=\u001b[39mpatch_sizes,\n\u001b[1;32m    104\u001b[0m     out_features\u001b[38;5;241m=\u001b[39md_model,\n\u001b[1;32m    105\u001b[0m )\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mTransformerEncoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_dropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_dropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRMSNorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_glu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_qk_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar_attn_bias_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBinaryAttentionBias\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_qk_proj_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mQueryKeyProjection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproj_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRotaryProjection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshared_var_attn_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshared_time_qk_proj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_ff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistr_output \u001b[38;5;241m=\u001b[39m distr_output\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistr_output\u001b[38;5;241m.\u001b[39mget_param_proj(d_model, patch_sizes)\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/module/transformer.py:139\u001b[0m, in \u001b[0;36mTransformerEncoder.__init__\u001b[0;34m(self, d_model, num_layers, num_heads, num_groups, pre_norm, attn_dropout_p, dropout_p, norm_layer, activation, use_glu, use_qk_norm, var_attn_bias_layer, time_attn_bias_layer, var_qk_proj_layer, time_qk_proj_layer, shared_var_attn_bias, shared_time_attn_bias, shared_var_qk_proj, shared_time_qk_proj, d_ff)\u001b[0m\n\u001b[1;32m    129\u001b[0m time_attn_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_layer(\n\u001b[1;32m    130\u001b[0m     d_model,\n\u001b[1;32m    131\u001b[0m     num_heads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     shared_time_attn_bias,\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    136\u001b[0m var_qk_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_layer(\n\u001b[1;32m    137\u001b[0m     d_model, num_heads, num_groups, var_qk_proj_layer, shared_var_qk_proj\n\u001b[1;32m    138\u001b[0m )\n\u001b[0;32m--> 139\u001b[0m time_qk_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_qk_proj_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_time_qk_proj\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m get_self_attn \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    144\u001b[0m     GroupedQueryAttention,\n\u001b[1;32m    145\u001b[0m     dim\u001b[38;5;241m=\u001b[39md_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     time_qk_proj\u001b[38;5;241m=\u001b[39mtime_qk_proj,\n\u001b[1;32m    156\u001b[0m )\n\u001b[1;32m    157\u001b[0m get_ffn \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    158\u001b[0m     GatedLinearUnitFeedForward \u001b[38;5;28;01mif\u001b[39;00m use_glu \u001b[38;5;28;01melse\u001b[39;00m FeedForward,\n\u001b[1;32m    159\u001b[0m     in_dim\u001b[38;5;241m=\u001b[39md_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     ffn_dropout_p\u001b[38;5;241m=\u001b[39mdropout_p,\n\u001b[1;32m    165\u001b[0m )\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/module/transformer.py:194\u001b[0m, in \u001b[0;36mTransformerEncoder.get_layer\u001b[0;34m(dim, num_heads, num_groups, layer, shared_layer)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shared_layer:\n\u001b[0;32m--> 194\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_groups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m: module\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m partial(layer, dim\u001b[38;5;241m=\u001b[39mdim, num_heads\u001b[38;5;241m=\u001b[39mnum_heads, num_groups\u001b[38;5;241m=\u001b[39mnum_groups)\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/module/position/attn_projection.py:155\u001b[0m, in \u001b[0;36mQueryKeyProjection.__init__\u001b[0;34m(self, dim, num_heads, num_groups, proj_layer, kwargs, key_proj_layer, key_kwargs, partial_factor)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m partial_factor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m partial_factor[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m partial_factor[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    154\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpartial_factor[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpartial_factor[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m num_heads \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;241m%\u001b[39m num_heads \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (num_heads \u001b[38;5;241m%\u001b[39m num_groups \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (num_heads \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_groups)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim \u001b[38;5;241m=\u001b[39m dim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_heads\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "module = MoiraiModule(\n",
    "    distr_output = None,\n",
    "    d_model = 32,\n",
    "    num_layers = 3,\n",
    "    patch_sizes = [ patch_size ] *batch_size*n_patches*patch_size, \n",
    "    max_seq_len = target.shape[2],\n",
    "    attn_dropout_p = 0.5,\n",
    "    dropout_p = 0.5,\n",
    "    scaling = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b4ec4-11b6-442a-94a0-b653b88e6eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11c8a9-5ded-4410-837e-0a1ba62080b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "module(target, observed_mask, sample_id, time_id, variate_id, prediction_mask, patch_size_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
