{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c0bbb9-7788-4ff0-8f2b-a1a70c940cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser(\"~/work/nbs_pipeline\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e6da0b-c516-4b80-a8f6-40ad7f502ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "verbose                       = 1\n",
    "check_memory_usage            = True\n",
    "time_flag                     = True\n",
    "window_size_percentage        = True\n",
    "show_plots                    = True\n",
    "reset_kernel                  = False\n",
    "pre_configured_case           = True\n",
    "case_id                       = 7\n",
    "frequency_factor              = 1\n",
    "frequency_factor_change_alias = True\n",
    "check_parameters              = True\n",
    "cuda_device                   = 0\n",
    "remove_lambdas_flag           = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe0f92c-7e77-4ba3-87f1-8b05e7f5cb09",
   "metadata": {},
   "source": [
    "MOIRAI: Toy complete execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019ba616-f2e0-48dc-a2c7-8dc4074f8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "import sys\n",
    "import dvats.utils as ut\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import uni2ts\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.eval_util.plot import plot_next_multi\n",
    "import pyarrow.feather as ft\n",
    "from gluonts.transform.split import TFTInstanceSplitter\n",
    "from gluonts.transform.sampler import TestSplitSampler\n",
    "import numpy as np\n",
    "import einops\n",
    "import torch.nn.functional as F\n",
    "from dvats.memory import gpu_memory_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16086970-ff73-48bb-9635-9ac7d6bd05e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU | Used mem: 8\n",
      "GPU | Used mem: 24\n",
      "GPU | Memory Usage: [\u001b[94m██████--------------\u001b[0m] \u001b[94m33%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "device = torch.device(f'cuda:{cuda_device}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "if check_memory_usage:\n",
    "    gpu_device = torch.cuda.current_device()\n",
    "    gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f01f2e-bc85-4f14-89ec-c7ed11dd2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dvats.config as cfg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d4aaca-ff78-4184-a725-e3957b57453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: \n",
      "0 - monash_australian_electricity_demand_0\n",
      "1 - monash_solar_4_seconds_0\n",
      "2 - wikipedia_0\n",
      "3 - traffic_san_francisco_0\n",
      "4 - monash_solar_10_minutes_0\n",
      "5 - etth1_0\n",
      "6 - stumpy_abp_0\n",
      "7 - stumpy_toy_0\n"
     ]
    }
   ],
   "source": [
    "cfg_.show_available_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3385948e-ece8-495b-bd4e-4cb69ebe9d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7f1b48174b20>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"umap\")\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from dvats.all import *\n",
    "from fastcore.all import *\n",
    "from tsai.basics import *\n",
    "from tsai.models.InceptionTimePlus import *\n",
    "from tsai.callback.MVP import *\n",
    "import matplotlib.colors as colors\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.progress import ShowGraphCallback\n",
    "from fastai.callback.schedule import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback\n",
    "import wandb\n",
    "from momentfm import MOMENTPipeline\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.eval_util.plot import plot_next_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a14c009b-3b06-4f36-bc46-d641ee31cd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1martifact_name is missing in original dict | toy \u001b[0m\n",
      "\u001b[93m\u001b[1mnorm_use_by_single_batch is missing in original dict | (False,) \u001b[0m\n",
      "norm_use_single_batch: False\u001b[0m\n",
      "\u001b[93m\u001b[1mtime_col is missing in original dict | None \u001b[0m\n",
      "epochs: 100\u001b[0m\n",
      "r: 0.71\u001b[0m\n",
      "mask_sync: False\u001b[0m\n",
      "wandb_group: None\u001b[0m\n",
      "\u001b[94mtrain_artifact: mi-santamaria/deepvats/PulsusParadoxus-SP02:latest\u001b[0m -> mi-santamaria/deepvats/toy:latest\u001b[0m\n",
      "valid_artifact: None\u001b[0m\n",
      "\u001b[93m\u001b[1mdata_fpath is missing in original dict | ~/data/toy.csv \u001b[0m\n",
      "mask_stateful: True\u001b[0m\n",
      "\u001b[94mmvp_ws: (15, 100)\u001b[0m -> [10, 30]\u001b[0m\n",
      "\u001b[93m\u001b[1mfreq is missing in original dict | 1s \u001b[0m\n",
      "\u001b[94mw: 100\u001b[0m -> 30\u001b[0m\n",
      "\u001b[94mstride: 900\u001b[0m -> 1\u001b[0m\n",
      "\u001b[94mbatch_size: 512\u001b[0m -> 32\u001b[0m\n",
      "\u001b[93m\u001b[1mcsv_config is missing in original dict | {} \u001b[0m\n",
      "mask_future: False\u001b[0m\n",
      "valid_size: 0.2\u001b[0m\n",
      "norm_by_sample: False\u001b[0m\n",
      "\u001b[94malias: PulsusParadoxus-SP02\u001b[0m -> toy\u001b[0m\n",
      "\u001b[93m\u001b[1mdata_cols is missing in original dict | [] \u001b[0m\n",
      "analysis_mode: online\u001b[0m\n",
      "use_wandb: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "user, project, version, data, config, job_type = cfg_.get_artifact_config_MVP(False)\n",
    "if pre_configured_case: \n",
    "    cfg_.force_artifact_config_mvp(\n",
    "        config = config,\n",
    "        id = case_id,\n",
    "        verbose = verbose, \n",
    "        both = verbose > 0,\n",
    "        frequency_factor = frequency_factor,\n",
    "        frequency_factor_change_alias = frequency_factor_change_alias\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8267b5ad-4e24-4cdf-af50-1b58c284ae6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 02c_encoder_moment-embedding\n",
      "alias: toy\n",
      "analysis_mode: online\n",
      "batch_size: 32\n",
      "epochs: 100\n",
      "mask_future: False\n",
      "mask_stateful: True\n",
      "mask_sync: False\n",
      "mvp_ws: [10, 30]\n",
      "norm_by_sample: False\n",
      "norm_use_single_batch: False\n",
      "r: 0.71\n",
      "stride: 1\n",
      "train_artifact: mi-santamaria/deepvats/toy:latest\n",
      "valid_artifact: None\n",
      "use_wandb: True\n",
      "valid_size: 0.2\n",
      "w: 30\n",
      "wandb_group: None\n",
      "artifact_name: toy\n",
      "data_cols: []\n",
      "data_fpath: ~/data/toy.csv\n",
      "freq: 1s\n",
      "time_col: None\n",
      "csv_config: {}\n",
      "norm_use_by_single_batch: (False,)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"02c_encoder_moment-embedding\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "if verbose > 0: print(\"runname: \"+runname)\n",
    "if verbose > 0: cfg_.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9677a75b-aed4-41e9-ac0e-01ac7e481b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Wandb init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/macu/work/nbs_pipeline/02c_encoder_moment-embedding.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20241012_111331-vwp42ia2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/vwp42ia2' target=\"_blank\">02c_encoder_moment-embedding</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/vwp42ia2' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/vwp42ia2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wandb init -->\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"--> Wandb init\")\n",
    "run = wandb.init(\n",
    "    entity = user,\n",
    "    # work-nbs is a place to log draft runs\n",
    "    project=project,\n",
    "    group=config.wandb_group,\n",
    "    job_type=job_type,\n",
    "    allow_val_change=True,\n",
    "    mode=config.analysis_mode,\n",
    "    config=config,\n",
    "    # When use_wandb is false the run is not linked to a personal account\n",
    "    #NOTE: This is not working right now\n",
    "    anonymous = 'never' if config.use_wandb else 'must', \n",
    "    resume=False,\n",
    "    name = runname\n",
    ")\n",
    "if verbose > 0: print(\"Wandb init -->\")\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa4817bb-194d-4d37-a300-9d66e2ceea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alias: toy\n",
      "analysis_mode: online\n",
      "batch_size: 32\n",
      "epochs: 100\n",
      "mask_future: False\n",
      "mask_stateful: True\n",
      "mask_sync: False\n",
      "mvp_ws: [10, 30]\n",
      "norm_by_sample: False\n",
      "norm_use_single_batch: False\n",
      "r: 0.71\n",
      "stride: 1\n",
      "train_artifact: mi-santamaria/deepvats/toy:latest\n",
      "valid_artifact: None\n",
      "use_wandb: True\n",
      "valid_size: 0.2\n",
      "w: 30\n",
      "wandb_group: None\n",
      "artifact_name: toy\n",
      "data_cols: []\n",
      "data_fpath: ~/data/toy.csv\n",
      "freq: 1s\n",
      "time_col: None\n",
      "csv_config: {}\n",
      "norm_use_by_single_batch: [False]\n",
      "---> W&B Train Artifact\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "if verbose > 0: cfg_.show_attrdict(config)\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact\n",
    "train_artifact = artifacts_gettr(config.train_artifact)\n",
    "if verbose > 0: print(\"---> W&B Train Artifact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8860c59-3096-4865-8765-172a8756cd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(550, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "import pyarrow.feather as ft\n",
    "df_train = train_artifact.to_df()\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "473361e5-17b3-4eea-9edc-b9fb3b9f8608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:10</th>\n",
       "      <td>0.603472</td>\n",
       "      <td>0.607729</td>\n",
       "      <td>0.353346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:11</th>\n",
       "      <td>0.655628</td>\n",
       "      <td>0.714424</td>\n",
       "      <td>0.305794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:12</th>\n",
       "      <td>0.663067</td>\n",
       "      <td>0.620628</td>\n",
       "      <td>0.313750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:13</th>\n",
       "      <td>0.689184</td>\n",
       "      <td>0.630930</td>\n",
       "      <td>0.353046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:14</th>\n",
       "      <td>0.701148</td>\n",
       "      <td>0.661374</td>\n",
       "      <td>0.335391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           T3        T2        T1\n",
       "1970-01-01 00:00:10  0.603472  0.607729  0.353346\n",
       "1970-01-01 00:00:11  0.655628  0.714424  0.305794\n",
       "1970-01-01 00:00:12  0.663067  0.620628  0.313750\n",
       "1970-01-01 00:00:13  0.689184  0.630930  0.353046\n",
       "1970-01-01 00:00:14  0.701148  0.661374  0.335391"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "#display(df_train.head())\n",
    "display(df_train[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40a5ad68-8ee4-4a26-b1a0-ade114d01385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Sliding window |  30  |  1\n",
      " Sliding window |  30  |  1 ---> | df_train ~  (550, 3)\n",
      " sw_df_train |  30  |  1 --->\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"---> Sliding window | \", config.w,  \" | \", config.stride )\n",
    "sw = SlidingWindow(window_len=config.w, stride=config.stride, get_y=[])\n",
    "if verbose > 0: print(\" Sliding window | \", config.w,  \" | \", config.stride, \"---> | df_train ~ \", df_train.shape )\n",
    "X_train, _ = sw(df_train)\n",
    "if verbose > 0: print(\" sw_df_train | \", config.w,  \" | \", config.stride, \"--->\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d023745e-1e68-4947-8696-f91287e104e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 3, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_win x n_vars x win_size\n",
    "# n_batches x n_features x patch_size (before padding)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c3eb054-85f5-49c3-af71-0c4db5e9b6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X):  521\n",
      "--> Split 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split --> 417\n"
     ]
    }
   ],
   "source": [
    "assert config.analysis_mode in ['offline','online'], 'Invalid analysis mode'\n",
    "\n",
    "X = X_train\n",
    "if verbose > 0: print(\"len(X): \", len(X));\n",
    "if config.analysis_mode == 'online':\n",
    "    if verbose > 0: print(\"--> Split 1\")\n",
    "    splits = TimeSplitter(valid_size=0.2, show_plot=show_plots)(X)\n",
    "elif config.analysis_mode == 'offline':\n",
    "    if verbose > 0: print(\"--> Split 2\")\n",
    "    splits = get_splits(np.arange(len(X)), valid_size=config.valid_size, show_plot = show_plots)\n",
    "if verbose > 0: \n",
    "    print(\"Split -->\", len(splits[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42f0d804-2d94-4764-94d0-581fb713a9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521, 3, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((#417) [0,1,2,3,4,5,6,7,8,9...],\n",
       " (#104) [417,418,419,420,421,422,423,424,425,426...])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "if verbose > 0: \n",
    "    print(X.shape)\n",
    "    display(splits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99ab9c74-4458-4f0a-8f92-2da517a8d1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)\n",
    "len(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5e18e35-c24b-4775-a93a-cb01b19406e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 3, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ee893-812d-47a4-9e42-bd37ee637710",
   "metadata": {},
   "source": [
    "Ñapa para ver si es un problema de tamaños o qué (dejar 1 ventana solo como en el  ejemplo de uso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6261e0f-cb2b-410e-99ad-ca07f1ab30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train[0]\n",
    "#X_train = einops.rearrange(  torch.as_tensor(X_train, dtype = torch.float32), \"... -> 1 ...\")\n",
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ad7a2-b798-473e-9c76-bce8e5cc02fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42f36d9f-5c6b-4d30-8b6d-af6fcfb9f478",
   "metadata": {},
   "source": [
    "Hasta aquí la ñapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "493c68b0-c1c5-42e0-a8ab-d84283f66d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_target = einops.rearrange(\n",
    "    torch.as_tensor(X_train, dtype = torch.float32),\n",
    "    \"n_windows n_vars window_size -> n_windows window_size n_vars\"\n",
    ")\n",
    "# 1s if the value is observed, 0s otherwise. Shape: (batch, time, variate)\n",
    "past_observed_target = torch.ones_like(past_target, dtype=torch.bool)\n",
    "# 1s if the value is padding, 0s otherwise. Shape: (batch, time)\n",
    "past_is_pad = torch.zeros_like(past_target, dtype=torch.bool)[...,:,-1] # Kill last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd4f5d5f-81eb-4b65-be17-db271420bc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([521, 30, 3])\n",
      "torch.Size([521, 30, 3])\n",
      "torch.Size([521, 30])\n"
     ]
    }
   ],
   "source": [
    "print(past_target.shape)\n",
    "print(past_observed_target.shape)\n",
    "print(past_is_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8943aae-db91-4d09-a090-6893cfea20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch_size = 32 -> ok\n",
    "patch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a41def3-2076-461a-ba0d-1e9b212696d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_mask = torch.ones_like(past_target, dtype = bool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8497cc0-d6da-439a-96f9-df5569e234ba",
   "metadata": {},
   "source": [
    "¿ Pero tiene sentido separar en Train y test en un zero - shot ? \n",
    "Cojámoslo entero\n",
    "Y cojamos todo como input en lugar de input y label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0250e69c-3db7-48fd-a004-92ae754ddd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "def remove_lambdas(verbose = 0, base_path = \"/usr/local/share/lib/\"):\n",
    "    \n",
    "    \n",
    "    path = base_path+\"uni2ts/src/uni2ts/distribution/mixture.py\"\n",
    "    if verbose > 0: print(f\"remove_lambdas | read file {path}\")\n",
    "    # Read the file\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    # Check wether identity is defined or not\n",
    "    identity_defined = any(\"def identity(\" in line for line in lines)\n",
    "    if verbose > 0: print(f\"remove_lambdas | identity already defined? {identity_defined}\")\n",
    "    if not identity_defined: \n",
    "        if verbose > 0: print(\"remove_lambdas | Look for domain_map line\")\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"@property\" in line and \"def domain_map\" in lines[i+1]:                \n",
    "                domain_map_property_index = i\n",
    "                break\n",
    "        if verbose > 0: print(f\"remove_lambdas | Domain map in line {i}\")\n",
    "        # Insert identity function\n",
    "        identity_code = \"\"\"\n",
    "    def identity(self, x): \n",
    "        return x\n",
    "\n",
    "\"\"\"\n",
    "        lines.insert(domain_map_property_index, identity_code)\n",
    "        # Modify weights_logits line \n",
    "        inside_domain_map = False\n",
    "        for i in range(domain_map_property_index, len(lines)):\n",
    "            if \"weights_logits\" in lines[i]:\n",
    "                # Reemplazar la línea para que use identity\n",
    "                lines[i] = \"            weights_logits = self.identity,\\n\"\n",
    "                break\n",
    "        # Write changes \n",
    "        with open(path, 'w') as file:\n",
    "            file.writelines(lines)\n",
    "        importlib.reload(uni2ts)\n",
    "    else:\n",
    "        if identity_defined:\n",
    "            print(\"Identity already defined\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5494b83-d684-4cd2-93bb-57f70b9c59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.expanduser(\"~/work/nbs_pipeline/_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a62f6f0b-ee7f-4ae9-a8ec-fbf7e316af6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./uni2ts/src/uni2ts/distribution/mixture.py\n"
     ]
    }
   ],
   "source": [
    "! ls ./uni2ts/src/uni2ts/distribution/mixture.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dabfbab4-06f2-4baf-9bde-b52667906891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n"
     ]
    }
   ],
   "source": [
    "remove_lambdas(0,\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69483619-1138-4d27-9159-0563558815e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'method' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mMoiraiModule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSalesforce/moirai-1.1-R-small\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/huggingface_hub/hub_mixin.py:569\u001b[0m, in \u001b[0;36mModelHubMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_hub_mixin_inject_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m    567\u001b[0m         model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 569\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# Implicitly set the config as instance attribute if not already set by the class\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# This way `config` will be available when calling `save_pretrained` or `push_to_hub`.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mgetattr\u001b[39m(instance, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hub_mixin_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, {})):\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/huggingface_hub/hub_mixin.py:789\u001b[0m, in \u001b[0;36mPyTorchModelHubMixin._from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, map_location, strict, **model_kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_pretrained\u001b[39m(\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m    787\u001b[0m ):\n\u001b[1;32m    788\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load Pytorch pretrained weights and return the loaded model.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(model_id):\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading weights from local directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/share/lib/uni2ts/src/uni2ts/model/moirai/module.py:129\u001b[0m, in \u001b[0;36mMoiraiModule.__init__\u001b[0;34m(self, distr_output, d_model, num_layers, patch_sizes, max_seq_len, attn_dropout_p, dropout_p, scaling)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m TransformerEncoder(\n\u001b[1;32m    107\u001b[0m     d_model,\n\u001b[1;32m    108\u001b[0m     num_layers,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m     d_ff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    127\u001b[0m )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistr_output \u001b[38;5;241m=\u001b[39m distr_output\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistr_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_param_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/lib/uni2ts/src/uni2ts/distribution/_base.py:223\u001b[0m, in \u001b[0;36mDistributionOutput.get_param_proj\u001b[0;34m(self, in_features, out_features, proj_layer, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_param_proj\u001b[39m(\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    209\u001b[0m     in_features: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    213\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m nn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[1;32m    214\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    Get a projection layer mapping representations to distribution parameters.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    :return: distribution parameter projection layer\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDistrParamProj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdomain_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproj_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproj_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/lib/uni2ts/src/uni2ts/distribution/_base.py:110\u001b[0m, in \u001b[0;36mDistrParamProj.__init__\u001b[0;34m(self, in_features, out_features, args_dim, domain_map, proj_layer, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_features must be int or sequence of ints, got invalid type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(out_features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m     )\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj \u001b[38;5;241m=\u001b[39m convert_to_module(\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_dim\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_size \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    112\u001b[0m     out_features \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out_features, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(out_features)\n\u001b[1;32m    113\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/utils/_pytree.py:948\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, *rests)\u001b[0m\n\u001b[1;32m    946\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf\u001b[38;5;241m=\u001b[39mis_leaf)\n\u001b[1;32m    947\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/utils/_pytree.py:787\u001b[0m, in \u001b[0;36mTreeSpec.unflatten\u001b[0;34m(self, leaves)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munflatten\u001b[39m(\u001b[38;5;28mself\u001b[39m, leaves: Iterable[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PyTree:\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(leaves, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 787\u001b[0m         leaves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mleaves\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(leaves) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_leaves:\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    790\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtreespec.unflatten(leaves): `leaves` has length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(leaves)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut the spec refers to a pytree that holds \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_leaves\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    793\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/share/lib/uni2ts/src/uni2ts/distribution/_base.py:100\u001b[0m, in \u001b[0;36mDistrParamProj.__init__.<locals>.proj\u001b[0;34m(dim)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproj\u001b[39m(dim):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proj_layer(\n\u001b[1;32m     99\u001b[0m         in_features,\n\u001b[0;32m--> 100\u001b[0m         \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mof\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mof\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    101\u001b[0m         dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    103\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/share/lib/uni2ts/src/uni2ts/distribution/_base.py:100\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproj\u001b[39m(dim):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proj_layer(\n\u001b[1;32m     99\u001b[0m         in_features,\n\u001b[0;32m--> 100\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mof\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m of \u001b[38;5;129;01min\u001b[39;00m out_features),\n\u001b[1;32m    101\u001b[0m         dim\u001b[38;5;241m=\u001b[39mdim,\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    103\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'method' and 'int'"
     ]
    }
   ],
   "source": [
    "module = MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.1-R-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f019b10a-71c6-43e9-b42c-72dd2208e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "def restore_lambdas(verbose=0):\n",
    "    base_path = \"/usr/local/share/lib/\"\n",
    "    path = base_path + \"uni2ts/src/uni2ts/distribution/mixture.py\"\n",
    "    if verbose > 0: \n",
    "        print(f\"restore_lambdas | read file {path}\")\n",
    "    \n",
    "    # Leer el archivo\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Buscar la función identity e identificar si ya está presente\n",
    "    identity_defined = any(\"def identity(\" in line for line in lines)\n",
    "    \n",
    "    if verbose > 0: \n",
    "        print(f\"restore_lambdas | identity already defined? {identity_defined}\")\n",
    "    \n",
    "    # Si identity está definido, removerlo y restaurar el lambda original\n",
    "    if identity_defined:\n",
    "        if verbose > 0: \n",
    "            print(\"restore_lambdas | Removing identity function and restoring lambda\")\n",
    "\n",
    "        # Encontrar el índice de la función identity\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"def identity(\" in line:\n",
    "                identity_start_index = i\n",
    "                break\n",
    "\n",
    "        # Eliminar la función identity\n",
    "        # Asumimos que la función identity tiene 3 líneas: def, return, y una línea en blanco\n",
    "        del lines[identity_start_index:identity_start_index + 3]\n",
    "\n",
    "        # Restaurar el lambda en la línea de weights_logits\n",
    "        inside_domain_map = False\n",
    "        for i in range(len(lines)):\n",
    "            if \"weights_logits\" in lines[i]:\n",
    "                # Restaurar la línea original\n",
    "                lines[i] = \"            weights_logits=lambda x: x,\\n\"\n",
    "                break\n",
    "        \n",
    "        # Escribir los cambios\n",
    "        with open(path, 'w') as file:\n",
    "            file.writelines(lines)\n",
    "        \n",
    "        # Recargar el módulo modificado\n",
    "        importlib.reload(uni2ts)\n",
    "    else:\n",
    "        print(\"restore_lambdas | No identity function found to remove.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2d15373-9066-4079-b35d-6ca483ae8a4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/usr/local/share/lib/uni2ts/src/uni2ts/distribution/mixture.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrestore_lambdas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 43\u001b[0m, in \u001b[0;36mrestore_lambdas\u001b[0;34m(verbose)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Escribir los cambios\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     44\u001b[0m     file\u001b[38;5;241m.\u001b[39mwritelines(lines)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Recargar el módulo modificado\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/usr/local/share/lib/uni2ts/src/uni2ts/distribution/mixture.py'"
     ]
    }
   ],
   "source": [
    "restore_lambdas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86caf4f1-760c-4b26-b407-4c6427778f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar model for conversions just to ensure correct sizes\n",
    "forecast_model =  MoiraiForecast(\n",
    "    module=module,\n",
    "    prediction_length=past_target.shape[2], #random, just for getting the model\n",
    "    context_length=past_target.shape[1],\n",
    "    patch_size=patch_size,\n",
    "    num_samples=100, #Random, is the number of forecasting, not interesting for us\n",
    "    target_dim=past_target.shape[2],\n",
    "    feat_dynamic_real_dim=0,\n",
    "    past_feat_dynamic_real_dim=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10700d-35c2-4456-9bb2-047d1a24c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = forecast_model(\n",
    "    past_target=past_target,\n",
    "    past_observed_target=past_observed_target,\n",
    "    past_is_pad=past_is_pad,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2a929-422c-4780-843b-006364cac8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    target,\n",
    "    observed_mask,\n",
    "    sample_id,\n",
    "    time_id,\n",
    "    variate_id,\n",
    "    prediction_mask,\n",
    ") = forecast_model._convert(\n",
    "    patch_size,\n",
    "    past_target,\n",
    "    past_observed_target,\n",
    "    past_is_pad\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf34074-394d-4473-b980-4c624ca97e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.hook import *\n",
    "\n",
    "from tsai.models.layers import *\n",
    "\n",
    "def get_acts_and_grads(\n",
    "    model, \n",
    "    modules, \n",
    "    y=None, \n",
    "    detach=True, \n",
    "    cpu=False,\n",
    "    attr_name = \"data\",\n",
    "    verbose = 0,\n",
    "    **model_kwargs\n",
    "):\n",
    "    r\"\"\"Returns activations and gradients for given modules in a model and a single input or a batch. \n",
    "    Gradients require y value(s). If they are not provided, it will use the predictions. \"\"\"\n",
    "    if not isinstance(modules, list): modules = [modules]\n",
    "    if ('x' in model_kwargs):\n",
    "        x = x[None, None] if x.ndim == 1 else x[None] if x.ndim == 2 else x\n",
    "    if cpu: \n",
    "        model = model.cpu()\n",
    "        #x = x.cpu()\n",
    "        for key in model_kwargs:\n",
    "            try: #if not able to be moved, just not move it\n",
    "                model_kwargs[key] = model_kwargs[key].cpu()\n",
    "            except:\n",
    "                continue\n",
    "    with hook_outputs(modules, detach=detach, cpu=cpu) as h_act:\n",
    "        if verbose > 0:\n",
    "            print(\"get_act_and_grads | hook outputs | h_act\")\n",
    "        with hook_outputs(modules, grad=True, detach=detach, cpu=cpu) as h_grad:\n",
    "            if verbose > 0:\n",
    "                print(\"get_act_and_grads | hook outputs | h_grad\")\n",
    "            preds = model.eval()(**model_kwargs)\n",
    "            try:\n",
    "                preds.requires_grad_(True)\n",
    "                if verbose > 1:\n",
    "                    print(f\"Get_acts_and_grads | hooks | preds req grads ? {preds.requires_grad}\")\n",
    "                #print(f\"Get_acts_and_grads | hooks | preds ? {preds}\")\n",
    "                if y is None: \n",
    "                    preds.max(dim=-1).values.mean().backward()\n",
    "                    #print(f\"Get_acts_and_grads | hooks | preds grad ? {preds.grad}\")\n",
    "                else: \n",
    "                    y = y.detach().cpu().numpy()\n",
    "                    if preds.shape[0] == 1: \n",
    "                        preds[0, y].backward()\n",
    "                    else: \n",
    "                        if y.ndim == 1: y = y.reshape(-1, 1)\n",
    "                        torch_slice_by_dim(preds, y).mean().backward()\n",
    "            except Exception as e: \n",
    "                if verbose > 1:\n",
    "                    print(f\"Preds {type(preds)} does not have requires_grad\")\n",
    "    if len(modules) == 1: \n",
    "        if verbose > 1:\n",
    "            print(f\"get_act_and_grads | h_act stored ~ \", len(h_act.stored))\n",
    "            print(f\"get_act_and_grads | h_act stored: \", h_act.stored)\n",
    "        try:\n",
    "            res = getattr(h_act.stored[0], attr_name), getattr(h_act.stored[0][0], attr_name)\n",
    "        except:\n",
    "            res = getattr(h_act.stored[0][0], attr_name), getattr(h_act.stored[0][0][0], attr_name)\n",
    "        return res\n",
    "    else: \n",
    "        return [h.data for h in h_act.stored], [getattr(h_act.stored[0], attr_name) for h in h_grad.stored]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ccea3-9ed7-4580-a571-29f446ccc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs={\n",
    "    'target': target, \n",
    "    'observed_mask': observed_mask,\n",
    "    'sample_id': sample_id,\n",
    "    'time_id': time_id,\n",
    "    'variate_id': variate_id,\n",
    "    'prediction_mask': prediction_mask,\n",
    "    'patch_size': torch.ones_like(sample_id, dtype = torch.float32)*patch_size\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944e1d0-b24a-41a3-95ee-6b5ba7d120ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_model_kwargs={\n",
    "    'past_target': past_target, \n",
    "    'past_observed_target': past_observed_target,\n",
    "    'past_is_pad': past_is_pad\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9111a-07f4-45d6-80ef-79694b984e64",
   "metadata": {},
   "source": [
    "Pequeño trial porque se queda bloqueado y no entiendo por qué\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7a9d2-372a-41b4-acbe-d7be84c9f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor = forecast_model.create_predictor(batch_size = target.shape[0])\n",
    "#forecasts = predictor.predict(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b806d4-6cae-481d-9d18-5427ce3e12f7",
   "metadata": {},
   "source": [
    "Fin del trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82e37a-1af2-46f9-b6a5-d8e06650c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvats.utils import Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed7830-b316-4954-a2f2-5453cd3b40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = Time()\n",
    "timer.start()\n",
    "module.eval()\n",
    "embs = [\n",
    "        get_acts_and_grads(\n",
    "            model   = module,\n",
    "            modules = module.encoder.norm,         \n",
    "            cpu     = False,\n",
    "            attr_name = \"data\",\n",
    "            verbose = 0,\n",
    "            **model_kwargs\n",
    "        )[0] \n",
    "        for xb in target\n",
    "    ]\n",
    "timer.end()\n",
    "timer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b080e-816d-4a58-abcf-051164dacc85",
   "metadata": {},
   "source": [
    "Me da que MOIRAI va a perder la batalla por tiempo de obtención de embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4fdfda-c287-4f12-857f-147ba0e142e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ab895-0f18-41cd-bf3a-c0f9b65a3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6295c-fee5-40ab-a513-00cb328685cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = embs.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c28b26-5cac-4e60-9527-90acbaf2629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4438481-e04d-4271-b2f8-42488a4c523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings_from_all_layers(model, enc_input, **model_kwargs):\n",
    "    # Iteramos sobre todas las capas del modelo\n",
    "    for name, module in model.named_modules():\n",
    "        print(f\"Processing layer: {name}\")\n",
    "        mssg = \"\"\n",
    "        try:\n",
    "            embs = [\n",
    "                get_acts_and_grads(\n",
    "                    model   = model,\n",
    "                    modules = [module],  # Registramos el hook en la capa actual\n",
    "                    cpu     = True,\n",
    "                    attr_name = \"data\",  # Ajusta esto si necesitas otro atributo\n",
    "                    **model_kwargs\n",
    "                )[0] \n",
    "                for xb in enc_input\n",
    "            ]\n",
    "            mssg = f\"Layer: {name}, Embedding shape: {embs[0].shape}\" \n",
    "        except Exception as e:\n",
    "            mssg = f\"Layer: {name},  {e}\"\n",
    "        \n",
    "        # Si se capturan las activaciones, imprimimos el nombre de la capa y su shape\n",
    "        print(mssg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e2765-3abc-47ba-81d4-bd21faeee428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Por qué salen AffineTransformed objects en lugar de gradientes?\n",
    "#extract_embeddings_from_all_layers(\n",
    "#    model=module,\n",
    "#    enc_input = target,\n",
    "#    **model_kwargs\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f33b69-f983-4f15-9cd7-700263926002",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_model.named_modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
