{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2236ba8-be38-41a9-a41f-0e7d523af26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "import sys\n",
    "import dvats.utils as ut\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import uni2ts\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.eval_util.plot import plot_next_multi\n",
    "import pyarrow.feather as ft\n",
    "from gluonts.transform.split import TFTInstanceSplitter\n",
    "from gluonts.transform.sampler import TestSplitSampler\n",
    "import numpy as np\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231eca57-5c5d-4611-8f9c-b636781bcfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889557be-2391-4dba-8d86-2cc62da1f143",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b18fc5-3117-4400-9483-d7044b6a881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_id(batch_size, seq_len):\n",
    "    # Generamos un tensor que comienza en 0 y va incrementando de 1 en 1 hasta seq_len * batch_size - 1\n",
    "    return torch.arange(batch_size * seq_len).view(batch_size, seq_len)\n",
    "def get_variate_id(batch_size, seq_len, n_vars):\n",
    "    total_repeats = seq_len // n_vars  # Cantidad de veces que cada variate_id debe repetirse para llenar seq_len\n",
    "    remaining = seq_len % n_vars  # Resto que no completa una división exacta\n",
    "    var_ids = torch.arange(n_vars).repeat_interleave(total_repeats)\n",
    "    if remaining > 0:\n",
    "        var_ids = torch.cat((var_ids, torch.arange(remaining)))\n",
    "    return var_ids.unsqueeze(0).repeat(batch_size, 1)\n",
    "    \n",
    "def get_time_id(batch_size, seq_len, patches_per_var):\n",
    "    patches_per_var = int (patches_per_var)\n",
    "    # Creamos un tensor que repite una secuencia de 0 a patches_per_var-1\n",
    "    time_ids = torch.arange(patches_per_var).repeat(seq_len // patches_per_var + 1)[:seq_len]\n",
    "    # Repetimos este patrón para cada muestra en el batch\n",
    "    return time_ids.unsqueeze(0).repeat(batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625af1db-d381-4f59-ae7f-678f48399965",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf85f20a-0e10-4a57-b46c-45869ba0f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (521, 3, 30)\n",
    "X = torch.rand(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c35b3cdc-b89c-4875-9f83-9be42f140d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_windows, num_variates, window_len = shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7668d797-646c-4ea1-bbfe-4f0dc2a0aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = num_windows\n",
    "seq_len = window_len * num_variates\n",
    "#patch_size = 8\n",
    "patch_size = 128\n",
    "max_patch = patch_size\n",
    "n_patches = int(np.ceil(seq_len / patch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02db0727-c9cc-4998-898b-f4c96b262f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = rearrange(X, 'num_windows num_variates window_len -> num_windows window_len num_variates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dddae73b-c1de-4fef-b78e-6bd115c84d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(window_len)\n",
    "print(patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3e1e8ca-3e53-4442-94e4-4d53adf1337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# Calcular el número total de parches necesarios para una sola variable\n",
    "n_patches_single_var = int(np.ceil(window_len / patch_size))\n",
    "total_length_needed = n_patches_single_var * patch_size  # Longitud total requerida con padding\n",
    "\n",
    "# Calcular el padding necesario si existe\n",
    "padding_size = total_length_needed - window_len\n",
    "\n",
    "# Añadir padding a X si es necesario\n",
    "if padding_size > 0:\n",
    "    X = F.pad(X, (0, padding_size), mode='constant', value=0)  # Pad al final de la última dimensión\n",
    "\n",
    "# Ajustar n_patches considerando todas las variables\n",
    "n_patches = n_patches_single_var * num_variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d55bcf16-637d-4124-8e78-f81c30a56e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rearrange(\n",
    "    X,\n",
    "    'batch_size n_vars (n_patches p) -> batch_size (n_vars n_patches) p',\n",
    "    p = patch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a8129e4-0786-4220-a9e9-18b1977eb44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 3, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c15aa12-bd68-48c3-9e3d-06d4540cc92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_patches = int(np.ceil(window_len/patch_size))*num_variates\n",
    "#print(n_patches)\n",
    "#target = einops.rearrange(\n",
    "#    X,\n",
    "#    'batch_size window_len n_vars -> batch_size n_patches p',\n",
    "#    p = patch_size, \n",
    "#    n_patches = n_patches\n",
    "#)\n",
    "#print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10c0b164-db9e-4798-bf16-bfaa7dcc6e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 3, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = y\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bd2e60e-dcbc-4a00-a797-7bebc28d7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_mask = torch.ones_like(target, dtype = bool)\n",
    "#prediction_mask = torch.zeros((target.shape[0], target.shape[1]), dtype = bool)\n",
    "#observed_mask = torch.ones((batch_size, window_len, num_variates), dtype = bool)\n",
    "#prediction_mask = torch.zeros((batch_size, window_len), dtype = bool)\n",
    "prediction_mask = torch.zeros((batch_size, n_patches), dtype = bool)\n",
    "sample_id = get_sample_id(batch_size, n_patches)\n",
    "variate_id = get_variate_id(batch_size, n_patches, num_variates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74991567-6403-474a-87f5-8a3849bbfacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([521, 3, 128])\n",
      "torch.Size([521, 3])\n"
     ]
    }
   ],
   "source": [
    "print(observed_mask.shape)\n",
    "print(prediction_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8975a5aa-5e2a-45c6-b94c-2a3e1daa6d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 3, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = ~prediction_mask.unsqueeze(-1)\n",
    "neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f62e009-48e8-4510-99c7-adc537de73fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 3, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol = observed_mask * neg\n",
    "sol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83817b6f-0c19-452e-827e-c90039794e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([521, 3, 128])\n",
      "torch.Size([521, 3, 128])\n"
     ]
    }
   ],
   "source": [
    "print(target.shape)\n",
    "print(observed_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f9a15f8-7bd7-4c5d-b0d6-4216e84a7b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 1, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einops.reduce(target * observed_mask, \"... seq dim -> ... 1 seq\", \"sum\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f69e7068-dfa5-4d7f-894e-d5ac86048be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([521, 3, 1]) torch.Size([521, 1, 3])\n",
      "torch.Size([521, 3, 1]) torch.Size([521, 3, 1])\n",
      "id_mask ~ torch.Size([521, 3, 3])\n",
      "Reduced:  torch.Size([521, 1, 3])\n",
      "torch.Size([521, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = sample_id.unsqueeze(-1)\n",
    "b = sample_id.unsqueeze(-2)\n",
    "e = torch.eq(a,b)\n",
    "print(a.shape, b.shape)\n",
    "\n",
    "c = variate_id.unsqueeze(-1)\n",
    "d = variate_id.unsqueeze(2)\n",
    "f = torch.eq(c,d)\n",
    "\n",
    "print(c.shape, d.shape)\n",
    "id_mask = torch.logical_and(e,f)\n",
    "print(\"id_mask ~\", id_mask.shape)\n",
    "reduced = einops.reduce(observed_mask, \"... seq dim -> ... 1 seq\", \"sum\")\n",
    "print(\"Reduced: \", reduced.shape)\n",
    "sol = id_mask * reduced\n",
    "print(sol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f80bab7c-3f24-47b9-957f-0e72a1df1e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 3, 128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#patch_size_tensor =  torch.zeros((batch_size, patch_size))+patch_size\n",
    "patch_size_tensor =  torch.zeros((batch_size, n_patches, patch_size))+patch_size\n",
    "patch_size_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30935193-4227-436b-ba42-1a45eead7296",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feat_size = target\n",
    "feat_size = patch_size_tensor.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fe1561c-b435-428a-ba1f-a5c15b1bf6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_feat_size ~ torch.Size([521, 3, 128])\n",
      "feat_size ~ torch.Size([521, 3, 128])\n",
      "feat_size_sq ~ torch.Size([521, 3, 128, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f\"in_feat_size ~ {in_feat_size.shape}\")\n",
    "print(f\"feat_size ~ {feat_size.shape}\")\n",
    "print(f\"feat_size_sq ~ {feat_size.unsqueeze(-1).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "958a14e3-feb7-4a54-afc2-cf3ea9fd9937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 3, 128, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(in_feat_size, feat_size).unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d39348c4-fbe2-4294-817c-7b783a525632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object ` forecast_module.forward` not found.\n"
     ]
    }
   ],
   "source": [
    "?? forecast_module.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e6454e6-1271-407d-b9ea-d0e0128e5617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 90])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample_id = get_sample_id(batch_size, seq_len)\n",
    "#variate_id = get_variate_id(batch_size, seq_len, num_variates)\n",
    "#time_id = get_time_id(batch_size, seq_len, n_patches)\n",
    "time_id = get_time_id(batch_size, seq_len, 1)\n",
    "time_id.shape\n",
    "#print(sample_id.shape)\n",
    "#print(variate_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "639e569d-7a88-4248-810b-518d01f1414e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 3, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40fcfe58-0531-430b-a1ce-b2dcf790b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_module = MoiraiForecast(\n",
    "    module=MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.0-R-small\"),\n",
    "    prediction_length=30, # No puede ser 0 porque falla el predictor... Pongo window len que es lo más parecido que tengo a \"aprender mismos tamaños\"\n",
    "    context_length=30,\n",
    "    patch_size=patch_size,\n",
    "    num_samples=100,\n",
    "    target_dim=3,\n",
    "    feat_dynamic_real_dim = 0,\n",
    "    past_feat_dynamic_real_dim = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "199b4358-9dff-455a-bd0a-f0f9b8a4ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transform = forecast_module.get_default_transform()\n",
    "instance_splitter = TFTInstanceSplitter(\n",
    "    instance_sampler=TestSplitSampler(),\n",
    "    past_length=window_len,\n",
    "    future_length=window_len, \n",
    "    observed_value_field=\"observed_target\",\n",
    "    time_series_fields=[],\n",
    "    past_time_series_fields=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "527b1c31-dddf-4b18-af74-4a9b33d982c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 3, 128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e2186eb-fab9-4d3e-9f7b-12dbd3eca232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 3, 128])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_size_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fbcffc3e-880a-4a08-911a-c3f104d59fcd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobserved_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariate_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvariate_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprediction_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_size_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/model/moirai/module.py:168\u001b[0m, in \u001b[0;36mMoiraiModule.forward\u001b[0;34m(self, target, observed_mask, sample_id, time_id, variate_id, prediction_mask, patch_size)\u001b[0m\n\u001b[1;32m    161\u001b[0m loc, scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler(\n\u001b[1;32m    162\u001b[0m     target,\n\u001b[1;32m    163\u001b[0m     observed_mask \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m~\u001b[39mprediction_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    164\u001b[0m     sample_id,\n\u001b[1;32m    165\u001b[0m     variate_id,\n\u001b[1;32m    166\u001b[0m )\n\u001b[1;32m    167\u001b[0m scaled_target \u001b[38;5;241m=\u001b[39m (target \u001b[38;5;241m-\u001b[39m loc) \u001b[38;5;241m/\u001b[39m scale\n\u001b[0;32m--> 168\u001b[0m reprs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m masked_reprs \u001b[38;5;241m=\u001b[39m mask_fill(reprs, prediction_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_encoding\u001b[38;5;241m.\u001b[39mweight)\n\u001b[1;32m    170\u001b[0m reprs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    171\u001b[0m     masked_reprs,\n\u001b[1;32m    172\u001b[0m     packed_attention_mask(sample_id),\n\u001b[1;32m    173\u001b[0m     time_id\u001b[38;5;241m=\u001b[39mtime_id,\n\u001b[1;32m    174\u001b[0m     var_id\u001b[38;5;241m=\u001b[39mvariate_id,\n\u001b[1;32m    175\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/module/ts_embed.py:99\u001b[0m, in \u001b[0;36mMultiInSizeLinear.forward\u001b[0;34m(self, x, in_feat_size)\u001b[0m\n\u001b[1;32m     96\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight[idx] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask[idx]\n\u001b[1;32m     97\u001b[0m     bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[idx] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     98\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m---> 99\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_feat_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout inp, ... inp -> ... out\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "res = forecast_module.module(\n",
    "    target = target.float(),\n",
    "    observed_mask = observed_mask.float(),\n",
    "    sample_id = sample_id,\n",
    "    time_id = time_id,\n",
    "    variate_id = variate_id,\n",
    "    prediction_mask = prediction_mask,\n",
    "    patch_size = patch_size_tensor.float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be71075a-8015-4c63-8dda-3ce25b7f272c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target ~ torch.Size([521, 3, 128])\n",
      "observed_mask ~ torch.Size([521, 3, 128])\n",
      "sample_id ~ torch.Size([521, 3])\n",
      "time_id ~ torch.Size([521, 90])\n",
      "variate_id ~ torch.Size([521, 3])\n",
      "patch_size ~ torch.Size([521, 3, 128])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Target ~ {target.shape}\")\n",
    "print(f\"observed_mask ~ {observed_mask.shape}\")\n",
    "print(f\"sample_id ~ {sample_id.shape}\")\n",
    "print(f\"time_id ~ {time_id.shape}\")\n",
    "print(f\"variate_id ~ {variate_id.shape}\")\n",
    "print(f\"patch_size ~ {patch_size_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3ee37-4f48-46db-acb8-e39ac1622051",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_module.module.named_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e0003-fca1-4ed7-95d7-bf103ad15ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"observed: \", observed_mask.shape)\n",
    "print(\"prediction: \", prediction_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bfed00-bc5b-4497-92e1-9dda192fa185",
   "metadata": {},
   "outputs": [],
   "source": [
    "?? forecast_module.module.forward"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
