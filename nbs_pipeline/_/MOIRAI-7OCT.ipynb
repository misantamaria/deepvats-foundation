{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e6da0b-c516-4b80-a8f6-40ad7f502ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "verbose                       = 0\n",
    "check_memory_usage            = True\n",
    "time_flag                     = True\n",
    "window_size_percentage        = True\n",
    "show_plots                    = True\n",
    "reset_kernel                  = True\n",
    "pre_configured_case           = True\n",
    "case_id                       = 7\n",
    "frequency_factor              = 1\n",
    "frequency_factor_change_alias = True\n",
    "check_parameters              = True\n",
    "cuda_device                   = 0\n",
    "remove_lambdas_flag           = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe0f92c-7e77-4ba3-87f1-8b05e7f5cb09",
   "metadata": {},
   "source": [
    "MOIRAI: Toy complete execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019ba616-f2e0-48dc-a2c7-8dc4074f8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "import sys\n",
    "import dvats.utils as ut\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import uni2ts\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.eval_util.plot import plot_next_multi\n",
    "import pyarrow.feather as ft\n",
    "from gluonts.transform.split import TFTInstanceSplitter\n",
    "from gluonts.transform.sampler import TestSplitSampler\n",
    "import numpy as np\n",
    "import einops\n",
    "import torch.nn.functional as F\n",
    "from dvats.memory import gpu_memory_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16086970-ff73-48bb-9635-9ac7d6bd05e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU | Used mem: 22\n",
      "GPU | Used mem: 24\n",
      "GPU | Memory Usage: [\u001b[91m██████████████████--\u001b[0m] \u001b[91m92%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "device = torch.device(f'cuda:{cuda_device}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "if check_memory_usage:\n",
    "    gpu_device = torch.cuda.current_device()\n",
    "    gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61f01f2e-bc85-4f14-89ec-c7ed11dd2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dvats.config as cfg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3385948e-ece8-495b-bd4e-4cb69ebe9d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcWriteOptions size changed, may indicate binary incompatibility. Expected 72 from C header, got 88 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcReadOptions size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Tensor size changed, may indicate binary incompatibility. Expected 64 from C header, got 80 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.NativeFile size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7fdc1807e170>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"umap\")\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from dvats.all import *\n",
    "from fastcore.all import *\n",
    "from tsai.basics import *\n",
    "from tsai.models.InceptionTimePlus import *\n",
    "from tsai.callback.MVP import *\n",
    "import matplotlib.colors as colors\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.progress import ShowGraphCallback\n",
    "from fastai.callback.schedule import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback\n",
    "import wandb\n",
    "from momentfm import MOMENTPipeline\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.eval_util.plot import plot_next_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f5a8c5-697b-4c29-b34f-701933e81e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a14c009b-3b06-4f36-bc46-d641ee31cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "user, project, version, data, config, job_type = cfg_.get_artifact_config_MVP(False)\n",
    "if pre_configured_case: \n",
    "    cfg_.force_artifact_config_mvp(\n",
    "        config = config,\n",
    "        id = case_id,\n",
    "        verbose = verbose, \n",
    "        both = verbose > 0,\n",
    "        frequency_factor = frequency_factor,\n",
    "        frequency_factor_change_alias = frequency_factor_change_alias\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8267b5ad-4e24-4cdf-af50-1b58c284ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"02c_encoder_moment-embedding\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "if verbose > 0: print(\"runname: \"+runname)\n",
    "if verbose > 0: cfg_.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9677a75b-aed4-41e9-ac0e-01ac7e481b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/macu/work/nbs_pipeline/02c_encoder_moment-embedding.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20241007_154648-dvu9ykop</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/dvu9ykop' target=\"_blank\">02c_encoder_moment-embedding</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/dvu9ykop' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/dvu9ykop</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"--> Wandb init\")\n",
    "run = wandb.init(\n",
    "    entity = user,\n",
    "    # work-nbs is a place to log draft runs\n",
    "    project=project,\n",
    "    group=config.wandb_group,\n",
    "    job_type=job_type,\n",
    "    allow_val_change=True,\n",
    "    mode=config.analysis_mode,\n",
    "    config=config,\n",
    "    # When use_wandb is false the run is not linked to a personal account\n",
    "    #NOTE: This is not working right now\n",
    "    anonymous = 'never' if config.use_wandb else 'must', \n",
    "    resume=False,\n",
    "    name = runname\n",
    ")\n",
    "if verbose > 0: print(\"Wandb init -->\")\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa4817bb-194d-4d37-a300-9d66e2ceea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "if verbose > 0: cfg_.show_attrdict(config)\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact\n",
    "train_artifact = artifacts_gettr(config.train_artifact)\n",
    "if verbose > 0: print(\"---> W&B Train Artifact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8860c59-3096-4865-8765-172a8756cd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(550, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "import pyarrow.feather as ft\n",
    "df_train = train_artifact.to_df()\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "473361e5-17b3-4eea-9edc-b9fb3b9f8608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.741822</td>\n",
       "      <td>0.637180</td>\n",
       "      <td>0.565117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>0.739731</td>\n",
       "      <td>0.629415</td>\n",
       "      <td>0.493513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.718757</td>\n",
       "      <td>0.539220</td>\n",
       "      <td>0.469350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>0.730169</td>\n",
       "      <td>0.577670</td>\n",
       "      <td>0.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.752406</td>\n",
       "      <td>0.570180</td>\n",
       "      <td>0.373008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           T3        T2        T1\n",
       "1970-01-01 00:00:00  0.741822  0.637180  0.565117\n",
       "1970-01-01 00:00:01  0.739731  0.629415  0.493513\n",
       "1970-01-01 00:00:02  0.718757  0.539220  0.469350\n",
       "1970-01-01 00:00:03  0.730169  0.577670  0.444100\n",
       "1970-01-01 00:00:04  0.752406  0.570180  0.373008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40a5ad68-8ee4-4a26-b1a0-ade114d01385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"---> Sliding window | \", config.w,  \" | \", config.stride )\n",
    "sw = SlidingWindow(window_len=config.w, stride=config.stride, get_y=[])\n",
    "if verbose > 0: print(\" Sliding window | \", config.w,  \" | \", config.stride, \"---> | df_train ~ \", df_train.shape )\n",
    "X_train, _ = sw(df_train)\n",
    "if verbose > 0: print(\" sw_df_train | \", config.w,  \" | \", config.stride, \"--->\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d023745e-1e68-4947-8696-f91287e104e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 3, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_win x n_vars x win_size\n",
    "# n_batches x n_features x patch_size (before padding)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24e28aa4-a46b-46d0-b5da-ef8a97658416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> get_enc_embs_moirai\n",
      "get_enc_embs_moirai | Using CUDA\n",
      "get_enc_embs_moirai | Get Outputs\n",
      "--> get_enc_embs_moirai | past_target ~ torch.Size([521, 30, 3])\n",
      "--> get_enc_embs_moirai | past_observed_target ~ torch.Size([521, 30, 3])\n",
      "--> get_enc_embs_moirai | past_is_pad ~ torch.Size([521, 30])\n",
      "--> get_enc_embs_moirai | Auxiliar model\n",
      "--> get_enc_embs_moirai | Convert sizes\n",
      "_convert | patch_size ~ 8\n",
      "_convert | past_target ~ torch.Size([521, 30, 3])\n",
      "_convert | past_observed_target ~ torch.Size([521, 30, 3])\n",
      "_convert | past_is_pad ~ torch.Size([521, 30])\n",
      "_convert | future_target ~  torch.Size([521, 3, 3])\n",
      "_convert | target before extend ~  0\n",
      "_convert | target extend ~  2\n",
      "_convert | future_observed_target ~  torch.Size([521, 3, 3])\n",
      "_convert | observed_mask before extend ~  0\n",
      "_convert | observed_mask extend ~  2\n",
      "_convert | future_is_pad ~  torch.Size([521, 3])\n",
      "_convert | sample_id before extend ~  0\n",
      "_convert | sample_id after extend ~  2\n",
      "_convert | time_id after extend ~  6\n",
      "_convert | variate_id after extend ~  2\n",
      "_convert --> |  target~torch.Size([521, 15, 128])\n",
      "_convert --> |  observed_mask~ torch.Size([521, 15, 128])\n",
      "_convert --> |  sample_id~torch.Size([521, 15])\n",
      "_convert --> |  time_id~torch.Size([521, 15])\n",
      "_convert --> |  variate_id~torch.Size([521, 15])\n",
      "_convert --> |  prediction_mask~torch.Size([521, 15])\n",
      "--> get_enc_embs_moirai | target ~ torch.Size([521, 15, 128])\n",
      "--> get_enc_embs_moirai | observed_mask ~ torch.Size([521, 15, 128])\n",
      "--> get_enc_embs_moirai | sample_id ~ torch.Size([521, 15])\n",
      "--> get_enc_embs_moirai | time_id ~ torch.Size([521, 15])\n",
      "--> get_enc_embs_moirai | variate_id ~ torch.Size([521, 15])\n",
      "--> get_enc_embs_moirai | prediction_mask ~ torch.Size([521, 15])\n",
      "get_enc_embs_moirai | embs ~ embs.shape\n",
      "get_enc_embs_moirai -->\n"
     ]
    }
   ],
   "source": [
    "embs = get_enc_embs(\n",
    "    X          = X_train, \n",
    "    enc_learn = MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.1-R-small\"),\n",
    "    cpu       = False,\n",
    "    average_seq_dim = True,\n",
    "    to_numpy        = True,\n",
    "    verbose         = 1,\n",
    "    patch_size      = 8,\n",
    "    size            = \"small\",\n",
    "    time            = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55d8d038-721c-4f7c-bc76-fc3085384236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 384)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ba5ca-5c0a-40f8-b52f-34916f3595eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe7e237-5d45-40ba-bee7-a496cd428d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction for execution time \n",
    "#X_train = X_train[:3, :, :]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3eb054-85f5-49c3-af71-0c4db5e9b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert config.analysis_mode in ['offline','online'], 'Invalid analysis mode'\n",
    "\n",
    "X = X_train\n",
    "if verbose > 0: print(\"len(X): \", len(X));\n",
    "if config.analysis_mode == 'online':\n",
    "    if verbose > 0: print(\"--> Split 1\")\n",
    "    splits = TimeSplitter(valid_size=0.2, show_plot=show_plots)(X)\n",
    "elif config.analysis_mode == 'offline':\n",
    "    if verbose > 0: print(\"--> Split 2\")\n",
    "    splits = get_splits(np.arange(len(X)), valid_size=config.valid_size, show_plot = show_plots)\n",
    "if verbose > 0: \n",
    "    print(\"Split -->\", len(splits[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0d804-2d94-4764-94d0-581fb713a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if verbose > 0: \n",
    "    print(X.shape)\n",
    "    display(splits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab9c74-4458-4f0a-8f92-2da517a8d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splits)\n",
    "len(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e18e35-c24b-4775-a93a-cb01b19406e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ee893-812d-47a4-9e42-bd37ee637710",
   "metadata": {},
   "source": [
    "Ñapa para ver si es un problema de tamaños o qué (dejar 1 ventana solo como en el  ejemplo de uso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6261e0f-cb2b-410e-99ad-ca07f1ab30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train[0]\n",
    "#X_train = einops.rearrange(  torch.as_tensor(X_train, dtype = torch.float32), \"... -> 1 ...\")\n",
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ad7a2-b798-473e-9c76-bce8e5cc02fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42f36d9f-5c6b-4d30-8b6d-af6fcfb9f478",
   "metadata": {},
   "source": [
    "Hasta aquí la ñapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c68b0-c1c5-42e0-a8ab-d84283f66d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_target = einops.rearrange(\n",
    "    torch.as_tensor(X_train, dtype = torch.float32),\n",
    "    \"n_windows n_vars window_size -> n_windows window_size n_vars\"\n",
    ")\n",
    "# 1s if the value is observed, 0s otherwise. Shape: (batch, time, variate)\n",
    "past_observed_target = torch.ones_like(past_target, dtype=torch.bool)\n",
    "# 1s if the value is padding, 0s otherwise. Shape: (batch, time)\n",
    "past_is_pad = torch.zeros_like(past_target, dtype=torch.bool)[...,:,-1] # Kill last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f5d5f-81eb-4b65-be17-db271420bc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(past_target.shape)\n",
    "print(past_observed_target.shape)\n",
    "print(past_is_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8943aae-db91-4d09-a090-6893cfea20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch_size = 32 -> ok\n",
    "patch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a41def3-2076-461a-ba0d-1e9b212696d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_mask = torch.ones_like(past_target, dtype = bool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8497cc0-d6da-439a-96f9-df5569e234ba",
   "metadata": {},
   "source": [
    "¿ Pero tiene sentido separar en Train y test en un zero - shot ? \n",
    "Cojámoslo entero\n",
    "Y cojamos todo como input en lugar de input y label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69483619-1138-4d27-9159-0563558815e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.1-R-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86caf4f1-760c-4b26-b407-4c6427778f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar model for conversions just to ensure correct sizes\n",
    "forecast_model =  MoiraiForecast(\n",
    "    module=module,\n",
    "    prediction_length=past_target.shape[2], #random, just for getting the model\n",
    "    context_length=past_target.shape[1],\n",
    "    patch_size=patch_size,\n",
    "    num_samples=100, #Random, is the number of forecasting, not interesting for us\n",
    "    target_dim=past_target.shape[2],\n",
    "    feat_dynamic_real_dim=0,\n",
    "    past_feat_dynamic_real_dim=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10700d-35c2-4456-9bb2-047d1a24c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = forecast_model(\n",
    "    past_target=past_target,\n",
    "    past_observed_target=past_observed_target,\n",
    "    past_is_pad=past_is_pad,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2a929-422c-4780-843b-006364cac8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    target,\n",
    "    observed_mask,\n",
    "    sample_id,\n",
    "    time_id,\n",
    "    variate_id,\n",
    "    prediction_mask,\n",
    ") = forecast_model._convert(\n",
    "    patch_size,\n",
    "    past_target,\n",
    "    past_observed_target,\n",
    "    past_is_pad\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf34074-394d-4473-b980-4c624ca97e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.hook import *\n",
    "\n",
    "from tsai.models.layers import *\n",
    "\n",
    "def get_acts(\n",
    "    model, \n",
    "    modules, \n",
    "    y=None, \n",
    "    detach=True, \n",
    "    cpu=False,\n",
    "    attr_name = \"data\",\n",
    "    verbose = 0,\n",
    "    **model_kwargs\n",
    "):\n",
    "    r\"\"\"Returns activations and gradients for given modules in a model and a single input or a batch. \n",
    "    Gradients require y value(s). If they are not provided, it will use the predictions. \"\"\"\n",
    "    if not isinstance(modules, list): modules = [modules]\n",
    "    if ('x' in model_kwargs):\n",
    "        x = x[None, None] if x.ndim == 1 else x[None] if x.ndim == 2 else x\n",
    "    if cpu: \n",
    "        model = model.cpu()\n",
    "        #x = x.cpu()\n",
    "        for key in model_kwargs:\n",
    "            try: #if not able to be moved, just not move it\n",
    "                model_kwargs[key] = model_kwargs[key].cpu()\n",
    "            except:\n",
    "                continue\n",
    "    with hook_outputs(modules, detach=detach, cpu=cpu) as h_act:\n",
    "        if verbose > 0:\n",
    "            print(\"get_acts | hook outputs | h_act\")\n",
    "        preds = model.eval()(**model_kwargs)\n",
    "    \n",
    "    if len(modules) == 1: \n",
    "        if verbose > 1:\n",
    "            print(f\"get_acts | h_act stored ~ \", len(h_act.stored))\n",
    "            print(f\"get_acts | h_act stored: \", h_act.stored)\n",
    "        #try:\n",
    "        res = getattr(h_act.stored[0], attr_name), getattr(h_act.stored[0][0], attr_name)\n",
    "        #except:\n",
    "            #res = getattr(h_act.stored[0][0], attr_name), getattr(h_act.stored[0][0][0], attr_name)\n",
    "        return res\n",
    "    else: \n",
    "        return [h.data for h in h_act.stored], [getattr(h_act.stored[0], attr_name) for h in h_grad.stored]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ccea3-9ed7-4580-a571-29f446ccc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs={\n",
    "    'target': target, \n",
    "    'observed_mask': observed_mask,\n",
    "    'sample_id': sample_id,\n",
    "    'time_id': time_id,\n",
    "    'variate_id': variate_id,\n",
    "    'prediction_mask': prediction_mask,\n",
    "    'patch_size': torch.ones_like(sample_id, dtype = torch.float32)*patch_size\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944e1d0-b24a-41a3-95ee-6b5ba7d120ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_model_kwargs={\n",
    "    'past_target': past_target, \n",
    "    'past_observed_target': past_observed_target,\n",
    "    'past_is_pad': past_is_pad\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9111a-07f4-45d6-80ef-79694b984e64",
   "metadata": {},
   "source": [
    "Pequeño trial porque se queda bloqueado y no entiendo por qué\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7a9d2-372a-41b4-acbe-d7be84c9f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor = forecast_model.create_predictor(batch_size = target.shape[0])\n",
    "#forecasts = predictor.predict(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b806d4-6cae-481d-9d18-5427ce3e12f7",
   "metadata": {},
   "source": [
    "Fin del trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82e37a-1af2-46f9-b6a5-d8e06650c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvats.utils import Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8dd9c2-4f36-4071-bb52-dc236e8951f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_module_activation(model, module, cpu, **model_kwargs):\n",
    "    if cpu:\n",
    "        for key in model_kwargs:\n",
    "            try: #if not able to be moved, just not move it\n",
    "                model_kwargs[key] = model_kwargs[key].cpu()\n",
    "            except:\n",
    "                continue\n",
    "    h_act = hook_outputs([module], detach = True, cpu = cpu, grad = False)\n",
    "    preds = model.eval()(**model_kwargs)\n",
    "    return [o.stored for o in h_act]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c6092-56fe-44b7-9259-4f640fe298aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(module.encoder.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5d386-e34d-405c-8229-dbbe61284e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "? uni2ts.module.norm.RMSNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f0c53-048c-4cf5-b4c5-bccde5ece15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = Time()\n",
    "modules = [module.encoder.norm]\n",
    "timer.start()\n",
    "acts = get_module_activation(\n",
    "    model = module, \n",
    "    module = module.encoder.norm, \n",
    "    cpu = False, \n",
    "    **model_kwargs\n",
    ")\n",
    "timer.end()\n",
    "timer.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e5172-29f4-45f4-a7c4-6f30e6df27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = acts[0]\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266497c-3358-496f-94a1-74c06ab5ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = embs.mean(dim = 1)\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6826ff34-8a10-4155-b4ad-c2bf12182332",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
