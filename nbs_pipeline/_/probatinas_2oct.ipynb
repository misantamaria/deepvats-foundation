{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef5c395-30d8-4596-ad9e-2a4618097291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "import sys\n",
    "import dvats.utils as ut\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import uni2ts\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.eval_util.plot import plot_next_multi\n",
    "import pyarrow.feather as ft\n",
    "from gluonts.transform.split import TFTInstanceSplitter\n",
    "from gluonts.transform.sampler import TestSplitSampler\n",
    "import numpy as np\n",
    "import einops\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3fd9eca-3d28-46b5-83fe-5b980c14c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aff248c-43cc-4f8c-8d22-5d4eec9adb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_id(batch_size, seq_len):\n",
    "    # Creamos un tensor con valores [0, 1, ..., batch_size - 1]\n",
    "    # Luego lo repetimos seq_len veces a lo largo de la dimensión 1\n",
    "    return einops.repeat(torch.arange(batch_size), 'b -> b seq', seq=seq_len)\n",
    "    \n",
    "def get_variate_id(batch_size, seq_len, n_vars):\n",
    "    total_repeats = seq_len // n_vars  # Cantidad de veces que cada variate_id debe repetirse para llenar seq_len\n",
    "    remaining = seq_len % n_vars  # Resto que no completa una división exacta\n",
    "    var_ids = torch.arange(n_vars).repeat_interleave(total_repeats)\n",
    "    if remaining > 0:\n",
    "        var_ids = torch.cat((var_ids, torch.arange(remaining)))\n",
    "    return var_ids.unsqueeze(0).repeat(batch_size, 1)\n",
    "    \n",
    "def get_time_id(batch_size, seq_len, patches_per_var):\n",
    "    patches_per_var = int (patches_per_var)\n",
    "    # Creamos un tensor que repite una secuencia de 0 a patches_per_var-1\n",
    "    time_ids = torch.arange(patches_per_var).repeat(seq_len // patches_per_var + 1)[:seq_len]\n",
    "    # Repetimos este patrón para cada muestra en el batch\n",
    "    return time_ids.unsqueeze(0).repeat(batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb157fe9-8486-4302-a393-69b93ef7dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padd_tensor(X, window_len, patch_size, num_variates):\n",
    "    # Calcular el número total de parches necesarios para una sola variable\n",
    "    n_patches_single_var = int(np.ceil(window_len / patch_size))\n",
    "    total_length_needed = n_patches_single_var * patch_size  # Longitud total requerida con padding\n",
    "\n",
    "    # Calcular el padding necesario si existe\n",
    "    padding_size = total_length_needed - window_len\n",
    "\n",
    "    # Añadir padding a X si es necesario\n",
    "    x_padd = X\n",
    "    if padding_size > 0:\n",
    "        x_padd = F.pad(X, (0, padding_size), mode='constant', value=0)  # Pad al final de la última dimensión\n",
    "\n",
    "    # Ajustar n_patches considerando todas las variables\n",
    "    n_patches = n_patches_single_var * num_variates\n",
    "    return x_padd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831e5dfe-8d9e-4152-9676-78d72804f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_windows, num_variates, window_len = shape = (521, 3, 30) \n",
    "X = torch.rand(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5df84f87-e93a-4cf1-956c-85e38860aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = num_windows\n",
    "patch_size = 128 #Porque 8 no le gusta y parece que está hecho a 64\n",
    "max_patch = patch_size \n",
    "n_patches = int(np.ceil(window_len/patch_size))*num_variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cca5d4-8042-4c50-8b4a-ba2ce903ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be05ce-1712-43ba-b749-8d31c2da7598",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b5206-cee8-48f6-bcc9-5428327bd571",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ceil(window_len/patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dca2ed-25d9-4519-a97b-70e562ef5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patches = int(np.ceil(window_len/patch_size))*num_variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e04aee7-99b9-4a52-b0e6-9c7253bcd976",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ec58058-61b9-4617-9d34-bdc150768c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_padded = padd_tensor(X, window_len, patch_size, num_variates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f01d9c9-8fab-41f0-82c0-9b894f6eeca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b1a06c1-3f8c-4d95-9a10-21f3da7fb586",
   "metadata": {},
   "outputs": [],
   "source": [
    "module=MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.0-R-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7404bc6-2e72-4283-8a3c-8bd24009ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "? module.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3b84a5e-d39e-47ca-8553-298d6c8be48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = einops.rearrange(\n",
    "    x_padded,\n",
    "    'batch_size n_vars (n_patches p) -> batch_size (n_vars n_patches) p',\n",
    "    p = patch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e17e57e3-e01a-4040-9bb9-ae2b8bd8ea6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       " \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len max_patch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mobserved_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len max_patch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msample_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtime_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvariate_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprediction_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaxtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*batch seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Defines the forward pass of MoiraiModule.\n",
       "This method expects processed inputs.\n",
       "\n",
       "1. Apply scaling to observations\n",
       "2. Project from observations to representations\n",
       "3. Replace prediction window with learnable mask\n",
       "4. Apply transformer layers\n",
       "5. Project from representations to distribution parameters\n",
       "6. Return distribution object\n",
       "\n",
       ":param target: input data\n",
       ":param observed_mask: binary mask for missing values, 1 if observed, 0 otherwise\n",
       ":param sample_id: indices indicating the sample index (for packing)\n",
       ":param time_id: indices indicating the time index\n",
       ":param variate_id: indices indicating the variate index\n",
       ":param prediction_mask: binary mask for prediction horizon, 1 if part of the horizon, 0 otherwise\n",
       ":param patch_size: patch size for each token\n",
       ":return: predictive distribution\n",
       "\u001b[0;31mFile:\u001b[0m      ~/work/nbs_pipeline/uni2ts/src/uni2ts/model/moirai/module.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? module.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fda0c83a-cd55-48b7-a82b-9d1465c3e0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 3, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, seq_len, max_patch = target.shape\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8485986-3c71-44f0-ac5c-467080589c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_mask = torch.ones_like(target, dtype = bool)\n",
    "prediction_mask = torch.zeros((batch_size, n_patches), dtype = bool)\n",
    "sample_id = get_sample_id(batch_size, n_patches)\n",
    "variate_id = get_variate_id(batch_size, n_patches, num_variates)\n",
    "time_id = get_time_id(batch_size, seq_len, 1)\n",
    "patch_size_tensor =  torch.zeros((batch_size, n_patches, patch_size))+patch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efb94646-fc32-4c86-85a1-d61899f98136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target ~ torch.Size([521, 3, 128])\n",
      "observed_mask ~ torch.Size([521, 3, 128])\n",
      "prediction_mask ~ torch.Size([521, 3])\n",
      "sample_id ~ torch.Size([521, 3])\n",
      "time_id ~ torch.Size([521, 3])\n",
      "variate_id ~ torch.Size([521, 3])\n",
      "patch_size ~ torch.Size([521, 3, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([521, 3, 128])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Target ~ {target.shape}\")\n",
    "print(f\"observed_mask ~ {observed_mask.shape}\")\n",
    "print(f\"prediction_mask ~ {prediction_mask.shape}\")\n",
    "print(f\"sample_id ~ {sample_id.shape}\")\n",
    "print(f\"time_id ~ {time_id.shape}\")\n",
    "print(f\"variate_id ~ {variate_id.shape}\")\n",
    "print(f\"patch_size ~ {patch_size_tensor.shape}\")\n",
    "patch_size_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acc1588e-d7a2-46d6-94ec-3289fa824a8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariate_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/model/moirai/module.py:168\u001b[0m, in \u001b[0;36mMoiraiModule.forward\u001b[0;34m(self, target, observed_mask, sample_id, time_id, variate_id, prediction_mask, patch_size)\u001b[0m\n\u001b[1;32m    161\u001b[0m loc, scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler(\n\u001b[1;32m    162\u001b[0m     target,\n\u001b[1;32m    163\u001b[0m     observed_mask \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m~\u001b[39mprediction_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    164\u001b[0m     sample_id,\n\u001b[1;32m    165\u001b[0m     variate_id,\n\u001b[1;32m    166\u001b[0m )\n\u001b[1;32m    167\u001b[0m scaled_target \u001b[38;5;241m=\u001b[39m (target \u001b[38;5;241m-\u001b[39m loc) \u001b[38;5;241m/\u001b[39m scale\n\u001b[0;32m--> 168\u001b[0m reprs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m masked_reprs \u001b[38;5;241m=\u001b[39m mask_fill(reprs, prediction_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_encoding\u001b[38;5;241m.\u001b[39mweight)\n\u001b[1;32m    170\u001b[0m reprs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    171\u001b[0m     masked_reprs,\n\u001b[1;32m    172\u001b[0m     packed_attention_mask(sample_id),\n\u001b[1;32m    173\u001b[0m     time_id\u001b[38;5;241m=\u001b[39mtime_id,\n\u001b[1;32m    174\u001b[0m     var_id\u001b[38;5;241m=\u001b[39mvariate_id,\n\u001b[1;32m    175\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/module/ts_embed.py:99\u001b[0m, in \u001b[0;36mMultiInSizeLinear.forward\u001b[0;34m(self, x, in_feat_size)\u001b[0m\n\u001b[1;32m     96\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight[idx] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask[idx]\n\u001b[1;32m     97\u001b[0m     bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[idx] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     98\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m---> 99\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_feat_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout inp, ... inp -> ... out\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "module(target, observed_mask, sample_id, time_id, variate_id, prediction_mask, patch_size_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b0a90-1985-4adc-b8cd-c9dfdf727b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62924ce-add6-44a7-b2dd-311068134bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470dde6-4dcb-4a47-a3ed-cae13e8d4d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730158c1-83e5-49a0-bf64-da52eb71ca4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8eaf3-fd04-4ef0-82bd-093718f57c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a054df0-45cb-4bbe-b650-de8ad4620702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb27fec-edb0-41b1-955d-683cbedc6630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989810d0-8508-4a07-bcc4-1e03cf6176f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c09e6-cf82-4002-a71d-ec207f96e792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f830b1-eedf-47ad-a285-0295c43fd720",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee056e-1b68-46b9-81c4-8acc03e1b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_module = MoiraiForecast(\n",
    "    module=MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.0-R-small\"),\n",
    "    prediction_length=30, # No puede ser 0 porque falla el predictor... Pongo window len que es lo más parecido que tengo a \"aprender mismos tamaños\"\n",
    "    context_length=30,\n",
    "    patch_size=patch_size,\n",
    "    num_samples=100,\n",
    "    target_dim=3,\n",
    "    feat_dynamic_real_dim = 0,\n",
    "    past_feat_dynamic_real_dim = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d56279c-e1e9-414a-826d-ba8f4027ccb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2645d10a-73c8-45d0-9527-cc435570f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transform = forecast_module.get_default_transform()\n",
    "instance_splitter = TFTInstanceSplitter(\n",
    "    instance_sampler=TestSplitSampler(),\n",
    "    past_length=window_len,\n",
    "    future_length=window_len, \n",
    "    observed_value_field=\"observed_target\",\n",
    "    time_series_fields=[],\n",
    "    past_time_series_fields=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646c884-c9db-4de0-b1c2-777dabb3d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "?? forecast_module.create_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d247b2-92b1-4b5c-8d80-fbd70d6d47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37cdea-9666-4b67-8dda-1b7a875edaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = forecast_module.create_predictor(batch_size = batch_size)\n",
    "forecasts = predictor.predict(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577e2f4-c0b9-4fad-a996-c3037b0ca727",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_module = forecast_module.to(device)\n",
    "target = target.float().to(device)\n",
    "observed_mask = observed_mask.float().to(device)\n",
    "sample_id = sample_id.to(device)\n",
    "time_id = time_id.to(device)\n",
    "variate_id = variate_id.to(device)\n",
    "prediction_mask = prediction_mask.to(device)\n",
    "patch_size_tensor = patch_size_tensor.float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91a338a-c681-41bb-b8ef-ec5a56fd3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a64300-1c29-45c2-aa56-a0d62fd1045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = forecast_module.module(\n",
    "    target = target.float(),\n",
    "    observed_mask = observed_mask.float(),\n",
    "    sample_id = sample_id,\n",
    "    time_id = time_id,\n",
    "    variate_id = variate_id,\n",
    "    prediction_mask = prediction_mask,\n",
    "    patch_size = patch_size_tensor.float()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9049c-09a8-4498-8b7c-3dab4311f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_module.describe_inputs(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676df5c-6e1d-43ea-9936-f0e3e6e4eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_module.module.mask_encoding.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446a2c2-6754-4419-9f9b-3320b5b6fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?? forecast_module.module\n",
    "state_dict = module.state_dict()\n",
    "for key, value in state_dict.items():\n",
    "    print(f\"{key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0dc337-cd89-4ca3-b050-2acd64c7ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_module = forecast_module.to(device)\n",
    "target = target.float().to(device)\n",
    "observed_mask = observed_mask.bool().to(device)\n",
    "sample_id = sample_id.int().to(device)\n",
    "time_id = time_id.int().to(device)\n",
    "variate_id = variate_id.int().to(device)\n",
    "prediction_mask = prediction_mask.to(device)\n",
    "patch_size_tensor = patch_size_tensor.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba46648-3bad-4fca-bcc7-24e90c664acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ade46b-9dc4-47c8-9a0f-71211f5b71af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Target ~ {target.shape}\")\n",
    "print(f\"observed_mask ~ {observed_mask.shape}\")\n",
    "print(f\"prediction_mask ~ {prediction_mask.shape}\")\n",
    "print(f\"sample_id ~ {sample_id.shape}\")\n",
    "print(f\"time_id ~ {time_id.shape}\")\n",
    "print(f\"variate_id ~ {variate_id.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e17e76c-aa9f-4414-9d29-41f3cd5b9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "2*128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24516e29-43ac-40e4-a0be-b886c0ed430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_module.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d975b4-6adc-48d4-aeed-83fc5f340222",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_module.hparams_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a000d-e6a7-4676-a8e9-65ac6d3016eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = forecast_module.forward(\n",
    "    past_target = target.float().to(device),\n",
    "    past_observed_target = observed_mask.bool().to(device),\n",
    "    past_is_pad = torch.zeros((target.shape[0], target.shape[1]), dtype = bool).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35db74b-761c-4a54-9e98-8e2e24ca2e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversos = forecast_module._convert(\n",
    "    patch_size = patch_size,\n",
    "    past_target = target.to(device),\n",
    "    past_observed_target = observed_mask.to(device),\n",
    "    past_is_pad = torch.zeros((target.shape[0], target.shape[1]), dtype = bool).to(device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713f569-d953-4f12-a339-455c02c2fe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.torch.model.predictor import  PyTorchPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf9f93-7c28-415a-b563-cb5d16182afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = forecast_module.describe_inputs(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8e676-7b02-474d-9628-28ea9c17b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvats import config as cfg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4ecf1-856f-4278-b933-a947763866cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_.show_attrdict(input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040fbf8-03da-41a1-9669-d77fe9c8e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_predictor = PyTorchPredictor(\n",
    "    input_names = list(input_names),\n",
    "    prediction_net = module, \n",
    "    batch_size = batch_size,\n",
    "    prediction_length = 30,\n",
    "    input_transform = forecast_module.get_default_transform(),\n",
    "    device = device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b61f5c6-c981-4a57-aaf5-1c7a9b2e8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = predictor.predict(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf5ccb3-ce73-4ac4-ab87-67d4571b6abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "?? module_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec17e4-99a9-4cf2-bd57-d8d40321adbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b64ae-1c42-40b0-b6fb-22694a3f69e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "?? forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5153ee4-9c53-47d7-aee4-d3a2de1e1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = module.get_latent_representation(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdee027-ce1d-4fdb-82c8-e1f726ffb286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uni2ts.model.moirai import MoiraiModule\n",
    "\n",
    "class MoiraiEmbeddingExtractor(MoiraiModule):\n",
    "    def forward(self, batch, patch_size, return_embeddings=False):\n",
    "        # Step through your model and intercept the embeddings layer\n",
    "        hidden_states = self.encode(batch)  # Modify this line based on model specifics\n",
    "        if return_embeddings:\n",
    "            return hidden_states  # Extract embeddings before final prediction\n",
    "        return self.decode(hidden_states)  # Proceed with prediction if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e6790-30c6-4370-aeba-283a24a75db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_aux_no_forecast = MoiraiEmbeddingExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d833267-4538-46fb-8ad1-5b5170d7bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = module(batch_size, patch_size, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae3271-838a-4ccc-961c-91a222ad5f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.0-R-small\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c63467-bfbf-4e28-bcec-e96b7df53c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "module.mask_encoding.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c8678-6f2d-49d9-b4aa-aab23f3025fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "module(\n",
    "    target,\n",
    "    observed_mask,\n",
    "    sample_id, \n",
    "    time_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
