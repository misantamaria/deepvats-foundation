{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b82079-ae97-482c-ac78-cd3cf62f720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cd3216-c8fb-4b5d-bffb-d459f79c3d57",
   "metadata": {},
   "source": [
    "Comprobando el padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f1be1c2-79ba-4838-9f67-73bf55955287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (batch, seq_length, max_patch) = (batch, past_time, tgt)\n",
    "#past_observed_target = torch.ones(1,4,2)\n",
    "past_observed_target = torch.ones(5,500,50)\n",
    "batch, past_time, tgt = past_observed_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ebb3a0f-0a7f-4df5-900c-456fceb4f241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 500, 50])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_observed_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b073a5fd-b38a-4778-a3ed-1a1363e355ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "max_patch = 6\n",
    "patch_size = 5\n",
    "#patch_size = 7\n",
    "pad = (-tgt % patch_size, 0)\n",
    "print(pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baaeeb3-dcae-4266-aa99-a41b899283ba",
   "metadata": {},
   "source": [
    "Nota: cuidado al interpretar el residuo con valores negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b482289b-3fe5-4124-a0f1-cd442fa77b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.0\n",
      "-10\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "coef = -tgt/patch_size\n",
    "print(coef) \n",
    "coef = round(coef)\n",
    "print(coef) \n",
    "res = -tgt - coef*patch_size\n",
    "print ( res )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef449302-92a3-4bb2-ac6b-9d7bad57daf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5900ee-1cc9-4746-8433-ecb3fff7b73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e5c0e87a-97ea-4dea-92e1-f706d278d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.nn.functional.pad(\n",
    "    input = past_observed_target,\n",
    "    pad   = pad,\n",
    "    mode  = 'constant',\n",
    "    value = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ffebc0f8-4edc-4f6f-9a53-7eb8293c4a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 500, 50])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a0c8c9d-3f31-43ee-b071-686b0b4ef745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 1.],\n",
       "         [0., 1., 1.],\n",
       "         [0., 1., 1.],\n",
       "         [0., 1., 1.]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b517aaf-79ee-4487-8d4f-321add55a9e6",
   "metadata": {},
   "source": [
    "Ha aumentado en 1 la tercera dimensión (la última), metiendo ceros por delante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb22dc20-ffd7-499a-aeb4-23805808d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5689707-812c-4fee-bd09-6aebe6becfee",
   "metadata": {},
   "outputs": [
    {
     "ename": "EinopsError",
     "evalue": " Error while processing max-reduction pattern \"... (seq patch) dim -> ... seq\".\n Input tensor shape: torch.Size([1, 4, 7]). Additional info: {'patch': 7}.\n Shape mismatch, can't divide axis of length 4 in chunks of 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/einops/einops.py:523\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    522\u001b[0m     recipe \u001b[38;5;241m=\u001b[39m _prepare_transformation_recipe(pattern, reduction, axes_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(axes_lengths), ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(shape))\n\u001b[0;32m--> 523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_recipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhashable_axes_lengths\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EinopsError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/einops/einops.py:234\u001b[0m, in \u001b[0;36m_apply_recipe\u001b[0;34m(backend, recipe, tensor, reduction_type, axes_lengths)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     init_shapes, axes_reordering, reduced_axes, added_axes, final_shapes, n_axes_w_added \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct_from_shape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_lengths\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# shape or one of passed axes lengths is not hashable (i.e. they are symbols)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/einops/einops.py:187\u001b[0m, in \u001b[0;36m_reconstruct_from_shape_uncached\u001b[0;34m(self, shape, axes_dims)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(length, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(known_product, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m length \u001b[38;5;241m%\u001b[39m known_product \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch, can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt divide axis of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlength\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in chunks of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mknown_product\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m unknown_axis \u001b[38;5;241m=\u001b[39m unknown_axes[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mEinopsError\u001b[0m: Shape mismatch, can't divide axis of length 4 in chunks of 7",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m past_seq_id \u001b[38;5;241m=\u001b[39m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m... (seq patch) dim -> ... seq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/einops/einops.py:533\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Input is list. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdditional info: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(axes_lengths)\n\u001b[0;32m--> 533\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m EinopsError(message \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e))\n",
      "\u001b[0;31mEinopsError\u001b[0m:  Error while processing max-reduction pattern \"... (seq patch) dim -> ... seq\".\n Input tensor shape: torch.Size([1, 4, 7]). Additional info: {'patch': 7}.\n Shape mismatch, can't divide axis of length 4 in chunks of 7"
     ]
    }
   ],
   "source": [
    "past_seq_id = reduce(\n",
    "    res, \n",
    "    \"... (seq patch) dim -> ... seq\",\n",
    "    \"max\",\n",
    "    patch = patch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127da23-cbd1-4fa9-a17f-cd7ff13feb1b",
   "metadata": {},
   "source": [
    "A juzgar por el error, va a tratar de dividir la segunda dimensión en lotes de patch_dim\n",
    "Ajustemos los valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2f61440-fa10-497a-9076-bf055ea9f564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 500, 50])\n",
      "(0, 0)\n",
      "torch.Size([5, 500, 50])\n"
     ]
    }
   ],
   "source": [
    "# (batch, seq_length, max_patch) = (batch, past_time, tgt)\n",
    "past_observed_target = torch.ones(5,500,50)\n",
    "batch, past_time, tgt = past_observed_target.shape\n",
    "print (past_observed_target.shape)\n",
    "max_patch = 6\n",
    "patch_size = 5\n",
    "pad = (-tgt % patch_size, 0)\n",
    "print(pad)\n",
    "\n",
    "res = torch.nn.functional.pad(\n",
    "    input = past_observed_target,\n",
    "    pad   = pad,\n",
    "    mode  = 'constant',\n",
    "    value = None\n",
    ")\n",
    "\n",
    "print (res.shape)\n",
    "\n",
    "past_seq_id = reduce(\n",
    "    res, \n",
    "    \"... (seq patch) dim -> ... seq\",\n",
    "    \"max\",\n",
    "    patch = patch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66480d63-1c87-4cfa-bf4f-161c4edec248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 100])\n"
     ]
    }
   ],
   "source": [
    "print(past_seq_id.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f427f4-82fc-4527-b4a5-b4f08e74e766",
   "metadata": {},
   "source": [
    "Resumen \n",
    "\n",
    "past_observed_target ~ (batch, past_time, tgt)\n",
    "padded_tensor ~ (batch, past_time, padded_tgt) , donde en padded_tgt se ha ajustado tgt para ser multiplo de patch_size\n",
    "past_seq_id ~ (batch, past_time, reduced_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bdea10a4-f301-46a5-8f57-82b29a5b97c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed: torch.Size([2, 8, 5])\n",
      "Padded: torch.Size([2, 8, 8])\n",
      "Aplastando la última dimensión con máximo torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from einops import reduce\n",
    "\n",
    "# Supongamos que tenemos un tensor de tamaño (batch, past_time, tgt)\n",
    "batch_size = 2\n",
    "past_time = 8\n",
    "tgt = 5\n",
    "patch_size = 4\n",
    "\n",
    "# Crear un tensor de ejemplo\n",
    "past_observed_target = torch.randn(batch_size, past_time, tgt)\n",
    "\n",
    "# Función de padding (ejemplo simplificado)\n",
    "def _patched_seq_pad(patch_size, tensor, dim, left=True):\n",
    "    size = tensor.size(dim)\n",
    "    pad_length = -size % patch_size\n",
    "    if pad_length > 0:\n",
    "        pad = (pad_length, 0) if left else (0, pad_length)\n",
    "        tensor = torch.nn.functional.pad(tensor, pad, \"constant\", 0)\n",
    "    return tensor\n",
    "print(f\"observed: {past_observed_target.shape}\")\n",
    "# Aplicar padding\n",
    "padded_tensor = _patched_seq_pad(patch_size, past_observed_target, -1, left=True)\n",
    "print(f\"Padded: {padded_tensor.shape}\")\n",
    "# Aplicar reducción con einops.reduce\n",
    "past_seq_id = reduce(\n",
    "    padded_tensor,\n",
    "    \"... (seq patch) dim -> ... seq\",\n",
    "    \"max\",\n",
    "    patch=patch_size\n",
    ")\n",
    "print(f\"Aplastando la última dimensión con máximo {past_seq_id.shape}\")  # Salida: (batch_size, past_time//patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29821b17-f240-420c-b2e9-b28500d9ac4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000, -0.6181, -0.3906, -1.2436,  1.1761,\n",
       "          -0.1643],\n",
       "         [ 0.0000,  0.0000,  0.0000,  1.8827,  0.5280,  0.7877,  0.5154,\n",
       "           1.2527],\n",
       "         [ 0.0000,  0.0000,  0.0000, -1.1373,  0.0117,  0.1479,  1.0995,\n",
       "           0.3216],\n",
       "         [ 0.0000,  0.0000,  0.0000, -2.0903, -0.9213, -0.2917,  1.6650,\n",
       "          -0.1102],\n",
       "         [ 0.0000,  0.0000,  0.0000, -0.1578,  0.4736, -1.4402, -0.2708,\n",
       "          -0.9566],\n",
       "         [ 0.0000,  0.0000,  0.0000, -1.0781,  0.8618, -0.4100,  2.8120,\n",
       "          -0.1540],\n",
       "         [ 0.0000,  0.0000,  0.0000,  1.3022, -0.6925,  0.1545,  0.3131,\n",
       "          -1.1866],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.9113, -0.2068, -0.5051, -1.5341,\n",
       "          -0.0877]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0999, -1.7418, -0.9186,  1.3988,\n",
       "           1.0960],\n",
       "         [ 0.0000,  0.0000,  0.0000, -1.9745,  1.8979, -1.9370,  1.5482,\n",
       "           1.0405],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.1731, -2.0370,  0.7417, -0.6418,\n",
       "           0.7269],\n",
       "         [ 0.0000,  0.0000,  0.0000, -0.0134, -1.0395, -0.9296, -0.1030,\n",
       "          -1.8498],\n",
       "         [ 0.0000,  0.0000,  0.0000, -0.6902,  0.6836,  1.7730,  0.5069,\n",
       "           0.9441],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0483,  2.2819, -0.4284, -1.7632,\n",
       "          -1.0816],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.6242,  0.7902, -1.7581, -0.0868,\n",
       "          -0.3085],\n",
       "         [ 0.0000,  0.0000,  0.0000, -1.2289,  1.5275, -1.4346, -1.3296,\n",
       "          -0.1408]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5e92e79-74a2-4252-9521-6f8eb3cc5c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8827, 2.8120],\n",
       "        [1.8979, 2.2819]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_seq_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
