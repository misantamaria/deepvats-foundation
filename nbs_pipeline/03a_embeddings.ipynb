{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de2cd87-7d93-45ec-bd92-d97a85cf73b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Getting the embeddings\n",
    "\n",
    "> This notebook gets the embeddings (or latent space) from a multivariate time series \n",
    "given by a encoder (e.g., autoencoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816ae963-a2d2-467a-90ee-2be0f383c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_patch_size = 8\n",
    "verbose          = 0\n",
    "reset_kernel     = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db2cd5f-dd8d-42a3-bdc1-afc12ff80afb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7fa8ab7ae200>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "from dvats.all import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from yaml import load, FullLoader\n",
    "import dvats.utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6774bdd-fc22-4e8e-96c4-c29417380137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280e30d-8195-4f39-898a-495d9253778b",
   "metadata": {},
   "source": [
    "## Config parameters\n",
    "> Configuration parameters are obtained from 'config\\03-embeddings.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fd16b-1ca7-4bed-9173-642cabdbe9bb",
   "metadata": {},
   "source": [
    "### Get configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47519e96-4dd2-4096-8189-d735f88155ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, job_type = get_artifact_config_embeddings(verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515769be-e06d-4ae2-b3ab-1636642a158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/zeroshot-moment-small-embedding:latest\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372ce1e-f3c8-4df4-a802-1250bc9a80cb",
   "metadata": {},
   "source": [
    "### Show configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5f95d2-f07a-4e39-bfed-ade6555641bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/zeroshot-moment-small-embedding:latest\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe624f-f4ff-4310-9d3c-23099381ed91",
   "metadata": {},
   "source": [
    "## Build W&B artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67704d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 03a_embeddings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"03a_embeddings\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "print(\"runname: \"+runname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa46f602-bbf9-4d2d-ae68-771adae56199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20250121_181503-m9c0m1u1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/m9c0m1u1' target=\"_blank\">03a_embeddings</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/m9c0m1u1' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/m9c0m1u1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    entity      = config.wandb_entity,\n",
    "    project     = config.wandb_project if config.use_wandb else 'work-nbs', \n",
    "    group       = config.wandb_group,\n",
    "    job_type    = job_type,\n",
    "    mode        = 'online' if config.use_wandb else 'disabled',\n",
    "    anonymous   = 'never'  if config.use_wandb else 'must',\n",
    "    config      = config,\n",
    "    resume      = 'allow',\n",
    "    name        = runname\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b68a48-1629-4ad4-940b-2abc310ad942",
   "metadata": {},
   "source": [
    "## Get trained model artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa21e68-a1fd-4bf5-b3fc-84f5295f4ad1",
   "metadata": {},
   "source": [
    "### Build artifact selector\n",
    "> Botch to use artifacts offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26dac90a-ed13-4f50-b95e-fc78c635e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08922829-19f7-4cdc-97b1-86f5a3b4f3d2",
   "metadata": {},
   "source": [
    "### Get the model from W&B\n",
    "> Restore the encoder model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e978658-78de-4dff-9679-d2ed1453dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_artifact = artifacts_gettr(config.enc_artifact, type='learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fbe313-d3b6-4793-aaf3-34d4b858065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact zeroshot-moment-small-embedding:latest, 144.63MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n"
     ]
    }
   ],
   "source": [
    "# TODO: This only works when you run it two timeS! WTF?\n",
    "try:\n",
    "    enc_learner = enc_artifact.to_obj()\n",
    "except:\n",
    "    enc_learner = enc_artifact.to_obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb98d5-9ba2-4cc9-a033-91282bdab376",
   "metadata": {},
   "source": [
    "## Get dataset artifact from W&B\n",
    "### Restore the dataset artifact used for training the encoder. \n",
    "> Even if we do not compute the dimensionality reduction over this dataset, we need to know the metadata of the encoder training set, to check that it matches with the dataset that we want to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4335e626-5faa-4d27-845c-015f23ab9375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gtrends_khols-normalized_yearly:v0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run            = enc_artifact.logged_by()\n",
    "enc_artifact_train = artifacts_gettr(\n",
    "                        enc_run.config['train_artifact'], \n",
    "                        type='dataset'\n",
    "                    )\n",
    "enc_artifact_train.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b5100a8-f044-4337-8731-4e7a76854a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: 0.4\n",
      "w: 17\n",
      "alias: gtrends_khols-normalized_yearly\n",
      "epochs: 200\n",
      "mvp_ws: [12, 17]\n",
      "stride: 1\n",
      "mask_sync: False\n",
      "use_wandb: True\n",
      "batch_size: 16\n",
      "valid_size: 0.2\n",
      "mask_future: True\n",
      "wandb_group: None\n",
      "analysis_mode: online\n",
      "mask_stateful: False\n",
      "norm_by_sample: False\n",
      "train_artifact: mi-santamaria/deepvats/gtrends_khols-normalized_yearly:v0\n",
      "valid_artifact: None\n",
      "norm_use_single_batch: False\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(enc_run.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918829a-dd1f-4ddb-915c-cebf41665160",
   "metadata": {},
   "source": [
    "### Specify the dataset artifact that we want to get the embeddings from\n",
    "> If no artifact is defined, the artifact to reduce will be the one used for validate the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b394f66-6b1d-4c39-a4c8-6786c4f9b493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run.config['stride']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ff4ef9-cabd-41cb-84c8-ec86cadf5848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gtrends_khols-normalized_yearly:v0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ar_name = ifnone(\n",
    "    config.input_ar, \n",
    "    f'{enc_artifact_train.entity}/{enc_artifact_train.project}/{enc_artifact_train.name}'\n",
    ")\n",
    "wandb.config.update({'input_ar': input_ar_name}, allow_val_change=True)\n",
    "input_ar = artifacts_gettr(input_ar_name)\n",
    "input_ar.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a84cf086-f6ee-4f04-a234-581a738fc338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>0.090912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>0.090912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-15</th>\n",
       "      <td>0.090912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-22</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-29</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              volume\n",
       "2004-01-01  0.090912\n",
       "2004-01-08  0.090912\n",
       "2004-01-15  0.090912\n",
       "2004-01-22  0.000000\n",
       "2004-01-29  0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = input_ar.to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46c6bb02-9a43-4917-93a9-0832ee98b5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a5aa715-e4ea-44b1-b765-0257221d50ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(enc_run.config['w'])\n",
    "print(enc_run.config['stride'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a22dbdb5-8f92-4f56-bc4f-286bcd453986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc_run.config['w'] = 54\n",
    "#enc_run.config['stride'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df07cc30-657b-41e8-8f21-0908f6c8dcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run.config['norm_use_single_batch'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49908f03-6875-4e27-8050-09af41dc62bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 1, 17)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input, _ = SlidingWindow(window_len=enc_run.config['w'], \n",
    "                             stride=enc_run.config['stride'], \n",
    "                             get_y=[])(df)\n",
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf910313-b689-45f2-b405-5c4b3ef66012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1737483334.0370922"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = ut.Time()\n",
    "timer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97d09238-e62c-4135-baf7-4b7d38e3c19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mi-santamaria/deepvats/zeroshot-moment-small-embedding:latest'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.enc_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9dcf6e5-a338-4638-b0bc-2ecfc12eadf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(enc_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff3d78e0-5847-4606-9cab-b9c9e02c0a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4104"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(enc_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5b5fc61-1e0b-4cba-a4aa-d80b26c32edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_learn_class = str(enc_learner.__class__)[8:-2]\n",
    "\n",
    "match enc_learn_class:\n",
    "    case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"fastai.learner.Learner\":\n",
    "        get_embs_kwargs = {\n",
    "            \"stride\": enc_run.config['stride'],\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1,\n",
    "            \"patch_size\": 8, #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"size\": \"small\", #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"time\": True\n",
    "        }\n",
    "    case _:\n",
    "        print(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa815efc-5050-4e6f-b6b4-c1cbd78223d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'momentfm.models.moment.MOMENTPipeline'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_learn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f6ea32a-0d67-48de-95a3-401a13faa72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'momentfm.models.moment.MOMENTPipeline'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_learn_class = str(enc_learner.__class__)[8:-2]\n",
    "enc_learn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb74d900-463d-4f2c-8a6b-bbfafb69ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc learn class momentfm.models.moment.MOMENTPipeline\n",
      "kwargs: {'batch_size': 424, 'cpu': False, 'to_numpy': True, 'verbose': 1, 'padd_step': 10}\n"
     ]
    }
   ],
   "source": [
    "match enc_learn_class:\n",
    "    case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "        get_embs_kwargs = {\n",
    "            \"batch_size\": enc_input.shape[0],\n",
    "            \"cpu\"       : config.cpu,\n",
    "            \"to_numpy\"  : True,\n",
    "            \"verbose\"   : 1,\n",
    "            \"padd_step\" : 10\n",
    "        }\n",
    "    case \"fastai.learner.Learner\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\"            : config.cpu,\n",
    "            \"to_numpy\"       : True,\n",
    "            \"batch_size\"     : enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\"        : 4\n",
    "        }\n",
    "    case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\"            : config.cpu,\n",
    "            \"to_numpy\"       : True,\n",
    "            \"batch_size\"     : enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\"        : 2,\n",
    "            \"patch_size\"     : model_patch_size, #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"time\"           : True\n",
    "        }\n",
    "    case _:\n",
    "        print(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\")\n",
    "print(f\"Enc learn class {enc_learn_class}\\nkwargs: {get_embs_kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a05c5be8-47c7-45f9-8ba9-43201e704a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.losses import MSELossFlat\n",
    "from dvats.encoder import MAELossFlat, EvalMSE, EvalRMSE, EvalMAE, EvalSMAPE\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c505452b-ab49-464f-856c-46288048c233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] [ --> _get_encoder ]\n",
      "[5]  [ _get_encoder ] About to exec _get_enc_input\n",
      "[5] [ --> _get_enc_input ]\n",
      "[5]  [ _get_enc_input ] is none enc_input? True\n",
      "[5]  [ _get_enc_input ] About to get the windows\n",
      "[5] [ --> windowed_dataset ]\n",
      "[5]  [ _get_enc_input ] X is a DataFrame, X~(440, 1) | window_sizes 0, n_window_sizes 3\n",
      "[5]  [ _get_enc_input ] X is a DataFrame | Selecting Fourier's dominant frequences\n",
      "[5] [ --> Find_dominant_window_sizes_list ]\n",
      "[5]  [ Find_dominant_window_sizes_list ] X ~ (440, 1)\n",
      "[5]  [ Find_dominant_window_sizes_list ] Get sizes for var 0\n",
      "[5]  [ Find_dominant_window_sizes_list ] Get sizes for var 0 | [17, 12, 18]\n",
      "[5]  [ Find_dominant_window_sizes_list ] Grouping sizes\n",
      "[5]  [ Find_dominant_window_sizes_list ] Final selected window sizes: [17, 12, 18]\n",
      "[5] [Find_dominant_window_sizes_list --> ]\n",
      "[5]  [ windowed_dataset ] X is a DataFrame | Window sizes: 3\n",
      "[5]  [ windowed_dataset ] Building the windows\n",
      "[5]  [ windowed_dataset ] w = 17\n",
      "[5]  [ windowed_dataset ] w 17 | enc_input~(424, 1, 17) | dss~1\n",
      "[5]  [ windowed_dataset ] w = 12\n",
      "[5]  [ windowed_dataset ] w 12 | enc_input~(429, 1, 12) | dss~2\n",
      "[5]  [ windowed_dataset ] w = 18\n",
      "[5]  [ windowed_dataset ] w 18 | enc_input~(423, 1, 18) | dss~3\n",
      "[5]  [ windowed_dataset ] Number of windows: 3\n",
      "[5] [windowed_dataset --> ]\n",
      "[5]  [ _get_enc_input ] About to get the encoder input | windows~3\n",
      "[5]  [ _get_enc_input ] Enc input obtained | enc_input~(424, 1, 17)\n",
      "[5] [_get_encoder --> ]\n",
      "[5]  [ _get_encoder ] enc_input~(424, 1, 17)\n",
      "[5]  [ _get_encoder ] About to exec _get_optimizer\n",
      "[5] [ --> _get_optimizer ]\n",
      "[5] [_get_encoder --> ]\n",
      "[5] [_get_encoder --> ]\n",
      "[5] [ --> set_fine_tune_ ]\n",
      "[5]  [ set_fine_tune_ ] Model class: momentfm.models.moment.MOMENTPipeline\n",
      "[5]  [ set_fine_tune_ ] Moment\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [_get_encoder --> ]\n",
      "[5] [ --> fine_tune ]\n",
      "[5]  [ fine_tune ] Original enc_learn MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")  | Final model MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")\n",
      "[5] [ --> set_fine_tune_ ]\n",
      "[5]  [ set_fine_tune_ ] Model class: momentfm.models.moment.MOMENTPipeline\n",
      "[5]  [ set_fine_tune_ ] Moment\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5]  [ set_fine_tune_ ] Use fine_tune_moment parameters\n",
      "[5] [ --> fine_tune_moment_ ]\n",
      "[5]  [ set_fine_tune_ ] Processing 3 datasets : (424, 1, 17)\n",
      "[5]  [ set_fine_tune_ ] Setting up optimizer as AdamW\n",
      "[5]  [ set_fine_tune_ ] Processing wlen 17\n",
      "[5] [ --> fine_tune_moment_single ]\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Prepare the dataset | X ~ (424, 1, 17)\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting ds train | 102 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting validation train | 102 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | Random windows\n",
      "[4] [ --> fine_tune_moment_single | prepare_train_and_eval_dataloaders | random_windows ]\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] N windows: None\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] n_windows: 82\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] windows~torch.Size([82, 1, 17])\n",
      "[4] [fine_tune_moment_single | prepare_train_and_eval_dataloaders --> ]\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | DataLoader\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Validation DataLoader\n",
      "[5]  [ fine_tune_moment_single ] Eval Pre | wlen 17\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 7/7 [00:02<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] \u001b[91m [ fine_tune_moment_single ] Eval results: {'mse': 0.342390470661696, 'rmse': 0.11897325238673793, 'mae': 0.2432825950376105, 'smape': 1.3955356942919357}.\u001b[0m\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737483340.6998758 | End: 1737483343.3167422 | Duration: 2.62 seconds\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n",
      "[5]  [ fine_tune_moment_single ] Train | wlen 17\n",
      "[4] fine_tune_moment_train_ | Training loop\n",
      "[4] fine_tune_moment_train | Fine tune loop | print_to_path False | batch_masks~tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0% 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | num_epochs 5 | n_batches 6\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 0 | train 0 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06839297711849213\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 0 | train 0 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% 1/30 [00:00<00:03,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 0 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06941816955804825\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 0 | train 1 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 0 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09351618587970734\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 0 | train 2 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 3/30 [00:00<00:01, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 0 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.10661966353654861\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 0 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 0 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.07399355620145798\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 0 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17% 5/30 [00:00<00:01, 16.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 0 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09121689200401306\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 0 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 1 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.11118150502443314\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 1 | train 1 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23% 7/30 [00:00<00:01, 17.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 1 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09617333859205246\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 1 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 1 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0690690353512764\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 1 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 9/30 [00:00<00:01, 17.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 1 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.05939697101712227\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 1 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 1 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06964161992073059\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 1 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37% 11/30 [00:00<00:01, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 1 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.004790712147951126\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 1 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 2 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08782728761434555\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 2 | train 2 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43% 13/30 [00:00<00:00, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 2 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0573015958070755\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 2 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 2 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08426212519407272\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 2 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 15/30 [00:00<00:00, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 2 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.07739315927028656\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 2 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 2 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08570843935012817\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 2 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57% 17/30 [00:00<00:00, 18.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 2 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.10415183007717133\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 2 | train 7 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 3 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08990392088890076\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 3 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63% 19/30 [00:01<00:00, 18.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 3 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08685794472694397\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 3 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 3 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09837397187948227\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 3 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 21/30 [00:01<00:00, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 3 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06426038593053818\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 3 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 3 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.07632990181446075\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 3 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77% 23/30 [00:01<00:00, 18.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 3 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.006464082282036543\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 3 | train 8 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 4 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09681026637554169\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 4 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83% 25/30 [00:01<00:00, 18.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 4 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09778948128223419\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 4 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 4 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0908336490392685\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 4 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 27/30 [00:01<00:00, 18.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 4 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.07209073007106781\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 4 | train 7 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 4 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.04339546710252762\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 4 | train 8 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97% 29/30 [00:01<00:00, 18.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 4 | train 9 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06821218132972717\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 4 | train 9 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 30/30 [00:01<00:00, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | -->\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737483343.319604 | End: 1737483345.0129774 | Duration: 1.69 seconds\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Eval Post | wlen 17\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100% 7/7 [00:01<00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] \u001b[91m [ fine_tune_moment_single ] Eval results: {'mse': 0.342390470661696, 'rmse': 0.11897325238673793, 'mae': 0.2432825950376105, 'smape': 1.3955356942919357}.\u001b[0m\n",
      "[5] \u001b[91m [ fine_tune_moment_single ] Eval_results_post = {'mse': 0.342390470661696, 'rmse': 0.11897325238673793, 'mae': 0.2432825950376105, 'smape': 1.3955356942919357}\u001b[0m\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737483345.0164802 | End: 1737483346.3342333 | Duration: 1.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single_ | Evaluation summary\n",
      "[5]  [ fine_tune_moment_single ] Eval pre: \n",
      "mse: 0.342390470661696\n",
      "rmse: 0.11897325238673793\n",
      "mae: 0.2432825950376105\n",
      "smape: 1.3955356942919357\n",
      "[5]  [ fine_tune_moment_single ] Eval post: \n",
      "mse: 0.342390470661696\n",
      "rmse: 0.11897325238673793\n",
      "mae: 0.2432825950376105\n",
      "smape: 1.3955356942919357\n",
      "[5] [fine_tune_moment_single_ --> ]\n",
      "[5] \u001b[91m [ set_fine_tune_ ] About to concat {'mse': 0.342390470661696, 'rmse': 0.11897325238673793, 'mae': 0.2432825950376105, 'smape': 1.3955356942919357} to {}\u001b[0m\n",
      "[5] \u001b[91m [ set_fine_tune_ ] After concat {'mse': [0.342390470661696], 'rmse': [0.11897325238673793], 'mae': [0.2432825950376105], 'smape': [1.3955356942919357]}\u001b[0m\n",
      "[5]  [ set_fine_tune_ ] Processing wlen 17\n",
      "[5] [ --> fine_tune_moment_single ]\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Prepare the dataset | X ~ (429, 1, 12)\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting ds train | 103 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting validation train | 103 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | Random windows\n",
      "[4] [ --> fine_tune_moment_single | prepare_train_and_eval_dataloaders | random_windows ]\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] N windows: None\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] n_windows: 83\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] windows~torch.Size([83, 1, 12])\n",
      "[4] [fine_tune_moment_single | prepare_train_and_eval_dataloaders --> ]\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | DataLoader\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Validation DataLoader\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n",
      "[5]  [ fine_tune_moment_single ] Train | wlen 12\n",
      "[4] fine_tune_moment_train_ | Training loop\n",
      "[4] fine_tune_moment_train | Fine tune loop | print_to_path False | batch_masks~tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | num_epochs 5 | n_batches 6\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 0 | train 0 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.12147501856088638\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 0 | train 0 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 0 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.10209324955940247\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 0 | train 1 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% 2/30 [00:00<00:01, 17.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 0 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.021652953699231148\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 0 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 0 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08710738271474838\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 0 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 0 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09346699714660645\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 0 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17% 5/30 [00:00<00:01, 19.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 0 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.023379331454634666\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 0 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 1 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.11267195641994476\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 1 | train 1 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23% 7/30 [00:00<00:01, 18.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 1 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.05838131904602051\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 1 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 1 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.07310234010219574\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 1 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 9/30 [00:00<00:01, 18.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 1 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.07989797741174698\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 1 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 1 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.061777208000421524\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 1 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37% 11/30 [00:00<00:01, 18.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 1 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.017584290355443954\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 1 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 2 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.1169721856713295\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 2 | train 2 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43% 13/30 [00:00<00:00, 18.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 2 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.03998013585805893\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 2 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 2 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.05636417120695114\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 2 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 15/30 [00:00<00:00, 18.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 2 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.07705114781856537\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 2 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 2 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.10232502222061157\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 2 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57% 17/30 [00:00<00:00, 18.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 2 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.02755569852888584\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 2 | train 7 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 3 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06312645971775055\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 3 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63% 19/30 [00:01<00:00, 18.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 3 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09992846101522446\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 3 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 3 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.11373717337846756\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 3 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 21/30 [00:01<00:00, 18.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 3 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09059064090251923\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 3 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 3 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.023967811837792397\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 3 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77% 23/30 [00:01<00:00, 18.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 3 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.14115089178085327\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 3 | train 8 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 4 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09054647386074066\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 4 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83% 25/30 [00:01<00:00, 19.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 4 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06366540491580963\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 4 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 4 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0856599360704422\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 4 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 27/30 [00:01<00:00, 18.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 4 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.07517649978399277\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 4 | train 7 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 4 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06254935264587402\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 4 | train 8 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97% 29/30 [00:01<00:00, 19.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 4 | train 9 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0940798670053482\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 4 | train 9 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 30/30 [00:01<00:00, 18.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | -->\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737483346.489558 | End: 1737483348.088956 | Duration: 1.60 seconds\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Eval Post | wlen 17\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100% 7/7 [00:01<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] \u001b[91m [ fine_tune_moment_single ] Eval results: {'mse': 0.3477775791921818, 'rmse': 0.12260583294967765, 'mae': 0.25138872509865956, 'smape': 1.5183167191689604}.\u001b[0m\n",
      "[5] \u001b[91m [ fine_tune_moment_single ] Eval_results_post = {'mse': 0.3477775791921818, 'rmse': 0.12260583294967765, 'mae': 0.25138872509865956, 'smape': 1.5183167191689604}\u001b[0m\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737483348.0927641 | End: 1737483349.3698924 | Duration: 1.28 seconds\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single_ | Evaluation summary\n",
      "[5]  [ fine_tune_moment_single ] Eval post: \n",
      "mse: 0.3477775791921818\n",
      "rmse: 0.12260583294967765\n",
      "mae: 0.25138872509865956\n",
      "smape: 1.5183167191689604\n",
      "[5] [fine_tune_moment_single_ --> ]\n",
      "[5] \u001b[91m [ set_fine_tune_ ] About to concat {'mse': 0.3477775791921818, 'rmse': 0.12260583294967765, 'mae': 0.25138872509865956, 'smape': 1.5183167191689604} to {'mse': [0.342390470661696], 'rmse': [0.11897325238673793], 'mae': [0.2432825950376105], 'smape': [1.3955356942919357]}\u001b[0m\n",
      "[5] \u001b[91m [ set_fine_tune_ ] After concat {'mse': [0.342390470661696, 0.3477775791921818], 'rmse': [0.11897325238673793, 0.12260583294967765], 'mae': [0.2432825950376105, 0.25138872509865956], 'smape': [1.3955356942919357, 1.5183167191689604]}\u001b[0m\n",
      "[5]  [ set_fine_tune_ ] Processing wlen 17\n",
      "[5] [ --> fine_tune_moment_single ]\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Prepare the dataset | X ~ (423, 1, 18)\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting ds train | 102 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting validation train | 102 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | Random windows\n",
      "[4] [ --> fine_tune_moment_single | prepare_train_and_eval_dataloaders | random_windows ]\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] N windows: None\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] n_windows: 82\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] windows~torch.Size([82, 1, 18])\n",
      "[4] [fine_tune_moment_single | prepare_train_and_eval_dataloaders --> ]\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | DataLoader\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Validation DataLoader\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n",
      "[5]  [ fine_tune_moment_single ] Train | wlen 18\n",
      "[4] fine_tune_moment_train_ | Training loop\n",
      "[4] fine_tune_moment_train | Fine tune loop | print_to_path False | batch_masks~tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | num_epochs 5 | n_batches 6\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 18]) | epoch 0 | train 0 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0640861913561821\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 18]) | epoch 0 | train 0 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 18]) | epoch 0 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06257151812314987\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 18]) | epoch 0 | train 1 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% 2/30 [00:00<00:01, 19.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 18]) | epoch 0 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.05341104790568352\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 18]) | epoch 0 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 18]) | epoch 0 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.05938080698251724\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 18]) | epoch 0 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% 4/30 [00:00<00:01, 19.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 18]) | epoch 0 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.05751718953251839\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 18]) | epoch 0 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 18]) | epoch 0 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18]) | mask ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18]) | mask ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.005526727996766567\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 18]) | epoch 0 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 6/30 [00:00<00:01, 18.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 18]) | epoch 1 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.05651073902845383\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 18]) | epoch 1 | train 1 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 18]) | epoch 1 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.046273715794086456\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 18]) | epoch 1 | train 2 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27% 8/30 [00:00<00:01, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 18]) | epoch 1 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0667869970202446\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 18]) | epoch 1 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 18]) | epoch 1 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.05151541158556938\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 18]) | epoch 1 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33% 10/30 [00:00<00:01, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 18]) | epoch 1 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.07502549141645432\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 18]) | epoch 1 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 18]) | epoch 1 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18]) | mask ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18]) | mask ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.013190950267016888\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 18]) | epoch 1 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 12/30 [00:00<00:00, 18.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 18]) | epoch 2 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.030895765870809555\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 18]) | epoch 2 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 18]) | epoch 2 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.039254311472177505\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 18]) | epoch 2 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47% 14/30 [00:00<00:00, 18.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 18]) | epoch 2 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.04744376242160797\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 18]) | epoch 2 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 18]) | epoch 2 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.03192780166864395\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 18]) | epoch 2 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53% 16/30 [00:00<00:00, 18.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 18]) | epoch 2 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.11245592683553696\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 18]) | epoch 2 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 18]) | epoch 2 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18]) | mask ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18]) | mask ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.22323517501354218\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 18]) | epoch 2 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 18/30 [00:00<00:00, 18.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 18]) | epoch 3 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0734139159321785\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 18]) | epoch 3 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 18]) | epoch 3 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.11656664311885834\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 18]) | epoch 3 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67% 20/30 [00:01<00:00, 18.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 18]) | epoch 3 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06260901689529419\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 18]) | epoch 3 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 18]) | epoch 3 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.044320717453956604\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 18]) | epoch 3 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73% 22/30 [00:01<00:00, 18.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 18]) | epoch 3 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.00868605263531208\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 18]) | epoch 3 | train 7 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 18]) | epoch 3 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18]) | mask ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18]) | mask ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09503776580095291\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 18]) | epoch 3 | train 8 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 24/30 [00:01<00:00, 18.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 18]) | epoch 4 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.060379136353731155\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 18]) | epoch 4 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 18]) | epoch 4 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08604400604963303\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 18]) | epoch 4 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87% 26/30 [00:01<00:00, 18.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 18]) | epoch 4 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.026164043694734573\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 18]) | epoch 4 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 18]) | epoch 4 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.030837031081318855\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 18]) | epoch 4 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93% 28/30 [00:01<00:00, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 18]) | epoch 4 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 18]) | batch_masks ~ torch.Size([16, 18]) | mask ~ torch.Size([16, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06944576650857925\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 18]) | epoch 4 | train 8 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 18]) | epoch 4 | train 9 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 18]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18]) | mask ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 18]) | batch_masks ~ torch.Size([2, 18]) | mask ~ torch.Size([2, 18])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 18])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 18]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 18]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 18 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 18]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 18]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.10377967357635498\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 18]) | epoch 4 | train 9 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 30/30 [00:01<00:00, 18.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | -->\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737483349.520069 | End: 1737483351.1342382 | Duration: 1.61 seconds\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Eval Post | wlen 17\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100% 7/7 [00:01<00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] \u001b[91m [ fine_tune_moment_single ] Eval results: {'mse': 0.34331038331280894, 'rmse': 0.11964095461884483, 'mae': 0.24329452144696267, 'smape': 1.3991945740022687}.\u001b[0m\n",
      "[5] \u001b[91m [ fine_tune_moment_single ] Eval_results_post = {'mse': 0.34331038331280894, 'rmse': 0.11964095461884483, 'mae': 0.24329452144696267, 'smape': 1.3991945740022687}\u001b[0m\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737483351.1386192 | End: 1737483352.4591823 | Duration: 1.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single_ | Evaluation summary\n",
      "[5]  [ fine_tune_moment_single ] Eval post: \n",
      "mse: 0.34331038331280894\n",
      "rmse: 0.11964095461884483\n",
      "mae: 0.24329452144696267\n",
      "smape: 1.3991945740022687\n",
      "[5] [fine_tune_moment_single_ --> ]\n",
      "[5] \u001b[91m [ set_fine_tune_ ] About to concat {'mse': 0.34331038331280894, 'rmse': 0.11964095461884483, 'mae': 0.24329452144696267, 'smape': 1.3991945740022687} to {'mse': [0.342390470661696, 0.3477775791921818], 'rmse': [0.11897325238673793, 0.12260583294967765], 'mae': [0.2432825950376105, 0.25138872509865956], 'smape': [1.3955356942919357, 1.5183167191689604]}\u001b[0m\n",
      "[5] \u001b[91m [ set_fine_tune_ ] After concat {'mse': [0.342390470661696, 0.3477775791921818, 0.34331038331280894], 'rmse': [0.11897325238673793, 0.12260583294967765, 0.11964095461884483], 'mae': [0.2432825950376105, 0.25138872509865956, 0.24329452144696267], 'smape': [1.3955356942919357, 1.5183167191689604, 1.3991945740022687]}\u001b[0m\n",
      "[5] [fine_tune_moment_ --> ]\n",
      "[5] [fine_tune_moment_ --> ]\n"
     ]
    }
   ],
   "source": [
    "result = fine_tune(\n",
    "    X                             = df,\n",
    "    enc_learn                     = enc_learner, \n",
    "    stride                        = 1,      \n",
    "    batch_size                    = enc_run.config['batch_size'],\n",
    "    cpu                           = config['cpu'], \n",
    "    to_numpy                      = False, \n",
    "    verbose                       = 5, \n",
    "    time_flag                     = True,\n",
    "    n_windows                     = None,\n",
    "    n_windows_percent             = 0.8, #Ventanas a tener en cuenta\n",
    "    window_mask_percent           = enc_run.config['r'],\n",
    "    training_percent              = 0.3, # Entreno con parte de los datos\n",
    "    validation_percent            = 0.3, # Evalúo con parte de los datos\n",
    "    num_epochs                    = 5,\n",
    "    shot                          = True,\n",
    "    eval_pre                      = True,\n",
    "    eval_post                     = True,\n",
    "    lr                            = enc_run.config['r'],\n",
    "    #lr_scheduler_flag             = True, #Don't work in mvp\n",
    "    lr_scheduler_flag             = False,\n",
    "    lr_scheduler_name             = \"cosine_with_restarts\",\n",
    "    lr_scheduler_num_warmup_steps = None,\n",
    "    window_sizes                  = None,\n",
    "    n_window_sizes                = 3,\n",
    "    full_dataset                  = True,\n",
    "    window_sizes_offset           = 0.05,\n",
    "    windows_min_distance          = 5,\n",
    "    print_to_path                 = False,\n",
    "    print_path                    =\"~/data/logs.txt\",\n",
    "    print_mode                    = 'w',\n",
    "    use_moment_masks              = False,\n",
    "    mask_stateful                 = enc_run.config['mask_stateful'],\n",
    "    mask_future                   = enc_run.config['mask_future'],\n",
    "    mask_sync                     = enc_run.config['mask_sync'],\n",
    "    analysis_mode                 = enc_run.config['analysis_mode'],\n",
    "    use_wandb                     = enc_run.config['use_wandb'],\n",
    "    norm_by_sample                = enc_run.config['norm_by_sample'],\n",
    "    norm_use_single_batch         = enc_run.config['norm_use_single_batch'],\n",
    "    show_plot                     = True,\n",
    "    # mvp\n",
    "    #metrics                       = [MSELossFlat, RMSELossFlat, SMAPELossFlat, MAELossFlat],\n",
    "    # moment/moirai\n",
    "    metrics                        = [EvalMSE, EvalRMSE, EvalMAE, EvalSMAPE],\n",
    "    metrics_args                   = [{'squared': False}, {'squared': True}, {}, {}],\n",
    "    metrics_names                  = [\"mse\", \"rmse\", \"mae\", \"smape\"],\n",
    "    metrics_dict                   = None\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "103ec925-fb4b-435d-b073-bdef87186721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results pre:\n",
      "mse: 0.342390470661696\n",
      "rmse: 0.11897325238673793\n",
      "mae: 0.2432825950376105\n",
      "smape: 1.3955356942919357\n",
      "Eval results post:\n",
      "{'mse': [0.342390470661696, 0.3477775791921818, 0.34331038331280894], 'rmse': [0.11897325238673793, 0.12260583294967765, 0.11964095461884483], 'mae': [0.2432825950376105, 0.25138872509865956, 0.24329452144696267], 'smape': [1.3955356942919357, 1.5183167191689604, 1.3991945740022687]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( \n",
    "    losses, \n",
    "    eval_results_pre, eval_results_post, \n",
    "    t_shots, t_shot, \n",
    "    t_evals, t_eval, model\n",
    ") = result\n",
    "print(\"Eval results pre:\")\n",
    "show_attrdict(eval_results_pre)\n",
    "print(\"Eval results post:\")\n",
    "print(eval_results_post)\n",
    "len(eval_results_post)\n",
    "#show_attrdict(eval_results_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99befe23-ffaf-4d45-a384-1f4c10dda855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \u001b[91m [ _check_value ] Invalid type for 'model' (tuple). Expected one of: MOMENTPipeline, Learner, MoiraiModule. Using default: None\u001b[0m\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "{'mse': 0.342390470661696, 'rmse': 0.11897325238673793, 'mae': 0.2432825950376105, 'smape': 1.3955356942919357}\n",
      "{'mse': [0.342390470661696, 0.3477775791921818, 0.34331038331280894], 'rmse': [0.11897325238673793, 0.12260583294967765, 0.11964095461884483], 'mae': [0.2432825950376105, 0.25138872509865956, 0.24329452144696267], 'smape': [1.3955356942919357, 1.5183167191689604, 1.3991945740022687]}\n",
      "[1] [ --> plot_eval_stats ]\n",
      "[1] \u001b[91m [ plot_eval_stats ] epochs~4: [0, 1, 2, 3]\u001b[0m\n",
      "[1] \u001b[91m [ plot_eval_stats ] mse.values~3: [0.68478094 0.69016805 0.68570085]\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (4,) and (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(enc\u001b[38;5;241m.\u001b[39meval_stats_pre)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(enc\u001b[38;5;241m.\u001b[39meval_stats_post)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mplot_eval_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/dvats/encoder.py:506\u001b[0m, in \u001b[0;36mplot_eval_stats\u001b[0;34m(self, figsize, save_fig, save_path, fname)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint_error(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.values~\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(values)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# Graficar la métrica\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# Configurar etiquetas y leyenda\u001b[39;00m\n\u001b[1;32m    509\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation Metrics Across Epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/matplotlib/pyplot.py:3578\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3570\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3572\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3584\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/matplotlib/axes/_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/matplotlib/axes/_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (4,) and (3,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cambiar en el momento que todo se haga con clases\n",
    "enc = Encoder(mssg = Mssg(level = -1, verbose = 1))\n",
    "enc.eval_stats_pre = eval_results_pre\n",
    "enc.eval_stats_post = eval_results_post\n",
    "enc.num_epochs = 5\n",
    "print(enc.eval_stats_pre)\n",
    "print(enc.eval_stats_post)\n",
    "plot_eval_stats(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bfd363-3c5d-4f4d-a7e7-cb65c8bd9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = get_enc_embs_set_stride_set_batch_size(\n",
    "    X          = enc_input, \n",
    "    enc_learn  = enc_learner, \n",
    "    stride     = enc_run.config['stride'],\n",
    "    **get_embs_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92080d9-0851-43ec-be9d-ce5897e415c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74290c89-62d6-4a4a-ba5c-045cab824d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc_learner.task_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd215c-a9f4-47bb-ba2e-4892117b73c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.end()\n",
    "timer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a24fb-4416-4345-a1c8-131bed978e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"Execution ended\")\n",
    "from dvats.imports import beep\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca0597-64fb-4bc5-946f-2ae110b3cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
