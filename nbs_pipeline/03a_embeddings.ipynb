{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de2cd87-7d93-45ec-bd92-d97a85cf73b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Getting the embeddings\n",
    "\n",
    "> This notebook gets the embeddings (or latent space) from a multivariate time series \n",
    "given by a encoder (e.g., autoencoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816ae963-a2d2-467a-90ee-2be0f383c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_patch_size = 8\n",
    "verbose = 0\n",
    "reset_kernel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db2cd5f-dd8d-42a3-bdc1-afc12ff80afb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7f170728cfa0>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "from dvats.all import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from yaml import load, FullLoader\n",
    "import dvats.utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6774bdd-fc22-4e8e-96c4-c29417380137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280e30d-8195-4f39-898a-495d9253778b",
   "metadata": {},
   "source": [
    "## Config parameters\n",
    "> Configuration parameters are obtained from 'config\\03-embeddings.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fd16b-1ca7-4bed-9173-642cabdbe9bb",
   "metadata": {},
   "source": [
    "### Get configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47519e96-4dd2-4096-8189-d735f88155ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, job_type = get_artifact_config_embeddings(verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515769be-e06d-4ae2-b3ab-1636642a158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/moment-small-embedding:latest\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372ce1e-f3c8-4df4-a802-1250bc9a80cb",
   "metadata": {},
   "source": [
    "### Show configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5f95d2-f07a-4e39-bfed-ade6555641bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/moment-small-embedding:latest\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe624f-f4ff-4310-9d3c-23099381ed91",
   "metadata": {},
   "source": [
    "## Build W&B artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67704d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 03a_embeddings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"03a_embeddings\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "print(\"runname: \"+runname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa46f602-bbf9-4d2d-ae68-771adae56199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20241025_094446-c7wbfhwu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/c7wbfhwu' target=\"_blank\">03a_embeddings</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/c7wbfhwu' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/c7wbfhwu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    entity      = config.wandb_entity,\n",
    "    project     = config.wandb_project if config.use_wandb else 'work-nbs', \n",
    "    group       = config.wandb_group,\n",
    "    job_type    = job_type,\n",
    "    mode        = 'online' if config.use_wandb else 'disabled',\n",
    "    anonymous   = 'never' if config.use_wandb else 'must',\n",
    "    config      = config,\n",
    "    resume      = 'allow',\n",
    "    name        = runname\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b68a48-1629-4ad4-940b-2abc310ad942",
   "metadata": {},
   "source": [
    "## Get trained model artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa21e68-a1fd-4bf5-b3fc-84f5295f4ad1",
   "metadata": {},
   "source": [
    "### Build artifact selector\n",
    "> Botch to use artifacts offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26dac90a-ed13-4f50-b95e-fc78c635e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08922829-19f7-4cdc-97b1-86f5a3b4f3d2",
   "metadata": {},
   "source": [
    "### Get the model from W&B\n",
    "> Restore the encoder model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e978658-78de-4dff-9679-d2ed1453dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_artifact = artifacts_gettr(config.enc_artifact, type='learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fbe313-d3b6-4793-aaf3-34d4b858065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact moment-small-embedding:latest, 144.63MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n"
     ]
    }
   ],
   "source": [
    "# TODO: This only works when you run it two timeS! WTF?\n",
    "try:\n",
    "    enc_learner = enc_artifact.to_obj()\n",
    "except:\n",
    "    enc_learner = enc_artifact.to_obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb98d5-9ba2-4cc9-a033-91282bdab376",
   "metadata": {},
   "source": [
    "## Get dataset artifact from W&B\n",
    "### Restore the dataset artifact used for training the encoder. \n",
    "> Even if we do not compute the dimensionality reduction over this dataset, we need to know the metadata of the encoder training set, to check that it matches with the dataset that we want to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4335e626-5faa-4d27-845c-015f23ab9375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toy:v2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run = enc_artifact.logged_by()\n",
    "enc_artifact_train = artifacts_gettr(enc_run.config['train_artifact'], type='dataset')\n",
    "enc_artifact_train.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b5100a8-f044-4337-8731-4e7a76854a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: 0.71\n",
      "w: 30\n",
      "freq: 1s\n",
      "alias: toy\n",
      "epochs: 100\n",
      "mvp_ws: [10, 30]\n",
      "stride: 1\n",
      "time_col: None\n",
      "data_cols: []\n",
      "mask_sync: False\n",
      "use_wandb: True\n",
      "batch_size: 32\n",
      "csv_config: {}\n",
      "data_fpath: ~/data/toy.csv\n",
      "valid_size: 0.2\n",
      "mask_future: False\n",
      "wandb_group: None\n",
      "analysis_mode: online\n",
      "artifact_name: toy\n",
      "mask_stateful: True\n",
      "norm_by_sample: False\n",
      "train_artifact: mi-santamaria/deepvats/toy:latest\n",
      "valid_artifact: None\n",
      "norm_use_single_batch: False\n",
      "norm_use_by_single_batch: [False]\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(enc_run.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918829a-dd1f-4ddb-915c-cebf41665160",
   "metadata": {},
   "source": [
    "### Specify the dataset artifact that we want to get the embeddings from\n",
    "> If no artifact is defined, the artifact to reduce will be the one used for validate the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b394f66-6b1d-4c39-a4c8-6786c4f9b493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run.config['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ff4ef9-cabd-41cb-84c8-ec86cadf5848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toy:v2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ar_name = ifnone(\n",
    "    config.input_ar, \n",
    "    f'{enc_artifact_train.entity}/{enc_artifact_train.project}/{enc_artifact_train.name}'\n",
    ")\n",
    "wandb.config.update({'input_ar': input_ar_name}, allow_val_change=True)\n",
    "input_ar = artifacts_gettr(input_ar_name)\n",
    "input_ar.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a84cf086-f6ee-4f04-a234-581a738fc338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.741822</td>\n",
       "      <td>0.637180</td>\n",
       "      <td>0.565117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>0.739731</td>\n",
       "      <td>0.629415</td>\n",
       "      <td>0.493513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.718757</td>\n",
       "      <td>0.539220</td>\n",
       "      <td>0.469350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>0.730169</td>\n",
       "      <td>0.577670</td>\n",
       "      <td>0.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.752406</td>\n",
       "      <td>0.570180</td>\n",
       "      <td>0.373008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           T3        T2        T1\n",
       "1970-01-01 00:00:00  0.741822  0.637180  0.565117\n",
       "1970-01-01 00:00:01  0.739731  0.629415  0.493513\n",
       "1970-01-01 00:00:02  0.718757  0.539220  0.469350\n",
       "1970-01-01 00:00:03  0.730169  0.577670  0.444100\n",
       "1970-01-01 00:00:04  0.752406  0.570180  0.373008"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = input_ar.to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46c6bb02-9a43-4917-93a9-0832ee98b5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49908f03-6875-4e27-8050-09af41dc62bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 3, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input, _ = SlidingWindow(window_len=enc_run.config['w'], \n",
    "                             stride=enc_run.config['stride'], \n",
    "                             get_y=[])(df)\n",
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf910313-b689-45f2-b405-5c4b3ef66012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1729849517.1566298"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = ut.Time()\n",
    "timer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97d09238-e62c-4135-baf7-4b7d38e3c19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mi-santamaria/deepvats/moment-small-embedding:latest'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.enc_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9dcf6e5-a338-4638-b0bc-2ecfc12eadf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(enc_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5b5fc61-1e0b-4cba-a4aa-d80b26c32edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_learn_class = str(enc_learner.__class__)[8:-2]\n",
    "\n",
    "match enc_learn_class:\n",
    "    case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"fastai.learner.Learner\":\n",
    "        get_embs_kwargs = {\n",
    "            \"stride\": enc_run.config['stride'],\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1,\n",
    "            \"patch_size\": 8, #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"size\": \"small\", #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"time\": True\n",
    "        }\n",
    "    case _:\n",
    "        print(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa815efc-5050-4e6f-b6b4-c1cbd78223d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'momentfm.models.moment.MOMENTPipeline'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_learn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f6ea32a-0d67-48de-95a3-401a13faa72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'momentfm.models.moment.MOMENTPipeline'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_learn_class = str(enc_learner.__class__)[8:-2]\n",
    "enc_learn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb74d900-463d-4f2c-8a6b-bbfafb69ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc learn class momentfm.models.moment.MOMENTPipeline\n",
      "kwargs: {'batch_size': 521, 'cpu': False, 'to_numpy': True, 'verbose': 1, 'padd_step': 2}\n"
     ]
    }
   ],
   "source": [
    "match enc_learn_class:\n",
    "    case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "        get_embs_kwargs = {\n",
    "            \"batch_size\": enc_input.shape[0],\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"verbose\": 1,\n",
    "            \"padd_step\":2\n",
    "        }\n",
    "    case \"fastai.learner.Learner\":\n",
    "        get_embs_kwargs = {\n",
    "            \"stride\": enc_run.config['stride'],\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 2,\n",
    "            \"patch_size\": model_patch_size, #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"time\": True\n",
    "        }\n",
    "    case _:\n",
    "        print(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\")\n",
    "print(f\"Enc learn class {enc_learn_class}\\nkwargs: {get_embs_kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "615ff0d6-7514-49db-a9c4-60f022a5ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.print_flush(\"patata\", \"xd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "811f644e-170e-4fc6-862e-ee96637dcbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       " \u001b[0mprint_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmssg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprint_to_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprint_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'~/data/logs/logs.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprint_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprint_time\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprint_both\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/work/dvats/utils.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? print_flush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9803d515-3475-48a2-a8a0-f3f8a3ec1bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] --> fine_tune_moment_\n",
      "[3] fine_tune_moment_ | X not-windowed dataset\n",
      "[3] fine_tune_moment_ | X not-windowed dataset | Selecting Fourier's dominant frequences\n",
      "[2] ---> Find_dominant_window_sizes_list\n",
      "[2] Find_dominant_window_sizes_list | X ~ (550, 3)\n",
      "[2] Find_dominant_window_sizes_list | Get sizes for var 0\n",
      "[2] ---> Find_dominant_window_sizes_list\n",
      "[2] Find_dominant_window_sizes_list | X ~ (550,)\n",
      "[2] Find_dominant_window_sizes_list | Looking for - at most - the best 3 window sizes\n",
      "[2] Find_dominant_window_sizes_list | Offset 0.05 max size: 27.5\n",
      "[2] Find_dominant_window_sizes_list | --> Freqs\n",
      "[2] Find_dominant_window_sizes_list | Freqs -->\n",
      "[2] Find_dominant_window_sizes_list | Coefs and window_sizes -->\n",
      "[2] Find_dominant_window_sizes_list | --> Find and return valid window_sizes\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 0 ... [  1   2   0   8   4   3  15  11   7  19  13  10   9  14  12  22   6  25\n",
      "  17  29  16  24  31  36  63  54   5  20  50  30  18  27  21  39  46  32\n",
      "  44  76  42  53  45  82  71  33  58  41  40  68  52  74  38  65  35  48\n",
      "  60  85  47  66  37  99  43 157  51 109 136  55  94 170  72  59 142 138\n",
      "  49 141  56 164  77 207  62 122  73  69  93 105 126 108 153 250 241 115\n",
      " 201 123 257 219 205 119 151  75 124 177 199  84  34 213 249  95 131  98\n",
      " 172 167 269  70 133 176 270 224 144  90 147 193 267  87 187 102  78 273\n",
      " 130 239  26 204 160 246  67 220 244 195  86  23 197 182  79 140 185 255\n",
      " 237 107 118 155 186  96 214 194 174 268 206  61 230 163 149 166 137 134\n",
      " 227 252 254 114 236 196 238 125 181 120 106 173  28 104 234 148 211 203\n",
      "  81 240 175 263  83 233 190 171 178 103 101 215 259  57 256 248 243 265\n",
      " 121 208 113 145 192  92 191 210 132 242 165 179 161 212 200 218 253 100\n",
      " 225 232 209 139 272 202 111 135 168 223 184  88 247  91 229 150 129 127\n",
      " 117 251 158 152 264 156 112 146 231 216 162 228  64 188 226 261 116 221\n",
      " 235 258 189 183  89 143 154 266 222 110 128  80  97 260 217 271 159 198\n",
      " 169 180 245 262]\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 1 ...\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 2 ...\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 2b ... 3\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes -->\n",
      "[2] Find_dominant_window_sizes_list | Sizes: [23, 18, 8]\n",
      "[2] Find dominant_window_sizes_list --->\n",
      "[2] Find_dominant_window_sizes_list | Get sizes for var 0 | [23, 18, 8]\n",
      "[2] Find_dominant_window_sizes_list | Get sizes for var 1\n",
      "[2] ---> Find_dominant_window_sizes_list\n",
      "[2] Find_dominant_window_sizes_list | X ~ (550,)\n",
      "[2] Find_dominant_window_sizes_list | Looking for - at most - the best 3 window sizes\n",
      "[2] Find_dominant_window_sizes_list | Offset 0.05 max size: 27.5\n",
      "[2] Find_dominant_window_sizes_list | --> Freqs\n",
      "[2] Find_dominant_window_sizes_list | Freqs -->\n",
      "[2] Find_dominant_window_sizes_list | Coefs and window_sizes -->\n",
      "[2] Find_dominant_window_sizes_list | --> Find and return valid window_sizes\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 0 ... [  0   2   1   3   7   4  15   6  18   5  10  12  11  13  14  31  16  29\n",
      "  51  17  42  39  24   9  21  48  98  30  49  45  36  20  54  46  52  86\n",
      "  33  44  90  60  89  62   8  53  59  84  55  43  19  72  38 104  34  76\n",
      "  27  65 153 173 125  50  87  56  22 137 157  85 120  63 163 152 176  79\n",
      "  37  28 162 196  66 116  23 216 183  35 122  58 105  99  78 127 108 128\n",
      " 134  25  93 166 236 132  26 209 244  73  83  47 185 214  71  67 178 195\n",
      " 238 256 201 111 265 193 220 135  70 230 159 228 242 226 215 182 208  97\n",
      " 158 124 161 146  91 243 144 271  92 106 119 235  77 268 212 241 165 206\n",
      " 246 253  41  82 232 188 156  69 203 231 202 198 130 164 160 222 114 266\n",
      " 259 139 113 100 223 192 257 207 273  81 189  74  40 168  95 102  96 131\n",
      " 190 169 258 140 172 225  57 138 217 107 199  61  80 148 147 200 136 239\n",
      " 174 252 248 205 221 171 112 234 133 204 167 224 143 117  75 123 191 175\n",
      " 155 194  32 233 227 240 141 151 109  88 229 210 115 245 118 179 251 219\n",
      "  64 180 110 170 181 184 247 126 270 103 264 101 186  68 260 211 145  94\n",
      " 250 254 261 142 272 149 249 197 121 129 218 187 177 263 213 154 269 262\n",
      " 150 255 267 237]\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 1 ...\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 2 ...\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 2b ... 3\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes -->\n",
      "[2] Find_dominant_window_sizes_list | Sizes: [17, 10, 22]\n",
      "[2] Find dominant_window_sizes_list --->\n",
      "[2] Find_dominant_window_sizes_list | Get sizes for var 1 | [17, 10, 22]\n",
      "[2] Find_dominant_window_sizes_list | Get sizes for var 2\n",
      "[2] ---> Find_dominant_window_sizes_list\n",
      "[2] Find_dominant_window_sizes_list | X ~ (550,)\n",
      "[2] Find_dominant_window_sizes_list | Looking for - at most - the best 3 window sizes\n",
      "[2] Find_dominant_window_sizes_list | Offset 0.05 max size: 27.5\n",
      "[2] Find_dominant_window_sizes_list | --> Freqs\n",
      "[2] Find_dominant_window_sizes_list | Freqs -->\n",
      "[2] Find_dominant_window_sizes_list | Coefs and window_sizes -->\n",
      "[2] Find_dominant_window_sizes_list | --> Find and return valid window_sizes\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 0 ... [  0   1   3   5   4  14  23  10   6   9  13  18  16  11  15  19   8   2\n",
      "  22  26   7  28  12  24  17  38  34  25  30  20  54  49  27  31  55  39\n",
      " 128  52  46  36  53  21  68  50  89  56  41 117  66  67  40  60 112  96\n",
      " 114  87  65  88  81  64  75  57 235 135  43  58  59  86  63  70 177  62\n",
      " 125  93  32 162 172 143  84 110  95 100  77  35 150 161  48  51  82 164\n",
      " 192  29 101  42  91  73  78 215 156 230 108  45 214 248 165 145 115  90\n",
      " 136  80 104 160 208  94 216 140 263  85 159 126 242 148 151 218  79 168\n",
      " 131 270 223 265 179 271 232 186 207 111  71 191 266 204 132 250 174 129\n",
      "  37 210 205 166 121 189 154 201 139 190  74 175 141 118 196 197 228 123\n",
      " 113 149 147 217 102 182 134 173  33 240 259 105 269 171 130 243  76 195\n",
      "  72 245 167 198  47  97 120 137 241 153  98 219 116 187 267 238 220 124\n",
      " 251 260  92 106 188 169 253 133 170  44 142 194  61 213  99 193 212 200\n",
      " 203 234 256 262 236  69 246 225 264 222 273 122 158 258 202 119 247 244\n",
      " 229 231 183 233 261 181 227 224 127 138 144 226 254 103 176 237 157 155\n",
      " 146  83 199 255 107 252 221 180 209 184 268 257 178 206 211 185 239 109\n",
      " 163 249 272 152]\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 1 ...\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 2 ...\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes | ... 2b ... 3\n",
      "[2] Find_dominant_window_sizes_list | Find and return valid window_sizes -->\n",
      "[2] Find_dominant_window_sizes_list | Sizes: [22, 14, 21]\n",
      "[2] Find dominant_window_sizes_list --->\n",
      "[2] Find_dominant_window_sizes_list | Get sizes for var 2 | [22, 14, 21]\n",
      "[2] Find_dominant_window_sizes_list | Grouping sizes\n",
      "[2] find_dominant_window_sizes_list | Final selected window sizes: [17, 10, 23]\n",
      "[2] Find_dominant_window_sizes_list -->\n",
      "[3] fine_tune_moment_ | X not-windowed dataset | Selecting Fourier's dominant frequences | [17, 10, 23]\n",
      "[3] fine_tune_moment_ | Building the datasets\n",
      "[3] fine_tune_moment_ | Processing 3 datasets\n",
      "[3] fine_tune_moment_ | Processing wlen 17\n",
      "--> fine_tune_moment_single\n",
      "fine_tune_moment_single | Prepare the dataset\n",
      "[3] fine_tune_moment_single | Selecting ds train | 161 windows\n",
      "[3] fine_tune_moment_single | Train DataLoader | Random windows\n",
      "[2] Random windows | n_windows: 129\n",
      "[2] windows ~ torch.Size([129, 3, 17])\n",
      "[3] fine_tune_moment_single | Train DataLoader | DataLoader\n",
      "[3] fine_tune_moment_single | Train | wlen 17\n",
      "[2] fine_tune_moment_train_ | Training loop\n",
      "[2] fine_tune_moment_train | Fine tune loop | print_to_path False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa5bb6d177b41bfa77c7018da159a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine_tune_moment_train | num_epochs 1 | n_batches 2\n",
      "fine_tune_moment_train | batch 0 ~ torch.Size([128, 3, 17]) | epoch 0 | train 0 of 2\n",
      "[2] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([128, 3, 17]) | batch_masks ~ torch.Size([128, 17])\n",
      "[2] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([128, 3, 17]) | batch_masks ~ torch.Size([128, 17]) | mask ~ torch.Size([128, 17])\n",
      "[2] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:1 | mcuda:1 | bmcuda:1\n",
      "[2] ---> sure_eval_moment\n",
      "[2] sure_eval_moment | cpu | False | device | 1\n",
      "[2] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([128, 3, 17])\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | input_mask~torch.Size([128, 17]) device: cuda:1\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | mask device~torch.Size([128, 17]): cuda:1\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | y~torch.Size([128, 3, 17]) device: cuda:1\n",
      "[2] sure_eval_moment -->\n",
      "[2] --> fine_tune_moment_compute_loss\n",
      "[2] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[2]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[2] ---------- Checking loss  ------- | reconstruction ~ torch.Size([128, 3, 16]) | original_ ~ torch.Size([128, 3, 16])\n",
      "[2] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[2] fine_tune_moment_compute_loss | b~torch.Size([128, 3, 16]) | o~torch.Size([128, 3, 16])\n",
      "[2] fine_tune_moment_compute_loss | batch ~ torch.Size([128, 3, 16]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([128, 17]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | mask ~ torch.Size([128, 17]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | loss: 0.006475754082202911\n",
      "Loss type: <class 'torch.Tensor'>\n",
      "[2] fine_tune_moment_compute_loss -->\n",
      "fine_tune_moment_train | batch 1 ~ torch.Size([1, 3, 17]) | epoch 0 | train 1 of 2\n",
      "[2] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([1, 3, 17]) | batch_masks ~ torch.Size([1, 17])\n",
      "[2] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([1, 3, 17]) | batch_masks ~ torch.Size([1, 17]) | mask ~ torch.Size([1, 17])\n",
      "[2] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:1 | mcuda:1 | bmcuda:1\n",
      "[2] ---> sure_eval_moment\n",
      "[2] sure_eval_moment | cpu | False | device | 1\n",
      "[2] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([1, 3, 17])\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | input_mask~torch.Size([1, 17]) device: cuda:1\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | mask device~torch.Size([1, 17]): cuda:1\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | y~torch.Size([1, 3, 17]) device: cuda:1\n",
      "[2] sure_eval_moment -->\n",
      "[2] --> fine_tune_moment_compute_loss\n",
      "[2] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[2]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[2] ---------- Checking loss  ------- | reconstruction ~ torch.Size([1, 3, 16]) | original_ ~ torch.Size([1, 3, 16])\n",
      "[2] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[2] fine_tune_moment_compute_loss | b~torch.Size([1, 3, 16]) | o~torch.Size([1, 3, 16])\n",
      "[2] fine_tune_moment_compute_loss | batch ~ torch.Size([1, 3, 16]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([1, 17]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | mask ~ torch.Size([1, 17]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | loss: 0.005832562688738108\n",
      "Loss type: <class 'torch.Tensor'>\n",
      "[2] fine_tune_moment_compute_loss -->\n",
      "[3] [] Start: 1729849517.4075 | End: 1729849520.307516 | Duration: 2.9000160694122314 seconds\n",
      "[3] fine_tune_moment_single -->\n",
      "[3] fine_tune_moment_ | Processing wlen 10\n",
      "--> fine_tune_moment_single\n",
      "fine_tune_moment_single | Prepare the dataset\n",
      "[3] fine_tune_moment_single | Selecting ds train | 163 windows\n",
      "[3] fine_tune_moment_single | Train DataLoader | Random windows\n",
      "[2] Random windows | n_windows: 131\n",
      "[2] windows ~ torch.Size([131, 3, 10])\n",
      "[3] fine_tune_moment_single | Train DataLoader | DataLoader\n",
      "[3] fine_tune_moment_single | Train | wlen 10\n",
      "[2] fine_tune_moment_train_ | Training loop\n",
      "[2] fine_tune_moment_train | Fine tune loop | print_to_path False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9132ee509844aab5ab4af094d3f702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine_tune_moment_train | num_epochs 1 | n_batches 2\n",
      "fine_tune_moment_train | batch 0 ~ torch.Size([128, 3, 10]) | epoch 0 | train 0 of 2\n",
      "[2] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([128, 3, 10]) | batch_masks ~ torch.Size([128, 10])\n",
      "[2] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([128, 3, 10]) | batch_masks ~ torch.Size([128, 10]) | mask ~ torch.Size([128, 10])\n",
      "[2] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:1 | mcuda:1 | bmcuda:1\n",
      "[2] ---> sure_eval_moment\n",
      "[2] sure_eval_moment | cpu | False | device | 1\n",
      "[2] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([128, 3, 10])\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | input_mask~torch.Size([128, 10]) device: cuda:1\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | mask device~torch.Size([128, 10]): cuda:1\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | y~torch.Size([128, 3, 10]) device: cuda:1\n",
      "[2] sure_eval_moment -->\n",
      "[2] --> fine_tune_moment_compute_loss\n",
      "[2] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[2]  Fine tune loop | TODO: Why? Original 10 > 8  Reconstruction\n",
      "[2] ---------- Checking loss  ------- | reconstruction ~ torch.Size([128, 3, 8]) | original_ ~ torch.Size([128, 3, 8])\n",
      "[2] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[2] fine_tune_moment_compute_loss | b~torch.Size([128, 3, 8]) | o~torch.Size([128, 3, 8])\n",
      "[2] fine_tune_moment_compute_loss | batch ~ torch.Size([128, 3, 8]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([128, 10]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | mask ~ torch.Size([128, 10]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | loss: 0.0037312936037778854\n",
      "Loss type: <class 'torch.Tensor'>\n",
      "[2] fine_tune_moment_compute_loss -->\n",
      "fine_tune_moment_train | batch 1 ~ torch.Size([3, 3, 10]) | epoch 0 | train 1 of 2\n",
      "[2] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 3, 10]) | batch_masks ~ torch.Size([3, 10])\n",
      "[2] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 3, 10]) | batch_masks ~ torch.Size([3, 10]) | mask ~ torch.Size([3, 10])\n",
      "[2] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:1 | mcuda:1 | bmcuda:1\n",
      "[2] ---> sure_eval_moment\n",
      "[2] sure_eval_moment | cpu | False | device | 1\n",
      "[2] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 3, 10])\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | input_mask~torch.Size([3, 10]) device: cuda:1\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | mask device~torch.Size([3, 10]): cuda:1\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | y~torch.Size([3, 3, 10]) device: cuda:1\n",
      "[2] sure_eval_moment -->\n",
      "[2] --> fine_tune_moment_compute_loss\n",
      "[2] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[2]  Fine tune loop | TODO: Why? Original 10 > 8  Reconstruction\n",
      "[2] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 3, 8]) | original_ ~ torch.Size([3, 3, 8])\n",
      "[2] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[2] fine_tune_moment_compute_loss | b~torch.Size([3, 3, 8]) | o~torch.Size([3, 3, 8])\n",
      "[2] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 3, 8]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 10]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 10]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | loss: 0.009978340938687325\n",
      "Loss type: <class 'torch.Tensor'>\n",
      "[2] fine_tune_moment_compute_loss -->\n",
      "[3] [] Start: 1729849520.3175664 | End: 1729849520.4458287 | Duration: 0.12826228141784668 seconds\n",
      "[3] fine_tune_moment_single -->\n",
      "[3] fine_tune_moment_ | Processing wlen 23\n",
      "--> fine_tune_moment_single\n",
      "fine_tune_moment_single | Prepare the dataset\n",
      "[3] fine_tune_moment_single | Selecting ds train | 159 windows\n",
      "[3] fine_tune_moment_single | Train DataLoader | Random windows\n",
      "[2] Random windows | n_windows: 128\n",
      "[2] windows ~ torch.Size([128, 3, 23])\n",
      "[3] fine_tune_moment_single | Train DataLoader | DataLoader\n",
      "[3] fine_tune_moment_single | Train | wlen 23\n",
      "[2] fine_tune_moment_train_ | Training loop\n",
      "[2] fine_tune_moment_train | Fine tune loop | print_to_path False\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730c0924bad142f6bf34deeb08d0680f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine_tune_moment_train | num_epochs 1 | n_batches 1\n",
      "fine_tune_moment_train | batch 0 ~ torch.Size([128, 3, 23]) | epoch 0 | train 0 of 1\n",
      "[2] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([128, 3, 23]) | batch_masks ~ torch.Size([128, 23])\n",
      "[2] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([128, 3, 23]) | batch_masks ~ torch.Size([128, 23]) | mask ~ torch.Size([128, 23])\n",
      "[2] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:1 | mcuda:1 | bmcuda:1\n",
      "[2] ---> sure_eval_moment\n",
      "[2] sure_eval_moment | cpu | False | device | 1\n",
      "[2] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([128, 3, 23])\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | input_mask~torch.Size([128, 23]) device: cuda:1\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | mask device~torch.Size([128, 23]): cuda:1\n",
      "[2] sure_eval_moment | Trial 1 | device 1 | y~torch.Size([128, 3, 23]) device: cuda:1\n",
      "[2] sure_eval_moment -->\n",
      "[2] --> fine_tune_moment_compute_loss\n",
      "[2] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[2]  Fine tune loop | TODO: Why? Original 23 > 16  Reconstruction\n",
      "[2] ---------- Checking loss  ------- | reconstruction ~ torch.Size([128, 3, 16]) | original_ ~ torch.Size([128, 3, 16])\n",
      "[2] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[2] fine_tune_moment_compute_loss | b~torch.Size([128, 3, 16]) | o~torch.Size([128, 3, 16])\n",
      "[2] fine_tune_moment_compute_loss | batch ~ torch.Size([128, 3, 16]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([128, 23]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | mask ~ torch.Size([128, 23]) | cuda:1\n",
      "[2] fine_tune_moment_compute_loss | loss: 0.005843176506459713\n",
      "Loss type: <class 'torch.Tensor'>\n",
      "[2] fine_tune_moment_compute_loss -->\n",
      "[3] [] Start: 1729849520.4557927 | End: 1729849520.5291173 | Duration: 0.07332468032836914 seconds\n",
      "[3] fine_tune_moment_single -->\n"
     ]
    }
   ],
   "source": [
    "result = fine_tune_moment_(\n",
    "    X                             = df,\n",
    "    enc_learn                     = enc_learner, \n",
    "    stride                        = 1,      \n",
    "    batch_size                    = 128,\n",
    "    cpu                           = False, \n",
    "    to_numpy                      = True, \n",
    "    verbose                       = 3, \n",
    "    time_flag                     = True,\n",
    "    #n_windows                     = 32,\n",
    "    n_windows_percent             = 0.8, # Enmascaro el parte del entrenamiento\n",
    "    training_percent              = 0.3, # Entreno con parte de los datos\n",
    "    validation_percent            = 0.3, # Evalúo con parte de los datos\n",
    "    num_epochs                    = 1,\n",
    "    shot                          = True,\n",
    "    eval_pre                      = False,\n",
    "    eval_post                     = False,\n",
    "    lr_scheduler_flag             = False,\n",
    "    lr_scheduler_name             = False,\n",
    "    lr_scheduler_num_warmup_steps = 0,\n",
    "    window_sizes                  = None,\n",
    "    n_window_sizes                = 3,\n",
    "    window_sizes_offset           = 0.05,\n",
    "    windows_min_distance          = 5,\n",
    "    print_to_path                 = False,\n",
    "    print_mode                    = 'w'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "103ec925-fb4b-435d-b073-bdef87186721",
   "metadata": {},
   "outputs": [],
   "source": [
    "( \n",
    "    losses, \n",
    "    eval_results_pre, eval_results_post, \n",
    "    t_shots, t_shot, \n",
    "    t_evals, t_eval\n",
    ") = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34b9c054-5a4e-4f47-bb9b-b48539337578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.006475754082202911, 0.005832562688738108],\n",
       "  [0.0037312936037778854, 0.009978340938687325],\n",
       "  [0.005843176506459713]],\n",
       " '',\n",
       " ['', '', ''],\n",
       " [2.9000160694122314, 0.12826228141784668, 0.07332468032836914],\n",
       " 3.1016030311584473,\n",
       " [],\n",
       " 0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e89347f0-6dbf-4003-892b-996364ca472c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1016030311584473"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08bfd363-3c5d-4f4d-a7e7-cb65c8bd9f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> get_enc_embs_set_stride_set_batch_size\n",
      "get_enc_embs_set_stride_set_batch_size | Moment | True\n",
      "get_acts_moment | Trial 1 | x_enc ~ torch.Size([521, 3, 30])\n",
      "get_acts_moment | Trial 1 | About to pad X (encoder input) | exception The size of tensor a (24) must match the size of tensor b (30) at non-singleton dimension 1 | padd step: 2\n",
      "get_acts_moment | Trial 1 | y ~ torch.Size([521, 3, 30])\n",
      "------------------- Trial 1 | Padd -----------------\n",
      "get_acts_moment | Trial 2 | x_enc ~ torch.Size([521, 3, 32])\n",
      "get_acts_moment | Trial 2 | embs ~ torch.Size([521, 3, 4, 512])\n",
      "get_enc_embs_set_stride_set_batch_size | Before moving to CPU | embs~(521, 512)\n",
      "get_enc_embs_set_stride_set_batch_size | embs~(521, 512) -->\n"
     ]
    }
   ],
   "source": [
    "embs = get_enc_embs_set_stride_set_batch_size(\n",
    "    X          = enc_input, \n",
    "    enc_learn  = enc_learner, \n",
    "    stride     = enc_run.config['stride'],\n",
    "    **get_embs_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74290c89-62d6-4a4a-ba5c-045cab824d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reconstruction'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_learner.task_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7bd215c-a9f4-47bb-ba2e-4892117b73c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Start: 1729849517.1566298 | End: 1729849520.6837041 | Duration: 3.5270743370056152 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.5270743370056152"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.end()\n",
    "timer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad5a24fb-4416-4345-a1c8-131bed978e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,UklGRvQHAABXQVZFZm10IBAAAAABAAEAECcAACBOAAACABAAZGF0YdAHAAAAAPF/iPh/gOoOon6w6ayCoR2ZeyfbjobxK+F2Hs0XjKc5i3DGvzaTlEaraE+zz5uLUl9f46fHpWJdxVSrnfmw8mYEScqUP70cb0Q8X41uysJ1si6Eh1jYzXp9IE2DzOYsftYRyoCY9dJ/8QICgIcEun8D9PmAaBPlfT7lq4MFIlh61tYPiCswIHX+yBaOqT1QbuW7qpVQSv9lu6+xnvRVSlyopAypbGBTUdSalrSTaUBFYpInwUpxOzhti5TOdndyKhCGrdwAfBUcXIJB69p+Vw1egB76+n9q/h6ADglbf4LvnIHfF/981ODThF4m8HiS0riJVjQ6c+/EOZCYQfJrGrhBmPVNMmNArLKhQlkXWYqhbaxXY8ZNHphLuBJsZUEckCTFVHMgNKGJytIDeSUmw4QN4Qx9pReTgb3vYX/TCBuApf75f+P5Y4CRDdN+B+tngk8c8nt03CKGqipgd13OhotwOC5x9MCAknFFcmlmtPmagFFFYOCo0qRzXMhVi57pryNmIEqJlRi8bm52PfuNM8k4dfQv+4cO12l6zCGdg3jl730uE/KAPvS+f0wEAoAsA89/XfXQgBESIn6S5luDtiC8eh/YmIfpLqt1OMp5jXg8/24MveqUNUnPZsqw0Z3yVDldnaUOqIZfXlKrm36zzWhjRhaT+r+ncHI5/otUzfd2uSt7hl/bqXtoHaCC6+mqfrAOeoDD+PJ/xf8RgLMHfH/b8GeBihZIfSXidoQSJWB52NM1iRkzz3MkxpKPbUCrbDu5d5fgTAxkSK3JoEhYD1p2omere2LZTuqYLbdWa49Cx5Dww7tyXDUnioXRkHhwJyKFvd/AfPoYy4Fl7j1/LQorgEr9/X89+0qAOAwAf13sJoL8Gkd8wt25hWIp3Heez/eKODfPcSPCzpFNRDVqf7UlmnNQKGHgqd+jgVvJVm2f265QZTpLS5byur1tpT6ajvrHq3Q2MXWIxtUCehoj8YMk5LB9hRQegeTypn+nBQWA0QHgf7f2q4C5EFt+5ucOg2YfHXtq2SSHpS0ydnTL4IxFO6pvNb4ulBdInWfcsfSc7VMmXpSmE6eeXmZThJxpsgRohEfOk86+AHCoOpOMFsx1dv8s6oYT2k17uR7ngpXod34IEJqAaPfnfyABCIBZBpl/NPI2gTQVjX134x2ExSPMeR7VtYjZMWJ0W8ftjkA/YW1durCWykvjZFKu4p9LVwVbZKNkqpxh6U+6mRC2mGq2Q3SRvsIgcpc2sIpD0Bp4uiiFhW3ecXxOGgaCDe0Vf4cLPoDv+/5/mfw1gN4KKX+17emBqBmYfBHfVYUZKFR44NBtiv41bHJUwx+RJkP1apu2VJlkTwli4qrwoo1ax1dToNCtemRSTBGXz7kJbdM/PY/Dxht0dTLziH7Ul3loJEiE0uJsfdsVTYGL8Yt/AgcMgHYA7X8S+IqAYA+QfjzpxIIVHnp7tdqzhmAstXaxzEqMETpScGC/dJP3Rmdo8LIZnOVSEF+Opxumsl1sVF+dVrE5Z6NIiZSkvVdv2zsqjdnK8HVDLlyHyNjuegogM4NA5z9+YRG9gA722H97AgOA/gSyf43zCIHdE899yuTIg3ciNXpm1jmImTDwdJPITI4RPhRugbvslbFKt2Vfr/6eTFb4W1WkY6m6YPdQjJr2tNZp3EQlko7BgXHRNz2LAc+gdwMq7IUf3R58ohtFgrbr6n7hDFWAlPr8f/T9I4CECU9/De+vgVQY5nxh4POEzybJeCTS5YnCNAZzhsRzkP1Bsmu4t4aYU07nYuerA6KWWcJYO6HHrKJjaE3Zl624UWz/QOOPjcWHc7QzdIk40yl5tCWjhIDhJX0xF4CBMvBsf10IF4Ac//Z/bPlsgAcOwn6S6n6CwxzUewLcRoYaKzV38M23i9o493CNwL6S1UUuaQe0QpvbUfdfiqglpcRccFU+nkWwambASUiVfLyqbg49xY2eyWh1hy/Sh37XjHpaIYKD7OUEfrgS5IC09MV/1gMBgKMDyH/n9N6AhhINfh7mdoMoIZt6r9fAh1cvfHXNya6N4DzDbqi8K5WWSYlmbbAdnkpV6FxJpWSo1V8DUmGb3rMRaQBG2JJgwN9wCDnNi8HNI3dKK1aG0dvHe/UciIJf6rt+Og5wgDn59X9P/xWAKQhxf2XweYH+FjB9suGVhIMlOnlo02GJhTOdc7vFyo/TQGxs2Li7lz9NwmPurBihnVi7WSWiwKvGYntOpJiOt5drKUKMkFnE8HLxNPmJ9NG4eP8mAYUv4Np8hhi3gdruSX+3CSWAwP38f8f6UoCuDPF+6Os8gnAbKnxQ3d2F0imydzDPKIuiN5lxu8EKkrFE82kftW2az1DbYImpMqTUW3FWIJ83r5hl2koJlla7+m0+PmSOZcjcdMgwS4g11iZ6qCLUg5jkxn0QFA6BWvOvfzEFBIBHAtp/Qfa3gC4RSH5y5yeD2B/8evnYS4cULgR2CMsUja47cG/QvW6UeEhXZ3+xP51GVNVdP6Zpp+1eDFM5nMeySWghR4+TNL85cD46YIyCzKJ2kCzEhoTabXtGHs+CCemJfpMPjoDe9+t/qQALgM8Gj3++8UaBqRV2fQTjO4Q3JKd5r9TgiEYyMHTxxiWPpz8jbfq585YpTJpk960xoKFXsVoTo7yq6GGMTw==\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"Execution ended\")\n",
    "from dvats.imports import beep\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3dca0597-64fb-4bc5-946f-2ae110b3cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
