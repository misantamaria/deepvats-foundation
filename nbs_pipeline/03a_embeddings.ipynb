{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de2cd87-7d93-45ec-bd92-d97a85cf73b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Getting the embeddings\n",
    "\n",
    "> This notebook gets the embeddings (or latent space) from a multivariate time series \n",
    "given by a encoder (e.g., autoencoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816ae963-a2d2-467a-90ee-2be0f383c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_patch_size = 8\n",
    "verbose          = 0\n",
    "reset_kernel     = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db2cd5f-dd8d-42a3-bdc1-afc12ff80afb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7f51ff3c0130>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "from dvats.all import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from yaml import load, FullLoader\n",
    "import dvats.utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6774bdd-fc22-4e8e-96c4-c29417380137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280e30d-8195-4f39-898a-495d9253778b",
   "metadata": {},
   "source": [
    "## Config parameters\n",
    "> Configuration parameters are obtained from 'config\\03-embeddings.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fd16b-1ca7-4bed-9173-642cabdbe9bb",
   "metadata": {},
   "source": [
    "### Get configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47519e96-4dd2-4096-8189-d735f88155ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, job_type = get_artifact_config_embeddings(verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515769be-e06d-4ae2-b3ab-1636642a158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/mvp:v0\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372ce1e-f3c8-4df4-a802-1250bc9a80cb",
   "metadata": {},
   "source": [
    "### Show configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5f95d2-f07a-4e39-bfed-ade6555641bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/mvp:v0\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe624f-f4ff-4310-9d3c-23099381ed91",
   "metadata": {},
   "source": [
    "## Build W&B artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67704d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 03a_embeddings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"03a_embeddings\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "print(\"runname: \"+runname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa46f602-bbf9-4d2d-ae68-771adae56199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20250113_094954-mhkp5an8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/mhkp5an8' target=\"_blank\">03a_embeddings</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/mhkp5an8' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/mhkp5an8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    entity      = config.wandb_entity,\n",
    "    project     = config.wandb_project if config.use_wandb else 'work-nbs', \n",
    "    group       = config.wandb_group,\n",
    "    job_type    = job_type,\n",
    "    mode        = 'online' if config.use_wandb else 'disabled',\n",
    "    anonymous   = 'never'  if config.use_wandb else 'must',\n",
    "    config      = config,\n",
    "    resume      = 'allow',\n",
    "    name        = runname\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b68a48-1629-4ad4-940b-2abc310ad942",
   "metadata": {},
   "source": [
    "## Get trained model artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa21e68-a1fd-4bf5-b3fc-84f5295f4ad1",
   "metadata": {},
   "source": [
    "### Build artifact selector\n",
    "> Botch to use artifacts offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26dac90a-ed13-4f50-b95e-fc78c635e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08922829-19f7-4cdc-97b1-86f5a3b4f3d2",
   "metadata": {},
   "source": [
    "### Get the model from W&B\n",
    "> Restore the encoder model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e978658-78de-4dff-9679-d2ed1453dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_artifact = artifacts_gettr(config.enc_artifact, type='learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fbe313-d3b6-4793-aaf3-34d4b858065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Local file reference: Failed to find file at path /home/macu/data/wandb_artifacts/864112207175472325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/utils.py\", line 329, in to_obj\n",
      "    path = original_path if original_path.exists() else Path(self.download()).ls()[0]\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/apis/public.py\", line 4753, in download\n",
      "    pool.map(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/multiprocessing/pool.py\", line 367, in map\n",
      "    return self._map_async(func, iterable, mapstar, chunksize).get()\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/multiprocessing/pool.py\", line 774, in get\n",
      "    raise self._value\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/apis/public.py\", line 4848, in _download_file\n",
      "    downloaded_path = self.get_path(name).download(root)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/apis/public.py\", line 4154, in download\n",
      "    cache_path = manifest.storage_policy.load_reference(entry, local=True)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py\", line 910, in load_reference\n",
      "    return self._handler.load_path(manifest_entry, local)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py\", line 1115, in load_path\n",
      "    return self._handlers[str(url.scheme)].load_path(manifest_entry, local=local)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/wandb/sdk/wandb_artifacts.py\", line 1228, in load_path\n",
      "    raise ValueError(\n",
      "ValueError: Local file reference: Failed to find file at path /home/macu/data/wandb_artifacts/864112207175472325\n"
     ]
    }
   ],
   "source": [
    "# TODO: This only works when you run it two timeS! WTF?\n",
    "try:\n",
    "    enc_learner = enc_artifact.to_obj()\n",
    "except:\n",
    "    enc_learner = enc_artifact.to_obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb98d5-9ba2-4cc9-a033-91282bdab376",
   "metadata": {},
   "source": [
    "## Get dataset artifact from W&B\n",
    "### Restore the dataset artifact used for training the encoder. \n",
    "> Even if we do not compute the dimensionality reduction over this dataset, we need to know the metadata of the encoder training set, to check that it matches with the dataset that we want to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4335e626-5faa-4d27-845c-015f23ab9375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ETTh1:v2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run            = enc_artifact.logged_by()\n",
    "enc_artifact_train = artifacts_gettr(\n",
    "                        enc_run.config['train_artifact'], \n",
    "                        type='dataset'\n",
    "                    )\n",
    "enc_artifact_train.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b5100a8-f044-4337-8731-4e7a76854a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: 0.7\n",
      "w: 30\n",
      "MVP: {'r': 0.7, 'lm': 3, 'crit': None, 'sync': False, 'fname': 'encoder_MVP', 'dropout': 0.1, 'verbose': False, 'stateful': True, 'save_best': True, 'nan_to_num': 0, 'custom_mask': None, 'future_mask': False, 'weights_path': None, 'variable_mask': False, 'subsequence_mask': True}\n",
      "alias: ETTh1\n",
      "n_inp: 1\n",
      "device: cuda\n",
      "epochs: 100\n",
      "frozen: False\n",
      "mvp_ws: [10, 30]\n",
      "stride: 1\n",
      "Learner: {'lr': 0.001, 'wd': None, 'arch': 'tsai.models.InceptionTimePlus.InceptionTimePlus', 'moms': [0.95, 0.85, 0.95], 'path': '.', '_name': '<fastai.learner.Learner object at 0x7f37955eece0>', 'metrics': None, 'opt_func': 'fastai.optimizer.Adam', 'splitter': 'tsai.models.utils.ts_splitter', 'train_bn': True, 'loss_func': {'axis': -1, '_name': {'axis': -1, '_name': 'FlattenedLoss of MSELoss()', 'is_2d': False, 'flatten': True, 'floatify': True}, 'is_2d': False, 'flatten': True, 'floatify': True}, 'model_dir': 'models', 'wd_bn_bias': False, 'default_cbs': True}\n",
      "Recorder: {'add_time': True, 'train_metrics': False, 'valid_metrics': True}\n",
      "ShowGraph: {'perc': 0.5, 'final_losses': True, 'plot_metrics': True}\n",
      "mask_sync: False\n",
      "use_wandb: True\n",
      "batch size: 32\n",
      "batch_size: 32\n",
      "frozen idx: 0\n",
      "valid_size: 0.2\n",
      "mask_future: False\n",
      "wandb_group: None\n",
      "CastToTensor: True\n",
      "dataset.tfms: [ToFloat:\n",
      "encodes: (Tensor,object) -> encodes\n",
      "(object,object) -> encodes\n",
      "decodes: (object,object) -> decodes\n",
      ", None]\n",
      "WandbCallback: {'log': None, 'seed': 12345, 'n_preds': 36, 'reorder': True, 'valid_dl': None, 'log_model': False, 'log_preds': False, 'model_name': None, 'log_dataset': False, 'dataset_name': None, 'log_preds_every_epoch': False}\n",
      "analysis_mode: online\n",
      "input 1 dim 1: 32\n",
      "input 1 dim 2: 4\n",
      "input 1 dim 3: 30\n",
      "mask_stateful: True\n",
      "ParamScheduler: True\n",
      "dls.after_item: Pipeline: \n",
      "norm_by_sample: False\n",
      "train_artifact: mi-santamaria/deepvats/ETTh1:latest\n",
      "batch per epoch: 434\n",
      "dls.after_batch: Pipeline: TSStandardize\n",
      "ProgressCallback: True\n",
      "dls.before_batch: Pipeline: \n",
      "model parameters: 455940\n",
      "TrainEvalCallback: True\n",
      "norm_use_single_batch: False\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(enc_run.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918829a-dd1f-4ddb-915c-cebf41665160",
   "metadata": {},
   "source": [
    "### Specify the dataset artifact that we want to get the embeddings from\n",
    "> If no artifact is defined, the artifact to reduce will be the one used for validate the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b394f66-6b1d-4c39-a4c8-6786c4f9b493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run.config['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ff4ef9-cabd-41cb-84c8-ec86cadf5848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ETTh1:v2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ar_name = ifnone(\n",
    "    config.input_ar, \n",
    "    f'{enc_artifact_train.entity}/{enc_artifact_train.project}/{enc_artifact_train.name}'\n",
    ")\n",
    "wandb.config.update({'input_ar': input_ar_name}, allow_val_change=True)\n",
    "input_ar = artifacts_gettr(input_ar_name)\n",
    "input_ar.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a84cf086-f6ee-4f04-a234-581a738fc338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "Not a Feather V1 or Arrow IPC file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43minput_ar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/work/dvats/load.py:167\u001b[0m, in \u001b[0;36mto_df\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload())\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTS\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom-df\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# Call read_pickle with the single file from dir\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m#return pd.read_pickle(dir.ls()[0])\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR: Only from_df method is allowed yet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pyarrow/feather.py:231\u001b[0m, in \u001b[0;36mread_feather\u001b[0;34m(source, columns, use_threads, memory_map)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03mRead a pandas.DataFrame from Feather format. To read as pyarrow.Table use\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03mfeather.read_table.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03mdf : pandas.DataFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    230\u001b[0m _check_pandas_version()\n\u001b[0;32m--> 231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_pandas(use_threads\u001b[38;5;241m=\u001b[39muse_threads))\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pyarrow/feather.py:256\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, memory_map, use_threads)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_table\u001b[39m(source, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, use_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    Read a pyarrow.Table from Feather format\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    table : pyarrow.Table\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43m_feather\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatherReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_memory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pyarrow/_feather.pyx:79\u001b[0m, in \u001b[0;36mpyarrow._feather.FeatherReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Not a Feather V1 or Arrow IPC file"
     ]
    }
   ],
   "source": [
    "df = input_ar.to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6bb02-9a43-4917-93a9-0832ee98b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22dbdb5-8f92-4f56-bc4f-286bcd453986",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_run.config['w'] = 54\n",
    "enc_run.config['stride'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49908f03-6875-4e27-8050-09af41dc62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input, _ = SlidingWindow(window_len=enc_run.config['w'], \n",
    "                             stride=enc_run.config['stride'], \n",
    "                             get_y=[])(df)\n",
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf910313-b689-45f2-b405-5c4b3ef66012",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = ut.Time()\n",
    "timer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d09238-e62c-4135-baf7-4b7d38e3c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.enc_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dcf6e5-a338-4638-b0bc-2ecfc12eadf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enc_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5fc61-1e0b-4cba-a4aa-d80b26c32edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_learn_class = str(enc_learner.__class__)[8:-2]\n",
    "\n",
    "match enc_learn_class:\n",
    "    case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"fastai.learner.Learner\":\n",
    "        get_embs_kwargs = {\n",
    "            \"stride\": enc_run.config['stride'],\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1,\n",
    "            \"patch_size\": 8, #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"size\": \"small\", #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"time\": True\n",
    "        }\n",
    "    case _:\n",
    "        print(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa815efc-5050-4e6f-b6b4-c1cbd78223d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_learn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6ea32a-0d67-48de-95a3-401a13faa72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_learn_class = str(enc_learner.__class__)[8:-2]\n",
    "enc_learn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74d900-463d-4f2c-8a6b-bbfafb69ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "match enc_learn_class:\n",
    "    case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "        get_embs_kwargs = {\n",
    "            \"batch_size\": enc_input.shape[0],\n",
    "            \"cpu\"       : config.cpu,\n",
    "            \"to_numpy\"  : True,\n",
    "            \"verbose\"   : 1,\n",
    "            \"padd_step\" : 10\n",
    "        }\n",
    "    case \"fastai.learner.Learner\":\n",
    "        get_embs_kwargs = {\n",
    "            \"stride\"         : 1,\n",
    "            \"cpu\"            : config.cpu,\n",
    "            \"to_numpy\"       : True,\n",
    "            \"batch_size\"     : enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\"        : 4\n",
    "        }\n",
    "    case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\"            : config.cpu,\n",
    "            \"to_numpy\"       : True,\n",
    "            \"batch_size\"     : enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\"        : 2,\n",
    "            \"patch_size\"     : model_patch_size, #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"time\"           : True\n",
    "        }\n",
    "    case _:\n",
    "        print(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\")\n",
    "print(f\"Enc learn class {enc_learn_class}\\nkwargs: {get_embs_kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b897b59-63c4-480c-8395-71c49e30bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05befd70-6604-4170-8d69-03afd9af5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_learner.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505452b-ab49-464f-856c-46288048c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fine_tune(\n",
    "    X                             = df,\n",
    "    enc_learn                     = enc_learner, \n",
    "    stride                        = 1,      \n",
    "    batch_size                    = 128,\n",
    "    cpu                           = False, \n",
    "    to_numpy                      = True, \n",
    "    verbose                       = 4, \n",
    "    time_flag                     = True,\n",
    "    #n_windows                     = 32,\n",
    "    #n_windows_percent             = 0.8, # Enmascaro el parte del entrenamiento\n",
    "    window_mask_percent           = enc_run.config['r'],\n",
    "    training_percent              = 0.3, # Entreno con parte de los datos\n",
    "    validation_percent            = 0.3, # Evalúo con parte de los datos\n",
    "    num_epochs                    = 1,\n",
    "    shot                          = True,\n",
    "    eval_pre                      = True,\n",
    "    eval_post                     = True,\n",
    "    lr_scheduler_flag             = True,\n",
    "    #lr_scheduler_name             = \"\",\n",
    "    lr_scheduler_num_warmup_steps = 1000,\n",
    "    window_sizes                  = None,\n",
    "    n_window_sizes                = 3,\n",
    "    full_dataset                  = True,\n",
    "    window_sizes_offset           = 0.05,\n",
    "    windows_min_distance          = 5,\n",
    "    print_to_path                 = True,\n",
    "    print_path                    =\"~/data/logs.txt\",\n",
    "    print_mode                    = 'w',\n",
    "    use_moment_masks              = False,\n",
    "    mask_stateful                 = enc_run.config['mask_stateful'],\n",
    "    mask_future                   = enc_run.config['mask_future'],\n",
    "    mask_sync                     = enc_run.config['mask_sync']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ec925-fb4b-435d-b073-bdef87186721",
   "metadata": {},
   "outputs": [],
   "source": [
    "( \n",
    "    losses, \n",
    "    eval_results_pre, eval_results_post, \n",
    "    t_shots, t_shot, \n",
    "    t_evals, t_eval, model\n",
    ") = result\n",
    "\n",
    "print(eval_results_pre)\n",
    "print(eval_results_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bfd363-3c5d-4f4d-a7e7-cb65c8bd9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = get_enc_embs_set_stride_set_batch_size(\n",
    "    X          = enc_input, \n",
    "    enc_learn  = enc_learner, \n",
    "    stride     = enc_run.config['stride'],\n",
    "    **get_embs_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92080d9-0851-43ec-be9d-ce5897e415c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74290c89-62d6-4a4a-ba5c-045cab824d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc_learner.task_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd215c-a9f4-47bb-ba2e-4892117b73c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.end()\n",
    "timer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a24fb-4416-4345-a1c8-131bed978e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"Execution ended\")\n",
    "from dvats.imports import beep\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca0597-64fb-4bc5-946f-2ae110b3cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
