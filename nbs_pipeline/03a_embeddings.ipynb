{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de2cd87-7d93-45ec-bd92-d97a85cf73b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Getting the embeddings\n",
    "\n",
    "> This notebook gets the embeddings (or latent space) from a multivariate time series \n",
    "given by a encoder (e.g., autoencoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816ae963-a2d2-467a-90ee-2be0f383c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_patch_size = 8\n",
    "verbose = 0\n",
    "reset_kernel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db2cd5f-dd8d-42a3-bdc1-afc12ff80afb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7fb4f4371c60>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "from dvats.all import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from yaml import load, FullLoader\n",
    "import dvats.utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6774bdd-fc22-4e8e-96c4-c29417380137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280e30d-8195-4f39-898a-495d9253778b",
   "metadata": {},
   "source": [
    "## Config parameters\n",
    "> Configuration parameters are obtained from 'config\\03-embeddings.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fd16b-1ca7-4bed-9173-642cabdbe9bb",
   "metadata": {},
   "source": [
    "### Get configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47519e96-4dd2-4096-8189-d735f88155ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, job_type = get_artifact_config_embeddings(verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515769be-e06d-4ae2-b3ab-1636642a158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/moment-small-embedding:latest\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372ce1e-f3c8-4df4-a802-1250bc9a80cb",
   "metadata": {},
   "source": [
    "### Show configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5f95d2-f07a-4e39-bfed-ade6555641bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/moment-small-embedding:latest\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe624f-f4ff-4310-9d3c-23099381ed91",
   "metadata": {},
   "source": [
    "## Build W&B artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67704d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 03a_embeddings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"03a_embeddings\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "print(\"runname: \"+runname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa46f602-bbf9-4d2d-ae68-771adae56199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20241112_173959-7g1zisj1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/7g1zisj1' target=\"_blank\">03a_embeddings</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/7g1zisj1' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/7g1zisj1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    entity      = config.wandb_entity,\n",
    "    project     = config.wandb_project if config.use_wandb else 'work-nbs', \n",
    "    group       = config.wandb_group,\n",
    "    job_type    = job_type,\n",
    "    mode        = 'online' if config.use_wandb else 'disabled',\n",
    "    anonymous   = 'never' if config.use_wandb else 'must',\n",
    "    config      = config,\n",
    "    resume      = 'allow',\n",
    "    name        = runname\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b68a48-1629-4ad4-940b-2abc310ad942",
   "metadata": {},
   "source": [
    "## Get trained model artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa21e68-a1fd-4bf5-b3fc-84f5295f4ad1",
   "metadata": {},
   "source": [
    "### Build artifact selector\n",
    "> Botch to use artifacts offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26dac90a-ed13-4f50-b95e-fc78c635e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08922829-19f7-4cdc-97b1-86f5a3b4f3d2",
   "metadata": {},
   "source": [
    "### Get the model from W&B\n",
    "> Restore the encoder model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e978658-78de-4dff-9679-d2ed1453dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_artifact = artifacts_gettr(config.enc_artifact, type='learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fbe313-d3b6-4793-aaf3-34d4b858065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact moment-small-embedding:latest, 144.63MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n"
     ]
    }
   ],
   "source": [
    "# TODO: This only works when you run it two timeS! WTF?\n",
    "try:\n",
    "    enc_learner = enc_artifact.to_obj()\n",
    "except:\n",
    "    enc_learner = enc_artifact.to_obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb98d5-9ba2-4cc9-a033-91282bdab376",
   "metadata": {},
   "source": [
    "## Get dataset artifact from W&B\n",
    "### Restore the dataset artifact used for training the encoder. \n",
    "> Even if we do not compute the dimensionality reduction over this dataset, we need to know the metadata of the encoder training set, to check that it matches with the dataset that we want to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4335e626-5faa-4d27-845c-015f23ab9375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toy:v2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run = enc_artifact.logged_by()\n",
    "enc_artifact_train = artifacts_gettr(enc_run.config['train_artifact'], type='dataset')\n",
    "enc_artifact_train.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b5100a8-f044-4337-8731-4e7a76854a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: 0.71\n",
      "w: 30\n",
      "freq: 1s\n",
      "alias: toy\n",
      "epochs: 100\n",
      "mvp_ws: [10, 30]\n",
      "stride: 1\n",
      "time_col: None\n",
      "data_cols: []\n",
      "mask_sync: False\n",
      "use_wandb: True\n",
      "batch_size: 32\n",
      "csv_config: {}\n",
      "data_fpath: ~/data/toy.csv\n",
      "valid_size: 0.2\n",
      "mask_future: False\n",
      "wandb_group: None\n",
      "analysis_mode: online\n",
      "artifact_name: toy\n",
      "mask_stateful: True\n",
      "norm_by_sample: False\n",
      "train_artifact: mi-santamaria/deepvats/toy:latest\n",
      "valid_artifact: None\n",
      "norm_use_single_batch: False\n",
      "norm_use_by_single_batch: [False]\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(enc_run.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918829a-dd1f-4ddb-915c-cebf41665160",
   "metadata": {},
   "source": [
    "### Specify the dataset artifact that we want to get the embeddings from\n",
    "> If no artifact is defined, the artifact to reduce will be the one used for validate the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b394f66-6b1d-4c39-a4c8-6786c4f9b493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run.config['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ff4ef9-cabd-41cb-84c8-ec86cadf5848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toy:v2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ar_name = ifnone(\n",
    "    config.input_ar, \n",
    "    f'{enc_artifact_train.entity}/{enc_artifact_train.project}/{enc_artifact_train.name}'\n",
    ")\n",
    "wandb.config.update({'input_ar': input_ar_name}, allow_val_change=True)\n",
    "input_ar = artifacts_gettr(input_ar_name)\n",
    "input_ar.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a84cf086-f6ee-4f04-a234-581a738fc338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T3</th>\n",
       "      <th>T2</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:00</th>\n",
       "      <td>0.741822</td>\n",
       "      <td>0.637180</td>\n",
       "      <td>0.565117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:01</th>\n",
       "      <td>0.739731</td>\n",
       "      <td>0.629415</td>\n",
       "      <td>0.493513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:02</th>\n",
       "      <td>0.718757</td>\n",
       "      <td>0.539220</td>\n",
       "      <td>0.469350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:03</th>\n",
       "      <td>0.730169</td>\n",
       "      <td>0.577670</td>\n",
       "      <td>0.444100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-01 00:00:04</th>\n",
       "      <td>0.752406</td>\n",
       "      <td>0.570180</td>\n",
       "      <td>0.373008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           T3        T2        T1\n",
       "1970-01-01 00:00:00  0.741822  0.637180  0.565117\n",
       "1970-01-01 00:00:01  0.739731  0.629415  0.493513\n",
       "1970-01-01 00:00:02  0.718757  0.539220  0.469350\n",
       "1970-01-01 00:00:03  0.730169  0.577670  0.444100\n",
       "1970-01-01 00:00:04  0.752406  0.570180  0.373008"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = input_ar.to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46c6bb02-9a43-4917-93a9-0832ee98b5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a22dbdb5-8f92-4f56-bc4f-286bcd453986",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_run.config['w'] = 54\n",
    "enc_run.config['stride'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49908f03-6875-4e27-8050-09af41dc62bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 3, 54)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input, _ = SlidingWindow(window_len=enc_run.config['w'], \n",
    "                             stride=enc_run.config['stride'], \n",
    "                             get_y=[])(df)\n",
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf910313-b689-45f2-b405-5c4b3ef66012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1731433229.5317543"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = ut.Time()\n",
    "timer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97d09238-e62c-4135-baf7-4b7d38e3c19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mi-santamaria/deepvats/moment-small-embedding:latest'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.enc_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9dcf6e5-a338-4638-b0bc-2ecfc12eadf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(enc_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5b5fc61-1e0b-4cba-a4aa-d80b26c32edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_learn_class = str(enc_learner.__class__)[8:-2]\n",
    "\n",
    "match enc_learn_class:\n",
    "    case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"fastai.learner.Learner\":\n",
    "        get_embs_kwargs = {\n",
    "            \"stride\": enc_run.config['stride'],\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1,\n",
    "            \"patch_size\": 8, #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"size\": \"small\", #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"time\": True\n",
    "        }\n",
    "    case _:\n",
    "        print(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa815efc-5050-4e6f-b6b4-c1cbd78223d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'momentfm.models.moment.MOMENTPipeline'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_learn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f6ea32a-0d67-48de-95a3-401a13faa72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'momentfm.models.moment.MOMENTPipeline'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_learn_class = str(enc_learner.__class__)[8:-2]\n",
    "enc_learn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb74d900-463d-4f2c-8a6b-bbfafb69ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc learn class momentfm.models.moment.MOMENTPipeline\n",
      "kwargs: {'batch_size': 249, 'cpu': False, 'to_numpy': True, 'verbose': 1, 'padd_step': 2}\n"
     ]
    }
   ],
   "source": [
    "match enc_learn_class:\n",
    "    case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "        get_embs_kwargs = {\n",
    "            \"batch_size\": enc_input.shape[0],\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"verbose\": 1,\n",
    "            \"padd_step\":2\n",
    "        }\n",
    "    case \"fastai.learner.Learner\":\n",
    "        get_embs_kwargs = {\n",
    "            \"stride\": 1,\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 4\n",
    "        }\n",
    "    case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 2,\n",
    "            \"patch_size\": model_patch_size, #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"time\": True\n",
    "        }\n",
    "    case _:\n",
    "        print(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\")\n",
    "print(f\"Enc learn class {enc_learn_class}\\nkwargs: {get_embs_kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "615ff0d6-7514-49db-a9c4-60f022a5ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.print_flush(\"patata\", \"xd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "811f644e-170e-4fc6-862e-ee96637dcbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       " \u001b[0mprint_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmssg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprint_to_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprint_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'~/data/logs/logs.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprint_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprint_time\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprint_both\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/work/dvats/utils.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "? print_flush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b897b59-63c4-480c-8395-71c49e30bab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 0.71,\n",
       " 'w': 54,\n",
       " 'freq': '1s',\n",
       " 'alias': 'toy',\n",
       " 'epochs': 100,\n",
       " 'mvp_ws': [10, 30],\n",
       " 'stride': 2,\n",
       " 'time_col': None,\n",
       " 'data_cols': [],\n",
       " 'mask_sync': False,\n",
       " 'use_wandb': True,\n",
       " 'batch_size': 32,\n",
       " 'csv_config': {},\n",
       " 'data_fpath': '~/data/toy.csv',\n",
       " 'valid_size': 0.2,\n",
       " 'mask_future': False,\n",
       " 'wandb_group': None,\n",
       " 'analysis_mode': 'online',\n",
       " 'artifact_name': 'toy',\n",
       " 'mask_stateful': True,\n",
       " 'norm_by_sample': False,\n",
       " 'train_artifact': 'mi-santamaria/deepvats/toy:latest',\n",
       " 'valid_artifact': None,\n",
       " 'norm_use_single_batch': False,\n",
       " 'norm_use_by_single_batch': [False]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c505452b-ab49-464f-856c-46288048c233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] --> fine_tune_moment_\n",
      "[2] fine_tune_moment_ | X not-windowed dataset\n",
      "[2] fine_tune_moment_ | X not-windowed dataset | Selecting Fourier's dominant frequences\n",
      "[1] ---> Find_dominant_window_sizes_list\n",
      "[1] Find_dominant_window_sizes_list | X ~ (550, 3)\n",
      "[1] ---> Find_dominant_window_sizes_list\n",
      "[1] Find_dominant_window_sizes_list | --> Freqs\n",
      "[1] Find_dominant_window_sizes_list | Freqs -->\n",
      "[1] Find_dominant_window_sizes_list | Coefs and window_sizes -->\n",
      "[1] Find_dominant_window_sizes_list | --> Find and return valid window_sizes\n",
      "[1] Find_dominant_window_sizes_list | Find and return valid window_sizes -->\n",
      "[1] Find dominant_window_sizes_list --->\n",
      "[1] ---> Find_dominant_window_sizes_list\n",
      "[1] Find_dominant_window_sizes_list | --> Freqs\n",
      "[1] Find_dominant_window_sizes_list | Freqs -->\n",
      "[1] Find_dominant_window_sizes_list | Coefs and window_sizes -->\n",
      "[1] Find_dominant_window_sizes_list | --> Find and return valid window_sizes\n",
      "[1] Find_dominant_window_sizes_list | Find and return valid window_sizes -->\n",
      "[1] Find dominant_window_sizes_list --->\n",
      "[1] ---> Find_dominant_window_sizes_list\n",
      "[1] Find_dominant_window_sizes_list | --> Freqs\n",
      "[1] Find_dominant_window_sizes_list | Freqs -->\n",
      "[1] Find_dominant_window_sizes_list | Coefs and window_sizes -->\n",
      "[1] Find_dominant_window_sizes_list | --> Find and return valid window_sizes\n",
      "[1] Find_dominant_window_sizes_list | Find and return valid window_sizes -->\n",
      "[1] Find dominant_window_sizes_list --->\n",
      "[1] Find_dominant_window_sizes_list | Grouping sizes\n",
      "[1] Find_dominant_window_sizes_list -->\n",
      "[2] fine_tune_moment_ | X not-windowed dataset | Selecting Fourier's dominant frequences | [17, 10, 23]\n",
      "[2] fine_tune_moment_ | Building the datasets\n",
      "[2] fine_tune_moment_ | Processing 3 datasets | First length : (534, 3, 17)\n",
      "[2] fine_tune_moment_ | Setting up optimizer as AdamW\n",
      "[2] fine_tune_moment_ | Processing wlen 17\n",
      "[2] --> fine_tune_moment_single\n",
      "[2] fine_tune_moment_single | Prepare the dataset\n",
      "[2] fine_tune_moment_single | Selecting ds train | 161 windows\n",
      "[2] fine_tune_moment_single | Train DataLoader | Random windows\n",
      "[1] windows ~ torch.Size([161, 3, 17])\n",
      "[2] fine_tune_moment_single | Train DataLoader | DataLoader\n",
      "[2] fine_tune_moment_single | Train | wlen 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd7672b465a4a09a103543187d3b36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] fine_tune_moment_train | num_epochs 1 | n_batches 2\n",
      "[1] fine_tune_moment_train | batch 0 ~ torch.Size([128, 3, 17]) | epoch 0 | train 0 of 2\n",
      "[1] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.71 | batch ~ torch.Size([128, 3, 17])\n",
      "[1] ---> sure_eval_moment\n",
      "[1] sure_eval_moment | cpu | False | device | 1\n",
      "[1] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([128, 3, 17])\n",
      "[1] sure_eval_moment | Trial 1 | device 1 | input_mask~torch.Size([1, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 1 | device 1 | mask device~torch.Size([1, 128, 17]): cuda:1\n",
      "[1] sure_eval_moment | Trial 1 | device 1 | y~torch.Size([128, 3, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor | padd step: 100\n",
      "[1] sure_eval_moment | Trial 1 | y ~ torch.Size([128, 3, 17])\n",
      "[1] Not the usual error. No padding, just fail\n",
      "[1] sure_eval_moment -->\n",
      "[1] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([128, 3, 17])\n",
      "[1] sure_eval_moment | Trial 2 | device 1 | input_mask~torch.Size([1, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 2 | device 1 | mask device~torch.Size([1, 128, 17]): cuda:1\n",
      "[1] sure_eval_moment | Trial 2 | device 1 | y~torch.Size([128, 3, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor | padd step: 100\n",
      "[1] sure_eval_moment | Trial 2 | y ~ torch.Size([128, 3, 17])\n",
      "[1] Not the usual error. No padding, just fail\n",
      "[1] sure_eval_moment -->\n",
      "[1] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([128, 3, 17])\n",
      "[1] sure_eval_moment | Trial 3 | device 1 | input_mask~torch.Size([1, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 3 | device 1 | mask device~torch.Size([1, 128, 17]): cuda:1\n",
      "[1] sure_eval_moment | Trial 3 | device 1 | y~torch.Size([128, 3, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor | padd step: 100\n",
      "[1] sure_eval_moment | Trial 3 | y ~ torch.Size([128, 3, 17])\n",
      "[1] Not the usual error. No padding, just fail\n",
      "[1] sure_eval_moment -->\n",
      "[1] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([128, 3, 17])\n",
      "[1] sure_eval_moment | Trial 4 | device 1 | input_mask~torch.Size([1, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 4 | device 1 | mask device~torch.Size([1, 128, 17]): cuda:1\n",
      "[1] sure_eval_moment | Trial 4 | device 1 | y~torch.Size([128, 3, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor | padd step: 100\n",
      "[1] sure_eval_moment | Trial 4 | y ~ torch.Size([128, 3, 17])\n",
      "[1] Not the usual error. No padding, just fail\n",
      "[1] sure_eval_moment -->\n",
      "[1] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([128, 3, 17])\n",
      "[1] sure_eval_moment | Trial 5 | device 1 | input_mask~torch.Size([1, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 5 | device 1 | mask device~torch.Size([1, 128, 17]): cuda:1\n",
      "[1] sure_eval_moment | Trial 5 | device 1 | y~torch.Size([128, 3, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor | padd step: 100\n",
      "[1] sure_eval_moment | Trial 5 | y ~ torch.Size([128, 3, 17])\n",
      "[1] Not the usual error. No padding, just fail\n",
      "[1] sure_eval_moment -->\n",
      "[1] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[1] fine_tune_moment_train | batch 0 ~ torch.Size([128, 3, 17]) | epoch 0 | train 0 of 2 | Loss backward\n",
      "[1] fine_tune_moment_train | batch 0 ~ torch.Size([128, 3, 17]) | epoch 0 | train 0 of 2 | Loss backward failed: 'tuple' object has no attribute 'item'\n",
      "[1] fine_tune_moment_train | batch 1 ~ torch.Size([33, 3, 17]) | epoch 0 | train 1 of 2\n",
      "[1] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.71 | batch ~ torch.Size([33, 3, 17])\n",
      "[1] ---> sure_eval_moment\n",
      "[1] sure_eval_moment | cpu | False | device | 1\n",
      "[1] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([33, 3, 17])\n",
      "[1] sure_eval_moment | Trial 1 | device 1 | input_mask~torch.Size([1, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 1 | device 1 | mask device~torch.Size([1, 33, 17]): cuda:1\n",
      "[1] sure_eval_moment | Trial 1 | device 1 | y~torch.Size([33, 3, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 1 | About to pad X (encoder input) | exception Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor | padd step: 100\n",
      "[1] sure_eval_moment | Trial 1 | y ~ torch.Size([33, 3, 17])\n",
      "[1] Not the usual error. No padding, just fail\n",
      "[1] sure_eval_moment -->\n",
      "[1] sure_eval_moment | Trial 2 | x_enc ~ torch.Size([33, 3, 17])\n",
      "[1] sure_eval_moment | Trial 2 | device 1 | input_mask~torch.Size([1, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 2 | device 1 | mask device~torch.Size([1, 33, 17]): cuda:1\n",
      "[1] sure_eval_moment | Trial 2 | device 1 | y~torch.Size([33, 3, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 2 | About to pad X (encoder input) | exception Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor | padd step: 100\n",
      "[1] sure_eval_moment | Trial 2 | y ~ torch.Size([33, 3, 17])\n",
      "[1] Not the usual error. No padding, just fail\n",
      "[1] sure_eval_moment -->\n",
      "[1] sure_eval_moment | Trial 3 | x_enc ~ torch.Size([33, 3, 17])\n",
      "[1] sure_eval_moment | Trial 3 | device 1 | input_mask~torch.Size([1, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 3 | device 1 | mask device~torch.Size([1, 33, 17]): cuda:1\n",
      "[1] sure_eval_moment | Trial 3 | device 1 | y~torch.Size([33, 3, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 3 | About to pad X (encoder input) | exception Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor | padd step: 100\n",
      "[1] sure_eval_moment | Trial 3 | y ~ torch.Size([33, 3, 17])\n",
      "[1] Not the usual error. No padding, just fail\n",
      "[1] sure_eval_moment -->\n",
      "[1] sure_eval_moment | Trial 4 | x_enc ~ torch.Size([33, 3, 17])\n",
      "[1] sure_eval_moment | Trial 4 | device 1 | input_mask~torch.Size([1, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 4 | device 1 | mask device~torch.Size([1, 33, 17]): cuda:1\n",
      "[1] sure_eval_moment | Trial 4 | device 1 | y~torch.Size([33, 3, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 4 | About to pad X (encoder input) | exception Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor | padd step: 100\n",
      "[1] sure_eval_moment | Trial 4 | y ~ torch.Size([33, 3, 17])\n",
      "[1] Not the usual error. No padding, just fail\n",
      "[1] sure_eval_moment -->\n",
      "[1] sure_eval_moment | Trial 5 | x_enc ~ torch.Size([33, 3, 17])\n",
      "[1] sure_eval_moment | Trial 5 | device 1 | input_mask~torch.Size([1, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 5 | device 1 | mask device~torch.Size([1, 33, 17]): cuda:1\n",
      "[1] sure_eval_moment | Trial 5 | device 1 | y~torch.Size([33, 3, 17]) device: cuda:1\n",
      "[1] sure_eval_moment | Trial 5 | About to pad X (encoder input) | exception Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor | padd step: 100\n",
      "[1] sure_eval_moment | Trial 5 | y ~ torch.Size([33, 3, 17])\n",
      "[1] Not the usual error. No padding, just fail\n",
      "[1] sure_eval_moment -->\n",
      "[1] fine_tune_moment_train_loop_step_ | Execution failed | Output none \n",
      "[1] fine_tune_moment_train | batch 1 ~ torch.Size([33, 3, 17]) | epoch 0 | train 1 of 2 | Loss backward\n",
      "[1] fine_tune_moment_train | batch 1 ~ torch.Size([33, 3, 17]) | epoch 0 | train 1 of 2 | Loss backward failed: 'tuple' object has no attribute 'item'\n",
      "[2] [] Start: 1731433231.1112862 | End: 1731433231.407257 | Duration: 0.2959709167480469 seconds\n",
      "[2] fine_tune_moment_single -->\n",
      "[2] fine_tune_moment_ | Processing wlen 10\n",
      "[2] --> fine_tune_moment_single\n",
      "[2] fine_tune_moment_single | Prepare the dataset\n",
      "[2] fine_tune_moment_single | Selecting ds train | 163 windows\n",
      "[2] fine_tune_moment_single | Train DataLoader | Random windows\n",
      "[1] windows ~ torch.Size([163, 3, 10])\n",
      "[2] fine_tune_moment_single | Train DataLoader | DataLoader\n",
      "[2] fine_tune_moment_single | Train | wlen 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 281, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 295, in reconstruction\n",
      "    x_enc = self.normalizer(x=x_enc, mask=mask * input_mask, mode=\"norm\")\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 40, in forward\n",
      "    self._get_statistics(x, mask=mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 61, in _get_statistics\n",
      "    mask = mask.unsqueeze(1).repeat(1, n_channels, 1).bool()\n",
      "RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 281, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 295, in reconstruction\n",
      "    x_enc = self.normalizer(x=x_enc, mask=mask * input_mask, mode=\"norm\")\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 40, in forward\n",
      "    self._get_statistics(x, mask=mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 61, in _get_statistics\n",
      "    mask = mask.unsqueeze(1).repeat(1, n_channels, 1).bool()\n",
      "RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 281, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 295, in reconstruction\n",
      "    x_enc = self.normalizer(x=x_enc, mask=mask * input_mask, mode=\"norm\")\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 40, in forward\n",
      "    self._get_statistics(x, mask=mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 61, in _get_statistics\n",
      "    mask = mask.unsqueeze(1).repeat(1, n_channels, 1).bool()\n",
      "RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 281, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 295, in reconstruction\n",
      "    x_enc = self.normalizer(x=x_enc, mask=mask * input_mask, mode=\"norm\")\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 40, in forward\n",
      "    self._get_statistics(x, mask=mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 61, in _get_statistics\n",
      "    mask = mask.unsqueeze(1).repeat(1, n_channels, 1).bool()\n",
      "RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 281, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 295, in reconstruction\n",
      "    x_enc = self.normalizer(x=x_enc, mask=mask * input_mask, mode=\"norm\")\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 40, in forward\n",
      "    self._get_statistics(x, mask=mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 61, in _get_statistics\n",
      "    mask = mask.unsqueeze(1).repeat(1, n_channels, 1).bool()\n",
      "RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 281, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 295, in reconstruction\n",
      "    x_enc = self.normalizer(x=x_enc, mask=mask * input_mask, mode=\"norm\")\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 40, in forward\n",
      "    self._get_statistics(x, mask=mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 61, in _get_statistics\n",
      "    mask = mask.unsqueeze(1).repeat(1, n_channels, 1).bool()\n",
      "RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 281, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 295, in reconstruction\n",
      "    x_enc = self.normalizer(x=x_enc, mask=mask * input_mask, mode=\"norm\")\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 40, in forward\n",
      "    self._get_statistics(x, mask=mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 61, in _get_statistics\n",
      "    mask = mask.unsqueeze(1).repeat(1, n_channels, 1).bool()\n",
      "RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 281, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 295, in reconstruction\n",
      "    x_enc = self.normalizer(x=x_enc, mask=mask * input_mask, mode=\"norm\")\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 40, in forward\n",
      "    self._get_statistics(x, mask=mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 61, in _get_statistics\n",
      "    mask = mask.unsqueeze(1).repeat(1, n_channels, 1).bool()\n",
      "RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 281, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 295, in reconstruction\n",
      "    x_enc = self.normalizer(x=x_enc, mask=mask * input_mask, mode=\"norm\")\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 40, in forward\n",
      "    self._get_statistics(x, mask=mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 61, in _get_statistics\n",
      "    mask = mask.unsqueeze(1).repeat(1, n_channels, 1).bool()\n",
      "RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 281, in sure_eval_moment\n",
      "    output = enc_learn(x_enc = y, input_mask = input_mask, mask = mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 227, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 566, in forward\n",
      "    return self.reconstruction(\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/moment.py\", line 295, in reconstruction\n",
      "    x_enc = self.normalizer(x=x_enc, mask=mask * input_mask, mode=\"norm\")\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 40, in forward\n",
      "    self._get_statistics(x, mask=mask)\n",
      "  File \"/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/momentfm/models/layers/revin.py\", line 61, in _get_statistics\n",
      "    mask = mask.unsqueeze(1).repeat(1, n_channels, 1).bool()\n",
      "RuntimeError: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9775462094e5449e8b1a7d51bd557675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] fine_tune_moment_train | num_epochs 1 | n_batches 2\n",
      "[1] fine_tune_moment_train | batch 0 ~ torch.Size([128, 3, 10]) | epoch 0 | train 0 of 2\n",
      "[1] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.71 | batch ~ torch.Size([128, 3, 10])\n",
      "[2] fine_tune_moment_single | Train | Window 10 not valid | 'float' object has no attribute 'to'\n",
      "[2] fine_tune_moment_single -->\n",
      "[2] fine_tune_moment_ | Processing wlen 23\n",
      "[2] --> fine_tune_moment_single\n",
      "[2] fine_tune_moment_single | Prepare the dataset\n",
      "[2] fine_tune_moment_single | Selecting ds train | 159 windows\n",
      "[2] fine_tune_moment_single | Train DataLoader | Random windows\n",
      "[1] windows ~ torch.Size([159, 3, 23])\n",
      "[2] fine_tune_moment_single | Train DataLoader | DataLoader\n",
      "[2] fine_tune_moment_single | Train | wlen 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 1605, in fine_tune_moment_single_\n",
      "    losses, enc_learn = fine_tune_moment_train_(\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 1433, in fine_tune_moment_train_\n",
      "    loss = fine_tune_moment_train_loop_step_(\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 1295, in fine_tune_moment_train_loop_step_\n",
      "    enc_learn = enc_learn.to(device)\n",
      "AttributeError: 'float' object has no attribute 'to'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780bfe0ec0cd403c8fecad3821590103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] fine_tune_moment_train | num_epochs 1 | n_batches 2\n",
      "[1] fine_tune_moment_train | batch 0 ~ torch.Size([128, 3, 23]) | epoch 0 | train 0 of 2\n",
      "[1] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.71 | batch ~ torch.Size([128, 3, 23])\n",
      "[2] fine_tune_moment_single | Train | Window 23 not valid | 'float' object has no attribute 'to'\n",
      "[2] fine_tune_moment_single -->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 1605, in fine_tune_moment_single_\n",
      "    losses, enc_learn = fine_tune_moment_train_(\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 1433, in fine_tune_moment_train_\n",
      "    loss = fine_tune_moment_train_loop_step_(\n",
      "  File \"/home/macu/work/dvats/encoder.py\", line 1295, in fine_tune_moment_train_loop_step_\n",
      "    enc_learn = enc_learn.to(device)\n",
      "AttributeError: 'float' object has no attribute 'to'\n"
     ]
    }
   ],
   "source": [
    "result = fine_tune_moment_(\n",
    "    X                             = df,\n",
    "    enc_learn                     = enc_learner, \n",
    "    stride                        = 1,      \n",
    "    batch_size                    = 128,\n",
    "    cpu                           = False, \n",
    "    to_numpy                      = True, \n",
    "    verbose                       = 2, \n",
    "    time_flag                     = True,\n",
    "    #n_windows                     = 32,\n",
    "    #n_windows_percent             = 0.8, # Enmascaro el parte del entrenamiento\n",
    "    window_mask_percent           = enc_run.config['r'],\n",
    "    training_percent              = 0.3, # Entreno con parte de los datos\n",
    "    validation_percent            = 0.3, # Evalúo con parte de los datos\n",
    "    num_epochs                    = 1,\n",
    "    shot                          = True,\n",
    "    eval_pre                      = False,\n",
    "    eval_post                     = False,\n",
    "    lr_scheduler_flag             = True,\n",
    "    #lr_scheduler_name             = \"\",\n",
    "    lr_scheduler_num_warmup_steps = 1000,\n",
    "    window_sizes                  = None,\n",
    "    n_window_sizes                = 3,\n",
    "    full_dataset                  = True,\n",
    "    window_sizes_offset           = 0.05,\n",
    "    windows_min_distance          = 5,\n",
    "    print_to_path                 = False,\n",
    "    print_mode                    = 'w',\n",
    "    use_moment_masks              = False,\n",
    "    mask_stateful                 = enc_run.config['mask_stateful'],\n",
    "    mask_future                   = enc_run.config['mask_future'],\n",
    "    mask_sync                     = enc_run.config['mask_sync']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "103ec925-fb4b-435d-b073-bdef87186721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#( \n",
    "#    losses, \n",
    "#    eval_results_pre, eval_results_post, \n",
    "#    t_shots, t_shot, \n",
    "#    t_evals, t_eval\n",
    "#) = result\n",
    "\n",
    "#print(eval_results_pre)\n",
    "#print(eval_results_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08bfd363-3c5d-4f4d-a7e7-cb65c8bd9f3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_enc_embs_set_stride_set_batch_size() missing 1 required positional argument: 'stride'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embs \u001b[38;5;241m=\u001b[39m \u001b[43mget_enc_embs_set_stride_set_batch_size\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc_learn\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_learner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#stride     = enc_run.config['stride'],\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mget_embs_kwargs\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_enc_embs_set_stride_set_batch_size() missing 1 required positional argument: 'stride'"
     ]
    }
   ],
   "source": [
    "embs = get_enc_embs_set_stride_set_batch_size(\n",
    "    X          = enc_input, \n",
    "    enc_learn  = enc_learner, \n",
    "    #stride     = enc_run.config['stride'],\n",
    "    **get_embs_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74290c89-62d6-4a4a-ba5c-045cab824d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc_learner.task_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd215c-a9f4-47bb-ba2e-4892117b73c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.end()\n",
    "timer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a24fb-4416-4345-a1c8-131bed978e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"Execution ended\")\n",
    "from dvats.imports import beep\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca0597-64fb-4bc5-946f-2ae110b3cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
