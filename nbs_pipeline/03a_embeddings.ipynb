{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de2cd87-7d93-45ec-bd92-d97a85cf73b3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Getting the embeddings\n",
    "\n",
    "> This notebook gets the embeddings (or latent space) from a multivariate time series \n",
    "given by a encoder (e.g., autoencoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "816ae963-a2d2-467a-90ee-2be0f383c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_patch_size = 8\n",
    "verbose          = 0\n",
    "reset_kernel     = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db2cd5f-dd8d-42a3-bdc1-afc12ff80afb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/aeon/base/__init__.py:24: FutureWarning: The aeon package will soon be releasing v1.0.0 with the removal of legacy modules and interfaces such as BaseTransformer and BaseForecaster. This will contain breaking changes. See aeon-toolkit.org for more information. Set aeon.AEON_DEPRECATION_WARNING or the AEON_DEPRECATION_WARNING environmental variable to 'False' to disable this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7f9e526e6350>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "from dvats.all import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "import wandb\n",
    "wandb_api = wandb.Api()\n",
    "from yaml import load, FullLoader\n",
    "import dvats.utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6774bdd-fc22-4e8e-96c4-c29417380137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280e30d-8195-4f39-898a-495d9253778b",
   "metadata": {},
   "source": [
    "## Config parameters\n",
    "> Configuration parameters are obtained from 'config\\03-embeddings.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fd16b-1ca7-4bed-9173-642cabdbe9bb",
   "metadata": {},
   "source": [
    "### Get configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47519e96-4dd2-4096-8189-d735f88155ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, job_type = get_artifact_config_embeddings(verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515769be-e06d-4ae2-b3ab-1636642a158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/zeroshot-moment-small-embedding:latest\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372ce1e-f3c8-4df4-a802-1250bc9a80cb",
   "metadata": {},
   "source": [
    "### Show configuration artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5f95d2-f07a-4e39-bfed-ade6555641bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: embeddings\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "enc_artifact: mi-santamaria/deepvats/zeroshot-moment-small-embedding:latest\n",
      "input_ar: None\n",
      "cpu: False\n"
     ]
    }
   ],
   "source": [
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe624f-f4ff-4310-9d3c-23099381ed91",
   "metadata": {},
   "source": [
    "## Build W&B artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67704d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 03a_embeddings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"03a_embeddings\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "print(\"runname: \"+runname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa46f602-bbf9-4d2d-ae68-771adae56199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20250121_181918-qmypofap</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/qmypofap' target=\"_blank\">03a_embeddings</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/qmypofap' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/qmypofap</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    entity      = config.wandb_entity,\n",
    "    project     = config.wandb_project if config.use_wandb else 'work-nbs', \n",
    "    group       = config.wandb_group,\n",
    "    job_type    = job_type,\n",
    "    mode        = 'online' if config.use_wandb else 'disabled',\n",
    "    anonymous   = 'never'  if config.use_wandb else 'must',\n",
    "    config      = config,\n",
    "    resume      = 'allow',\n",
    "    name        = runname\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b68a48-1629-4ad4-940b-2abc310ad942",
   "metadata": {},
   "source": [
    "## Get trained model artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa21e68-a1fd-4bf5-b3fc-84f5295f4ad1",
   "metadata": {},
   "source": [
    "### Build artifact selector\n",
    "> Botch to use artifacts offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26dac90a-ed13-4f50-b95e-fc78c635e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08922829-19f7-4cdc-97b1-86f5a3b4f3d2",
   "metadata": {},
   "source": [
    "### Get the model from W&B\n",
    "> Restore the encoder model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e978658-78de-4dff-9679-d2ed1453dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_artifact = artifacts_gettr(config.enc_artifact, type='learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fbe313-d3b6-4793-aaf3-34d4b858065c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact zeroshot-moment-small-embedding:latest, 144.63MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n"
     ]
    }
   ],
   "source": [
    "# TODO: This only works when you run it two timeS! WTF?\n",
    "try:\n",
    "    enc_learner = enc_artifact.to_obj()\n",
    "except:\n",
    "    enc_learner = enc_artifact.to_obj()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cb98d5-9ba2-4cc9-a033-91282bdab376",
   "metadata": {},
   "source": [
    "## Get dataset artifact from W&B\n",
    "### Restore the dataset artifact used for training the encoder. \n",
    "> Even if we do not compute the dimensionality reduction over this dataset, we need to know the metadata of the encoder training set, to check that it matches with the dataset that we want to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4335e626-5faa-4d27-845c-015f23ab9375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gtrends_khols-normalized_yearly:v0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run            = enc_artifact.logged_by()\n",
    "enc_artifact_train = artifacts_gettr(\n",
    "                        enc_run.config['train_artifact'], \n",
    "                        type='dataset'\n",
    "                    )\n",
    "enc_artifact_train.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b5100a8-f044-4337-8731-4e7a76854a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: 0.4\n",
      "w: 17\n",
      "alias: gtrends_khols-normalized_yearly\n",
      "epochs: 200\n",
      "mvp_ws: [12, 17]\n",
      "stride: 1\n",
      "mask_sync: False\n",
      "use_wandb: True\n",
      "batch_size: 16\n",
      "valid_size: 0.2\n",
      "mask_future: True\n",
      "wandb_group: None\n",
      "analysis_mode: online\n",
      "mask_stateful: False\n",
      "norm_by_sample: False\n",
      "train_artifact: mi-santamaria/deepvats/gtrends_khols-normalized_yearly:v0\n",
      "valid_artifact: None\n",
      "norm_use_single_batch: False\n"
     ]
    }
   ],
   "source": [
    "dvats.config.show_attrdict(enc_run.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918829a-dd1f-4ddb-915c-cebf41665160",
   "metadata": {},
   "source": [
    "### Specify the dataset artifact that we want to get the embeddings from\n",
    "> If no artifact is defined, the artifact to reduce will be the one used for validate the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b394f66-6b1d-4c39-a4c8-6786c4f9b493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run.config['stride']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ff4ef9-cabd-41cb-84c8-ec86cadf5848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gtrends_khols-normalized_yearly:v0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ar_name = ifnone(\n",
    "    config.input_ar, \n",
    "    f'{enc_artifact_train.entity}/{enc_artifact_train.project}/{enc_artifact_train.name}'\n",
    ")\n",
    "wandb.config.update({'input_ar': input_ar_name}, allow_val_change=True)\n",
    "input_ar = artifacts_gettr(input_ar_name)\n",
    "input_ar.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a84cf086-f6ee-4f04-a234-581a738fc338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-01</th>\n",
       "      <td>0.090912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>0.090912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-15</th>\n",
       "      <td>0.090912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-22</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-29</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              volume\n",
       "2004-01-01  0.090912\n",
       "2004-01-08  0.090912\n",
       "2004-01-15  0.090912\n",
       "2004-01-22  0.000000\n",
       "2004-01-29  0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = input_ar.to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46c6bb02-9a43-4917-93a9-0832ee98b5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(440, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a5aa715-e4ea-44b1-b765-0257221d50ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(enc_run.config['w'])\n",
    "print(enc_run.config['stride'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a22dbdb5-8f92-4f56-bc4f-286bcd453986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc_run.config['w'] = 54\n",
    "#enc_run.config['stride'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df07cc30-657b-41e8-8f21-0908f6c8dcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_run.config['norm_use_single_batch'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49908f03-6875-4e27-8050-09af41dc62bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 1, 17)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input, _ = SlidingWindow(window_len=enc_run.config['w'], \n",
    "                             stride=enc_run.config['stride'], \n",
    "                             get_y=[])(df)\n",
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf910313-b689-45f2-b405-5c4b3ef66012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1737483589.1233995"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = ut.Time()\n",
    "timer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97d09238-e62c-4135-baf7-4b7d38e3c19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mi-santamaria/deepvats/zeroshot-moment-small-embedding:latest'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.enc_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9dcf6e5-a338-4638-b0bc-2ecfc12eadf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(enc_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff3d78e0-5847-4606-9cab-b9c9e02c0a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4104"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(enc_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5b5fc61-1e0b-4cba-a4aa-d80b26c32edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_learn_class = str(enc_learner.__class__)[8:-2]\n",
    "\n",
    "match enc_learn_class:\n",
    "    case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"fastai.learner.Learner\":\n",
    "        get_embs_kwargs = {\n",
    "            \"stride\": enc_run.config['stride'],\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1\n",
    "        }\n",
    "    case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\": config.cpu,\n",
    "            \"to_numpy\": True,\n",
    "            \"batch_size\": enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\": 1,\n",
    "            \"patch_size\": 8, #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"size\": \"small\", #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"time\": True\n",
    "        }\n",
    "    case _:\n",
    "        print(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa815efc-5050-4e6f-b6b4-c1cbd78223d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'momentfm.models.moment.MOMENTPipeline'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_learn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f6ea32a-0d67-48de-95a3-401a13faa72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'momentfm.models.moment.MOMENTPipeline'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_learn_class = str(enc_learner.__class__)[8:-2]\n",
    "enc_learn_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb74d900-463d-4f2c-8a6b-bbfafb69ab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enc learn class momentfm.models.moment.MOMENTPipeline\n",
      "kwargs: {'batch_size': 424, 'cpu': False, 'to_numpy': True, 'verbose': 1, 'padd_step': 10}\n"
     ]
    }
   ],
   "source": [
    "match enc_learn_class:\n",
    "    case \"momentfm.models.moment.MOMENTPipeline\":\n",
    "        get_embs_kwargs = {\n",
    "            \"batch_size\": enc_input.shape[0],\n",
    "            \"cpu\"       : config.cpu,\n",
    "            \"to_numpy\"  : True,\n",
    "            \"verbose\"   : 1,\n",
    "            \"padd_step\" : 10\n",
    "        }\n",
    "    case \"fastai.learner.Learner\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\"            : config.cpu,\n",
    "            \"to_numpy\"       : True,\n",
    "            \"batch_size\"     : enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\"        : 4\n",
    "        }\n",
    "    case \"uni2ts.model.moirai.module.MoiraiModule\":\n",
    "        get_embs_kwargs = {\n",
    "            \"cpu\"            : config.cpu,\n",
    "            \"to_numpy\"       : True,\n",
    "            \"batch_size\"     : enc_run.config['batch_size'],\n",
    "            \"average_seq_dim\": True,\n",
    "            \"verbose\"        : 2,\n",
    "            \"patch_size\"     : model_patch_size, #Modificar en config (añadir en base.yml & modificar lectura a \"si existe, añadir\"),\n",
    "            \"time\"           : True\n",
    "        }\n",
    "    case _:\n",
    "        print(f\"Model embeddings implementation is not yet implemented for {enc_learn_class}.\")\n",
    "print(f\"Enc learn class {enc_learn_class}\\nkwargs: {get_embs_kwargs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a05c5be8-47c7-45f9-8ba9-43201e704a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.losses import MSELossFlat\n",
    "from dvats.encoder import MAELossFlat, EvalMSE, EvalRMSE, EvalMAE, EvalSMAPE\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c505452b-ab49-464f-856c-46288048c233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] [ --> _get_encoder ]\n",
      "[5]  [ _get_encoder ] About to exec _get_enc_input\n",
      "[5] [ --> _get_enc_input ]\n",
      "[5]  [ _get_enc_input ] is none enc_input? True\n",
      "[5]  [ _get_enc_input ] About to get the windows\n",
      "[5] [ --> windowed_dataset ]\n",
      "[5]  [ _get_enc_input ] X is a DataFrame, X~(440, 1) | window_sizes 0, n_window_sizes 3\n",
      "[5]  [ _get_enc_input ] X is a DataFrame | Selecting Fourier's dominant frequences\n",
      "[5] [ --> Find_dominant_window_sizes_list ]\n",
      "[5]  [ Find_dominant_window_sizes_list ] X ~ (440, 1)\n",
      "[5]  [ Find_dominant_window_sizes_list ] Get sizes for var 0\n",
      "[5]  [ Find_dominant_window_sizes_list ] Get sizes for var 0 | [17, 12, 18]\n",
      "[5]  [ Find_dominant_window_sizes_list ] Grouping sizes\n",
      "[5]  [ Find_dominant_window_sizes_list ] Final selected window sizes: [17, 12, 18]\n",
      "[5] [Find_dominant_window_sizes_list --> ]\n",
      "[5]  [ windowed_dataset ] X is a DataFrame | Window sizes: 3\n",
      "[5]  [ windowed_dataset ] Building the windows\n",
      "[5]  [ windowed_dataset ] w = 17\n",
      "[5]  [ windowed_dataset ] w 17 | enc_input~(424, 1, 17) | dss~1\n",
      "[5]  [ windowed_dataset ] w = 12\n",
      "[5]  [ windowed_dataset ] w 12 | enc_input~(429, 1, 12) | dss~2\n",
      "[5]  [ windowed_dataset ] w = 18\n",
      "[5]  [ windowed_dataset ] w 18 | enc_input~(423, 1, 18) | dss~3\n",
      "[5]  [ windowed_dataset ] Number of windows: 3\n",
      "[5] [windowed_dataset --> ]\n",
      "[5]  [ _get_enc_input ] About to get the encoder input | windows~3\n",
      "[5]  [ _get_enc_input ] Enc input obtained | enc_input~(424, 1, 17)\n",
      "[5] [_get_encoder --> ]\n",
      "[5]  [ _get_encoder ] enc_input~(424, 1, 17)\n",
      "[5]  [ _get_encoder ] About to exec _get_optimizer\n",
      "[5] [ --> _get_optimizer ]\n",
      "[5] [_get_encoder --> ]\n",
      "[5] [_get_encoder --> ]\n",
      "[5] [ --> set_fine_tune_ ]\n",
      "[5]  [ set_fine_tune_ ] Model class: momentfm.models.moment.MOMENTPipeline\n",
      "[5]  [ set_fine_tune_ ] Moment\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5] [_get_encoder --> ]\n",
      "[5] [ --> fine_tune ]\n",
      "[5]  [ fine_tune ] Original enc_learn MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")  | Final model MOMENTPipeline(\n",
      "  (normalizer): RevIN()\n",
      "  (tokenizer): Patching()\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (head): PretrainHead(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear): Linear(in_features=512, out_features=8, bias=True)\n",
      "  )\n",
      ")\n",
      "[5] [ --> set_fine_tune_ ]\n",
      "[5]  [ set_fine_tune_ ] Model class: momentfm.models.moment.MOMENTPipeline\n",
      "[5]  [ set_fine_tune_ ] Moment\n",
      "[5] [set_fine_tune_ --> ]\n",
      "[5]  [ set_fine_tune_ ] Use fine_tune_moment parameters\n",
      "[5] [ --> fine_tune_moment_ ]\n",
      "[5]  [ set_fine_tune_ ] Processing 3 datasets : (424, 1, 17)\n",
      "[5]  [ set_fine_tune_ ] Setting up optimizer as AdamW\n",
      "[5]  [ set_fine_tune_ ] Processing wlen 17\n",
      "[5] [ --> fine_tune_moment_single ]\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Prepare the dataset | X ~ (424, 1, 17)\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting ds train | 102 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting validation train | 102 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | Random windows\n",
      "[4] [ --> fine_tune_moment_single | prepare_train_and_eval_dataloaders | random_windows ]\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] N windows: None\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] n_windows: 82\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] windows~torch.Size([82, 1, 17])\n",
      "[4] [fine_tune_moment_single | prepare_train_and_eval_dataloaders --> ]\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | DataLoader\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Validation DataLoader\n",
      "[5]  [ fine_tune_moment_single ] Eval Pre | wlen 17\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 7/7 [00:01<00:00,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] \u001b[91m [ fine_tune_moment_single ] Eval results: {'mse': 0.342390470661696, 'rmse': 0.11897325238673793, 'mae': 0.2432825950376105, 'smape': 1.3955356942919357}.\u001b[0m\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737485847.2453482 | End: 1737485848.576698 | Duration: 1.33 seconds\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n",
      "[5]  [ fine_tune_moment_single ] Train | wlen 17\n",
      "[4] fine_tune_moment_train_ | Training loop\n",
      "[4] fine_tune_moment_train | Fine tune loop | print_to_path False | batch_masks~tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0% 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | num_epochs 5 | n_batches 6\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 0 | train 0 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.10278401523828506\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 0 | train 0 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 0 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08756449818611145\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 0 | train 1 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% 2/30 [00:00<00:01, 19.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 0 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.10309391468763351\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 0 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 0 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08485758304595947\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 0 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 0 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09423352777957916\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 0 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17% 5/30 [00:00<00:01, 19.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 0 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.003038806142285466\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 0 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 1 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08178351074457169\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 1 | train 1 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23% 7/30 [00:00<00:01, 19.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 1 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09998662024736404\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 1 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 1 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06277452409267426\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 1 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 9/30 [00:00<00:01, 19.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 1 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.11154785007238388\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 1 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 1 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 1 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37% 11/30 [00:00<00:01, 18.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 1 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.1865326166152954\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 1 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 2 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09824369102716446\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 2 | train 2 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43% 13/30 [00:00<00:00, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 2 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09474875032901764\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 2 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 2 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06445616483688354\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 2 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 15/30 [00:00<00:00, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 2 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.11043596267700195\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 2 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 2 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08801044523715973\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 2 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57% 17/30 [00:00<00:00, 18.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 2 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.13449595868587494\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 2 | train 7 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 3 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.11940910667181015\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 3 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63% 19/30 [00:01<00:00, 18.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 3 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.11213601380586624\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 3 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 3 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09399144351482391\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 3 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 21/30 [00:01<00:00, 18.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 3 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.053567737340927124\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 3 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 3 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.07411482185125351\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 3 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77% 23/30 [00:01<00:00, 18.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 3 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.0741521343588829\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 3 | train 8 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 4 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.11543002724647522\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 17]) | epoch 4 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83% 25/30 [00:01<00:00, 18.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 4 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06029142439365387\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 17]) | epoch 4 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 4 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09490206092596054\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 17]) | epoch 4 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 27/30 [00:01<00:00, 18.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 4 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.11797211319208145\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 17]) | epoch 4 | train 7 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 4 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 17]) | batch_masks ~ torch.Size([16, 17]) | mask ~ torch.Size([16, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 16]) | original_ ~ torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 16]) | o~torch.Size([16, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06941745430231094\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 17]) | epoch 4 | train 8 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97% 29/30 [00:01<00:00, 18.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 4 | train 9 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([2, 1, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([2, 17]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([2, 1, 17]) | batch_masks ~ torch.Size([2, 17]) | mask ~ torch.Size([2, 17])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([2, 1, 17])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([2, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([2, 17]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([2, 1, 17]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 17 > 16  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([2, 1, 16]) | original_ ~ torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([2, 1, 16]) | o~torch.Size([2, 1, 16])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([2, 1, 16]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([2, 17]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.006482530385255814\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([2, 1, 17]) | epoch 4 | train 9 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 30/30 [00:01<00:00, 18.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | -->\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737485848.5794098 | End: 1737485850.1911235 | Duration: 1.61 seconds\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Eval Post | wlen 17\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100% 7/7 [00:01<00:00,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] \u001b[91m [ fine_tune_moment_single ] Eval results: {'mse': 0.342390470661696, 'rmse': 0.11897325238673793, 'mae': 0.2432825950376105, 'smape': 1.3955356942919357}.\u001b[0m\n",
      "[5] \u001b[91m [ fine_tune_moment_single ] Eval_results_post = {'mse': 0.342390470661696, 'rmse': 0.11897325238673793, 'mae': 0.2432825950376105, 'smape': 1.3955356942919357}\u001b[0m\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737485850.1948304 | End: 1737485851.5050719 | Duration: 1.31 seconds\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single_ | Evaluation summary\n",
      "[5]  [ fine_tune_moment_single ] Eval pre: \n",
      "mse: 0.342390470661696\n",
      "rmse: 0.11897325238673793\n",
      "mae: 0.2432825950376105\n",
      "smape: 1.3955356942919357\n",
      "[5]  [ fine_tune_moment_single ] Eval post: \n",
      "mse: 0.342390470661696\n",
      "rmse: 0.11897325238673793\n",
      "mae: 0.2432825950376105\n",
      "smape: 1.3955356942919357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] [fine_tune_moment_single_ --> ]\n",
      "[5] \u001b[91m [ set_fine_tune_ ] About to concat {'mse': 0.342390470661696, 'rmse': 0.11897325238673793, 'mae': 0.2432825950376105, 'smape': 1.3955356942919357} to {}\u001b[0m\n",
      "[5] \u001b[91m [ set_fine_tune_ ] After concat {'mse': [0.342390470661696], 'rmse': [0.11897325238673793], 'mae': [0.2432825950376105], 'smape': [1.3955356942919357]}\u001b[0m\n",
      "[5]  [ set_fine_tune_ ] Processing wlen 17\n",
      "[5] [ --> fine_tune_moment_single ]\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Prepare the dataset | X ~ (429, 1, 12)\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting ds train | 103 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Selecting validation train | 103 windows\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | Random windows\n",
      "[4] [ --> fine_tune_moment_single | prepare_train_and_eval_dataloaders | random_windows ]\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] N windows: None\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] n_windows: 83\n",
      "[4]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] windows~torch.Size([83, 1, 12])\n",
      "[4] [fine_tune_moment_single | prepare_train_and_eval_dataloaders --> ]\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Train DataLoader | DataLoader\n",
      "[5]  [ fine_tune_moment_single | prepare_train_and_eval_dataloaders ] Validation DataLoader\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n",
      "[5]  [ fine_tune_moment_single ] Train | wlen 12\n",
      "[4] fine_tune_moment_train_ | Training loop\n",
      "[4] fine_tune_moment_train | Fine tune loop | print_to_path False | batch_masks~tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | num_epochs 5 | n_batches 6\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 0 | train 0 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06379009783267975\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 0 | train 0 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 0 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08262316882610321\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 0 | train 1 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% 2/30 [00:00<00:01, 19.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 0 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.12323485314846039\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 0 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 0 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.10861481726169586\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 0 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13% 4/30 [00:00<00:01, 19.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 0 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.03444448485970497\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 0 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 0 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.004398187156766653\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 0 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 6/30 [00:00<00:01, 19.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 1 | train 1 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.1424001008272171\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 1 | train 1 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 1 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.04729370027780533\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 1 | train 2 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27% 8/30 [00:00<00:01, 19.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 1 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06417975574731827\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 1 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 1 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.041046805679798126\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 1 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33% 10/30 [00:00<00:01, 19.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 1 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08883747458457947\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 1 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 1 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.2941763997077942\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 1 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 12/30 [00:00<00:00, 18.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 2 | train 2 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.047470998018980026\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 2 | train 2 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 2 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.071830615401268\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 2 | train 3 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47% 14/30 [00:00<00:00, 18.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 2 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09656709432601929\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 2 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 2 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.078055240213871\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 2 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53% 16/30 [00:00<00:00, 19.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 2 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09215126186609268\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 2 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 2 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.1261199414730072\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 2 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 18/30 [00:00<00:00, 19.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 3 | train 3 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.07746332883834839\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 3 | train 3 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 3 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.06467308849096298\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 3 | train 4 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67% 20/30 [00:01<00:00, 19.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 3 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.04212271794676781\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 3 | train 5 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 3 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.08285930007696152\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 3 | train 6 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73% 22/30 [00:01<00:00, 18.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 3 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.12645664811134338\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 3 | train 7 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 3 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.1271512359380722\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 3 | train 8 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 24/30 [00:01<00:00, 19.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 4 | train 4 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.04475073516368866\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 0 ~ torch.Size([16, 1, 12]) | epoch 4 | train 4 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 4 | train 5 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.13818737864494324\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 1 ~ torch.Size([16, 1, 12]) | epoch 4 | train 5 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87% 26/30 [00:01<00:00, 18.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 4 | train 6 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.036908600479364395\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 2 ~ torch.Size([16, 1, 12]) | epoch 4 | train 6 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 4 | train 7 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.09174537658691406\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 3 ~ torch.Size([16, 1, 12]) | epoch 4 | train 7 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93% 28/30 [00:01<00:00, 19.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 4 | train 8 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([16, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([16, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([16, 1, 12]) | batch_masks ~ torch.Size([16, 12]) | mask ~ torch.Size([16, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([16, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([16, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([16, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([16, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([16, 1, 8]) | original_ ~ torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([16, 1, 8]) | o~torch.Size([16, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([16, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([16, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.13668975234031677\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 4 ~ torch.Size([16, 1, 12]) | epoch 4 | train 8 of 30 | Loss backward | After loop step \n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 4 | train 9 of 30 | Before loop step\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | window_mask_percent 0.4 | batch ~ torch.Size([3, 1, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | o ~ torch.Size([3, 12]) | stateful = False | sync = False | r = 0.4\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | Before shape adjustment | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | Fine tune loop | batch ~ torch.Size([3, 1, 12]) | batch_masks ~ torch.Size([3, 12]) | mask ~ torch.Size([3, 12])\n",
      "[4] fine_tune_moment_train_loop_step_ | sure_eval_moment | bcuda:0 | mcuda:0 | bmcuda:0\n",
      "[4] ---> sure_eval_moment\n",
      "[4] sure_eval_moment | cpu | False | device | 0\n",
      "[4] sure_eval_moment | Trial 1 | x_enc ~ torch.Size([3, 1, 12])\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | input_mask~torch.Size([3, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | mask device~torch.Size([3, 12]): cuda:0\n",
      "[4] sure_eval_moment | Trial 1 | device 0 | y~torch.Size([3, 1, 12]) device: cuda:0\n",
      "[4] sure_eval_moment | output <class 'momentfm.data.base.TimeseriesOutputs'> -->\n",
      "[4] --> fine_tune_moment_compute_loss\n",
      "[4] --> fine_tune_moment_compute_loss_check_sizes_\n",
      "[4]  Fine tune loop | TODO: Why? Original 12 > 8  Reconstruction\n",
      "[4] ---------- Checking loss  ------- | reconstruction ~ torch.Size([3, 1, 8]) | original_ ~ torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss_check_sizes_ -->\n",
      "[4] fine_tune_moment_compute_loss | b~torch.Size([3, 1, 8]) | o~torch.Size([3, 1, 8])\n",
      "[4] fine_tune_moment_compute_loss | batch ~ torch.Size([3, 1, 8]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | batch_masks ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] fine_tune_moment_compute_loss | mask ~ torch.Size([3, 12]) | cuda:0\n",
      "[4] Loss type: <class 'torch.Tensor'>\n",
      "[4] fine_tune_moment_compute_loss | loss: 0.00538771552965045\n",
      "[4] fine_tune_moment_compute_loss -->\n",
      "[4] fine_tune_moment_train | batch 5 ~ torch.Size([3, 1, 12]) | epoch 4 | train 9 of 30 | Loss backward | After loop step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 30/30 [00:01<00:00, 19.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] fine_tune_moment_train | -->\n",
      "[5]  [ fine_tune_moment_single ] End timer -->\n",
      "[5]  [ fine_tune_moment_single ] Start: 1737485851.6448867 | End: 1737485853.2263849 | Duration: 1.58 seconds\n",
      "[5]  [ fine_tune_moment_single ] fine_tune_moment_single | Eval Post | wlen 17\n",
      "[5]  [ fine_tune_moment_single ] Start timer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0% 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m                             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc_learn\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_learner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m                        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m                           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_flag\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_windows\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_windows_percent\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#Ventanas a tener en cuenta\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_mask_percent\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_percent\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Entreno con parte de los datos\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_percent\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Evalúo con parte de los datos\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshot\u001b[49m\u001b[43m                          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_pre\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_post\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m                            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#lr_scheduler_flag             = True, #Don't work in mvp\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler_flag\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler_name\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosine_with_restarts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler_num_warmup_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_sizes\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_window_sizes\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_dataset\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_sizes_offset\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindows_min_distance\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_to_path\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_path\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m~/data/logs.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_moment_masks\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_stateful\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask_stateful\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_future\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask_future\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_sync\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask_sync\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43manalysis_mode\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manalysis_mode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_wandb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_by_sample\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnorm_by_sample\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_use_single_batch\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menc_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnorm_use_single_batch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_plot\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# mvp\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#metrics                       = [MSELossFlat, RMSELossFlat, SMAPELossFlat, MAELossFlat],\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# moment/moirai\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m                        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mEvalMSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEvalRMSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEvalMAE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEvalSMAPE\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics_args\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msquared\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msquared\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics_names\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrmse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmae\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msmape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics_dict\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/dvats/encoder.py:3632\u001b[0m, in \u001b[0;36mfine_tune\u001b[0;34m(X, stride, batch_size, n_windows, n_windows_percent, validation_percent, training_percent, window_mask_percent, window_sizes, n_window_sizes, window_sizes_offset, windows_min_distance, full_dataset, enc_input, optim, criterion, optimizer, lr, lr_scheduler_flag, lr_scheduler_name, lr_scheduler_num_warmup_steps, verbose, print_to_path, print_path, print_mode, mssg, enc, num_epochs, enc_learn, cpu, to_numpy, use_moment_masks, mask_stateful, mask_future, mask_sync, time_flag, shot, eval_pre, eval_post, use_wandb, analysis_mode, norm_by_sample, norm_use_single_batch, show_plot, metrics, metrics_names, metrics_args, metrics_dict, scheduler_specific_kwargs)\u001b[0m\n\u001b[1;32m   3627\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfine_tune_moment_\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3628\u001b[0m     enc\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse fine_tune_moment parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3629\u001b[0m     ( \n\u001b[1;32m   3630\u001b[0m         lossess, eval_results_pre, eval_results_post, \n\u001b[1;32m   3631\u001b[0m         t_shots, t_shot, t_evals, t_eval, enc\u001b[38;5;241m.\u001b[39mmodel \n\u001b[0;32m-> 3632\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43menc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tune_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3633\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_post\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_flag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_moment_masks\u001b[49m\n\u001b[1;32m   3634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3635\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfine_tune_mvp_\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3636\u001b[0m     enc\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse fine_tune_mvp parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/work/dvats/encoder.py:2732\u001b[0m, in \u001b[0;36mfine_tune_moment_\u001b[0;34m(self, eval_pre, eval_post, shot, time_flag, use_moment_masks)\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39msize):\n\u001b[1;32m   2729\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing wlen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2730\u001b[0m     ( \n\u001b[1;32m   2731\u001b[0m         losses, eval_results_pre_, eval_results_post_, t_shot_, t_eval_1, t_eval_2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m-> 2732\u001b[0m     ) \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tune_moment_single_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_pre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_post\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_moment_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2733\u001b[0m     lossess\u001b[38;5;241m.\u001b[39mappend(losses)\n\u001b[1;32m   2734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (eval_pre): eval_results_pre \u001b[38;5;241m=\u001b[39m eval_results_pre_\n",
      "File \u001b[0;32m~/work/dvats/encoder.py:2674\u001b[0m, in \u001b[0;36mfine_tune_moment_single_\u001b[0;34m(self, eval_pre, eval_post, shot, sample_id, use_moment_masks)\u001b[0m\n\u001b[1;32m   2672\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfine_tune_moment_single | Eval Post | wlen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_flag: timer\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m-> 2674\u001b[0m eval_results_post \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tune_moment_eval_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2675\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmssg\u001b[38;5;241m.\u001b[39mprint_error(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEval_results_post = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_results_post\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_flag:\n",
      "File \u001b[0;32m~/work/dvats/encoder.py:2349\u001b[0m, in \u001b[0;36mfine_tune_moment_eval_\u001b[0;34m(self, dl_eval)\u001b[0m\n\u001b[1;32m   2347\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dl_eval:\n\u001b[1;32m   2348\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m-> 2349\u001b[0m     mse_metric, rmse_metric, mae_metric, smape_metric \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune_moment_eval_step_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2350\u001b[0m \u001b[43m        \u001b[49m\u001b[43menc_learn\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   2351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   2352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmse_metric\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmse_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   2353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrmse_metric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrmse_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmae_metric\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmae_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2355\u001b[0m \u001b[43m        \u001b[49m\u001b[43msmape_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msmape_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2357\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2358\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/work/dvats/encoder.py:2326\u001b[0m, in \u001b[0;36mfine_tune_moment_eval_step_\u001b[0;34m(enc_learn, batch, mse_metric, rmse_metric, mae_metric, smape_metric, cpu, verbose, print_to_path, print_path, print_mode)\u001b[0m\n\u001b[1;32m   2324\u001b[0m predictions, references \u001b[38;5;241m=\u001b[39m fine_tune_moment_eval_preprocess(predictions \u001b[38;5;241m=\u001b[39m predictions, references \u001b[38;5;241m=\u001b[39m references, verbose \u001b[38;5;241m=\u001b[39m verbose, print_to_path \u001b[38;5;241m=\u001b[39m print_to_path, print_path \u001b[38;5;241m=\u001b[39m print_path, print_mode \u001b[38;5;241m=\u001b[39m print_mode)\n\u001b[1;32m   2325\u001b[0m mse_metric\u001b[38;5;241m.\u001b[39madd_batch(predictions\u001b[38;5;241m=\u001b[39mpredictions, references \u001b[38;5;241m=\u001b[39m references)\n\u001b[0;32m-> 2326\u001b[0m \u001b[43mrmse_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2327\u001b[0m mae_metric\u001b[38;5;241m.\u001b[39madd_batch(predictions\u001b[38;5;241m=\u001b[39mpredictions, references \u001b[38;5;241m=\u001b[39m references)\n\u001b[1;32m   2328\u001b[0m smape_metric\u001b[38;5;241m.\u001b[39madd_batch(predictions\u001b[38;5;241m=\u001b[39mpredictions, references \u001b[38;5;241m=\u001b[39m references)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/evaluate/module.py:510\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_feature_from_batch(batch)\n\u001b[0;32m--> 510\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/evaluate/module.py:644\u001b[0m, in \u001b[0;36mEvaluationModule._init_writer\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;66;03m# Get cache file name and lock it\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilelock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     cache_file_name, filelock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_cache_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# get ready\u001b[39;00m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m cache_file_name\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilelock \u001b[38;5;241m=\u001b[39m filelock\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/evaluate/module.py:279\u001b[0m, in \u001b[0;36mEvaluationModule._create_cache_file\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m filelock \u001b[38;5;241m=\u001b[39m FileLock(file_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.lock\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[43mfilelock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Timeout:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# If we have reached the max number of attempts or we are not allow to find a free name (distributed setup)\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# We raise an error\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_process \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/filelock/_api.py:267\u001b[0m, in \u001b[0;36mBaseFileLock.acquire\u001b[0;34m(self, timeout, poll_interval, poll_intervall, blocking)\u001b[0m\n\u001b[1;32m    265\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLock \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not acquired on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, waiting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds ...\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m         _LOGGER\u001b[38;5;241m.\u001b[39mdebug(msg, lock_id, lock_filename, poll_interval)\n\u001b[0;32m--> 267\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# Something did go wrong, so decrement the counter.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mlock_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mlock_counter \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = fine_tune(\n",
    "    X                             = df,\n",
    "    enc_learn                     = enc_learner, \n",
    "    stride                        = 1,      \n",
    "    batch_size                    = enc_run.config['batch_size'],\n",
    "    cpu                           = config['cpu'], \n",
    "    to_numpy                      = False, \n",
    "    verbose                       = 5, \n",
    "    time_flag                     = True,\n",
    "    n_windows                     = None,\n",
    "    n_windows_percent             = 0.8, #Ventanas a tener en cuenta\n",
    "    window_mask_percent           = enc_run.config['r'],\n",
    "    training_percent              = 0.3, # Entreno con parte de los datos\n",
    "    validation_percent            = 0.3, # Evalúo con parte de los datos\n",
    "    num_epochs                    = 5,\n",
    "    shot                          = True,\n",
    "    eval_pre                      = True,\n",
    "    eval_post                     = True,\n",
    "    lr                            = enc_run.config['r'],\n",
    "    #lr_scheduler_flag             = True, #Don't work in mvp\n",
    "    lr_scheduler_flag             = False,\n",
    "    lr_scheduler_name             = \"cosine_with_restarts\",\n",
    "    lr_scheduler_num_warmup_steps = None,\n",
    "    window_sizes                  = None,\n",
    "    n_window_sizes                = 3,\n",
    "    full_dataset                  = True,\n",
    "    window_sizes_offset           = 0.05,\n",
    "    windows_min_distance          = 5,\n",
    "    print_to_path                 = False,\n",
    "    print_path                    =\"~/data/logs.txt\",\n",
    "    print_mode                    = 'w',\n",
    "    use_moment_masks              = False,\n",
    "    mask_stateful                 = enc_run.config['mask_stateful'],\n",
    "    mask_future                   = enc_run.config['mask_future'],\n",
    "    mask_sync                     = enc_run.config['mask_sync'],\n",
    "    analysis_mode                 = enc_run.config['analysis_mode'],\n",
    "    use_wandb                     = enc_run.config['use_wandb'],\n",
    "    norm_by_sample                = enc_run.config['norm_by_sample'],\n",
    "    norm_use_single_batch         = enc_run.config['norm_use_single_batch'],\n",
    "    show_plot                     = True,\n",
    "    # mvp\n",
    "    #metrics                       = [MSELossFlat, RMSELossFlat, SMAPELossFlat, MAELossFlat],\n",
    "    # moment/moirai\n",
    "    metrics                        = [EvalMSE, EvalRMSE, EvalMAE, EvalSMAPE],\n",
    "    metrics_args                   = [{'squared': False}, {'squared': True}, {}, {}],\n",
    "    metrics_names                  = [\"mse\", \"rmse\", \"mae\", \"smape\"],\n",
    "    metrics_dict                   = None\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "103ec925-fb4b-435d-b073-bdef87186721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval results pre:\n",
      "mse: 0.342390470661696\n",
      "rmse: 0.11897325238673793\n",
      "mae: 0.2432825950376105\n",
      "smape: 1.3955356942919357\n",
      "Eval results post:\n",
      "{'mse': [0.342390470661696, 0.3477775791921818, 0.34331038331280894], 'rmse': [0.11897325238673793, 0.12260583294967765, 0.11964095461884483], 'mae': [0.2432825950376105, 0.25138872509865956, 0.24329452144696267], 'smape': [1.3955356942919357, 1.5183167191689604, 1.3991945740022687]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( \n",
    "    losses, \n",
    "    eval_results_pre, eval_results_post, \n",
    "    t_shots, t_shot, \n",
    "    t_evals, t_eval, model\n",
    ") = result\n",
    "print(\"Eval results pre:\")\n",
    "show_attrdict(eval_results_pre)\n",
    "print(\"Eval results post:\")\n",
    "print(eval_results_post)\n",
    "len(eval_results_post)\n",
    "#show_attrdict(eval_results_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99befe23-ffaf-4d45-a384-1f4c10dda855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \u001b[91m [ _check_value ] Invalid type for 'model' (tuple). Expected one of: MOMENTPipeline, Learner, MoiraiModule. Using default: None\u001b[0m\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "[1] [_check_value --> ]\n",
      "{'mse': 0.342390470661696, 'rmse': 0.11897325238673793, 'mae': 0.2432825950376105, 'smape': 1.3955356942919357}\n",
      "{'mse': [0.342390470661696, 0.3477775791921818, 0.34331038331280894], 'rmse': [0.11897325238673793, 0.12260583294967765, 0.11964095461884483], 'mae': [0.2432825950376105, 0.25138872509865956, 0.24329452144696267], 'smape': [1.3955356942919357, 1.5183167191689604, 1.3991945740022687]}\n",
      "[1] [ --> plot_eval_stats ]\n",
      "[1] \u001b[91m [ plot_eval_stats ] epochs~4: [0, 1, 2, 3]\u001b[0m\n",
      "[1] \u001b[91m [ plot_eval_stats ] mse.values~4: [0.342390470661696, 0.342390470661696, 0.3477775791921818, 0.34331038331280894]\u001b[0m\n",
      "[1] \u001b[91m [ plot_eval_stats ] rmse.values~4: [0.11897325238673793, 0.11897325238673793, 0.12260583294967765, 0.11964095461884483]\u001b[0m\n",
      "[1] \u001b[91m [ plot_eval_stats ] mae.values~4: [0.2432825950376105, 0.2432825950376105, 0.25138872509865956, 0.24329452144696267]\u001b[0m\n",
      "[1] \u001b[91m [ plot_eval_stats ] smape.values~4: [1.3955356942919357, 1.3955356942919357, 1.5183167191689604, 1.3991945740022687]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [plot_eval_stats --> ]\n"
     ]
    }
   ],
   "source": [
    "# Cambiar en el momento que todo se haga con clases\n",
    "enc = Encoder(mssg = Mssg(level = -1, verbose = 1))\n",
    "enc.eval_stats_pre = eval_results_pre\n",
    "enc.eval_stats_post = eval_results_post\n",
    "enc.num_epochs = 5\n",
    "print(enc.eval_stats_pre)\n",
    "print(enc.eval_stats_post)\n",
    "plot_eval_stats(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08bfd363-3c5d-4f4d-a7e7-cb65c8bd9f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] --> get_enc_embs_set_stride_set_batch_size\n",
      "[1] get_enc_embs_set_stride_set_batch_size | Moment | True\n",
      "[1] get_acts_moment | Trial 1 | x_enc ~ torch.Size([424, 1, 17])\n",
      "[1] get_acts_moment | Trial 1 | About to pad X (encoder input) | exception The size of tensor a (16) must match the size of tensor b (17) at non-singleton dimension 1 | padd step: 10\n",
      "[1] get_acts_moment | Trial 1 | y ~ torch.Size([424, 1, 17])\n",
      "[1] ------------------- Trial 1 | Padd -----------------\n",
      "[1] get_acts_moment | Trial 2 | x_enc ~ torch.Size([424, 1, 27])\n",
      "[1] get_acts_moment | Trial 2 | About to pad X (encoder input) | exception The size of tensor a (24) must match the size of tensor b (27) at non-singleton dimension 1 | padd step: 10\n",
      "[1] get_acts_moment | Trial 2 | y ~ torch.Size([424, 1, 27])\n",
      "[1] ------------------- Trial 2  -----------------\n",
      "[1] ------------------- Trial 2 | a > a_old -----------------\n",
      "[1] ------------------- Trial 2 |a > a_old | Reduced |  y ~ torch.Size([424, 1, 24]) -----------------\n",
      "[1] get_acts_moment | Trial 3 | x_enc ~ torch.Size([424, 1, 24])\n",
      "[1] get_acts_moment | Trial 3 | embs ~ torch.Size([424, 1, 3, 512])\n",
      "[1] get_enc_embs_set_stride_set_batch_size | Before moving to CPU | embs~(424, 512)\n",
      "[1] get_enc_embs_set_stride_set_batch_size | embs~(424, 512) -->\n"
     ]
    }
   ],
   "source": [
    "embs = get_enc_embs_set_stride_set_batch_size(\n",
    "    X          = enc_input, \n",
    "    enc_learn  = enc_learner, \n",
    "    stride     = enc_run.config['stride'],\n",
    "    **get_embs_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a92080d9-0851-43ec-be9d-ce5897e415c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424, 512)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74290c89-62d6-4a4a-ba5c-045cab824d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc_learner.task_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7bd215c-a9f4-47bb-ba2e-4892117b73c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.28752589225769"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.end()\n",
    "timer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad5a24fb-4416-4345-a1c8-131bed978e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"Execution ended\")\n",
    "from dvats.imports import beep\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)\n",
    "beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3dca0597-64fb-4bc5-946f-2ae110b3cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if reset_kernel:\n",
    "    import os\n",
    "    os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
