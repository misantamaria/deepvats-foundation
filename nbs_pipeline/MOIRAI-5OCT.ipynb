{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e6da0b-c516-4b80-a8f6-40ad7f502ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "verbose                       = 1\n",
    "check_memory_usage            = True\n",
    "time_flag                     = True\n",
    "window_size_percentage        = True\n",
    "show_plots                    = True\n",
    "reset_kernel                  = False\n",
    "pre_configured_case           = True\n",
    "case_id                       = 7\n",
    "frequency_factor              = 1\n",
    "frequency_factor_change_alias = True\n",
    "check_parameters              = True\n",
    "cuda_device                   = 0\n",
    "remove_lambdas_flag           = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe0f92c-7e77-4ba3-87f1-8b05e7f5cb09",
   "metadata": {},
   "source": [
    "MOIRAI: Toy complete execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019ba616-f2e0-48dc-a2c7-8dc4074f8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "import sys\n",
    "import dvats.utils as ut\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import uni2ts\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.eval_util.plot import plot_next_multi\n",
    "import pyarrow.feather as ft\n",
    "from gluonts.transform.split import TFTInstanceSplitter\n",
    "from gluonts.transform.sampler import TestSplitSampler\n",
    "import numpy as np\n",
    "import einops\n",
    "import torch.nn.functional as F\n",
    "from dvats.memory import gpu_memory_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16086970-ff73-48bb-9635-9ac7d6bd05e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU | Used mem: 14\n",
      "GPU | Used mem: 24\n",
      "GPU | Memory Usage: [\u001b[92m███████████---------\u001b[0m] \u001b[92m58%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "device = torch.device(f'cuda:{cuda_device}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "if check_memory_usage:\n",
    "    gpu_device = torch.cuda.current_device()\n",
    "    gpu_memory_status(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61f01f2e-bc85-4f14-89ec-c7ed11dd2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dvats.config as cfg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d4aaca-ff78-4184-a725-e3957b57453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: \n",
      "0 - monash_australian_electricity_demand_0\n",
      "1 - monash_solar_4_seconds_0\n",
      "2 - wikipedia_0\n",
      "3 - traffic_san_francisco_0\n",
      "4 - monash_solar_10_minutes_0\n",
      "5 - etth1_0\n",
      "6 - stumpy_abp_0\n",
      "7 - stumpy_toy_0\n"
     ]
    }
   ],
   "source": [
    "cfg_.show_available_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3385948e-ece8-495b-bd4e-4cb69ebe9d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcWriteOptions size changed, may indicate binary incompatibility. Expected 72 from C header, got 88 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.IpcReadOptions size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.Tensor size changed, may indicate binary incompatibility. Expected 64 from C header, got 80 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.NativeFile size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.BufferedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedInputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: pyarrow.lib.CompressedOutputStream size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2004l\n",
      "Octave is ready <oct2py.core.Oct2Py object at 0x7f3805f38610>\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n",
      "\u001b[?2004l\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"umap\")\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from dvats.all import *\n",
    "from fastcore.all import *\n",
    "from tsai.basics import *\n",
    "from tsai.models.InceptionTimePlus import *\n",
    "from tsai.callback.MVP import *\n",
    "import matplotlib.colors as colors\n",
    "from fastai.callback.wandb import WandbCallback\n",
    "from fastai.callback.progress import ShowGraphCallback\n",
    "from fastai.callback.schedule import *\n",
    "from fastai.callback.tracker import EarlyStoppingCallback\n",
    "import wandb\n",
    "from momentfm import MOMENTPipeline\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from uni2ts.eval_util.plot import plot_single\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.eval_util.plot import plot_next_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a14c009b-3b06-4f36-bc46-d641ee31cd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r: 0.71\u001b[0m\n",
      "use_wandb: True\u001b[0m\n",
      "\u001b[93m\u001b[1mnorm_use_by_single_batch is missing in original dict | (False,) \u001b[0m\n",
      "norm_use_single_batch: False\u001b[0m\n",
      "wandb_group: None\u001b[0m\n",
      "batch_size: 512\u001b[0m\n",
      "valid_artifact: None\u001b[0m\n",
      "epochs: 100\u001b[0m\n",
      "\u001b[94mmvp_ws: (15, 100)\u001b[0m -> [1, 2160]\u001b[0m\n",
      "mask_sync: False\u001b[0m\n",
      "\u001b[94mstride: 900\u001b[0m -> 144\u001b[0m\n",
      "mask_future: False\u001b[0m\n",
      "\u001b[93m\u001b[1mdata_cols is missing in original dict | [0] \u001b[0m\n",
      "valid_size: 0.2\u001b[0m\n",
      "mask_stateful: True\u001b[0m\n",
      "norm_by_sample: False\u001b[0m\n",
      "\u001b[93m\u001b[1mtime_col is missing in original dict | None \u001b[0m\n",
      "\u001b[93m\u001b[1mdata_fpath is missing in original dict | ~/data/solar_10_minutes_dataset.tsf \u001b[0m\n",
      "\u001b[93m\u001b[1martifact_name is missing in original dict | Monash-Solar_10_minutes \u001b[0m\n",
      "\u001b[93m\u001b[1mcsv_config is missing in original dict | {} \u001b[0m\n",
      "\u001b[93m\u001b[1mfreq is missing in original dict | 10min \u001b[0m\n",
      "analysis_mode: online\u001b[0m\n",
      "\u001b[94mtrain_artifact: mi-santamaria/deepvats/PulsusParadoxus-SP02:latest\u001b[0m -> mi-santamaria/deepvats/Monash-Solar_10_minutes:latest\u001b[0m\n",
      "\u001b[94malias: PulsusParadoxus-SP02\u001b[0m -> Monash-Solar_10_minutes\u001b[0m\n",
      "\u001b[94mw: 100\u001b[0m -> 2160\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "user, project, version, data, config, job_type = cfg_.get_artifact_config_MVP(False)\n",
    "if pre_configured_case: \n",
    "    cfg_.force_artifact_config_mvp(\n",
    "        config = config,\n",
    "        id = case_id,\n",
    "        verbose = verbose, \n",
    "        both = verbose > 0,\n",
    "        frequency_factor = frequency_factor,\n",
    "        frequency_factor_change_alias = frequency_factor_change_alias\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8267b5ad-4e24-4cdf-af50-1b58c284ae6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runname: 02c_encoder_moment-embedding\n",
      "alias: Monash-Solar_10_minutes\n",
      "analysis_mode: online\n",
      "batch_size: 512\n",
      "epochs: 100\n",
      "mask_future: False\n",
      "mask_stateful: True\n",
      "mask_sync: False\n",
      "mvp_ws: [1, 2160]\n",
      "norm_by_sample: False\n",
      "norm_use_single_batch: False\n",
      "r: 0.71\n",
      "stride: 144\n",
      "train_artifact: mi-santamaria/deepvats/Monash-Solar_10_minutes:latest\n",
      "valid_artifact: None\n",
      "use_wandb: True\n",
      "valid_size: 0.2\n",
      "w: 2160\n",
      "wandb_group: None\n",
      "artifact_name: Monash-Solar_10_minutes\n",
      "data_cols: [0]\n",
      "data_fpath: ~/data/solar_10_minutes_dataset.tsf\n",
      "freq: 10min\n",
      "time_col: None\n",
      "csv_config: {}\n",
      "norm_use_by_single_batch: (False,)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"02c_encoder_moment-embedding\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\"\n",
    "runname=name\n",
    "if verbose > 0: print(\"runname: \"+runname)\n",
    "if verbose > 0: cfg_.show_attrdict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9677a75b-aed4-41e9-ac0e-01ac7e481b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Wandb init\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find /home/macu/work/nbs_pipeline/02c_encoder_moment-embedding.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmi-santamaria\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20241007_132655-dh61nl79</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/dh61nl79' target=\"_blank\">02c_encoder_moment-embedding</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/dh61nl79' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/dh61nl79</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wandb init -->\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"--> Wandb init\")\n",
    "run = wandb.init(\n",
    "    entity = user,\n",
    "    # work-nbs is a place to log draft runs\n",
    "    project=project,\n",
    "    group=config.wandb_group,\n",
    "    job_type=job_type,\n",
    "    allow_val_change=True,\n",
    "    mode=config.analysis_mode,\n",
    "    config=config,\n",
    "    # When use_wandb is false the run is not linked to a personal account\n",
    "    #NOTE: This is not working right now\n",
    "    anonymous = 'never' if config.use_wandb else 'must', \n",
    "    resume=False,\n",
    "    name = runname\n",
    ")\n",
    "if verbose > 0: print(\"Wandb init -->\")\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa4817bb-194d-4d37-a300-9d66e2ceea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alias: Monash-Solar_10_minutes\n",
      "analysis_mode: online\n",
      "batch_size: 512\n",
      "epochs: 100\n",
      "mask_future: False\n",
      "mask_stateful: True\n",
      "mask_sync: False\n",
      "mvp_ws: [1, 2160]\n",
      "norm_by_sample: False\n",
      "norm_use_single_batch: False\n",
      "r: 0.71\n",
      "stride: 144\n",
      "train_artifact: mi-santamaria/deepvats/Monash-Solar_10_minutes:latest\n",
      "valid_artifact: None\n",
      "use_wandb: True\n",
      "valid_size: 0.2\n",
      "w: 2160\n",
      "wandb_group: None\n",
      "artifact_name: Monash-Solar_10_minutes\n",
      "data_cols: [0]\n",
      "data_fpath: ~/data/solar_10_minutes_dataset.tsf\n",
      "freq: 10min\n",
      "time_col: None\n",
      "csv_config: {}\n",
      "norm_use_by_single_batch: [False]\n",
      "---> W&B Train Artifact\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "config = run.config  # Object for storing hyperparameters\n",
    "if verbose > 0: cfg_.show_attrdict(config)\n",
    "artifacts_gettr = run.use_artifact if config.use_wandb else wandb_api.artifact\n",
    "train_artifact = artifacts_gettr(config.train_artifact)\n",
    "if verbose > 0: print(\"---> W&B Train Artifact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8860c59-3096-4865-8765-172a8756cd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(52560, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| export\n",
    "import pyarrow.feather as ft\n",
    "df_train = train_artifact.to_df()\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473361e5-17b3-4eea-9edc-b9fb3b9f8608",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "#display(df_train.head())\n",
    "display(df_train[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40a5ad68-8ee4-4a26-b1a0-ade114d01385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Sliding window |  2160  |  144\n",
      " Sliding window |  2160  |  144 ---> | df_train ~  (52560, 1)\n",
      " sw_df_train |  2160  |  144 --->\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "if verbose > 0: print(\"---> Sliding window | \", config.w,  \" | \", config.stride )\n",
    "sw = SlidingWindow(window_len=config.w, stride=config.stride, get_y=[])\n",
    "if verbose > 0: print(\" Sliding window | \", config.w,  \" | \", config.stride, \"---> | df_train ~ \", df_train.shape )\n",
    "X_train, _ = sw(df_train)\n",
    "if verbose > 0: print(\" sw_df_train | \", config.w,  \" | \", config.stride, \"--->\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d023745e-1e68-4947-8696-f91287e104e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 1, 2160)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_win x n_vars x win_size\n",
    "# n_batches x n_features x patch_size (before padding)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c3eb054-85f5-49c3-af71-0c4db5e9b6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X):  351\n",
      "--> Split 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZcAAABmCAYAAAC3Bq+HAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAboElEQVR4nO3de1SVVf7H8c9BDzcFTEXgiIDYRU2kQcvoMpHXdLyUk5OVMzit1DI0HJ3SrAEL08HxWlFrphrsNl4mtUlnKkpBG7qYQSgZYwVoI2TaT8ULF2H//mg4dQSVo3IOR9+vtZ61ztnPfp79fU7f9rKvu/1YjDFGAAAAAAAAAAA4wcvdAQAAAAAAAAAAPA/FZQAAAAAAAACA0yguAwAAAAAAAACcRnEZAAAAAAAAAOA0issAAAAAAAAAAKdRXAYAAAAAAAAAOI3iMgAAAAAAAADAaRSXAQAAAAAAAABOo7gMAAAAAAAAAHAaxWUAAID/+eijj3TbbbcpIiJCPj4+CgkJUXx8vKZPn35W9yspKZHFYlFmZqa9LTMzUxaLRSUlJfa21157TUuWLDm34CVFRUVp/Pjx9u/Z2dmyWCzKzs526j4ZGRkOMTdFY2ONHz9ebdu2deo+Z5Kbm6vU1FQdPHiwwbmEhAQlJCSc1/EAAAAAnBrFZQAAAEkbNmzQddddp8OHDys9PV3vvPOOli5dquuvv14rV648b+P84he/0AcffKCwsDB72/kqLp8sLi5OH3zwgeLi4py67myKy2c7lrNyc3M1Z86cRovLGRkZysjIaNbxAQAAAPyotbsDAAAAaAnS09PVtWtXvf3222rd+sc/Io0dO1bp6ennbZzg4GAFBweft/udTmBgoK699tpmHaOmpkYWi8UlY51Jz5493To+AAAAcLFh5TIAAICkAwcOqGPHjg6F5XpeXo5/ZIqKitLw4cO1du1a9e7dW76+voqOjtayZcvOOM7J22IkJCRow4YNKi0tlcVisR+nU1NTo4ceekihoaHy9/fXDTfcoI8//rhBv8a2qvj66681duxY2Ww2+9YfAwYMUH5+vv3ZCgsLlZOTY48lKirK4X4vv/yypk+frs6dO8vHx0dffvnlabfgKCws1IABA9SmTRsFBwcrKSlJx44ds59vbPuQehaLRampqZKk1NRU/f73v5ckde3a1R5f/ZiNbYvx/fffa/LkyercubO8vb0VHR2t2bNnq6qqqsE4SUlJevnll9WjRw/5+/srNjZW69evP/U/CAAAAOAix8plAAAASfHx8Xr++ec1depU3X333YqLi5PVaj1l//z8fCUnJys1NVWhoaF69dVX9eCDD6q6ulozZsxo8rgZGRmaOHGivvrqK61du7ZJ10yYMEEvvfSSZsyYoUGDBmnHjh0aPXq0KioqznjtsGHDVFtbq/T0dEVERGj//v3Kzc21bzOxdu1a3X777QoKCrJvMeHj4+Nwj1mzZik+Pl7PPfecvLy81KlTJ5WXlzc6Xk1NjYYNG6ZJkyZp5syZys3NVVpamkpLS/Xmm2826Xnr3Xvvvfr+++/11FNPac2aNfatRU61YrmyslI333yzvvrqK82ZM0e9e/fWli1bNG/ePOXn52vDhg0O/Tds2KCtW7fq8ccfV9u2bZWenq7bbrtNRUVFio6OdipWAAAA4GJAcRkAAEDS/Pnz9cUXX+ipp57SU089JavVqquvvlojRoxQUlJSgxfT7d27V3l5eYqNjZUkDR06VPv27dMTTzyhyZMny9/fv0nj9uzZU+3atZOPj0+TtpX44osvtHz5ck2bNs2+XcegQYMUEhKiu++++7TXHjhwQEVFRVqyZInGjRtnbx89erT9889+9jP5+fmddpuLbt26afXq1U15PFVXV2v69OmaOnWqPVar1arZs2fr3//+t66//vom3UeSwsPDFRERYY+zfkX1qSxfvlwFBQVatWqVxowZYx+/bdu2evjhh5WVlaVBgwbZ+x8/flzvvvuuAgICJP2wj7TNZtOqVas0c+bMJscJAAAAXCzYFgMAAEBShw4dtGXLFm3dulXz58/XqFGj9J///EezZs1STEyM9u/f79D/yiuvtBeW69111106fPiwPv3002aLc9OmTZLUoJD8q1/9qtEtPX6qffv26tatmxYsWKBFixYpLy9PdXV1Tsfwy1/+0qn+J8d61113SfrxWZrLxo0b1aZNG91+++0O7ePHj5ckvffeew7tN998s72wLEkhISHq1KmTSktLmzVOAAAAwFNRXAYAAPiJvn376uGHH9bq1au1d+9eTZs2TSUlJQ1e6hcaGtrg2vq2AwcONFt89fc+efzWrVurQ4cOp73WYrHovffe05AhQ5Senq64uDgFBwdr6tSpTdpSo179dhRN0Vhcrvid6u8fGhraYA/rTp06qXXr1g3Gb+z38/Hx0fHjx5s1TgAAAMBTUVwGAAA4BavVqpSUFEnSjh07HM41tsdwfduZirznov7eJ49/4sSJJhVrIyMj9cILL6i8vFxFRUWaNm2aMjIy7C/Ka4ozvXDwTHGd/Dv5+vpKUoOX7J1r8blDhw769ttvZYxxaN+3b59OnDihjh07ntP9AQAAgIsdxWUAAABJZWVljbbv3LlTkmSz2RzaCwsL9dlnnzm0vfbaawoICFBcXJxTYzuzOjYhIUGS9Oqrrzq0r1q1SidOnHBq3Msvv1yPPvqoYmJiHLbyON+rdU+O9bXXXpP047OEhITI19dXBQUFDv3eeOONBveqf7lgU+IbMGCAjhw5onXr1jm0v/TSS/bzAAAAAM4eL/QDAACQNGTIEIWHh2vEiBHq3r276urqlJ+fr4ULF6pt27Z68MEHHfrbbDaNHDlSqampCgsL0yuvvKKsrCz98Y9/bPLL/OrFxMRozZo1evbZZ9WnTx95eXmpb9++jfbt0aOHxo0bpyVLlshqtWrgwIHasWOH/vSnPykwMPC04xQUFCgpKUljxozRZZddJm9vb23cuFEFBQUOL6yLiYnRihUrtHLlSkVHR8vX11cxMTFOPVM9b29vLVy4UEeOHNHVV1+t3NxcpaWlaejQobrhhhsk/bASety4cXrxxRfVrVs3xcbG6uOPP7YXoU/+rSRp6dKlSkxMlNVq1RVXXOGwV3K93/zmN3rmmWeUmJiokpISxcTE6P3339eTTz6pYcOGaeDAgWf1TAAAAAB+QHEZAABA0qOPPqo33nhDixcvVllZmaqqqhQWFqaBAwdq1qxZ6tGjh0P/q666Sr/97W+VkpKiXbt2yWazadGiRZo2bZrTYz/44IMqLCzUI488okOHDskY02Arh5964YUXFBISoszMTC1btkxXXXWVXn/9dY0dO/a044SGhqpbt27KyMjQnj17ZLFYFB0drYULF2rKlCn2fnPmzFFZWZkmTJigiooKRUZGqqSkxOnnkn7YWmT9+vWaOnWq0tLS5OfnpwkTJmjBggUO/RYuXChJSk9P15EjR9S/f3+tX79eUVFRDv0SEhI0a9YsLV++XH/5y19UV1enTZs22VdB/5Svr682bdqk2bNna8GCBfruu+/UuXNnzZgxw77dCQAAAICzZzGn+y8XAAAANBAVFaVevXpp/fr17g4FAAAAANyGPZcBAAAAAAAAAE6juAwAAAAAAAAAcBrbYgAAAAAAAAAAnMbKZQAAAAAAAACA0yguAwAAAAAAAACcRnEZAAAAAAAAAOC01q4esK6uTnv37lVAQIAsFourhwcAAAAAAAA8mjFGFRUVstls8vJi7Sjcx+XF5b1796pLly6uHhYAAAAAAAC4oOzZs0fh4eHuDgMXMZcXlwMCAv73aY+kQFcPDwAAAADARSM25+fuDgFAM6g9Wqsdw3b8pM4GuIfLi8s/boURKIrLAAAAAAA0n1ZtW7k7BADNiC1n4W5sygIAAAAAAAAAcBrFZQAAAAAAAACA0yguAwAAAAAAAACc5vI9lwEAAAAAAACgOdTW1qqmpsbdYXisVq1aqXXr1k3ez5viMgAAAAAAAACPd+TIEX3zzTcyxrg7FI/m7++vsLAweXt7n7EvxWUAAAAAAAAAHq22tlbffPON/P39FRwc3OSVt/iRMUbV1dX67rvvVFxcrMsuu0xeXqffVZniMgAAAAAAAACPVlNTI2OMgoOD5efn5+5wPJafn5+sVqtKS0tVXV0tX1/f0/bnhX4AAAAAAAAALgisWD53Z1qt7NC3GeMAAAAAAAAAAFygKC4DAAAAAAAAAJxGcRkAAAAAAAAALhAJCQlKTk52yVi80A8AAAAAAADABcnVWzAb0/S+Z9ofOjExUZmZmU7HsGbNGlmtVqevOxtOr1zevHmzRowYIZvNJovFonXr1jVDWAAAAAAAAABw4SorK7MfS5YsUWBgoEPb0qVLHfrX1NQ06b7t27dXQEBAc4TcgNPF5aNHjyo2NlZPP/10c8QDAAAAAAAAABe80NBQ+xEUFCSLxWL/XllZqXbt2mnVqlVKSEiQr6+vXnnlFR04cEB33nmnwsPD5e/vr5iYGP3tb39zuO/J22JERUXpySef1D333KOAgABFREToz3/+83l5BqeLy0OHDlVaWppGjx59XgIAAAAAAAAAADT08MMPa+rUqdq5c6eGDBmiyspK9enTR+vXr9eOHTs0ceJE/frXv9ZHH3102vssXLhQffv2VV5eniZPnqz7779fX3zxxTnH1+x7LldVVamqqsr+/fDhw809JAAAAAAAAAB4vOTk5AaLfGfMmGH/PGXKFL311ltavXq1+vXrd8r7DBs2TJMnT5b0Q8F68eLFys7OVvfu3c8pPqdXLjtr3rx5CgoKsh9dunRp7iEBAAAAAAAAwOP17dvX4Xttba3mzp2r3r17q0OHDmrbtq3eeecd7d69+7T36d27t/1z/fYb+/btO+f4mr24PGvWLB06dMh+7Nmzp7mHBAAAAAAAAACP16ZNG4fvCxcu1OLFi/XQQw9p48aNys/P15AhQ1RdXX3a+1itVofvFotFdXV15xxfs2+L4ePjIx8fn+YeBgAAAAAAAAAuaFu2bNGoUaM0btw4SVJdXZ127dqlHj16uCWeZl+5DAAAAAAAAAA4d5deeqmysrKUm5urnTt3atKkSSovL3dbPE6vXD5y5Ii+/PJL+/fi4mLl5+erffv2ioiIOK/BAQAAAAAAAMDZMsbdEZxfjz32mIqLizVkyBD5+/tr4sSJuvXWW3Xo0CG3xGMxxrmfODs7WzfffHOD9sTERGVmZp7x+sOHDysoKEjSIUmBzgwNAAAAAACcELetj7tDANAMao/U6rObPtOhQ4cUGEh9TZIqKytVXFysrl27ytfX193heDRnfkunVy4nJCTIyXo0AAAAAAAAAOACw57LAAAAAAAAAACnUVwGAAAAAAAAADiN4jIAAAAAAAAAwGkUlwEAAAAAAAAATqO4DAAAAAAAAABwGsVlAAAAAAAAAIDTKC4DAAAAAAAAAJxGcRkAAAAAAAAA4DSKywAAAAAAAAAAp7V2dwAAAAAAAAAA0Bz6fNrHpeNti9vW5L4Wi+W05xMTE5WZmXlWcURFRSk5OVnJyclndX1TUVwGAAAAAAAAABcrKyuzf165cqX+8Ic/qKioyN7m5+fnjrCc4vLisjHmf58Ou3poAAAAAAAuKrVHat0dAoBmUHv0h3+3f6yzwROFhobaPwcFBclisTi0vfnmm0pNTVVhYaFsNpsSExM1e/ZstW79Q0k3NTVVL774or799lt16NBBt99+u5YtW6aEhASVlpZq2rRpmjZtmqTmyxWXF5cPHDjwv09dXD00AAAAAAAXlc9ucncEAJpTRUWFgoKC3B0GmsHbb7+tcePGadmyZbrxxhv11VdfaeLEiZKklJQU/f3vf9fixYu1YsUKXXnllSovL9dnn30mSVqzZo1iY2M1ceJETZgwoVnjdHlxuX379pKk3bt3k/zwOIcPH1aXLl20Z88eBQYGujscwGnkMDwdOQxPRv7C05HD8GTkLzzdyTlsjFFFRYVsNpu7Q0MzmTt3rmbOnKnExERJUnR0tJ544gk99NBDSklJ0e7duxUaGqqBAwfKarUqIiJC11xzjaQf6q+tWrVSQECAw0ro5uDy4rKXl5ekH5Z6M6HDUwUGBpK/8GjkMDwdOQxPRv7C05HD8GTkLzzdT3OYRZsXtm3btmnr1q2aO3euva22tlaVlZU6duyYxowZoyVLlig6Olq33HKLhg0bphEjRti3zHAVXugHAAAAAAAAAC1IXV2d5syZo9GjRzc45+vrqy5duqioqEhZWVl69913NXnyZC1YsEA5OTmyWq0ui5PiMgAAAAAAAAC0IHFxcSoqKtKll156yj5+fn4aOXKkRo4cqQceeEDdu3fX9u3bFRcXJ29vb9XWNv9LXV1eXPbx8VFKSop8fHxcPTRwzshfeDpyGJ6OHIYnI3/h6chheDLyF56OHL74/OEPf9Dw4cPVpUsXjRkzRl5eXiooKND27duVlpamzMxM1dbWql+/fvL399fLL78sPz8/RUZGSpKioqK0efNmjR07Vj4+PurYsWOzxGkxxphmuTMAAAAAAAAAuEBlZaWKi4vVtWtX+fr6ujscp2VmZio5OVkHDx60t7399tt6/PHHlZeXJ6vVqu7du+vee+/VhAkTtG7dOs2fP187d+5UbW2tYmJilJaWpgEDBkiSPvzwQ02aNElFRUWqqqqSMyVgZ35LissAAAAAAAAAPJqnF5dbEmd+Sy8XxQQAAAAAAAAAuIBQXAYAAAAAAAAAOI3iMgAAAAAAAADAaRSXAQAAAAAAAABOc2lxOSMjw74RdJ8+fbRlyxZXDg80SWpqqiwWi8MRGhpqP2+MUWpqqmw2m/z8/JSQkKDCwkI3RoyL3ebNmzVixAjZbDZZLBatW7fO4XxTcraqqkpTpkxRx44d1aZNG40cOVLffPONC58CF7Mz5fD48eMbzMvXXnutQx9yGO4yb948XX311QoICFCnTp106623qqioyKEP8zBaqqbkL3MwWrJnn31WvXv3VmBgoAIDAxUfH69//etf9vPMv2jpzpTDzMFnxxjj7hA8njO/ocuKyytXrlRycrJmz56tvLw83XjjjRo6dKh2797tqhCAJrvyyitVVlZmP7Zv324/l56erkWLFunpp5/W1q1bFRoaqkGDBqmiosKNEeNidvToUcXGxurpp59u9HxTcjY5OVlr167VihUr9P777+vIkSMaPny4amtrXfUYuIidKYcl6ZZbbnGYl//5z386nCeH4S45OTl64IEH9OGHHyorK0snTpzQ4MGDdfToUXsf5mG0VE3JX4k5GC1XeHi45s+fr08++USffPKJ+vfvr1GjRtkLyMy/aOnOlMMSc7AzWrVqJUmqrq52cySe79ixY5Ikq9V65s7GRa655hpz3333ObR1797dzJw501UhAE2SkpJiYmNjGz1XV1dnQkNDzfz58+1tlZWVJigoyDz33HMuihA4NUlm7dq19u9NydmDBw8aq9VqVqxYYe/z3//+13h5eZm33nrLZbEDxjTMYWOMSUxMNKNGjTrlNeQwWpJ9+/YZSSYnJ8cYwzwMz3Jy/hrDHAzPc8kll5jnn3+e+Rceqz6HjWEOdlZdXZ0pKSkxu3btMkePHjXHjx/ncPI4duyY2b9/v/n888/N3r17m/S7t27GIrdddXW1tm3bppkzZzq0Dx48WLm5ua4IAXDKrl27ZLPZ5OPjo379+unJJ59UdHS0iouLVV5ersGDB9v7+vj46KabblJubq4mTZrkxqiBhpqSs9u2bVNNTY1DH5vNpl69eik3N1dDhgxxR+iAg+zsbHXq1Ent2rXTTTfdpLlz56pTp06SRA6jRTl06JAkqX379pKYh+FZTs7feszB8AS1tbVavXq1jh49qvj4eOZfeJyTc7gec3DTWSwWhYWFqbi4WKWlpe4Ox6O1a9fOYYvY03FJcXn//v2qra1VSEiIQ3tISIjKy8tdEQLQZP369dNLL72kyy+/XN9++63S0tJ03XXXqbCw0J6vjeUyExdaoqbkbHl5uby9vXXJJZc06MMcjZZg6NChGjNmjCIjI1VcXKzHHntM/fv317Zt2+Tj40MOo8Uwxuh3v/udbrjhBvXq1UsS8zA8R2P5KzEHo+Xbvn274uPjVVlZqbZt22rt2rXq2bOnfSEb8y9aulPlsMQcfDa8vb112WWXsTXGObBarfYtRprCJcXlehaLxeG7MaZBG+BuQ4cOtX+OiYlRfHy8unXrpuXLl9s3zieX4WnOJmfJa7QUd9xxh/1zr1691LdvX0VGRmrDhg0aPXr0Ka8jh+FqSUlJKigo0Pvvv9/gHPMwWrpT5S9zMFq6K664Qvn5+Tp48KBef/11JSYmKicnx36e+Rct3alyuGfPnszBZ8nLy0u+vr7uDuOi4ZIX+nXs2FGtWrVq8Lcm+/bta/C3iEBL06ZNG8XExGjXrl32/yWAXIanaErOhoaGqrq6Wv/3f/93yj5ASxIWFqbIyEjt2rVLEjmMlmHKlCn6xz/+oU2bNik8PNzezjwMT3Cq/G0MczBaGm9vb1166aXq27ev5s2bp9jYWC1dupT5Fx7jVDncGOZgtEQuKS57e3urT58+ysrKcmjPysrSdddd54oQgLNWVVWlnTt3KiwsTF27dlVoaKhDLldXVysnJ4dcRovUlJzt06ePrFarQ5+ysjLt2LGDvEaLdODAAe3Zs0dhYWGSyGG4lzFGSUlJWrNmjTZu3KiuXbs6nGceRkt2pvxtDHMwWjpjjKqqqph/4bHqc7gxzMFokc7vexlPbcWKFcZqtZoXXnjBfP755yY5Odm0adPGlJSUuCoEoEmmT59usrOzzddff20+/PBDM3z4cBMQEGDP1fnz55ugoCCzZs0as337dnPnnXeasLAwc/jwYTdHjotVRUWFycvLM3l5eUaSWbRokcnLyzOlpaXGmKbl7H333WfCw8PNu+++az799FPTv39/Exsba06cOOGux8JF5HQ5XFFRYaZPn25yc3NNcXGx2bRpk4mPjzedO3cmh9Ei3H///SYoKMhkZ2ebsrIy+3Hs2DF7H+ZhtFRnyl/mYLR0s2bNMps3bzbFxcWmoKDAPPLII8bLy8u88847xhjmX7R8p8th5mB4CpcVl40x5plnnjGRkZHG29vbxMXFmZycHFcODzTJHXfcYcLCwozVajU2m82MHj3aFBYW2s/X1dWZlJQUExoaanx8fMzPf/5zs337djdGjIvdpk2bjKQGR2JiojGmaTl7/Phxk5SUZNq3b2/8/PzM8OHDze7du93wNLgYnS6Hjx07ZgYPHmyCg4ON1Wo1ERERJjExsUF+ksNwl8ZyV5L561//au/DPIyW6kz5yxyMlu6ee+6x1xiCg4PNgAED7IVlY5h/0fKdLoeZg+EpLMYY47p10gAAAAAAAACAC4FL9lwGAAAAAAAAAFxYKC4DAAAAAAAAAJxGcRkAAAAAAAAA4DSKywAAAAAAAAAAp1FcBgAAAAAAAAA4jeIyAAAAAAAAAMBpFJcBAAAAAAAAAE6juAwAAAAAAAAAcBrFZQAAAAAAAACA0yguAwAAAAAAAACcRnEZAAAAAAAAAOC0/wffmUC0as6YZgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split --> 281\n"
     ]
    }
   ],
   "source": [
    "assert config.analysis_mode in ['offline','online'], 'Invalid analysis mode'\n",
    "\n",
    "X = X_train\n",
    "if verbose > 0: print(\"len(X): \", len(X));\n",
    "if config.analysis_mode == 'online':\n",
    "    if verbose > 0: print(\"--> Split 1\")\n",
    "    splits = TimeSplitter(valid_size=0.2, show_plot=show_plots)(X)\n",
    "elif config.analysis_mode == 'offline':\n",
    "    if verbose > 0: print(\"--> Split 2\")\n",
    "    splits = get_splits(np.arange(len(X)), valid_size=config.valid_size, show_plot = show_plots)\n",
    "if verbose > 0: \n",
    "    print(\"Split -->\", len(splits[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42f0d804-2d94-4764-94d0-581fb713a9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 1, 2160)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((#281) [0,1,2,3,4,5,6,7,8,9...],\n",
       " (#70) [281,282,283,284,285,286,287,288,289,290...])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "if verbose > 0: \n",
    "    print(X.shape)\n",
    "    display(splits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99ab9c74-4458-4f0a-8f92-2da517a8d1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)\n",
    "len(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5e18e35-c24b-4775-a93a-cb01b19406e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 1, 2160)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ee893-812d-47a4-9e42-bd37ee637710",
   "metadata": {},
   "source": [
    "Ñapa para ver si es un problema de tamaños o qué (dejar 1 ventana solo como en el  ejemplo de uso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6261e0f-cb2b-410e-99ad-ca07f1ab30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train[0]\n",
    "#X_train = einops.rearrange(  torch.as_tensor(X_train, dtype = torch.float32), \"... -> 1 ...\")\n",
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ad7a2-b798-473e-9c76-bce8e5cc02fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42f36d9f-5c6b-4d30-8b6d-af6fcfb9f478",
   "metadata": {},
   "source": [
    "Hasta aquí la ñapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "493c68b0-c1c5-42e0-a8ab-d84283f66d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_target = einops.rearrange(\n",
    "    torch.as_tensor(X_train, dtype = torch.float32),\n",
    "    \"n_windows n_vars window_size -> n_windows window_size n_vars\"\n",
    ")\n",
    "# 1s if the value is observed, 0s otherwise. Shape: (batch, time, variate)\n",
    "past_observed_target = torch.ones_like(past_target, dtype=torch.bool)\n",
    "# 1s if the value is padding, 0s otherwise. Shape: (batch, time)\n",
    "past_is_pad = torch.zeros_like(past_target, dtype=torch.bool)[...,:,-1] # Kill last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd4f5d5f-81eb-4b65-be17-db271420bc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([351, 2160, 1])\n",
      "torch.Size([351, 2160, 1])\n",
      "torch.Size([351, 2160])\n"
     ]
    }
   ],
   "source": [
    "print(past_target.shape)\n",
    "print(past_observed_target.shape)\n",
    "print(past_is_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8943aae-db91-4d09-a090-6893cfea20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch_size = 32 -> ok\n",
    "patch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a41def3-2076-461a-ba0d-1e9b212696d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_mask = torch.ones_like(past_target, dtype = bool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8497cc0-d6da-439a-96f9-df5569e234ba",
   "metadata": {},
   "source": [
    "¿ Pero tiene sentido separar en Train y test en un zero - shot ? \n",
    "Cojámoslo entero\n",
    "Y cojamos todo como input en lugar de input y label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69483619-1138-4d27-9159-0563558815e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = MoiraiModule.from_pretrained(f\"Salesforce/moirai-1.1-R-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86caf4f1-760c-4b26-b407-4c6427778f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar model for conversions just to ensure correct sizes\n",
    "forecast_model =  MoiraiForecast(\n",
    "    module=module,\n",
    "    prediction_length=past_target.shape[2], #random, just for getting the model\n",
    "    context_length=past_target.shape[1],\n",
    "    patch_size=patch_size,\n",
    "    num_samples=100, #Random, is the number of forecasting, not interesting for us\n",
    "    target_dim=past_target.shape[2],\n",
    "    feat_dynamic_real_dim=0,\n",
    "    past_feat_dynamic_real_dim=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd10700d-35c2-4456-9bb2-047d1a24c648",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m forecast \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_observed_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_observed_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_is_pad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_is_pad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/model/moirai/forecast.py:349\u001b[0m, in \u001b[0;36mMoiraiForecast.forward\u001b[0;34m(self, past_target, past_observed_target, past_is_pad, feat_dynamic_real, observed_feat_dynamic_real, past_feat_dynamic_real, past_observed_feat_dynamic_real, num_samples, verbose)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     distr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_distr(\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mpatch_size,\n\u001b[1;32m    340\u001b[0m         past_target,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m         verbose \u001b[38;5;241m=\u001b[39m verbose\n\u001b[1;32m    348\u001b[0m     )\n\u001b[0;32m--> 349\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mdistr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_preds(\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mpatch_size, preds, past_target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    352\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/distributions/transformed_distribution.py:139\u001b[0m, in \u001b[0;36mTransformedDistribution.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03mGenerates a sample_shape shaped sample or sample_shape shaped batch of\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03msamples if the distribution parameters are batched. Samples first from\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03mbase distribution and applies `transform()` for every transform in the\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03mlist.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 139\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m    141\u001b[0m         x \u001b[38;5;241m=\u001b[39m transform(x)\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/distribution/mixture.py:130\u001b[0m, in \u001b[0;36mMixture.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape: torch\u001b[38;5;241m.\u001b[39mSize \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize()) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    129\u001b[0m         components_samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m--> 130\u001b[0m             [comp\u001b[38;5;241m.\u001b[39msample(sample_shape) \u001b[38;5;28;01mfor\u001b[39;00m comp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    131\u001b[0m         )\n\u001b[1;32m    132\u001b[0m         weights_sample \u001b[38;5;241m=\u001b[39m unsqueeze_trailing_dims(\n\u001b[1;32m    133\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39msample(sample_shape), components_samples\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    134\u001b[0m         )\n\u001b[1;32m    135\u001b[0m         samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    136\u001b[0m             components_samples,\n\u001b[1;32m    137\u001b[0m             dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    138\u001b[0m             index\u001b[38;5;241m=\u001b[39mweights_sample,\n\u001b[1;32m    139\u001b[0m         )\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/work/nbs_pipeline/uni2ts/src/uni2ts/distribution/mixture.py:130\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape: torch\u001b[38;5;241m.\u001b[39mSize \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize()) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    129\u001b[0m         components_samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m--> 130\u001b[0m             [\u001b[43mcomp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m comp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    131\u001b[0m         )\n\u001b[1;32m    132\u001b[0m         weights_sample \u001b[38;5;241m=\u001b[39m unsqueeze_trailing_dims(\n\u001b[1;32m    133\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\u001b[38;5;241m.\u001b[39msample(sample_shape), components_samples\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    134\u001b[0m         )\n\u001b[1;32m    135\u001b[0m         samples \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    136\u001b[0m             components_samples,\n\u001b[1;32m    137\u001b[0m             dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    138\u001b[0m             index\u001b[38;5;241m=\u001b[39mweights_sample,\n\u001b[1;32m    139\u001b[0m         )\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/distributions/distribution.py:166\u001b[0m, in \u001b[0;36mDistribution.sample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03mGenerates a sample_shape shaped sample or sample_shape shaped batch of\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03msamples if the distribution parameters are batched.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/distributions/studentT.py:87\u001b[0m, in \u001b[0;36mStudentT.rsample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     85\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended_shape(sample_shape)\n\u001b[1;32m     86\u001b[0m X \u001b[38;5;241m=\u001b[39m _standard_normal(shape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 87\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chi2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m Y \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(Z \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m*\u001b[39m Y\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/distributions/gamma.py:72\u001b[0m, in \u001b[0;36mGamma.rsample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrsample\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample_shape\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mSize()):\n\u001b[1;32m     71\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extended_shape(sample_shape)\n\u001b[0;32m---> 72\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43m_standard_gamma\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcentration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate\u001b[38;5;241m.\u001b[39mexpand(\n\u001b[1;32m     73\u001b[0m         shape\n\u001b[1;32m     74\u001b[0m     )\n\u001b[1;32m     75\u001b[0m     value\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclamp_(\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfinfo(value\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mtiny\n\u001b[1;32m     77\u001b[0m     )  \u001b[38;5;66;03m# do not record in autograd graph\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m/usr/local/share/miniconda3/envs/env/lib/python3.10/site-packages/torch/distributions/gamma.py:13\u001b[0m, in \u001b[0;36m_standard_gamma\u001b[0;34m(concentration)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_standard_gamma\u001b[39m(concentration):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_standard_gamma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcentration\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "forecast = forecast_model(\n",
    "    past_target=past_target,\n",
    "    past_observed_target=past_observed_target,\n",
    "    past_is_pad=past_is_pad,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2a929-422c-4780-843b-006364cac8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    target,\n",
    "    observed_mask,\n",
    "    sample_id,\n",
    "    time_id,\n",
    "    variate_id,\n",
    "    prediction_mask,\n",
    ") = forecast_model._convert(\n",
    "    patch_size,\n",
    "    past_target,\n",
    "    past_observed_target,\n",
    "    past_is_pad\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf34074-394d-4473-b980-4c624ca97e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.hook import *\n",
    "\n",
    "from tsai.models.layers import *\n",
    "\n",
    "def get_acts_and_grads(\n",
    "    model, \n",
    "    modules, \n",
    "    y=None, \n",
    "    detach=True, \n",
    "    cpu=False,\n",
    "    attr_name = \"data\",\n",
    "    verbose = 0,\n",
    "    **model_kwargs\n",
    "):\n",
    "    r\"\"\"Returns activations and gradients for given modules in a model and a single input or a batch. \n",
    "    Gradients require y value(s). If they are not provided, it will use the predictions. \"\"\"\n",
    "    if not isinstance(modules, list): modules = [modules]\n",
    "    if ('x' in model_kwargs):\n",
    "        x = x[None, None] if x.ndim == 1 else x[None] if x.ndim == 2 else x\n",
    "    if cpu: \n",
    "        model = model.cpu()\n",
    "        #x = x.cpu()\n",
    "        for key in model_kwargs:\n",
    "            try: #if not able to be moved, just not move it\n",
    "                model_kwargs[key] = model_kwargs[key].cpu()\n",
    "            except:\n",
    "                continue\n",
    "    with hook_outputs(modules, detach=detach, cpu=cpu) as h_act:\n",
    "        if verbose > 0:\n",
    "            print(\"get_act_and_grads | hook outputs | h_act\")\n",
    "        with hook_outputs(modules, grad=True, detach=detach, cpu=cpu) as h_grad:\n",
    "            if verbose > 0:\n",
    "                print(\"get_act_and_grads | hook outputs | h_grad\")\n",
    "            preds = model.eval()(**model_kwargs)\n",
    "            try:\n",
    "                preds.requires_grad_(True)\n",
    "                if verbose > 1:\n",
    "                    print(f\"Get_acts_and_grads | hooks | preds req grads ? {preds.requires_grad}\")\n",
    "                #print(f\"Get_acts_and_grads | hooks | preds ? {preds}\")\n",
    "                if y is None: \n",
    "                    preds.max(dim=-1).values.mean().backward()\n",
    "                    #print(f\"Get_acts_and_grads | hooks | preds grad ? {preds.grad}\")\n",
    "                else: \n",
    "                    y = y.detach().cpu().numpy()\n",
    "                    if preds.shape[0] == 1: \n",
    "                        preds[0, y].backward()\n",
    "                    else: \n",
    "                        if y.ndim == 1: y = y.reshape(-1, 1)\n",
    "                        torch_slice_by_dim(preds, y).mean().backward()\n",
    "            except Exception as e: \n",
    "                if verbose > 1:\n",
    "                    print(f\"Preds {type(preds)} does not have requires_grad\")\n",
    "    if len(modules) == 1: \n",
    "        if verbose > 1:\n",
    "            print(f\"get_act_and_grads | h_act stored ~ \", len(h_act.stored))\n",
    "            print(f\"get_act_and_grads | h_act stored: \", h_act.stored)\n",
    "        try:\n",
    "            res = getattr(h_act.stored[0], attr_name), getattr(h_act.stored[0][0], attr_name)\n",
    "        except:\n",
    "            res = getattr(h_act.stored[0][0], attr_name), getattr(h_act.stored[0][0][0], attr_name)\n",
    "        return res\n",
    "    else: \n",
    "        return [h.data for h in h_act.stored], [getattr(h_act.stored[0], attr_name) for h in h_grad.stored]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ccea3-9ed7-4580-a571-29f446ccc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs={\n",
    "    'target': target, \n",
    "    'observed_mask': observed_mask,\n",
    "    'sample_id': sample_id,\n",
    "    'time_id': time_id,\n",
    "    'variate_id': variate_id,\n",
    "    'prediction_mask': prediction_mask,\n",
    "    'patch_size': torch.ones_like(sample_id, dtype = torch.float32)*patch_size\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944e1d0-b24a-41a3-95ee-6b5ba7d120ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_model_kwargs={\n",
    "    'past_target': past_target, \n",
    "    'past_observed_target': past_observed_target,\n",
    "    'past_is_pad': past_is_pad\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9111a-07f4-45d6-80ef-79694b984e64",
   "metadata": {},
   "source": [
    "Pequeño trial porque se queda bloqueado y no entiendo por qué\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7a9d2-372a-41b4-acbe-d7be84c9f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor = forecast_model.create_predictor(batch_size = target.shape[0])\n",
    "#forecasts = predictor.predict(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b806d4-6cae-481d-9d18-5427ce3e12f7",
   "metadata": {},
   "source": [
    "Fin del trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82e37a-1af2-46f9-b6a5-d8e06650c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dvats.utils import Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed7830-b316-4954-a2f2-5453cd3b40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = Time()\n",
    "timer.start()\n",
    "module.eval()\n",
    "embs = [\n",
    "        get_acts_and_grads(\n",
    "            model   = module,\n",
    "            modules = module.encoder.norm,         \n",
    "            cpu     = False,\n",
    "            attr_name = \"data\",\n",
    "            verbose = 0,\n",
    "            **model_kwargs\n",
    "        )[0] \n",
    "        for xb in target\n",
    "    ]\n",
    "timer.end()\n",
    "timer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b080e-816d-4a58-abcf-051164dacc85",
   "metadata": {},
   "source": [
    "Me da que MOIRAI va a perder la batalla por tiempo de obtención de embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4fdfda-c287-4f12-857f-147ba0e142e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ab895-0f18-41cd-bf3a-c0f9b65a3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6295c-fee5-40ab-a513-00cb328685cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = embs.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c28b26-5cac-4e60-9527-90acbaf2629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4438481-e04d-4271-b2f8-42488a4c523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings_from_all_layers(model, enc_input, **model_kwargs):\n",
    "    # Iteramos sobre todas las capas del modelo\n",
    "    for name, module in model.named_modules():\n",
    "        print(f\"Processing layer: {name}\")\n",
    "        mssg = \"\"\n",
    "        try:\n",
    "            embs = [\n",
    "                get_acts_and_grads(\n",
    "                    model   = model,\n",
    "                    modules = [module],  # Registramos el hook en la capa actual\n",
    "                    cpu     = True,\n",
    "                    attr_name = \"data\",  # Ajusta esto si necesitas otro atributo\n",
    "                    **model_kwargs\n",
    "                )[0] \n",
    "                for xb in enc_input\n",
    "            ]\n",
    "            mssg = f\"Layer: {name}, Embedding shape: {embs[0].shape}\" \n",
    "        except Exception as e:\n",
    "            mssg = f\"Layer: {name},  {e}\"\n",
    "        \n",
    "        # Si se capturan las activaciones, imprimimos el nombre de la capa y su shape\n",
    "        print(mssg)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e2765-3abc-47ba-81d4-bd21faeee428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Por qué salen AffineTransformed objects en lugar de gradientes?\n",
    "#extract_embeddings_from_all_layers(\n",
    "#    model=module,\n",
    "#    enc_input = target,\n",
    "#    **model_kwargs\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f33b69-f983-4f15-9cd7-700263926002",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_model.named_modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
