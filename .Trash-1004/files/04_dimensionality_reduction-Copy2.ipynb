{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "> This notebook gets the embeddings (or latent space) from a multivariate time series \n",
    "given by a encoder (e.g., autoencoder) and uses them as input for a \n",
    "dimensionality reduction algorithm, to generate projectsion of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.imports import *\n",
    "from tsai.data.preparation import SlidingWindow\n",
    "from fastcore.all import *\n",
    "from dvats.all import *\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "from yaml import load, FullLoader\n",
    "import hdbscan\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put here everything that could be needed if this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: /home/macu/work/nbs_pipeline\n",
      "yml: ./config/04-dimensionality_reduction.yaml\n",
      "Getting content./config/04-dimensionality_reduction.yaml\n",
      "... About to replace includes with content\n",
      "Load content./config/04-dimensionality_reduction.yaml\n",
      "enc_artifact: mi-santamaria/deepvats/mvp-SWV:latest\n"
     ]
    }
   ],
   "source": [
    "import nbs_pipeline.utils.config as cfg\n",
    "config, job_type = cfg.get_artifact_config_dimensionality_reduction(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_wandb: True\n",
      "wandb_group: None\n",
      "wandb_entity: mi-santamaria\n",
      "wandb_project: deepvats\n",
      "valid_artifact: None\n",
      "train_artifact: mi-santamaria/deepvats/mvp-SWV:latest\n",
      "n_neighbors: 15\n",
      "min_dist: 0.1\n",
      "random_state: 1234\n"
     ]
    }
   ],
   "source": [
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model needs to restore the encoder model fitted in the notebook `02x`, as well as the data and configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.path.expanduser(\"~/work/nbs_pipeline/\")\n",
    "name=\"04_dimensionality_reduction\"\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = path+name+\".ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runname: 04_dimensionality_reduction | train: mi-santamaria/deepvats/mvp-SWV:latest | valid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: mi-santamaria. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macu/work/wandb/run-20231127_211218-qn3wzt60</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mi-santamaria/deepvats/runs/qn3wzt60' target=\"_blank\">04_dimensionality_reduction | train: mi-santamaria/deepvats/mvp-SWV:latest | valid: None</a></strong> to <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mi-santamaria/deepvats' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mi-santamaria/deepvats/runs/qn3wzt60' target=\"_blank\">https://wandb.ai/mi-santamaria/deepvats/runs/qn3wzt60</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'stream.Stream' object attribute 'write' is read-only\n"
     ]
    }
   ],
   "source": [
    "if config.valid_artifact is not None:\n",
    "    runname=\"04_dimensionality_reduction | train: \"+ config.train_artifact + \" | valid: \"+config.valid_artifact\n",
    "else:\n",
    "    runname=\"04_dimensionality_reduction | train: \"+ config.train_artifact + \" | valid: None\"\n",
    "    \n",
    "    \n",
    "print(\"Runname: \"+ runname)\n",
    "run_dr = wandb.init(\n",
    "    entity              = config.wandb_entity,\n",
    "    project             = config.wandb_project if config.use_wandb else 'work-nbs', \n",
    "    group               = config.wandb_group,\n",
    "    allow_val_change    = True, \n",
    "    job_type            = job_type, \n",
    "    mode                = 'online' if config.use_wandb else 'disabled',\n",
    "    anonymous           = 'never' if config.use_wandb else 'must',\n",
    "    config              = config,\n",
    "    resume              = False,\n",
    "    name                = runname\n",
    ")\n",
    "config_dr = wandb.config # Object for storing hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Botch to use artifacts offline\n",
    "artifacts_gettr = run_dr.use_artifact if config_dr.use_wandb else api.artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the encoder model and its associated configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpu': False,\n",
       " 'ref': {'hash': '-4811609136384432385', 'type': \"<class 'numpy.ndarray'>\"},\n",
       " 'input_ar': 'mi-santamaria/deepvats/solar_4_seconds:v0',\n",
       " 'use_wandb': True,\n",
       " 'wandb_group': 'embeddings',\n",
       " 'enc_artifact': 'mi-santamaria/deepvats/mvp-SWV:latest',\n",
       " 'wandb_entity': 'mi-santamaria',\n",
       " 'wandb_project': 'deepvats'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_artifact = artifacts_gettr(\n",
    "    'mi-santamaria/deepvats/embeddings-SWV:latest', \n",
    "    type='object')\n",
    "enc_artifact.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Downloading large artifact embeddings-SWV:latest, 240.79MB. 1 files... \n",
      "wandb:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.9753598e-02, 7.8738242e-01, 8.7640753e+00, ..., 2.9195672e-01,\n",
       "        0.0000000e+00, 4.2660935e-03],\n",
       "       [8.9753598e-02, 7.8738242e-01, 8.7640753e+00, ..., 2.9195672e-01,\n",
       "        0.0000000e+00, 4.2660935e-03],\n",
       "       [8.9753598e-02, 7.8738242e-01, 8.7640753e+00, ..., 2.9195672e-01,\n",
       "        0.0000000e+00, 4.2660935e-03],\n",
       "       ...,\n",
       "       [8.9753598e-02, 7.8738242e-01, 8.7640753e+00, ..., 2.9195672e-01,\n",
       "        0.0000000e+00, 4.2660935e-03],\n",
       "       [8.9753598e-02, 7.8738242e-01, 8.7640753e+00, ..., 2.9195672e-01,\n",
       "        0.0000000e+00, 4.2660935e-03],\n",
       "       [8.9753598e-02, 7.8738242e-01, 8.7640753e+00, ..., 2.9195672e-01,\n",
       "        0.0000000e+00, 4.2660935e-03]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: This only works when you run it two timeS! WTF?\n",
    "try:\n",
    "    embs = enc_artifact.to_obj()\n",
    "except:\n",
    "    embs = enc_artifact.to_obj()\n",
    "embs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the dataset artifact used for training the encoder. Even if we do not compute the dimensionality reduction over this dataset, we need to know the metadata of the encoder training set, to check that \n",
    "it matches with the dataset that we want to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP\n",
      "You selected UMAP\n"
     ]
    }
   ],
   "source": [
    "dr_methods = ['UMAP', 'TSNE', 'PCA']\n",
    "dr_method = dr_methods[0]\n",
    "print(dr_method)\n",
    "match dr_method:\n",
    "    case 'UMAP':\n",
    "        print(\"You selected UMAP\")\n",
    "        res=get_UMAP_prjs(input_data = embs, cpu=F, random_state=1234),\n",
    "    case 'TSNE':\n",
    "        print(\"You selected TSNE\")\n",
    "        res=get_TSNE_prjs(X = embs, cpu=F, random_state=1234)\n",
    "    case 'PCA':\n",
    "        print(\"You selected PCA\")\n",
    "        res=get_PCA_prjs(X = embs, cpu=F, random_state=1234)\n",
    "    case _:\n",
    "        print(\"No way... Say UMAP\")\n",
    "        res=get_UMAP_prjs(input_data = embs, cpu=F, random_state=1234),\n",
    "    \n",
    "res = res.to_df() # TODO: This should be a matrix for improved efficiency\n",
    "#colnames(res) = c(\"xcoord\", \"ycoord\")\n",
    "#on.exit(print(\" prj_object -->\"))\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to check whether the artifact that is going to be used fort the dimensionality reduction matches the artifact used to train the encoder. Matching means having the same number of variables, the same window size and stride, and the same frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dr_artifact.to_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input, _ = SlidingWindow(window_len=enc_logger.config['w'], \n",
    "                             stride=enc_logger.config['stride'], \n",
    "                             get_y=[])(df)\n",
    "enc_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the embeddings (activations) from the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = get_enc_embs(enc_input, enc_learner, cpu=False)\n",
    "test_eq(embs.shape[0], enc_input.shape[0])\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average embeddings in the time dimension, if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction using UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use DR techniques to provide an alternative view for users to visually analyze and explore the time-series data. The algorithm UMAP shows its high competitiveness compared to t-SNE. t-SNE suffers from some limitations such as loss of large-scale information (the inter-cluster relationships). UMAP has a faster runtime and provides better scaling which helps to gain a meaningful organization of clusters, outliers and the preservation of continuums compared to t-SNE\n",
    "\n",
    "For this part of the implementation, the package [umap-learn](https://github.com/lmcinnes/umap) is used. The input of the algoritm is the $n \\times \\delta$ that contains, for each slice of the time series, the corresponding $\\delta$ latent embeddings given by the encoder.\n",
    "\n",
    "The hyperparameters of UMAP are given values by default here. If the value has been already set previously, that means this notebook is being called from a wandb sweep, and we must use the value that the sweep is bringing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_params = {\n",
    "    'n_neighbors' : config_dr.n_neighbors,\n",
    "    'min_dist' : config_dr.min_dist,\n",
    "    'random_state': config_dr.random_state\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prjs = get_UMAP_prjs(embs, cpu=False, **umap_params)\n",
    "prjs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the projections as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.use_wandb: \n",
    "    run.log_artifact(ReferenceArtifact(prjs, 'projections', type='projections', \n",
    "metadata=dict(run_dr.config)), aliases=f'run-{run.project}-{run.id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Precomputed Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to integrate precomputed clusters into the embedding space, it's necessary to log artifacts that include the labels of the newly created clusters. \n",
    "\n",
    "The cluster creation process is presented below. This creation procedure can be modified according to specific needs. However, the structure of the new artifact must be preserved (it must be a numpy.ndarray and the number of elements must be equal to the number of points in the embedding space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'HDBSCAN supported metrics: {list(hdbscan.dist_metrics.METRIC_MAPPING.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define HDBSCAN parameters\n",
    "hdbscan_kwargs = {\n",
    "    'min_cluster_size' : 100,\n",
    "    'min_samples' : 15,\n",
    "    'cluster_selection_epsilon' : 0.08,\n",
    "}\n",
    "metric_kwargs = {\n",
    "    'metric' : 'jaccard'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clusters using HDBSCAN\n",
    "clusters = hdbscan.HDBSCAN(**hdbscan_kwargs, **metric_kwargs).fit(prjs)\n",
    "clusters_labels = clusters.labels_\n",
    "clusters_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing artifact structure \n",
    "test_eq_type(type(clusters_labels), np.ndarray)\n",
    "test_eq(clusters_labels.size, prjs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and log 'clusters_labels' artifact\n",
    "clusters_ar = ReferenceArtifact(obj=clusters_labels, name='clusters_labels')\n",
    "clusters_ar.metadata, clusters_ar.manifest.entries.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dr.log_artifact(clusters_ar, aliases=['hdbscan_jaccard'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the connected scatter plot is a simple visualization technique, it has very specific functions in our approach. Every sliding window is represented as a dot in the plot after the projection process (Fig. 4C, D of the paper). Before labeling, all points have the same color and transparency, and when they are concentrated in one area, the densities are accumulated. Lines are used to connect consecutive points preserving the temporal ordering of the data and allowing the user to see temporal connections (Fig. 4B of the paper). Thus, the point is linked to the previous point (inner) and to the posterior point (outer) as an indication of the flow of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plot_projections(prjs, umap_params, fig_size = (25,25)):\n",
    "    \"Plot 2D projections thorugh a connected scatter plot\"\n",
    "    df_prjs = pd.DataFrame(prjs, columns = ['x1', 'x2'])\n",
    "    fig = plt.figure(figsize=(fig_size[0],fig_size[1]))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(df_prjs['x1'], df_prjs['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)\n",
    "    ax.plot(df_prjs['x1'], df_prjs['x2'], alpha=0.5, picker=1)\n",
    "    plt.title('DR params -  n_neighbors:{:d} min_dist:{:f}'.format(\n",
    "        umap_params['n_neighbors'],umap_params['min_dist']))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prjs_plt = plot_projections(prjs, umap_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prjs_plt = plot_projections(prjs, umap_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log this plot as part of the current wandb run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "# Get the figure of the embedding plot, and save it on thea wandb run.\n",
    "run_dr.log({\"img\": [wandb.Image(prjs_plt.get_figure(), caption=\"dr_projections_plot\")]})\n",
    "\n",
    "#run_dr.log({'embeddings_plot': embeddings_plot})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "run_dr.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability with SHAP (future work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# fig = plt.figure(figsize=(10,10))\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "# ax.scatter(df_embeddings['x1'], df_embeddings['x2'], marker='o', facecolors='none', edgecolors='b', alpha=0.1)\n",
    "# ax.plot(df_embeddings['x1'], df_embeddings['x2'], alpha=0.5, picker=1)\n",
    "# ax.set_title('Select the point you want to visualize as a time window in the original space')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the plot interactive to allow selection of subsets of the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_indices = None\n",
    "# selected_points = None\n",
    "\n",
    "# def onpick(event):\n",
    "#     global selected_points\n",
    "#     thisline = event.artist\n",
    "#     xdata = thisline.get_xdata()\n",
    "#     ydata = thisline.get_ydata()\n",
    "#     global selected_indices\n",
    "#     selected_indices = event.ind\n",
    "#     selected_points = tuple(zip(xdata[selected_indices], ydata[selected_indices]))\n",
    "#     print('onpick points (first):', selected_points[0])\n",
    "\n",
    "# fig.canvas.mpl_connect('pick_event', onpick)\n",
    "\n",
    "# plt.show()\n",
    "# fig.tight_layout()\n",
    "# fig.savefig(f'../img/w={w}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for the dimensionality reduction\n",
    "\n",
    "There are a number of parameters that can be set for the UMAP algorithm. The major \n",
    "ones are `n_neighbors` and `min_dist`. Thus, we will carry out a hyperparameter \n",
    "sweep in Weights and Biases for these two parameters. Note that there is no objective\n",
    "way of deciding that some embeddings are better than others. Thus, we must rely on our\n",
    "intuition by visualizing the 2D plots of each of the runs in the sweep.\n",
    "\n",
    "The first thing we need is gather all the pipeline of the previous section into a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Linking back points of the 2D projection to the original time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `selected_points` and `ind` contain an array of the points and indices selected in the previous 2D projection. We will take the first of them (there can be many selected points with just one click), and use its index to get the corresponding time window of the original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_window = input_data[df_embeddings.sample(n=1).index][0] if selected_indices is None else input_data[selected_indices[0]]\n",
    "# selected_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing all the variables in the time window (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# g = sns.FacetGrid(df_output_tidy, col=\"variable\", col_wrap=3, aspect=2)\n",
    "# g = g.map(plt.plot, \"timestamp\", \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution: Visualize only the most relevant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In high dimensional time series, not only is interesting to see the window associated to a point in the 2D space, but also it is extremely important to spot which variables are mainly causing that the window is positioned in that point of the 2D space.\n",
    "\n",
    "Since UMAP does not provide capabilities to understand feature importance, there are [different ways](https://stats.stackexchange.com/questions/438025/understand-important-features-in-umap) to tackle this problem:\n",
    "\n",
    "1. Use another dimensionality reduction technique that provides importance, such as [sparse PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html)\n",
    "\n",
    "2. Create a surrogate model on top of the inputs/output of UMAP and explain it using XAI techniques. We will try here this option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to have a surrogate model that takes the multivariate time series as input and produces the associated points in the 2D space as ouput. Since we already have a Deep Convolutional Autoencoder (DCAE) that takes a multivariate time series as input, and it contains the latent features that represent that input, we can use it for the surrogate. We will use the intermediate model that goes from the input to the layer containing the latent space, and then add a `Dense` layer with 2 units and linear activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# def train_surrogate_model(dcae, embeddings, lat_ln='latent_features'):\n",
    "#     \"Train a surrogate model that learns the `embeddings` from the latent features contained in the layer \\\n",
    "#     `lat_ln` of a previously trained Deep Convolutional AutoEncoder `dcae`\"\n",
    "#     x = dcae.get_layer(lat_ln).output\n",
    "#     x = Dense(units=embeddings.shape[1], activation='linear')(x)\n",
    "#     surrogate_model = Model(dcae.input, x)\n",
    "#     l_nms = [layer.name for layer in surrogate_model.layers]\n",
    "#     layer_idx = l_nms.index(lat_ln)\n",
    "#     # The layers that are already trained from the autoencoder must be `frozen`\n",
    "#     for layer in surrogate_model.layers[:layer_idx]:\n",
    "#         layer.trainable = False\n",
    "#     return surrogate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = train_surrogate_model(m, embeddings, lat_ln='latent_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.equals(sm.input.shape, m.input.shape)\n",
    "# test.equals(sm.output.shape[1], embeddings.shape[1])\n",
    "# l_nms = [layer.name for layer in sm.layers]\n",
    "# layer_idx = l_nms.index('latent_features')\n",
    "# test.all_equal([layer.trainable for layer in sm.layers], \\\n",
    "#                np.repeat([False, True], [layer_idx + 1, len(sm.layers) -1 -layer_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = 'mean_squared_error'\n",
    "# opt = 'adam'\n",
    "# bs = 100\n",
    "# epochs = 10\n",
    "# val = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.fit(x=input_data, y=embeddings, batch_size=bs, validation_split=val, epochs=epochs, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import innvestigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer = innvestigate.create_analyzer(\"gradient\", intermediate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asd= innvestigate.create_analyzer(\"gradient\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data[np.random.choice(input_data.shape[0], 100, replace=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background = input_data[np.random.choice(input_data.shape[0], 100, replace=False)]\n",
    "# e = shap.DeepExplainer(intermediate_model, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values = e.shap_values(input_data[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values[0][0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d45d555be0220b07bf61be557bfa0ebbf7a95015976aec9a23277863e1bd4593"
  },
  "kernelspec": {
   "display_name": "Python 3.10 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
